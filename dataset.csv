Text,Category
"  Neutron beam monitors with high efficiency, low gamma sensitivity, high time
and space resolution are required in neutron beam experiments to continuously
diagnose the delivered beam. In this work, commercially available neutron beam
monitors have been characterized using the R2D2 beamline at IFE (Norway) and
using a Be-based neutron source. For the gamma sensitivity measurements
different gamma sources have been used. The evaluation of the monitors
includes, the study of their efficiency, attenuation, scattering and
sensitivity to gamma. In this work we report the results of this
characterization.
",Physics
"  We present a method to construct number-conserving Hamiltonians whose ground
states exactly reproduce an arbitrarily chosen BCS-type mean-field state. Such
parent Hamiltonians can be constructed not only for the usual $s$-wave BCS
state, but also for more exotic states of this form, including the ground
states of Kitaev wires and 2D topological superconductors. This method leads to
infinite families of locally-interacting fermion models with exact topological
superconducting ground states. After explaining the general technique, we apply
this method to construct two specific classes of models. The first one is a
one-dimensional double wire lattice model with Majorana-like degenerate ground
states. The second one is a two-dimensional $p_x+ip_y$ superconducting model,
where we also obtain analytic expressions for topologically degenerate ground
states in the presence of vortices. Our models may provide a deeper conceptual
understanding of how Majorana zero modes could emerge in condensed matter
systems, as well as inspire novel routes to realize them in experiment.
",Physics
"  Motivated by recent experiments, we use the $+U$ extension of the generalized
gradient approximation to density functional theory to study superlattices
composed of alternating layers of LaNiO$_3$ and LaMnO$_3$. For comparison we
also study a rocksalt ((111) double perovskite) structure and bulk LaNiO$_3$
and LaMnO$_3$. A Wannier function analysis indicates that band parameters are
transferable from bulk to superlattice situations with the exception of the
transition metal d-level energy, which has a contribution from the change in
d-shell occupancy. The charge transfer from Mn to Ni is found to be moderate in
the superlattice, indicating metallic behavior, in contrast to the insulating
behavior found in recent experiments, while the rocksalt structure is found to
be insulating with a large Mn-Ni charge transfer. We suggest a high density of
cation antisite defects may account for the insulating behavior experimentally
observed in short-period superlattices.
",Physics
"  Magnetic field-induced giant modification of the probabilities of five
transitions of $5S_{1/2}, F_g=2 \rightarrow 5P_{3/2}, F_e=4$ of $^{85}$Rb and
three transitions of $5S_{1/2}, F_g=1 \rightarrow 5P_{3/2}, F_e=3$ of $^{87}$Rb
forbidden by selection rules for zero magnetic field has been observed
experimentally and described theoretically for the first time. For the case of
excitation with circularly-polarized ($\sigma^+$) laser radiation, the
probability of $F_g=2, ~m_F=-2 \rightarrow F_e=4, ~m_F=-1$ transition becomes
the largest among the seventeen transitions of $^{85}$Rb $F_g=2 \rightarrow
F_e=1,2,3,4$ group, and the probability of $F_g=1,~m_F=-1 \rightarrow
F_e=3,~m_F=0$ transition becomes the largest among the nine transitions of
$^{87}$Rb $F_g=1 \rightarrow F_e=0,1,2,3$ group, in a wide range of magnetic
field 200 -- 1000 G. Complete frequency separation of individual Zeeman
components was obtained by implementation of derivative selective reflection
technique with a 300 nm-thick nanocell filled with Rb, allowing formation of
narrow optical resonances. Possible applications are addressed. The theoretical
model is perfectly consistent with the experimental results.
",Physics
"  The OPERA experiment was designed to search for $\nu_{\mu} \rightarrow
\nu_{\tau}$ oscillations in appearance mode through the direct observation of
tau neutrinos in the CNGS neutrino beam. In this paper, we report a study of
the multiplicity of charged particles produced in charged-current neutrino
interactions in lead. We present charged hadron average multiplicities, their
dispersion and investigate the KNO scaling in different kinematical regions.
The results are presented in detail in the form of tables that can be used in
the validation of Monte Carlo generators of neutrino-lead interactions.
",Physics
"  While the enhancement of the spin-space symmetry from the usual
$\mathrm{SU}(2)$ to $\mathrm{SU}(N)$ is promising for finding nontrivial
quantum spin liquids, its realization in magnetic materials remains
challenging. Here we propose a new mechanism by which the $\mathrm{SU}(4)$
symmetry emerges in the strong spin-orbit coupling limit. In $d^1$ transition
metal compounds with edge-sharing anion octahedra, the spin-orbit coupling
gives rise to strongly bond-dependent and apparently $\mathrm{SU}(4)$-breaking
hopping between the $J_\textrm{eff}=3/2$ quartets. However, in the honeycomb
structure, a gauge transformation maps the system to an
$\mathrm{SU}(4)$-symmetric Hubbard model. In the strong repulsion limit at
quarter filling, as realized in $\alpha$-ZrCl$_3,$ the low-energy effective
model is the $\mathrm{SU}(4)$ Heisenberg model on the honeycomb lattice, which
cannot have a trivial gapped ground state and is expected to host a gapless
spin-orbital liquid. By generalizing this model to other three-dimensional
lattices, we also propose crystalline spin-orbital liquids protected by this
emergent $\mathrm{SU}(4)$ symmetry and space group symmetries.
",Physics
"  Using Lindblad dynamics we study quantum spin systems with dissipative
boundary dynamics that generate a stationary nonequilibrium state with a
non-vanishing spin current that is locally conserved except at the boundaries.
We demonstrate that with suitably chosen boundary target states one can solve
the many-body Lindblad equation exactly in any dimension. As solution we obtain
pure states at any finite value of the dissipation strength and any system
size. They are characterized by a helical stationary magnetization profile and
a superdiffusive ballistic current of order one, independent of system size
even when the quantum spin system is not integrable. These results are derived
in explicit form for the one-dimensional spin-1/2 Heisenberg chain and its
higher-spin generalizations (which include for spin-1 the integrable
Zamolodchikov-Fateev model and the bi-quadratic Heisenberg chain). The
extension of the results to higher dimensions is straightforward.
",Physics
"  This article deals with the first detection of gravitational waves by the
advanced Laser Interferometer Gravitational Wave Observatory (LIGO) detectors
on 14 September 2015, where the signal was generated by two stellar mass black
holes with masses 36 $ M_{\odot}$ and 29 $ M_{\odot}$ that merged to form a 62
$ M_{\odot}$ black hole, releasing 3 $M_{\odot}$ energy in gravitational waves,
almost 1.3 billion years ago. We begin by providing a brief overview of
gravitational waves, their sources and the gravitational wave detectors. We
then describe in detail the first detection of gravitational waves from a
binary black hole merger. We then comment on the electromagnetic follow up of
the detection event with various telescopes. Finally, we conclude with the
discussion on the tests of gravity and fundamental physics with the first
gravitational wave detection event.
",Physics
"  We present an investigation into the intrinsic magnetic properties of the
compounds YCo5 and GdCo5, members of the RETM5 class of permanent magnets (RE =
rare earth, TM = transition metal). Focusing on Y and Gd provides direct
insight into both the TM magnetization and RE-TM interactions without the
complication of strong crystal field effects. We synthesize single crystals of
YCo5 and GdCo5 using the optical floating zone technique and measure the
magnetization from liquid helium temperatures up to 800 K. These measurements
are interpreted through calculations based on a Green's function formulation of
density-functional theory, treating the thermal disorder of the local magnetic
moments within the coherent potential approximation. The rise in the
magnetization of GdCo5 with temperature is shown to arise from a faster
disordering of the Gd magnetic moments compared to the antiferromagnetically
aligned Co sublattice. We use the calculations to analyze the different Curie
temperatures of the compounds and also compare the molecular (Weiss) fields at
the RE site with previously published neutron scattering experiments. To gain
further insight into the RE-TM interactions, we perform substitutional doping
on the TM site, studying the compounds RECo4.5Ni0.5, RECo4Ni, and RECo4.5Fe0.5.
Both our calculations and experiments on powdered samples find an
increased/decreased magnetization with Fe/Ni doping, respectively. The
calculations further reveal a pronounced dependence on the location of the
dopant atoms of both the Curie temperatures and the Weiss field at the RE site.
",Physics
"  The common assumption that Theta-1-Ori C is the dominant ionizing source for
the Orion Nebula is critically examined. This assumption underlies much of the
existing analysis of the nebula. In this paper we establish through comparison
of the relative strengths of emission lines with expectations from Cloudy
models and through the direction of the bright edges of proplyds that
Theta-2-Ori-A, which lies beyond the Bright Bar, also plays an important role.
Theta-1-Ori-C does dominate ionization in the inner part of the Orion Nebula,
but outside of the Bright Bar as far as the southeast boundary of the Extended
Orion Nebula, Theta-2-Ori-A is the dominant source. In addition to identifying
the ionizing star in sample regions, we were able to locate those portions of
the nebula in 3-D. This analysis illustrates the power of MUSE spectral imaging
observations in identifying sources of ionization in extended regions.
",Physics
"  We develop an ac-biased shift register introduced in our previous work (V.K.
Semenov et al., IEEE Trans. Appl. Supercond., vol. 25, no. 3, 1301507, June
2015) into a benchmark circuit for evaluation of superconductor electronics
fabrication technology. The developed testing technique allows for extracting
margins of all individual cells in the shift register, which in turn makes it
possible to estimate statistical distribution of Josephson junctions in the
circuit. We applied this approach to successfully test registers having 8, 16,
36, and 202 thousand cells and, respectively, about 33000, 65000, 144000, and
809000 Josephson junctions. The circuits were fabricated at MIT Lincoln
Laboratory, using a fully planarized process, 0.4 {\mu}m inductor linewidth,
and 1.33x10^6 cm^-2 junction density. They are presently the largest
operational superconducting SFQ circuits ever made. The developed technique
distinguishes between hard defects (fabrication-related) and soft defects
(measurement-related) and locates them in the circuit. The soft defects are
specific to superconducting circuits and caused by magnetic flux trapping
either inside the active cells or in the dedicated flux-trapping moats near the
cells. The number and distribution of soft defects depend on the ambient
magnetic field and vary with thermal cycling even if done in the same magnetic
environment.
",Physics
"  It is shown that the total set of equations, which determines the dynamics of
the domain bounds (DB) in a weak ferromagnet, has the same type of specific
solution as the well-known Walker's solution for ferromagnets. We calculated
the functional dependence of the velocity of the DB on the magnetic field,
which is described by the obtained solution. This function has a maximum at a
finite field and a section of the negative differential mobility of the DB.
According to the calculation, the maximum velocity $ c \approx 2 \times 10^6$
cm/sec in YFeO$_3$ is reached at $H_m \approx 4 \times 10^3$ Oe.
",Physics
"  Single-photon detectors in space must retain useful performance
characteristics despite being bombarded with sub-atomic particles. Mitigating
the effects of this space radiation is vital to enabling new space applications
which require high-fidelity single-photon detection. To this end, we conducted
proton radiation tests of various models of avalanche photodiodes (APDs) and
one model of photomultiplier tube potentially suitable for satellite-based
quantum communications. The samples were irradiated with 106 MeV protons at
doses approximately equivalent to lifetimes of 0.6 , 6, 12 and 24 months in a
low-Earth polar orbit. Although most detection properties were preserved,
including efficiency, timing jitter and afterpulsing probability, all APD
samples demonstrated significant increases in dark count rate (DCR) due to
radiation-induced damage, many orders of magnitude higher than the 200 counts
per second (cps) required for ground-to-satellite quantum communications. We
then successfully demonstrated the mitigation of this DCR degradation through
the use of deep cooling, to as low as -86 degrees C. This achieved DCR below
the required 200 cps over the 24 months orbit duration. DCR was further reduced
by thermal annealing at temperatures of +50 to +100 degrees C.
",Physics
"  Intersubband (ISB) polarons result from the interaction of an ISB transition
and the longitudinal optical (LO) phonons in a semiconductor quantum well (QW).
Their observation requires a very dense two dimensional electron gas (2DEG) in
the QW and a polar or highly ionic semiconductor. Here we show that in
ZnO/MgZnO QWs the strength of such a coupling can be as high as 1.5 times the
LO-phonon frequency due to the very dense 2DEG achieved and the large
difference between the static and high-frequency dielectric constants in ZnO.
The ISB polaron is observed optically in multiple QW structures with 2DEG
densities ranging from $5\times 10^{12}$ to $5\times 10^{13}$ cm$^{-2}$, where
an unprecedented regime is reached in which the frequency of the upper ISB
polaron branch is three times larger than that of the bare ISB transition. This
study opens new prospects to the exploitation of oxides in phenomena happening
in the ultrastrong coupling regime.
",Physics
"  Though theoretically expected, the charge exchange emission from galaxy
clusters has not yet been confidently detected. Accumulating hints were
reported recently, including a rather marginal detection with the Hitomi data
of the Perseus cluster. As suggested in Gu et al. (2015), a detection of charge
exchange line emission from galaxy clusters would not only impact the
interpretation of the newly-discovered 3.5 keV line, but also open up a new
research topic on the interaction between hot and cold matter in clusters. We
aim to perform the most systematic search for the O VIII charge exchange line
in cluster spectra using the RGS on board XMM. We introduce a sample of 21
clusters observed with the RGS. The dominating thermal plasma emission is
modeled and subtracted with a two-temperature CIE component, and the residuals
are stacked for the line search. The systematic uncertainties in the fits are
quantified by refitting the spectra with a varying continuum and line
broadening. By the residual stacking, we do find a hint of a line-like feature
at 14.82 A, the characteristic wavelength expected for oxygen charge exchange.
This feature has a marginal significance of 2.8 sigma, and the average
equivalent width is 2.5E-4 keV. We further demonstrate that the putative
feature can be hardly affected by the systematic errors from continuum
modelling and instrumental effects, or the atomic uncertainties of the
neighbouring thermal lines. Assuming a realistic temperature and abundance
pattern, the physical model implied by the possible oxygen line agrees well
with the theoretical model proposed previously to explain the reported 3.5 keV
line. If the charge exchange source indeed exists, we would expect that the
oxygen abundance is potentially overestimated by 8-22% in previous X-ray
measurements which assumed pure thermal lines.
",Physics
"  It is believed that thermalization in closed systems of interacting particles
can occur only when the eigenstates are fully delocalized and chaotic in the
preferential (unperturbed) basis of the total Hamiltonian. Here we demonstrate
that at variance with this common belief the typical situation in the systems
with two-body inter-particle interaction is much more complicated and allows to
treat as thermal even eigenstates that are not fully delocalized. Using a
semi-analytical approach we establish the conditions for the emergence of such
thermal states in a model of randomly interacting bosons. Our numerical data
show an excellent correspondence with the predicted properties of {\it
localized thermal eigenstates}.
",Physics
"  The unsteady characteristics of the flow over thick flatback airfoils have
been investigated by means of CFD calculations. Sandia airfoils which have 35%
maximum thickness with three different trailing edge thicknesses were selected.
The calculations provided good results compared with available experimental
data with regard to the lift curve and the impact of trailing edge thickness.
Unsteady CFD simulations revealed that the Strouhal number is found to be
independent of the lift coefficient before stall and increases with the
trailing edge. The present work shows the dependency of the Strouhal number and
the wake development on the trailing edge thickness. A recommendation of the
Strouhal number definition is given for flatback airfoils by considering the
trailing edge separation at low angle of attack. The detailed unsteady
characteristics of thick flatback airfoils are discussed more in the present
paper.
",Physics
"  Covalent-organic frameworks (COFs) are intriguing platforms for designing
functional molecular materials. Here, we present a computational study based on
van der Waals dispersion-corrected hybrid density functional theory
calculations to analyze the material properties of boroxine-linked and
triazine-linked intercalated-COFs. The effect of Fe atoms on the electronic
band structures near the Fermi energy level of the intercalated-COFs have been
investigated. The density of states (DOSs) computations have been performed to
analyze the material properties of these kind of intercalated-COFs. We predict
that COFs's electronic properties can be fine tuned by adding Fe atoms between
two organic layers in their structures. The new COFs are predicted to be
thermoelectric materials. These intercalated-COFs provide a new strategy to
create thermoelectric materials within a rigid porous network in a highly
controlled and predictable manner.
",Physics
"  Nd2Hf2O7, belonging to the family of geometrically frustrated cubic rare
earth pyrochlore oxides, was recently identified to order antiferromagnetically
below T_N = 0.55 K with an all-in/all-out arrangement of Nd3+ moments, however
with a much reduced ordered state moment. Herein we investigate the spin
dynamics and crystal field states of Nd2Hf2O7 using muon spin relaxation (muSR)
and inelastic neutron scattering (INS) measurements. Our muSR study confirms
the long range magnetic ordering and shows evidence for coexisting persistent
dynamic spin fluctuations deep inside the ordered state down to 42 mK. The INS
data show the crytal electric field (CEF) excitations due to the transitions
both within the ground state multiplet and to the first excited state
multiplet. The INS data are analyzed by a model based on CEF and crystal field
states are determined. Strong Ising-type anisotropy is inferred from the ground
state wavefunction. The CEF parameters indicate the CEF-split Kramers doublet
ground state of Nd3+ to be consistent with the dipolar-octupolar character.
",Physics
"  The results of the probabilistic analysis of the direct numerical simulations
of irregular unidirectional deep-water waves are discussed. It is shown that an
occurrence of large-amplitude soliton-like groups represents an extraordinary
case, which is able to increase noticeably the probability of high waves even
in moderately rough sea conditions. The ensemble of wave realizations should be
large enough to take these rare events into account. Hence we provide a
striking example when long-living coherent structures make the water wave
statistics extreme.
",Physics
"  Context. Transit events of extrasolar planets offer the opportunity to study
the composition of their atmospheres. Previous work on transmission
spectroscopy of the close-in gas giant TrES-3 b revealed an increase in
absorption towards blue wavelengths of very large amplitude in terms of
atmospheric pressure scale heights, too large to be explained by
Rayleigh-scattering in the planetary atmosphere. Aims. We present a follow-up
study of the optical transmission spectrum of the hot Jupiter TrES-3 b to
investigate the strong increase in opacity towards short wavelengths found by a
previous study. Furthermore, we aim to estimate the effect of stellar spots on
the transmission spectrum. Methods. This work uses previously published long
slit spectroscopy transit data of the Gran Telescopio Canarias (GTC) and
published broad band observations as well as new observations in different
bands from the near-UV to the near-IR, for a homogeneous transit light curve
analysis. Additionally, a long-term photometric monitoring of the TrES-3 host
star was performed. Results. Our newly analysed GTC spectroscopic transit
observations show a slope of much lower amplitude than previous studies. We
conclude from our results the previously reported increasing signal towards
short wavelengths is not intrinsic to the TrES-3 system. Furthermore, the broad
band spectrum favours a flat spectrum. Long-term photometric monitoring rules
out a significant modification of the transmission spectrum by unocculted star
spots.
",Physics
"  We report results from twelve simulations of the collapse of a molecular
cloud core to form one or more protostars, comprising three field strengths
(mass-to-flux ratios, {\mu}, of 5, 10, and 20) and four field geometries (with
values of the angle between the field and rotation axes, {\theta}, of 0°,
20°, 45°, and 90°), using a smoothed particle
magnetohydrodynamics method. We find that the values of both parameters have a
strong effect on the resultant protostellar system and outflows. This ranges
from the formation of binary systems when {\mu} = 20 to strikingly differing
outflow structures for differing values of {\theta}, in particular highly
suppressed outflows when {\theta} = 90°. Misaligned magnetic fields can
also produce warped pseudo-discs where the outer regions align perpendicular to
the magnetic field but the innermost region re-orientates to be perpendicular
to the rotation axis. We follow the collapse to sizes comparable to those of
first cores and find that none of the outflow speeds exceed 8 km s$^{-1}$.
These results may place constraints on both observed protostellar outflows, and
also on which molecular cloud cores may eventually form either single stars and
binaries: a sufficiently weak magnetic field may allow for disc fragmentation,
whilst conversely the greater angular momentum transport of a strong field may
inhibit disc fragmentation.
",Physics
"  The control of the ultracold collisions between neutral atoms is an extensive
and successful field of study. The tools developed allow for ultracold chemical
reactions to be managed using magnetic fields, light fields and spin-state
manipulation of the colliding particles among other methods. The control of
chemical reactions in ultracold atom-ion collisions is a young and growing
field of research. Recently, the collision energy and the ion electronic state
were used to control atom-ion interactions. Here, we demonstrate
spin-controlled atom-ion inelastic processes. In our experiment, both
spin-exchange and charge-exchange reactions are controlled in an ultracold
Rb-Sr$^+$ mixture by the atomic spin state. We prepare a cloud of atoms in a
single hyperfine spin-state. Spin-exchange collisions between atoms and ion
subsequently polarize the ion spin. Electron transfer is only allowed for
(RbSr)$^+$ colliding in the singlet manifold. Initializing the atoms in various
spin states affects the overlap of the collision wavefunction with the singlet
molecular manifold and therefore also the reaction rate. We experimentally show
that by preparing the atoms in different spin states one can vary the
charge-exchange rate in agreement with theoretical predictions.
",Physics
"  We investigate the mechanical properties of amorphous polymers by means of
coarse-grained simulations and nonaffine lattice dynamics theory. A small
increase of polymer chain bending stiffness leads first to softening of the
material, while hardening happens only upon further strengthening of the
backbones. This nonmonotonic variation of the storage modulus $G'$ with bending
stiffness is caused by a competition between additional resistance to
deformation offered by stiffer backbones and decreased density of the material
due to a necessary decrease in monomer-monomer coordination. This
counter-intuitive finding suggests that the strength of polymer glasses may in
some circumstances be enhanced by softening the bending of constituent chains.
",Physics
"  An efficient Bayesian technique for estimation problems in fundamental
stellar astronomy is tested on simulated data for a binary observed both
astrometrically and spectroscopically. Posterior distributions are computed for
the components' masses and for the binary's parallax. One thousand independent
repetitions of the simulation demonstrate that the 1- and 2-$\!\sigma$
credibility intervals for these fundamental quantities have close to the
correct coverage fractions. In addition, the simulations allow the
investigation of the statistical properties of a Bayesian goodness-of-fit
criterion and of the corresponding p-value. The criterion has closely similar
properties to the traditional chi^{2} test for minimum-chi^{2} solutions.
",Physics
"  Synthetic biological macromolecule of magnetoferritin containing an iron
oxide core inside a protein shell (apoferritin) is prepared with different
content of iron. Its structure in aqueous solution is analyzed by small-angle
synchrotron X-ray (SAXS) and neutron (SANS) scattering. The loading factor (LF)
defined as the average number of iron atoms per protein is varied up to LF=800.
With an increase of the LF, the scattering curves exhibit a relative increase
in the total scattered intensity, a partial smearing and a shift of the match
point in the SANS contrast variation data. The analysis shows an increase in
the polydispersity of the proteins and a corresponding effective increase in
the relative content of magnetic material against the protein moiety of the
shell with the LF growth. At LFs above ~150, the apoferritin shell undergoes
structural changes, which is strongly indicative of the fact that the shell
stability is affected by iron oxide presence.
",Physics
"  In the present study, superheating treatment has been applied on A357
reinforced with 0.5 wt. % (Composite 1) and 1.0 wt.% (Composite 2) continuous
stainless steel composite. In Composite 1 the microstructure displayed poor
bonding between matrix and reinforcement interface. Poor bonding associated
with large voids also can be seen in Composite 1. The results also showed that
coarser eutectic silicon (Si) particles were less intensified around the
matrix-reinforcement interface. From energy dispersive spectrometry (EDS)
elemental mapping, it was clearly shown that the distribution of eutectic Si
particles were less concentrated at poor bonding regions associated with large
voids. Meanwhile in Composite 2, the microstructure displayed good bonding
combined with more concentrated finer eutectic Si particles around the
matrix-reinforcement interface. From EDS elemental mapping, it was clearly
showed more concentrated of eutectic Si particles were distributed at the good
bonding area. The superheating prior to casting has influenced the
microstructure and tends to produce finer, rounded and preferred oriented
{\alpha}-Al dendritic structures.
",Physics
"  We investigate the nature of the magnetic phase transition induced by the
short-ranged electron-electron interactions in a Weyl semimetal by using the
perturbative renormalization-group method. We find that the critical point
associated with the quantum phase transition is characterized by a Gaussian
fixed point perturbed by a dangerously irrelevant operator. Although the
low-energy and long-distance physics is governed by a free theory, the
velocities of the fermionic quasiparticles and the magnetic excitations suffer
from nontrivial renormalization effects. In particular, their ratio approaches
one, which indicates an emergent Lorentz symmetry at low energies. We further
investigate the stability of the fixed point in the presence of weak disorder.
We show that while the fixed point is generally stable against weak disorder,
among those disorders that are consistent with the emergent chiral symmetry of
the clean system, a moderately strong random chemical potential and/or random
vector potential may induce a quantum phase transition towards a
disorder-dominated phase. We propose a global phase diagram of the Weyl
semimetal in the presence of both electron-electron interactions and disorder
based on our results.
",Physics
"  In this work maximum entropy distributions in the space of steady states of
metabolic networks are defined upon constraining the first and second moment of
the growth rate. Inherent bistability of fast and slow phenotypes, akin to a
Van-Der Waals picture, emerges upon considering control on the average growth
(optimization/repression) and its fluctuations (heterogeneity). This is applied
to the carbon catabolic core of E.coli where it agrees with some stylized facts
on the persisters phenotype and it provides a quantitative map with metabolic
fluxes, opening for the possibility to detect coexistence from flux data.
Preliminary analysis on data for E.Coli cultures in standard conditions shows,
on the other hand, degeneracy for the inferred parameters that extend in the
coexistence region.
",Physics
"  We study production of primordial black holes (PBHs) during an early
matter-dominated phase. As a source of perturbations, we consider either the
inflaton field with a running spectral index or a spectator field that has a
blue spectrum and thus provides a significant contribution to the PBH
production at small scales. First, we identify the region of the parameter
space where a significant fraction of the observed dark matter can be produced,
taking into account all current PBH constraints. Then, we present constraints
on the amplitude and spectral index of the spectator field as a function of the
reheating temperature. We also derive constraints on the running of the
inflaton spectral index, ${\rm d}n/{\rm d}{\rm ln}k \lesssim -0.002$, which are
comparable to those from the Planck satellite for a scenario where the
spectator field is absent.
",Physics
"  A sample of Coma cluster ultra-diffuse galaxies (UDGs) are modelled in the
context of Extended Modified Newtonian Dynamics (EMOND) with the aim to explain
the large dark matter-like effect observed in these cluster galaxies.
We first build a model of the Coma cluster in the context of EMOND using gas
and galaxy mass profiles from the literature. Then assuming the dynamical mass
of the UDGs satisfies the fundamental manifold of other ellipticals, and that
the UDG stellar mass-to-light matches their colour, we can verify the EMOND
formulation by comparing two predictions of the baryonic mass of UDGs.
We find that EMOND can explain the UDG mass, within the expected modelling
errors, if they lie on the fundamental manifold of ellipsoids, however, given
that measurements show one UDG lying off the fundamental manifold, observations
of more UDGs are needed to confirm this assumption.
",Physics
"  The LSST software systems make extensive use of Python, with almost all of it
initially being developed solely in Python 2. Since LSST will be commissioned
when Python 2 is end-of-lifed it is critical that we have all our code support
Python 3 before commissioning begins. Over the past year we have made
significant progress in migrating the bulk of the code from the Data Management
system onto Python 3. This paper presents our migration methodology, and the
current status of the port, with our eventual aim to be running completely on
Python 3 by early 2018. We also discuss recent modernizations to our Python
codebase.
",Physics
"  We study, by means of the density-matrix renormalization group (DMRG)
technique, the evolution of the ground state in a one-dimensional topological
insulator, from the non-interacting to the strongly-interacting limit, where
the system can be mapped onto a topological Kondo-insulator model. We focus on
a toy model Hamiltonian (i.e., the interacting ""$sp$-ladder"" model), which
could be experimentally realized in optical lattices with higher orbitals
loaded with ultra-cold fermionic atoms. Our goal is to shed light on the
emergence of the strongly-interacting ground state and its topological
classification as the Hubbard-$U$ interaction parameter of the model is
increased. Our numerical results show that the ground state can be generically
classified as a symmetry-protected topological phase of the Haldane-type, even
in the non-interacting case $U=0$ where the system can be additionally
classified as a time-reversal $\mathbb{Z}_{2}$-topological insulator, and
evolves adiabatically between the non-interacting and strongly interacting
limits.
",Physics
"  Growth, electronic and magnetic properties of $\gamma'$-Fe$_{4}$N atomic
layers on Cu(001) are studied by scanning tunneling microscopy/spectroscopy and
x-ray absorption spectroscopy/magnetic circular dichroism. A continuous film of
ordered trilayer $\gamma'$-Fe$_{4}$N is obtained by Fe deposition under N$_{2}$
atmosphere onto monolayer Fe$_{2}$N/Cu(001), while the repetition of a
bombardment with 0.5 keV N$^{+}$ ions during growth cycles results in imperfect
bilayer $\gamma'$-Fe$_{4}$N. The increase in the sample thickness causes the
change of the surface electronic structure, as well as the enhancement in the
spin magnetic moment of Fe atoms reaching $\sim$ 1.4 $\mu_{\mathrm B}$/atom in
the trilayer sample. The observed thickness-dependent properties of the system
are well interpreted by layer-resolved density of states calculated using first
principles, which demonstrates the strongly layer-dependent electronic states
within each surface, subsurface, and interfacial plane of the
$\gamma'$-Fe$_{4}$N atomic layers on Cu(001).
",Physics
"  The search of binary sequences with low auto-correlations (LABS) is a
discrete combinatorial optimization problem contained in the NP-hard
computational complexity class. We study this problem using Warning Propagation
(WP) , a message passing algorithm, and compare the performance of the
algorithm in the original problem and in two different disordered versions. We
show that in all the cases Warning Propagation converges to low energy minima
of the solution space. Our results highlight the importance of the local
structure of the interaction graph of the variables for the convergence time of
the algorithm and for the quality of the solutions obtained by WP. While in
general the algorithm does not provide the optimal solutions in large systems
it does provide, in polynomial time, solutions that are energetically similar
to the optimal ones. Moreover, we designed hybrid models that interpolate
between the standard LABS problem and the disordered versions of it, and
exploit them to improved the convergence time of WP and the quality of the
solutions.
",Physics
"  We analyze the effect of intersite-interaction terms on the stability of the
coexisting superconucting-nematic phase (SC+N) within the extended Hubbard and
$t$-$J$-$U$ models on the square lattice. In order to take into account the
correlation effects with a proper precision, we use the approach based on the
\textit{diagrammatic expansion of the Gutzwiller wave function} (DE-GWF), which
goes beyond the renormalized mean field theory (RMFT) in a systematic manner.
As a starting point of our analysis we discuss the stability region of the SC+N
phase on the intrasite Coulomb repulsion-hole doping plane for the case of the
Hubbard model. Next, we show that the exchange interaction term enhances
superconductivity while suppresses the nematicity, whereas the intersite
Coulomb repulsion term acts in the opposite manner. The competing character of
the SC and N phases interplay is clearly visible throughout the analysis. A
universal conclusion is that the nematic phase does not survive within the
$t$-$J$-$U$ model with the value of $J$ integral typical for the high-T$_C$
cuprates ($J\approx 0.1$eV). For the sake of completeness, the effect of the
correlated hopping term is also analyzed. Thus the present discussion contains
all relevant two-site interaction terms which appear in the parametrized
one-band model within the second quantization scheme. At the end, the influence
of the higher-order terms of the diagrammatic expansion on the rotational
symmetry breaking is also shown by comparing the DE-GWF results with those
corresponding to the RMFT.
",Physics
"  We suggest an inverse dispersion method for calculating photonic band diagram
for materials with arbitrary frequency-dependent dielectric functions. The
method is able to calculate the complex wave vector for a given frequency by
solving the eigenvalue problem with a non-Hermitian operator. The analogy with
$\cal{PT}$-symmetric Hamiltonians reveals that the operator corresponds to the
momentum as a physical quantity and the singularities at the band edges are
related to the branch points and responses for the features on the band edges.
The method is realized using plane wave expansion technique for two-dimensional
periodical structure in the case of TE- and TM-polarization. We illustrate the
applicability of the method by calculation of the photonic band diagrams of an
infinite two-dimension square lattice composed of dielectric cylinders using
the measured frequency dependent dielectric functions of different materials
(amorphous hydrogenated carbon, silicon, and chalcogenide glass). We show that
the method allows to distinguish unambiguously between Bragg and Mie gaps in
the spectra.
",Physics
"  In a recent publication [Appl. Opt. 55, 2418 (2016)], a method for
two-dimensional phase unwrapping based on the transport of intensity equation
(TIE) was studied. We wish to show that this approach is associated with the
standard least squares phase unwrapping algorithm, but with additional
numerical errors.
",Physics
"  A semi-relativistic density-functional theory that includes spin-orbit
couplings and Zeeman fields on equal footing with the electromagnetic
potentials, is an appealing framework to develop a unified first-principles
computational approach for non-collinear magnetism, spintronics, orbitronics,
and topological states. The basic variables of this theory include the
paramagnetic current and the spin-current density, besides the particle and the
spin density, and the corresponding exchange-correlation (xc) energy functional
is invariant under local U(1)$\times$SU(2) gauge transformations. The xc-energy
functional must be approximated to enable practical applications, but, contrary
to the case of the standard density functional theory, finding simple
approximations suited to deal with realistic atomistic inhomogeneities has been
a long-standing challenge. Here, we propose a way out of this impasse by
showing that approximate gauge-invariant functionals can be easily generated
from existing approximate functionals of ordinary density-functional theory by
applying a simple {\it minimal substitution} on the kinetic energy density,
which controls the short-range behavior of the exchange hole. Our proposal
opens the way to the construction of approximate, yet non-empirical
functionals, which do not assume weak inhomogeneity and should therefore have a
wide range of applicability in atomic, molecular and condensed matter physics.
",Physics
"  We developed a simple, physical and self-consistent cloud model for brown
dwarfs and young giant exoplanets. We compared different parametrisations for
the cloud particle size, by either fixing particle radii, or fixing the mixing
efficiency (parameter fsed) or estimating particle radii from simple
microphysics. The cloud scheme with simple microphysics appears as the best
parametrisation by successfully reproducing the observed photometry and spectra
of brown dwarfs and young giant exoplanets. In particular, it reproduces the
L-T transition, due to the condensation of silicate and iron clouds below the
visible/near-IR photosphere. It also reproduces the reddening observed for
low-gravity objects, due to an increase of cloud optical depth for low gravity.
In addition, we found that the cloud greenhouse effect shifts chemical
equilibriums, increasing the abundances of species stable at high temperature.
This effect should significantly contribute to the strong variation of methane
abundance at the L-T transition and to the methane depletion observed on young
exoplanets. Finally, we predict the existence of a continuum of brown dwarfs
and exoplanets for absolute J magnitude=15-18 and J-K color=0-3, due to the
evolution of the L-T transition with gravity. This self-consistent model
therefore provides a general framework to understand the effects of clouds and
appears well-suited for atmospheric retrievals.
",Physics
"  Disk migration and high-eccentricity migration are two well-studied theories
to explain the formation of hot Jupiters. The former predicts that these
planets can migrate up until the planet-star Roche separation ($a_{Roche}$) and
the latter predicts they will tidally circularize at a minimum distance of
2$a_{Roche}$. Considering long-running radial velocity and transit surveys have
identified a couple hundred hot Jupiters to date, we can revisit the classic
question of hot Jupiter formation in a data-driven manner. We approach this
problem using data from several exoplanet surveys (radial velocity, Kepler,
HAT, and WASP) allowing for either a single population or a mixture of
populations associated with these formation channels, and applying a
hierarchical Bayesian mixture model of truncated power laws of the form
$x^{\gamma-1}$ to constrain the population-level parameters of interest (e.g.,
location of inner edges, $\gamma$, mixture fractions). Within the limitations
of our chosen models, we find the current radial velocity and Kepler sample of
hot Jupiters can be well explained with a single truncated power law
distribution with a lower cutoff near 2$a_{Roche}$, a result that still holds
after a decade, and $\gamma=-0.51\pm^{0.19}_{0.20}$. However, the HAT and WASP
data show evidence for multiple populations (Bayes factor $\approx 10^{21}$).
We find that $15\pm^{9}_{6}\%$ reside in a component consistent with disk
migration ($\gamma=-0.04\pm^{0.53}_{1.27}$) and $85\pm^{6}_{9}\%$ in one
consistent with high-eccentricity migration ($\gamma=-1.38\pm^{0.32}_{0.47}$).
We find no immediately strong connections with some observed host star
properties and speculate on how future exoplanet surveys could improve upon hot
Jupiter population inference.
",Physics
"  On the basis of quasipotential method in quantum electrodynamics we calculate
nuclear finite size radiative corrections of order $\alpha(Z \alpha)^5$ to the
Lamb shift in muonic hydrogen and helium. To construct the interaction
potential of particles, which gives the necessary contributions to the energy
spectrum, we use the method of projection operators to states with a definite
spin. Separate analytic expressions for the contributions of the muon
self-energy, the muon vertex operator and the amplitude with spanning photon
are obtained. We present also numerical results for these contributions using
modern experimental data on the electromagnetic form factors of light nuclei.
",Physics
"  Superconductor-Ferromagnet (SF) heterostructures are of interest due to
numerous phenomena related to the spin-dependent interaction of Cooper pairs
with the magnetization. Here we address the effects of a magnetic insulator on
the density of states of a superconductor based on a recently developed
boundary condition for strongly spin-dependent interfaces. We show that the
boundary to a magnetic insulator has a similar effect like the presence of
magnetic impurities. In particular we find that the impurity effects of
strongly scattering localized spins leading to the formation of Shiba bands can
be mapped onto the boundary problem.
",Physics
"  When rough grains in standard packing conditions are discharged from a silo,
a conical depression with a single slope is formed at the surface. We observed
that the increase of the volume fraction generates a more complex depression
characterized by two angles of discharge: a lower angle close to the one
measured for standard packing and a considerably larger upper angle. The change
in slope appears at the boundary between a densely packed stagnant region at
the periphery and the central flowing channel formed over the aperture. Since
the material in the latter zone is always fluidized, the flow rate is
unaffected by the initial packing of the bed. On the other hand, the contrast
between both angles is markedly smaller when smooth particles of the same size
and density are used, which reveals that high volume fraction and friction must
combine to produce the observed geometry. Our results show that the surface
profile helps to identify by simple visual inspection the packing conditions of
a granular bed, and this can be useful to prevent undesirable collapses during
silo discharge in industry.
",Physics
"  The Hubble Catalog of Variables (HCV) is a 3 year ESA funded project that
aims to develop a set of algorithms to identify variables among the sources
included in the Hubble Source Catalog (HSC) and produce the HCV. We will
process all HSC sources with more than a predefined number of measurements in a
single filter/instrument combination and compute a range of lightcurve features
to determine the variability status of each source. At the end of the project,
the first release of the Hubble Catalog of Variables will be made available at
the Mikulski Archive for Space Telescopes (MAST) and the ESA Science Archives.
The variability detection pipeline will be implemented at the Space Telescope
Science Institute (STScI) so that updated versions of the HCV may be created
following the future releases of the HSC.
",Physics
"  Of the roughly 3000 neutron stars known, only a handful have sub-stellar
companions. The most famous of these are the low-mass planets around the
millisecond pulsar B1257+12. New evidence indicates that observational biases
could still hide a wide variety of planetary systems around most neutron stars.
We consider the environment and physical processes relevant to neutron star
planets, in particular the effect of X-ray irradiation and the relativistic
pulsar wind on the planetary atmosphere. We discuss the survival time of planet
atmospheres and the planetary surface conditions around different classes of
neutron stars, and define a neutron star habitable zone. Depending on as-yet
poorly constrained aspects of the pulsar wind, both Super-Earths around
B1257+12 could lie within its habitable zone.
",Physics
"  We present optimized source galaxy selection schemes for measuring cluster
weak lensing (WL) mass profiles unaffected by cluster member dilution from the
Subaru Hyper Suprime-Cam Strategic Survey Program (HSC-SSP). The ongoing
HSC-SSP survey will uncover thousands of galaxy clusters to $z\lesssim1.5$. In
deriving cluster masses via WL, a critical source of systematics is
contamination and dilution of the lensing signal by cluster {members, and by
foreground galaxies whose photometric redshifts are biased}. Using the
first-year CAMIRA catalog of $\sim$900 clusters with richness larger than 20
found in $\sim$140 deg$^2$ of HSC-SSP data, we devise and compare several
source selection methods, including selection in color-color space (CC-cut),
and selection of robust photometric redshifts by applying constraints on their
cumulative probability distribution function (PDF; P-cut). We examine the
dependence of the contamination on the chosen limits adopted for each method.
Using the proper limits, these methods give mass profiles with minimal dilution
in agreement with one another. We find that not adopting either the CC-cut or
P-cut methods results in an underestimation of the total cluster mass
($13\pm4\%$) and the concentration of the profile ($24\pm11\%$). The level of
cluster contamination can reach as high as $\sim10\%$ at $R\approx 0.24$
Mpc/$h$ for low-z clusters without cuts, while employing either the P-cut or
CC-cut results in cluster contamination consistent with zero to within the 0.5%
uncertainties. Our robust methods yield a $\sim60\sigma$ detection of the
stacked CAMIRA surface mass density profile, with a mean mass of
$M_\mathrm{200c} = (1.67\pm0.05({\rm {stat}}))\times 10^{14}\,M_\odot/h$.
",Physics
"  We report on the first experimental observation of graphene optical emission
induced by the intense THz pulse. P-doped CVD graphene with the initial Fermi
energy of about 200 meV was used, optical photons was detected in the
wavelength range of 340-600 nm. Emission started when THz field amplitude
exceeded 100 kV/cm. For THz fields from 200 to 300 kV/cm the temperature of
optical radiation was constant, while the number of emitted photons increased
several dozen times. This fact clearly indicates multiplication of
electron-hole pairs induced by an external field itself and not due to electron
heating. The experimental data are in a good agreement with the theory of
Landau-Zener interband transitions. It is shown theoretically that Landau-Zener
transitions are possible even in the case of heavily doped graphene because the
strong THz field removes quasiparticles from the region of interband
transitions during several femtoseconds, which cancels the Pauli blocking
effect.
",Physics
"  The low-energy constants, namely the spin stiffness $\rho_s$, the staggered
magnetization density ${\cal M}_s$ per area, and the spinwave velocity $c$ of
the two-dimensional (2D) spin-1 Heisenberg model on the square and rectangular
lattices are determined using the first principles Monte Carlo method. In
particular, the studied models have antiferromagnetic couplings $J_1$ and $J_2$
in the spatial 1- and 2-directions, respectively. For each considered
$J_2/J_1$, the aspect ratio of the corresponding linear box sizes $L_2/L_1$
used in the simulations is adjusted so that the squares of the two spatial
winding numbers take the same values. In addition, the relevant finite-volume
and -temperature predictions from magnon chiral perturbation theory are
employed in extracting the numerical values of these low-energy constants. Our
results of $\rho_{s1}$ are in quantitative agreement with those obtained by the
series expansion method over a broad range of $J_2/J_1$. This in turn provides
convincing numerical evidence for the quantitative correctness of our approach.
The ${\cal M}_s$ and $c$ presented here for the spatially anisotropic models
are new and can be used as benchmarks for future related studies.
",Physics
"  Three-dimensional (3D) color codes have advantages for fault-tolerant quantum
computing, such as protected quantum gates with relatively low overhead and
robustness against imperfect measurement of error syndromes. Here we
investigate the storage threshold error rates for bit-flip and phase-flip noise
in the 3D color code on the body-centererd cubic lattice, assuming perfect
syndrome measurements. In particular, by exploiting a connection between error
correction and statistical mechanics, we estimate the threshold for 1D
string-like and 2D sheet-like logical operators to be $p^{(1)}_\mathrm{3DCC}
\simeq 1.9\%$ and $p^{(2)}_\mathrm{3DCC} \simeq 27.6\%$. We obtain these
results by using parallel tempering Monte Carlo simulations to study the
disorder-temperature phase diagrams of two new 3D statistical-mechanical
models: the 4- and 6-body random coupling Ising models.
",Physics
"  Based on BCS model with the external pair potential formulated in a work
\emph{K.V. Grigorishin} arXiv:1605.07080, analogous model with electron-phonon
coupling and Coulomb coupling is proposed. The generalized Eliashberg equations
in the regime of renormalization of the order parameter are obtained. High
temperature asymptotics and influence of Coulomb pseudopotential on them are
investigated: as in the BCS model the order parameter asymptotically tends to
zero as temperature rises, but the accounting of the Coulomb pseudopotential
leads to existence of critical temperature. The effective Ginzburg-Landau
theory is formulated for such model, where the temperature dependencies near
$T_{c}$ of the basic characteristics of a superconductor (coherence length,
magnetic penetration depth, GL parameter, the thermodynamical critical field,
the first and the second critical fields) recovers to the temperature
dependencies as in the ordinary GL theory after the BCS model with the external
pair potential.
",Physics
"  In this paper, we propose a new algorithm based on radial symmetry center
method to track colloidal particles close to contact, where the optical images
of the particles start to overlap in digital video microscopy. This overlapping
effect is important to observe the pair interaction potential in colloidal
studies and it appears as additional interaction in the measurement of the
interaction with conventional tracking analysis. The proposed algorithm in this
work is simple, fast and applicable for not only two particles but also three
and more particles without any modification. The algorithm uses gradient
vectors of the particle intensity distribution, which allows us to use a part
of the symmetric intensity distribution in the calculation of the actual
particle position. In this study, simulations are performed to see the
performance of the proposed algorithm for two and three particles, where the
simulation images are generated by using fitted curve to experimental particle
image for different sized particles. As a result, the algorithm yields the
maximum error smaller than 2 nm for 5.53 {\mu}m silica particles in contact
condition.
",Physics
"  We study phase transitions in a two dimensional weakly interacting Bose gas
in a random potential at finite temperatures. We identify superfluid, normal
fluid, and insulator phases and construct the phase diagram. At T=0 one has a
tricritical point where the three phases coexist. The truncation of the energy
distribution at the trap barrier, which is a generic phenomenon in cold atom
systems, limits the growth of the localization length and in contrast to the
thermodynamic limit the insulator phase is present at any temperature.
",Physics
"  The first transiting planetesimal orbiting a white dwarf was recently
detected in K2 data of WD1145+017 and has been followed up intensively. The
multiple, long, and variable transits suggest the transiting objects are dust
clouds, probably produced by a disintegrating asteroid. In addition, the system
contains circumstellar gas, evident by broad absorption lines, mostly in the
u'-band, and a dust disc, indicated by an infrared excess. Here we present the
first detection of a change in colour of WD1145+017 during transits, using
simultaneous multi-band fast-photometry ULTRACAM measurements over the
u'g'r'i'-bands. The observations reveal what appears to be 'bluing' during
transits; transits are deeper in the redder bands, with a u'-r' colour
difference of up to ~-0.05 mag. We explore various possible explanations for
the bluing. 'Spectral' photometry obtained by integrating over bandpasses in
the spectroscopic data in- and out-of-transit, compared to the photometric
data, shows that the observed colour difference is most likely the result of
reduced circumstellar absorption in the spectrum during transits. This
indicates that the transiting objects and the gas share the same line-of-sight,
and that the gas covers the white dwarf only partially, as would be expected if
the gas, the transiting debris, and the dust emitting the infrared excess, are
part of the same general disc structure (although possibly at different radii).
In addition, we present the results of a week-long monitoring campaign of the
system.
",Physics
"  Dyson demonstrated an equivalence between infinite-range Coulomb gas models
and classical random matrix ensembles for study of eigenvalue statistics. We
introduce finite-range Coulomb gas (FRCG) models via a Brownian matrix process,
and study them analytically and by Monte-Carlo simulations. These models yield
new universality classes, and provide a theoretical framework for study of
banded random matrices (BRM) and quantum kicked rotors (QKR). We demonstrate
that, for a BRM of bandwidth b and a QKR of chaos parameter {\alpha}, the
appropriate FRCG model has the effective range d = (b^2)/N = ({\alpha}^2)/N,
for large N matrix dimensionality. As d increases, there is a transition from
Poisson to classical random matrix statistics.
",Physics
"  We investigated the reliability and applicability of so-called magnetic force
linear response method to calculate spin-spin interaction strengths from
first-principles. We examined the dependence on the numerical parameters
including the number of basis orbitals and their cutoff radii within
non-orthogonal LCPAO (linear combination of pseudo-atomic orbitals) formalism.
It is shown that the parameter dependence and the ambiguity caused by these
choices are small enough in comparison to the other computation approach and
experiments. Further, we tried to pursue the possible extension of this
technique to a wider range of applications. We showed that magnetic force
theorem can provide the reasonable estimation especially for the case of
strongly localized moments even when the ground state configuration is unknown
or the total energy value is not accessible. The formalism is extended to carry
the orbital resolution from which the matrix form of the magnetic coupling
constant is calculated. From the applications to Fe-based superconductors
including LaFeAsO, NaFeAs, BaFe$_2$As$_2$ and FeTe, the distinctive
characteristics of orbital-resolved interactions are clearly noticed in between
single-stripe pnictides and double-stripe chalcogenides.
",Physics
"  We perform ultrasound velocity measurements on a single crystal of
nearly-metallic spinel Co$_{1.21}$V$_{1.79}$O$_4$ which exhibits a
ferrimagnetic phase transition at $T_C \sim$ 165 K. The experiments reveal a
variety of elastic anomalies in not only the paramagnetic phase above $T_C$ but
also the ferrimagnetic phase below $T_C$, which should be driven by the
nearly-itinerant character of the orbitally-degenerate V 3$d$ electrons. In the
paramagnetic phase above $T_C$, the elastic moduli exhibit
elastic-mode-dependent unusual temperature variations, suggesting the existence
of a dynamic spin-cluster state. Furthermore, above $T_C$, the sensitive
magnetic-field response of the elastic moduli suggests that, with the negative
magnetoresistance, the magnetic-field-enhanced nearly-itinerant character of
the V 3$d$ electrons emerges from the spin-cluster state. This should be
triggered by the inter-V-site interactions acting on the orbitally-degenerate
3$d$ electrons. In the ferrimagnetic phase below $T_C$, the elastic moduli
exhibit distinct anomalies at $T_1\sim$ 95 K and $T_2\sim$ 50 K, with a sign
change of the magnetoresistance at $T_1$ (positive below $T_1$) and an
enhancement of the positive magnetoresistance below $T_2$, respectively. These
observations below $T_C$ suggest the successive occurrence of an orbital glassy
order at $T_1$ and a structural phase transition at $T_2$, where the rather
localized character of the V 3$d$ electrons evolves below $T_1$ and is further
enhanced below $T_2$.
",Physics
"  We consider the nonlinear Schrödinger (NLS) equation with the subcritical
power nonlinearity on a star graph consisting of $N$ edges and a single vertex
under generalized Kirchhoff boundary conditions. The stationary NLS equation
may admit a family of solitary waves parameterized by a translational
parameter, which we call the shifted states. The two main examples include (i)
the star graph with even $N$ under the classical Kirchhoff boundary conditions
and (ii) the star graph with one incoming edge and $N-1$ outgoing edges under a
single constraint on coefficients of the generalized Kirchhoff boundary
conditions. We obtain the general counting results on the Morse index of the
shifted states and apply them to the two examples. In the case of (i), we prove
that the shifted states with even $N \geq 4$ are saddle points of the action
functional which are spectrally unstable under the NLS flow. In the case of
(ii), we prove that the shifted states with the monotone profiles in the $N-1$
outgoing edges are spectrally stable, whereas the shifted states with
non-monotone profiles in the $N-1$ outgoing edges are spectrally unstable, the
two families intersect at the half-soliton states which are spectrally stable
but nonlinearly unstable. Since the NLS equation on a star graph with shifted
states can be reduced to the homogeneous NLS equation on a line, the spectral
instability of shifted states is due to the perturbations breaking this
reduction. We give a simple argument suggesting that the spectrally stable
shifted states are nonlinear unstable under the NLS flow due to the
perturbations breaking the reduction to the NLS equation on a line.
",Physics
"  Transistors incorporating single-wall carbon nanotubes (CNTs) as the channel
material are used in a variety of electronics applications. However, a
competitive CNT-based technology requires the precise placement of CNTs at
predefined locations of a substrate. One promising placement approach is to use
chemical recognition to bind CNTs from solution at the desired locations on a
surface. Producing the chemical pattern on the substrate is challenging. Here
we describe a one-step patterning approach based on a highly photosensitive
surface monolayer. The monolayer contains chromophopric group as light
sensitive body with heteroatoms as high quantum yield photolysis center. As
deposited, the layer will bind CNTs from solution. However, when exposed to
ultraviolet (UV) light with a low dose (60 mJ/cm2) similar to that used for
conventional photoresists, the monolayer cleaves and no longer binds CNTs.
These features allow standard, wafer-scale UV lithography processes to be used
to form a patterned chemical monolayer without the need for complex substrate
patterning or monolayer stamping.
",Physics
"  Transition metal oxides are promising candidates for thermoelectric
applications, because they are stable at high temperature and because strong
electronic correlations can generate large Seebeck coefficients, but their
thermoelectric power factors are limited by the low electrical conductivity. We
report transport measurements on Ca3Co4O9 films on various perovskite
substrates and show that reversible incorporation of oxygen into SrTiO3 and
LaAlO3 substrates activates a parallel conduction channel for p-type carriers,
greatly enhancing the thermoelectric performance of the film-substrate system
at temperatures above 450 °C. Thin-film structures that take advantage of
both electronic correlations and the high oxygen mobility of transition metal
oxides thus open up new perspectives for thermopower generation at high
temperature.
",Physics
"  Hamiltonian dynamics has been applied to study the slip-stacking dynamics.
The canonical-perturbation method is employed to obtain the second-harmonic
correction term in the slip-stacking Hamiltonian. The Hamiltonian approach
provides a clear optimal method for choosing the slip-stacking parameter and
improving stacking efficiency. The dynamics are applied specifically to the
Fermilab Booster-Recycler complex. The dynamics can also be applied to other
accelerator complexes.
",Physics
"  We present a new model to explain the difference between the transport and
spectroscopy gaps in samarium hexaboride (SmB$_6$), which has been a mystery
for some time. We propose that SmB$_6$ can be modeled as an intrinsic
semiconductor with a depletion length that diverges at cryogenic temperatures.
In this model, we find a self-consistent solution to Poisson's equation in the
bulk, with boundary conditions based on Fermi energy pinning due to surface
charges. The solution yields band bending in the bulk; this explains the
difference between the two gaps because spectroscopic methods measure the gap
near the surface, while transport measures the average over the bulk. We also
connect the model to transport parameters, including the Hall coefficient and
thermopower, using semiclassical transport theory. The divergence of the
depletion length additionally explains the 10-12 K feature in data for these
parameters, demonstrating a crossover from bulk dominated transport above this
temperature to surface-dominated transport below this temperature. We find good
agreement between our model and a collection of transport data from 4-40 K.
This model can also be generalized to materials with similar band structure.
",Physics
"  Planetary cores consist of liquid metals (low Prandtl number $Pr$) that
convect as the core cools. Here we study nonlinear convection in a rotating
(low Ekman number $Ek$) planetary core using a fully 3D direct numerical
simulation. Near the critical thermal forcing (Rayleigh number $Ra$),
convection onsets as thermal Rossby waves, but as the $Ra$ increases, this
state is superceded by one dominated by advection. At moderate rotation, these
states (here called the weak branch and strong branch, respectively) are
smoothly connected. As the planetary core rotates faster, the smooth transition
is replaced by hysteresis cycles and subcriticality until the weak branch
disappears entirely and the strong branch onsets in a turbulent state at $Ek <
10^{-6}$. Here the strong branch persists even as the thermal forcing drops
well below the linear onset of convection ($Ra=0.7Ra_{crit}$ in this study). We
highlight the importance of the Reynolds stress, which is required for
convection to subsist below the linear onset. In addition, the Péclet number
is consistently above 10 in the strong branch. We further note the presence of
a strong zonal flow that is nonetheless unimportant to the convective state.
Our study suggests that, in the asymptotic regime of rapid rotation relevant
for planetary interiors, thermal convection of liquid metals in a sphere onsets
through a subcritical bifurcation.
",Physics
"  We study the loss of coherence of electrochemical oscillations on meso- and
nanosized electrodes with numeric simulations of the electrochemical master
equation for a prototypical electrochemical oscillator, the hydrogen peroxide
reduction on Pt electrodes in the presence of halides. On nanoelectrodes, the
electrode potential changes whenever a stochastic electron-transfer event takes
place. Electrochemical reaction rate coefficients depend exponentially on the
electrode potential and become thus fluctuating quantities as well. Therefore,
also the transition rates between system states become time-dependent which
constitutes a fundamental difference to purely chemical nanoscale oscillators.
Three implications are demonstrated: (a) oscillations and steady states shift
in phase space with decreasing system size, thereby also decreasing
considerably the oscillating parameter regions; (b) the minimal number of
molecules necessary to support correlated oscillations is more than 10 times as
large as for nanoscale chemical oscillators; (c) the relation between
correlation time and variance of the period of the oscillations predicted for
chemical oscillators in the weak noise limit is only fulfilled in a very
restricted parameter range for the electrochemical nano-oscillator.
",Physics
"  The Dirac equation requires a treatment of the step potential that differs
fundamentally from the traditional treatment, because the Dirac plane waves,
besides momentum and spin, are characterized by a quantum number with the
physical meaning of sign of charge. Since the Hermitean operator corresponding
to this quantum number does not commute with the step potential, the time
displacement parameter used in the ansatz of the stationary state does not have
the physical meaning of energy. Therefore there are no paradoxal values of the
energy. The new solution of the Dirac equation with a step potential is
obtained. This solution, again, allows for phenomena of the Klein paradox type,
but in addition it contains a positron amplitude localized at the threshold
point of the step potential.
",Physics
"  Earthquakes at seismogenic plate boundaries are a response to the
differential motions of tectonic blocks embedded within a geometrically complex
network of branching and coalescing faults. Elastic strain is accumulated at a
slow strain rate of the order of $10^{-15}$ s$^{-1}$, and released
intermittently at intervals $>100$ years, in the form of rapid (seconds to
minutes) coseismic ruptures. The development of macroscopic models of
quasi-static planar tectonic dynamics at these plate boundaries has remained
challenging due to uncertainty with regard to the spatial and kinematic
complexity of fault system behaviors. In particular, the characteristic length
scale of kinematically distinct tectonic structures is poorly constrained. Here
we analyze fluctuations in GPS recordings of interseismic velocities from the
southern California plate boundary, identifying heavy-tailed scaling behavior.
This suggests that the plate boundary can be understood as a densely packed
granular medium near the jamming transition, with a characteristic length scale
of $91 \pm 20$ km. In this picture fault and block systems may rapidly
rearrange the distribution of forces within them, driving a mixture of
transient and intermittent fault slip behaviors over tectonic time scales.
",Physics
"  We describe the first ever implementation of an emulsion multi-stage shifter
in an accelerator neutrino experiment. The system was installed in the neutrino
monitor building in J-PARC as a part of a test experiment T60 and stable
operation was maintained for a total of 126.6 days. By applying time
information to emulsion films, various results were obtained. Time resolutions
of 5.3 to 14.7 s were evaluated in an operation spanning 46.9 days (time
resolved numbers of 3.8--1.4$\times10^{5}$). By using timing and spatial
information, a reconstruction of coincident events that consisted of high
multiplicity events and vertex events, including neutrino events was performed.
Emulsion events were matched to events observed by INGRID, one of near
detectors of the T2K experiment, with high reliability (98.5\%) and hybrid
analysis was established via use of the multi-stage shifter. The results
demonstrate that the multi-stage shifter is feasible for use in neutrino
experiments.
",Physics
"  For random quantum spin models, the strong disorder perturbative expansion of
the Local Integrals of Motion (LIOMs) around the real-spin operators is
revisited. The emphasis is on the links with other properties of the
Many-Body-Localized phase, in particular the memory in the dynamics of the
local magnetizations and the statistics of matrix elements of local operators
in the eigenstate basis. Finally, this approach is applied to analyze the
Many-Body-Localization transition in a toy model studied previously from the
point of view of the entanglement entropy.
",Physics
"  The detection of thousands of extrasolar planets by the transit method
naturally raises the question of whether potential extrasolar observers could
detect the transits of the Solar System planets. We present a comprehensive
analysis of the regions in the sky from where transit events of the Solar
System planets can be detected. We specify how many different Solar System
planets can be observed from any given point in the sky, and find the maximum
number to be three. We report the probabilities of a randomly positioned
external observer to be able to observe single and multiple Solar System planet
transits; specifically, we find a probability of 2.518% to be able to observe
at least one transiting planet, 0.229% for at least two transiting planets, and
0.027% for three transiting planets. We identify 68 known exoplanets that have
a favourable geometric perspective to allow transit detections in the Solar
System and we show how the ongoing K2 mission will extend this list. We use
occurrence rates of exoplanets to estimate that there are $3.2\pm1.2$ and
$6.6^{+1.3}_{-0.8}$ temperate Earth-sized planets orbiting GK and M dwarf stars
brighter than $V=13$ and $V=16$ respectively, that are located in the Earth's
transit zone.
",Physics
"  We report on the growth of epitaxial Sr2RuO4 films using a hybrid molecular
beam epitaxy approach in which a volatile precursor containing RuO4 is used to
supply ruthenium and oxygen. The use of the precursor overcomes a number of
issues encountered in traditional MBE that uses elemental metal sources.
Phase-pure, epitaxial thin films of Sr2RuO4 are obtained. At high substrate
temperatures, growth proceeds in a layer-by-layer mode with intensity
oscillations observed in reflection high-energy electron diffraction. Films are
of high structural quality, as documented by x-ray diffraction, atomic force
microscopy, and transmission electron microscopy. The method should be suitable
for the growth of other complex oxides containing ruthenium, opening up
opportunities to investigate thin films that host rich exotic ground states.
",Physics
"  Compared with numerous X-ray dominant active galactic nuclei (AGNs) without
emission-line signatures in their optical spectra, the X-ray selected AGNs with
optical emission lines are probably still in the high-accretion phase of black
hole growth. This paper presents an investigation on the fraction of these
X-ray detected AGNs with optical emission-line spectra in 198 galaxy groups at
$z<1$ in a rest frame 0.1-2.4 keV luminosity range 41.3 <log(L_X/erg s-1) <
44.1 within the COSMOS field, as well as its variations with redshift and group
richness. For various selection criteria of member galaxies, the numbers of
galaxies and the AGNs with optical emission lines in each galaxy group are
obtained. It is found that, in total 198 X-ray groups, there are 27 AGNs
detected in 26 groups. AGN fraction is on everage less than $4.6 (\pm 1.2)\%$
for individual groups hosting at least one AGN. The corrected overall AGN
fraction for whole group sample is less than $0.98 (\pm 0.11) \%$. The
normalized locations of group AGNs show that 15 AGNs are found to be located in
group centers, including all 6 low-luminosity group AGNs. A week rising
tendency with $z$ are found: overall AGN fraction is 0.30-0.43% for the groups
at $z<0.5$, and 0.55-0.64% at 0.5 < z < 1.0. For the X-ray groups at $z>0.5$,
most member AGNs are X-ray bright, optically dull, which results in a lower AGN
fractions at higher redshifts. The AGN fraction in isolated fields also
exhibits a rising trend with redshift, and the slope is consistent with that in
groups. The environment of galaxy groups seems to make no difference in
detection probability of the AGNs with emission lines. Additionally, a larger
AGN fractions are found in poorer groups, which implies that the AGNs in poorer
groups might still be in the high-accretion phase, whereas the AGN population
in rich clusters is mostly in the low-accretion, X-ray dominant phase.
",Physics
"  The deconfined quantum critical point (QCP), separating the Néel and
valence bond solid phases in a 2D antiferromagnet, was proposed as an example
of $2+1$D criticality fundamentally different from standard
Landau-Ginzburg-Wilson-Fisher {criticality}. In this work we present multiple
equivalent descriptions of deconfined QCPs, and use these to address the
possibility of enlarged emergent symmetries in the low energy limit. The
easy-plane deconfined QCP, besides its previously discussed self-duality, is
dual to $N_f = 2$ fermionic quantum electrodynamics (QED), which has its own
self-duality and hence may have an O(4)$\times Z_2^T$ symmetry. We propose
several dualities for the deconfined QCP with ${\mathrm{SU}(2)}$ spin symmetry
which together make natural the emergence of a previously suggested $SO(5)$
symmetry rotating the Néel and VBS orders. These emergent symmetries are
implemented anomalously. The associated infra-red theories can also be viewed
as surface descriptions of 3+1D topological paramagnets, giving further insight
into the dualities. We describe a number of numerical tests of these dualities.
We also discuss the possibility of ""pseudocritical"" behavior for deconfined
critical points, and the meaning of the dualities and emergent symmetries in
such a scenario.
",Physics
"  Magnetic oxyselenides have been the topic of research for several decades
being first of interest in the context of photoconductivity and
thermoelectricity owing to their intrinsic semiconducting properties and
ability to tune the energy gap through metal ion substitution. More recently,
interest in the oxyselenides has experienced a resurgence owing to the possible
relation to strongly correlated phenomena given the fact that many oxyslenides
share a similar structure to unconventional superconducting pnictides and
chalcogenides. The two dimensional nature of many oxyselenide systems also
draws an analogy to cuprate physics where a strong interplay between
unconventional electronic phases and localised magnetism has been studied for
several decades. It is therefore timely to review the physics of the
oxyselenides in the context of the broader field of strongly correlated
magnetism and electronic phenomena. Here we review the current status and
progress in this area of research with the focus on the influence of
lanthanides and transition metal ions on the intertwined magnetic and
electronic properties of oxyselenides. The emphasis of the review is on the
magnetic properties and comparisons are made with iron based pnictide and
chalcogenide systems.
",Physics
"  With seven planets, the TRAPPIST-1 system has the largest number of
exoplanets discovered in a single system so far. The system is of
astrobiological interest, because three of its planets orbit in the habitable
zone of the ultracool M dwarf. Assuming the planets are composed of
non-compressible iron, rock, and H$_2$O, we determine possible interior
structures for each planet. To determine how much tidal heat may be dissipated
within each planet, we construct a tidal heat generation model using a single
uniform viscosity and rigidity for each planet based on the planet's
composition. With the exception of TRAPPIST-1c, all seven of the planets have
densities low enough to indicate the presence of significant H$_2$O in some
form. Planets b and c experience enough heating from planetary tides to
maintain magma oceans in their rock mantles; planet c may have eruptions of
silicate magma on its surface, which may be detectable with next-generation
instrumentation. Tidal heat fluxes on planets d, e, and f are lower, but are
still twenty times higher than Earth's mean heat flow. Planets d and e are the
most likely to be habitable. Planet d avoids the runaway greenhouse state if
its albedo is $\gtrsim$ 0.3. Determining the planet's masses within $\sim0.1$
to 0.5 Earth masses would confirm or rule out the presence of H$_2$O and/or
iron in each planet, and permit detailed models of heat production and
transport in each planet. Understanding the geodynamics of ice-rich planets f,
g, and h requires more sophisticated modeling that can self-consistently
balance heat production and transport in both rock and ice layers.
",Physics
"  The Future Circular Collider (FCC), currently in the design phase, will
address many outstanding questions in particle physics. The technology to
succeed in this 100 km circumference collider goes beyond present limits.
Ultra-high vacuum conditions in the beam pipe is one essential requirement to
provide a smooth operation. Different physics phenomena as photon-, ion- and
electron- induced desorption and thermal outgassing of the chamber walls
challenge this requirement. This paper presents an analytical model and a
computer code PyVASCO that supports the design of a stable vacuum system by
providing an overview of all the gas dynamics happening inside the beam pipes.
A mass balance equation system describes the density distribution of the four
dominating gas species $\text{H}_2, \text{CH}_4$, $\text{CO}$ and
$\text{CO}_2$. An appropriate solving algorithm is discussed in detail and a
validation of the model including a comparison of the output to the readings of
LHC gauges is presented. This enables the evaluation of different designs for
the FCC.
",Physics
"  The temperature coefficients for all the directions of the Nagoya muon
telescope were obtained. The zenith angular dependence of the temperature
coefficients was studied.
",Physics
"  Below the phase transition temperature $Tc \simeq 10^{-3}$K He-3B has a
mixture of normal and superfluid components. Turbulence in this material is
carried predominantly by the superfluid component. We explore the statistical
properties of this quantum turbulence, stressing the differences from the
better known classical counterpart. To this aim we study the time-honored
Hall-Vinen-Bekarevich-Khalatnikov coarse-grained equations of superfluid
turbulence. We combine pseudo-spectral direct numerical simulations with
analytic considerations based on an integral closure for the energy flux. We
avoid the assumption of locality of the energy transfer which was used
previously in both analytic and numerical studies of the superfluid He-3B
turbulence. For T<0.37 Tc, with relatively weak mutual friction, we confirm the
previously found ""subcritical"" energy spectrum E(k), given by a superposition
of two power laws that can be approximated as $E(k)~ k^{-x}$ with an apparent
scaling exponent 5/3 <x(k)< 3. For T>0.37 Tc and with strong mutual friction,
we observed numerically and confirmed analytically the scale-invariant spectrum
$E(k)~ k^{-x}$ with a (k-independent) exponent x > 3 that gradually increases
with the temperature and reaches a value $x\simeq 9$ for $T\approx 0.72 Tc$. In
the near-critical regimes we discover a strong enhancement of intermittency
which exceeds by an order of magnitude the corresponding level in classical
hydrodynamic turbulence.
",Physics
"  The problem of determining those multiplets of forces, or sets of force
multiplets, acting at a set of points, such that there exists a truss
structure, or wire web, that can support these force multiplets with all the
elements of the truss or wire web being under tension, is considered. The
two-dimensional problem where the points are at the vertices of a convex
polygon is essentially solved: each multiplet of forces must be such that the
net anticlockwise torque around any vertex of the forces summed over any number
of consecutive points clockwise past the vertex must be non-negative; and one
can find a truss structure that supports under tension, and only supports,
those force multiplets in a convex polyhedron of force multiplets that is
generated by a finite number of force multiplets each satisfying the torque
condition. Progress is also made on the problem where only a subset of the
points are at the vertices of a convex polygon, and the other points are
inside. In particular, in the case where only one point is inside, an explicit
procedure is described for constructing a suitable truss, if one exists. An
alternative recipe to that provided by Guevara-Vasquez, Milton, and Onofrei
(2011), based on earlier work of Camar Eddine and Seppecher (2003), is given
for constructing a truss structure, with elements under either compression or
tension, that supports an arbitrary collection of balanced forces at the
vertices of a convex polygon. Finally some constraints are given on the forces
that a three-dimension truss, or wire web, under tension must satisfy.
",Physics
"  Due to their exceptional plasmonic properties, noble metals such as gold and
silver have been the materials of choice for the demonstration of various
plasmonic and nanophotonic phenomena. However, noble metals' softness, lack of
tailorability and low melting point along with challenges in thin film
fabrication and device integration have prevented the realization of real-life
plasmonic devices.In the recent years, titanium nitride (TiN) has emerged as a
promising plasmonic material with good metallic and refractory (high
temperature stable) properties. The refractory nature of TiN could enable
practical plasmonic devices operating at elevated temperatures for energy
conversion and harsh-environment industries such as gas and oil. Here we report
on the temperature dependent dielectric functions of TiN thin films of varying
thicknesses in the technologically relevant visible and near-infrared
wavelength range from 330 nm to 2000 nm for temperatures up to 900 0C using
in-situ high temperature ellipsometry. Our findings show that the complex
dielectric function of TiN at elevated temperatures deviates from the optical
parameters at room temperature, indicating degradation in plasmonic properties
both in the real and imaginary parts of the dielectric constant. However, quite
strikingly, the relative changes of the optical properties of TiN are
significantly smaller compared to its noble metal counterparts. Using
simulations, we demonstrate that incorporating the temperature-induced
deviations into the numerical models leads to significant differences in the
optical responses of high temperature nanophotonic systems. These studies hold
the key for accurate modeling of high temperature TiN based optical elements
and nanophotonic systems for energy conversion, harsh-environment sensors and
heat-assisted applications.
",Physics
"  Numerical simulations of beam-plasma instabilities may produce quantitatively
incorrect results because of unrealistically high initial noise from which the
instabilities develop. Of particular importance is the wakefield noise, the
potential perturbations that have a phase velocity which is equal to the beam
velocity. Controlling the noise level in simulations may offer the possibility
of extrapolating simulation results to the more realistic low-noise case. We
propose a novel method for generating wakefield noise with a controllable
amplitude by randomly located charged rods propagating ahead of the beam. We
also illustrate the method with particle-in-cell simulations. The generation of
this noise is not accompanied by parasitic Cherenkov radiation waves.
",Physics
"  We report on the result of a campaign to monitor 25 HATSouth candidates using
the K2 space telescope during Campaign 7 of the K2 mission. We discover
HATS-36b (EPIC 215969174b), a hot Jupiter with a mass of 2.79$\pm$0.40 M$_J$
and a radius of 1.263$\pm$0.045 R$_J$ which transits a solar-type G0V star
(V=14.386) in a 4.1752d period. We also refine the properties of three
previously discovered HATSouth transiting planets (HATS-9b, HATS-11b, and
HATS-12b) and search the K2 data for TTVs and additional transiting planets in
these systems. In addition we also report on a further three systems that
remain as Jupiter-radius transiting exoplanet candidates. These candidates do
not have determined masses, however pass all of our other vetting observations.
Finally we report on the 18 candidates which we are now able to classify as
eclipsing binary or blended eclipsing binary systems based on a combination of
the HATSouth data, the K2 data, and follow-up ground-based photometry and
spectroscopy. These range in periods from 0.7 days to 16.7 days, and down to
1.5 mmag in eclipse depths. Our results show the power of combining
ground-based imaging and spectroscopy with higher precision space-based
photometry, and serve as an illustration as to what will be possible when
combining ground-based observations with TESS data.
",Physics
"  Thermochemical models have been used in the past to constrain the deep oxygen
abundance in the gas and ice giant planets from tropospheric CO spectroscopic
measurements. Knowing the oxygen abundance of these planets is a key to better
understand their formation. These models have widely used dry and/or moist
adiabats to extrapolate temperatures from the measured values in the upper
troposphere down to the level where the thermochemical equilibrium between
H$_2$O and CO is established. The mean molecular mass gradient produced by the
condensation of H$_2$O stabilizes the atmosphere against convection and results
in a vertical thermal profile and H$_2$O distribution that departs
significantly from previous estimates. We revisit O/H estimates using an
atmospheric structure that accounts for the inhibition of the convection by
condensation. We use a thermochemical network and the latest observations of CO
in Uranus and Neptune to calculate the internal oxygen enrichment required to
satisfy both these new estimates of the thermal profile and the observations.
We also present the current limitations of such modeling.
",Physics
"  Recent advances in microelectromechanical systems often require
multifunctional materials, which are designed so as to optimize more than one
property. Using density functional theory calculations for alloyed nitride
systems, we illustrate how co-alloying a piezoelectric material (AlN) with
different nitrides helps tune both its piezoelectric and mechanical properties
simultaneously. Wurtzite AlN-YN alloys display increased piezoelectric response
with YN concentration, accompanied by mechanical softening along the
crystallographic c direction. Both effects increase the electromechanical
coupling coefficients relevant for transducers and actuators. Resonator
applications, however, require superior stiffness, thus leading to the need to
decouple the increased piezoelectric response from a softened lattice. We show
that co-alloying of AlN with YN and BN results in improved elastic properties
while retaining most of the piezoelectric enhancements from YN alloying. This
finding may lead to new avenues for tuning the design properties of
piezoelectrics through composition-property maps.
Keywords: piezoelectricity, electromechanical coupling, density functional
theory, co-alloying
",Physics
"  We investigate the normal state of the superconducting compound PuCoGa$_5$
using the combination of density functional theory (DFT) and dynamical mean
field theory (DMFT), with the continuous time quantum Monte Carlo (CTQMC) and
the vertex-corrected one-crossing approximation (OCA) as the impurity solvers.
Our DFT+DMFT(CTQMC) calculations suggest a strong tendency of Pu-5$f$ orbitals
to differentiate at low temperatures. The renormalized 5$f_{5/2}$ states
exhibit a Fermi-liquid behavior whereas one electron in the 5$f_{7/2}$ states
is at the edge of a Mott localization. We find that the orbital differentiation
is manifested as the removing of 5$f_{7/2}$ spectral weight from the Fermi
level relative to DFT. We corroborate these conclusions with DFT+DMFT(OCA)
calculations which demonstrate that 5$f_{5/2}$ electrons have a much larger
Kondo scale than the 5$f_{7/2}$.
",Physics
"  Spontaneous symmetry breaking (SSB) is an important phenomenon observed in
various fields including physics and biology. In this connection, we here show
that the trade-off between attractive and repulsive couplings can induce
spontaneous symmetry breaking in a homogeneous system of coupled oscillators.
With a simple model of a system of two coupled Stuart-Landau oscillators, we
demonstrate how the tendency of attractive coupling in inducing in-phase
synchronized (IPS) oscillations and the tendency of repulsive coupling in
inducing out-of-phase synchronized (OPS) oscillations compete with each other
and give rise to symmetry breaking oscillatory (SBO) states and interesting
multistabilities. Further, we provide explicit expressions for synchronized and
anti-synchronized oscillatory states as well as the so called oscillation death
(OD) state and study their stability. If the Hopf bifurcation parameter
(${\lambda}$) is greater than the natural frequency ($\omega$) of the system,
the attractive coupling favours the emergence of an anti-symmetric OD state via
a Hopf bifurcation whereas the repulsive coupling favours the emergence of a
similar state through a saddle-node bifurcation. We show that an increase in
the repulsive coupling not only destabilizes the IPS state but also facilitates
the re-entrance of the IPS state.
",Physics
"  Grid based binary holography (GBH) is an attractive method for patterning
with light or matter waves. It is an approximate technique in which different
holographic masks can be used to produce similar patterns. Here we present an
optimal design method for GBH masks that allows for freely selecting the
fraction of open holes in the mask from below 10% to above 90%. Open-fraction
is an important design parameter when making masks for use in lithography
systems. The method also includes a rescaling feature that potentially enables
a better contrast of the generated patterns. Through simulations we investigate
the contrast and robustness of the patterns formed by masks generated by the
proposed optimal design method. It is demonstrated that high contrast patterns
are achievable for a wide range of open-fractions. We conclude that reaching a
desired open-fraction is a trade-off with the contrast of the pattern generated
by the mask.
",Physics
"  GC-1 and GC-2 are two globular clusters (GCs) in the remote halo of M81 and
M82 in the M81 group discovered by Jang et al. using the {\it Hubble Space
Telescope} ({\it HST}) images. These two GCs were observed as part of the
Beijing--Arizona--Taiwan--Connecticut (BATC) Multicolor Sky Survey, using 14
intermediate-band filters covering a wavelength range of 4000--10000 \AA. We
accurately determine these two clusters' ages and masses by comparing their
spectral energy distributions (from 2267 to 20000~{\AA}, comprising photometric
data in the near-ultraviolet of the {\it Galaxy Evolution Explorer}, 14 BATC
intermediate-band, and Two Micron All Sky Survey near-infrared $JHK_{\rm s}$
filters) with theoretical stellar population-synthesis models, resulting in
ages of $15.50\pm3.20$ for GC-1 and $15.10\pm2.70$ Gyr for GC-2. The masses of
GC-1 and GC-2 obtained here are $1.77-2.04\times 10^6$ and $5.20-7.11\times
10^6 \rm~M_\odot$, respectively. In addition, the deep observations with the
Advanced Camera for Surveys and Wide Field Camera 3 on the {\it HST} are used
to provide the surface brightness profiles of GC-1 and GC-2. The structural and
dynamical parameters are derived from fitting the profiles to three different
models; in particular, the internal velocity dispersions of GC-1 and GC-2 are
derived, which can be compared with ones obtained based on spectral
observations in the future. For the first time, in this paper, the $r_h$ versus
$M_V$ diagram shows that GC-2 is an ultra-compact dwarf in the M81 group.
",Physics
"  Quantum confinement and interference often generate exotic properties in
nanostructures. One recent highlight is the experimental indication of a
magnetic phase transition in zigzag-edged graphene nanoribbons at the critical
ribbon width of about 7 nm [G. Z. Magda et al., Nature \textbf{514}, 608
(2014)]. Here we show theoretically that with further increase in the ribbon
width, the magnetic correlation of the two edges can exhibit an intriguing
oscillatory behavior between antiferromagnetic and ferromagnetic, driven by
acquiring the positive coherence between the two edges to lower the free
energy. The oscillation effect is readily tunable in applied magnetic fields.
These novel properties suggest new experimental manifestation of the edge
magnetic orders in graphene nanoribbons, and enhance the hopes of graphene-like
spintronic nanodevices functioning at room temperature.
",Physics
"  Two-dimensional (2D) transition metal dichalcogenides (TMDs) have recently
emerged as promising candidates for future electronics and optoelectronics.
While most of TMDs are intrinsic n-type semiconductors due to electron donating
which originates from chalcogen vacancies, obtaining intrinsic high-quality
p-type semiconducting TMDs has been challenging. Here, we report an
experimental approach to obtain intrinsic p-type Tungsten (W)-based TMDs by
substitutional Ta-doping. The obtained few-layer Ta-doped WSe2 (Ta0.01W0.99Se2)
field-effect transistor (FET) devices exhibit competitive p-type performances,
including ~10^6 current on/off at room temperature. We also demonstrate high
quality van der Waals (vdW) p-n heterojunctions based on Ta0.01W0.99Se2/MoS2
structure, which exhibit nearly ideal diode characteristics (with an ideality
factor approaching 1 and a rectification ratio up to 10^5) and excellent
photodetecting performance. Our study suggests that substitutional Ta-doping
holds great promise to realize intrinsic p-type W-based TMDs for future
electronic and photonic applications.
",Physics
"  The El Niño-Southern Oscillation (ENSO) is a mode of interannual
variability in the coupled equatorial Pacific coupled atmosphere/ocean system.
El Niño describes a state in which sea surface temperatures in the eastern
Pacific increase and upwelling of colder, deep waters diminishes. El Niño
events typically peak in boreal winter, but their strength varies irregularly
on decadal time scales. There were exceptionally strong El Niño events in
1982-83, 1997-98 and 2015-16 that affected weather on a global scale. Widely
publicized forecasts in 2014 predicted that the 2015-16 event would occur a
year earlier. Predicting the strength of El Niño is a matter of practical
concern due to its effects on hydroclimate and agriculture around the world.
This paper discusses the frequency and regularity of strong El Niño events in
the context of chaotic dynamical systems. We discover a mechanism that limits
their predictability in a conceptual ""recharge oscillator"" model of ENSO. Weak
seasonal forcing or noise in this model can induce irregular switching between
an oscillatory state that has strong El Niño events and a chaotic state that
lacks strong events, In this regime, the timing of strong El Niño events on
decadal time scales is unpredictable.
",Physics
"  We present a deep radio search in the Reticulum II dwarf spheroidal (dSph)
galaxy performed with the Australia Telescope Compact Array. Observations were
conducted at 16 cm wavelength, with an rms sensitivity of 0.01 mJy/beam, and
with the goal of searching for synchrotron emission induced by annihilation or
decay of weakly interacting massive particles (WIMPs). Data were complemented
with observations on large angular scales taken with the KAT-7 telescope. We
find no evidence for a diffuse emission from the dSph and we derive competitive
bounds on the WIMP properties. In addition, we detect more than 200 new
background radio sources. Among them, we show there are two compelling
candidates for being the radio counterpart of the possible gamma-ray emission
reported by other groups using Fermi-LAT data.
",Physics
"  Access to the transverse spin of light has unlocked new regimes in
topological photonics and optomechanics. To achieve the transverse spin of
nonzero longitudinal fields, various platforms that derive transversely
confined waves based on focusing, interference, or evanescent waves have been
suggested. Nonetheless, because of the transverse confinement inherently
accompanying sign reversal of the field derivative, the resulting transverse
spin handedness experiences spatial inversion, which leads to a mismatch
between the densities of the wavefunction and its spin component and hinders
the global observation of the transverse spin. Here, we reveal a globally pure
transverse spin in which the wavefunction density signifies the spin
distribution, by employing inverse molding of the eigenmode in the spin basis.
Starting from the target spin profile, we analytically obtain the potential
landscape and then show that the elliptic-hyperbolic transition around the
epsilon-near-zero permittivity allows for the global conservation of transverse
spin handedness across the topological interface between anisotropic
metamaterials. Extending to the non-Hermitian regime, we also develop
annihilated transverse spin modes to cover the entire Poincare sphere of the
meridional plane. Our results enable the complete transfer of optical energy to
transverse spinning motions and realize the classical analogy of 3-dimensional
quantum spin states.
",Physics
"  Material mixing induced by a Rayleigh-Taylor instability occurs ubiquitously
in either nature or engineering when a light fluid pushes against a heavy
fluid, accompanying with the formation and evolution of chaotic bubbles. Its
general evolution involves two mechanisms: bubble-merge and bubble-competition.
The former obeys a universa1 evolution law and has been well-studied, while the
latter depends on many factors and has not been well-recognized. In this paper,
we establish a theory for the latter to clarify and quantify the longstanding
open question: the dependence of bubbles evolution on the dominant factors of
arbitrary density ratio, broadband initial perturbations and various material
properties (e.g., viscosity, miscibility, surface tensor). Evolution of the
most important characteristic quantities, i.e., the diameter of dominant bubble
$D$ and the height of bubble zone $h$, is derived: (i) the $D$ expands
self-similarly with steady aspect ratio $\beta \equiv D/h \thickapprox (1{\rm{
+ }}A)/4$, depending only on dimensionless density ratio $A$, and (ii) the $h$
grows quadratically with constant growth coefficient $\alpha \equiv h/(Ag{t^2})
\thickapprox [2\phi/{\ln}(2{\eta _{\rm{0}}})]^2$, depending on both
dimensionless initial perturbation amplitude ${\eta _{\rm{0}}}$ and
material-property-associated linear growth rate ratio
$\phi\equiv\Gamma_{actual}/\Gamma_{ideal}\leqslant1$. The theory successfully
explains the continued puzzle about the widely varying $\alpha\in (0.02,0.12)$
in experiments and simulations, conducted at all value of $A \in (0,1)$ and
widely varying value of ${\eta _{\rm{0}}} \in [{10^{ - 7}},{10^{ - 2}}]$ with
different materials. The good agreement between theory and experiments implies
that majority of actual mixing depends on initial perturbations and material
properties, to which more attention should be paid in either natural or
engineering problems.
",Physics
"  The CMS apparatus was identified, a few years before the start of the LHC
operation at CERN, to feature properties well suited to particle-flow (PF)
reconstruction: a highly-segmented tracker, a fine-grained electromagnetic
calorimeter, a hermetic hadron calorimeter, a strong magnetic field, and an
excellent muon spectrometer. A fully-fledged PF reconstruction algorithm tuned
to the CMS detector was therefore developed and has been consistently used in
physics analyses for the first time at a hadron collider. For each collision,
the comprehensive list of final-state particles identified and reconstructed by
the algorithm provides a global event description that leads to unprecedented
CMS performance for jet and hadronic tau decay reconstruction, missing
transverse momentum determination, and electron and muon identification. This
approach also allows particles from pileup interactions to be identified and
enables efficient pileup mitigation methods. The data collected by CMS at a
centre-of-mass energy of 8 TeV show excellent agreement with the simulation and
confirm the superior PF performance at least up to an average of 20 pileup
interactions.
",Physics
"  A one-parameter family of long-range resonating valence bond (RVB) state on
the square lattice was previously proposed to describe a critical spin liquid
(SL) phase of the spin-$1/2$ frustrated Heisenberg model. We provide evidence
that this RVB state in fact also realises a topological (long-range entangled)
$\mathbb{Z}_2$ SL, limited by two transitions to critical SL phases. The
topological phase is naturally connected to the $\mathbb{Z}_2$ gauge symmetry
of the local tensor. This work shows that, on one hand, spin-$1/2$ topological
SL with $C_{4v}$ point group symmetry and $SU(2)$ spin rotation symmetry exists
on the square lattice and, on the other hand, criticality and nonbipartiteness
are compatible. We also point out that, strong similarities between our phase
diagram and the ones of classical interacting dimer models suggest both can be
described by similar Kosterlitz-Thouless transitions. This scenario is further
supported by the analysis of the one-dimensional boundary state.
",Physics
"  The behavior of a new Hysteretic Nonlinear Energy Sink (HNES) coupled to a
linear primary oscillator is investigated in shock mitigation. Apart from a
small mass and a nonlinear elastic spring of the Duffing oscillator, the HNES
is also comprised of a purely hysteretic and a linear elastic spring of
potentially negative stiffness, connected in parallel. The Bouc-Wen model is
used to describe the force produced by both the purely hysteretic and linear
elastic springs. Coupling the primary oscillator with the HNES three nonlinear
equations of motion are derived, in terms of the two displacements and the
dimensionless hysteretic variable, which are integrated numerically using the
analog equation method. The performance of the HNES is examined by quantifying
the percentage of the initially induced energy in the primary system that is
passively transferred and dissipated by the HNES. Remarkable results are
achieved for a wide range of initial input energies. The great performance of
the HNES is mostly evidenced when the linear spring stiffness takes on negative
values.
",Physics
"  A unified viewpoint on the van Vleck and Herman-Kluk propagators in Hilbert
space and their recently developed counterparts in Wigner representation is
presented. It is shown that the numerical protocol for the Herman-Kluk
propagator, which contains the van Vleck one as a particular case, coincides in
both representations. The flexibility of the Wigner version in choosing the
Gaussians' width for the underlying coherent states, being not bound to minimal
uncertainty, is investigated numerically on prototypical potentials. Exploiting
this flexibility provides neither qualitative nor quantitative improvements.
Thus, the well-established Herman-Kluk propagator in Hilbert space remains the
best choice to date given the large number of semiclassical developments and
applications based on it.
",Physics
"  It is well known that the addition of noise in a multistable system can
induce random transitions between stable states. The rate of transition can be
characterised in terms of the noise-free system's dynamics and the added noise:
for potential systems in the presence of asymptotically low noise the
well-known Kramers' escape time gives an expression for the mean escape time.
This paper examines some general properties and examples of transitions between
local steady and oscillatory attractors within networks: the transition rates
at each node may be affected by the dynamics at other nodes. We use first
passage time theory to explain some properties of scalings noted in the
literature for an idealised model of initiation of epileptic seizures in small
systems of coupled bistable systems with both steady and oscillatory
attractors. We focus on the case of sequential escapes where a steady attractor
is only marginally stable but all nodes start in this state. As the nodes
escape to the oscillatory regime, we assume that the transitions back are very
infrequent in comparison. We quantify and characterise the resulting sequences
of noise-induced escapes. For weak enough coupling we show that a master
equation approach gives a good quantitative understanding of sequential
escapes, but for strong coupling this description breaks down.
",Physics
"  The unusually high surface tension of room temperature liquid metal is
molding it as unique material for diverse newly emerging areas. However, unlike
its practices on earth, such metal fluid would display very different behaviors
when working in space where gravity disappears and surface property dominates
the major physics. So far, few direct evidences are available to understand
such effect which would impede further exploration of liquid metal use for
space. Here to preliminarily probe into this intriguing issue, a low cost
experimental strategy to simulate microgravity environment on earth was
proposed through adopting bridges with high enough free falling distance as the
test platform. Then using digital cameras amounted along x, y, z directions on
outside wall of the transparent container with liquid metal and allied solution
inside, synchronous observations on the transient flow and transformational
activities of liquid metal were performed. Meanwhile, an unmanned aerial
vehicle was adopted to record the whole free falling dynamics of the test
capsule from the far end which can help justify subsequent experimental
procedures. A series of typical fundamental phenomena were thus observed as:
(a) A relatively large liquid metal object would spontaneously transform from
its original planar pool state into a sphere and float in the container if
initiating the free falling; (b) The liquid metal changes its three-dimensional
shape due to dynamic microgravity strength due to free falling and rebound of
the test capsule; and (c) A quick spatial transformation of liquid metal
immersed in the solution can easily be induced via external electrical fields.
The mechanisms of the surface tension driven liquid metal actuation in space
were interpreted. All these findings indicated that microgravity effect should
be fully treated in developing future generation liquid metal space
technologies.
",Physics
"  We present large-field (4.25~$\times$~3.75 deg$^2$) mapping observations
toward the Galactic region centered at $l = 150\arcdeg, b = 3.5\arcdeg$ in the
$J = 1-0$ emission line of CO isotopologues ($^{12}$CO, $^{13}$CO, and
C$^{18}$O), using the 13.7 m millimeter-wavelength telescope of the Purple
Mountain Observatory. Based on the $^{13}$CO observations, we reveal a
filamentary cloud in the Local Arm at a velocity range of $-$0.5 to
6.5~km~s$^{-1}$. This molecular cloud contains 1 main filament and 11
sub-filaments, showing the so-called ""ridge-nest"" structure. The main filament
and three sub-filaments are also detected in the C$^{18}$O line. The velocity
structures of most identified filaments display continuous distribution with
slight velocity gradients. The measured median excitation temperature, line
width, length, width, and linear mass of the filaments are $\sim$9.28~K,
0.85~km~s$^{-1}$, 7.30~pc, 0.79~pc, and 17.92~$M_\sun$~pc$^{-1}$, respectively,
assuming a distance of 400~pc. We find that the four filaments detected in the
C$^{18}$O line are thermally supercritical, and two of them are in the
virialized state, and thus tend to be gravitationally bound. We identify in
total 146 $^{13}$CO clumps in the cloud, about 77$\%$ of the clumps are
distributed along the filaments. About 56$\%$ of the virialized clumps are
found to be associated with the supercritical filaments. Three young stellar
object (YSO) candidates are also identified in the supercritical filaments,
based on the complementary infrared (IR) data. These results indicate that the
supercritical filaments, especially the virialized filaments, may contain
star-forming activities.
",Physics
"  The classical ground state magnetic response of the Heisenberg model when
rotationally invariant exchange interactions of integer order q>1 are added is
found to be discontinuous, even though the interactions lack magnetic
anisotropy. This holds even in the case of bipartite lattices which are not
frustrated, as well as for the frustrated triangular lattice. The total number
of discontinuities is associated with even-odd effects as it depends on the
parity of q via the relative strength of the bilinear and higher order exchange
interactions, and increases with q. These results demonstrate that the precise
form of the microscopic interactions is important for the ground state
magnetization response.
",Physics
"  In order to understand the exoplanet, you need to understand its parent star.
Astrophysical parameters of extrasolar planets are directly and indirectly
dependent on the properties of their respective host stars. These host stars
are very frequently the only visible component in the systems. This book
describes our work in the field of characterization of exoplanet host stars
using interferometry to determine angular diameters, trigonometric parallax to
determine physical radii, and SED fitting to determine effective temperatures
and luminosities. The interferometry data are based on our decade-long survey
using the CHARA Array. We describe our methods and give an update on the status
of the field, including a table with the astrophysical properties of all stars
with high-precision interferometric diameters out to 150 pc (status Nov 2016).
In addition, we elaborate in more detail on a number of particularly
significant or important exoplanet systems, particularly with respect to (1)
insights gained from transiting exoplanets, (2) the determination of system
habitable zones, and (3) the discrepancy between directly determined and
model-based stellar radii. Finally, we discuss current and future work
including the calibration of semi-empirical methods based on interferometric
data.
",Physics
"  We have studied the longitudinal spin Seebeck effect in a polar
antiferromagnet $\alpha$-Cu$_{2}$V$_{2}$O$_{7}$ in contact with a Pt film.
Below the antiferromagnetic transition temperature of
$\alpha$-Cu$_{2}$V$_{2}$O$_{7}$, spin Seebeck voltages whose magnetic field
dependence is similar to that reported in antiferromagnetic MnF$_{2}$$\mid$Pt
bilayers are observed. Though a small weak-ferromagnetic moment appears owing
to the Dzyaloshinskii-Moriya interaction in $\alpha$-Cu$_{2}$V$_{2}$O$_{7}$,
the magnetic field dependence of spin Seebeck voltages is found to be
irrelevant to the weak ferromagnetic moments. The dependences of the spin
Seebeck voltages on magnetic fields and temperature are analyzed by a magnon
spin current theory. The numerical calculation of spin Seebeck voltages using
magnetic parameters of $\alpha$-Cu$_{2}$V$_{2}$O$_{7}$ determined by previous
neutron scattering studies reveals that the magnetic-field and temperature
dependences of the spin Seebeck voltages for
$\alpha$-Cu$_{2}$V$_{2}$O$_{7}$$\mid$Pt are governed by the changes in magnon
lifetimes with magnetic fields and temperature.
",Physics
"  In this study, an alloy phase-field model is used to simulate solidification
microstructures at different locations within a solidified molten pool. The
temperature gradient $G$ and the solidification velocity $V$ are obtained from
a macroscopic heat transfer finite element simulation and provided as input to
the phase-field model. The effects of laser beam speed and the location within
the melt pool on the primary arm spacing and on the extent of Nb partitioning
at the cell tips are investigated. Simulated steady-state primary spacings are
compared with power law and geometrical models. Cell tip compositions are
compared to a dendrite growth model. The extent of non-equilibrium interface
partitioning of the phase-field model is investigated. Although the phase-field
model has an anti-trapping solute flux term meant to maintain local interface
equilibrium, we have found that during simulations it was insufficient at
maintaining equilibrium. This is due to the fact that the additive
manufacturing solidification conditions fall well outside the allowed limits of
this flux term.
",Physics
"  In this paper, theoretical and numerical studies of perfect/nearly-perfect
conversion of a plane wave into a surface wave are presented. The problem of
determining the electromagnetic properties of an inhomogeneous lossless
boundary which would fully transform an incident plane wave into a surface wave
propagating along the boundary is considered. An approximate field solution
which produces a slowly growing surface wave and satisfies the energy
conservation law is discussed and numerically demonstrated. The results of the
study are of great importance for the future development of such devices as
perfect leaky-wave antennas and can potentially lead to many novel
applications.
",Physics
"  The dissipation of small-scale perturbations in the early universe produces a
distortion in the blackbody spectrum of cosmic microwave background photons. In
this work, we propose to use these distortions as a probe of the microphysics
of dark matter on scales $1\,\textrm{Mpc}^{-1}\lesssim k \lesssim
10^{4}\,\textrm{Mpc}^{-1}$. We consider in particular models in which the dark
matter is kinetically coupled to either neutrinos or photons until shortly
before recombination, and compute the photon heating rate and the resultant
$\mu$-distortion in both cases. We show that the $\mu$-parameter is generally
enhanced relative to $\Lambda$CDM for interactions with neutrinos, and may be
either enhanced or suppressed in the case of interactions with photons. The
deviations from the $\Lambda$CDM signal are potentially within the sensitivity
reach of a PRISM-like experiment if $\sigma_{\textrm{DM}-\gamma} \gtrsim
1.1\times10^{-30} \left(m_{\textrm{DM}}/\textrm{GeV}\right) \textrm{cm}^{2}$
and $\sigma_{\textrm{DM}-\nu} \gtrsim 4.8\times 10^{-32}
\left(m_{\textrm{DM}}/\textrm{GeV}\right) \textrm{cm}^{2}$ for time-independent
cross sections, and $\sigma^{0}_{\textrm{DM}-\gamma} \gtrsim 1.8 \times
10^{-40} \left(m_{\textrm{DM}}/\textrm{GeV}\right) \textrm{cm}^{2}$ and
$\sigma^{0}_{\textrm{DM}-\nu} \gtrsim 2.5 \times 10^{-47}
\left(m_{\textrm{DM}}/\textrm{GeV}\right) \textrm{cm}^{2}$ for cross sections
scaling as temperature squared, coinciding with the parameter regions in which
late kinetic decoupling may serve as a solution to the small-scale crisis.
Furthermore, these $\mu$-distortion signals differ from those of warm dark
matter (no deviation from $\Lambda$CDM) and a suppressed primordial power
spectrum (strongly suppressed or a negative $\mu$-parameter), demonstrating
that CMB spectral distortion can potentially be used to distinguish between
solutions to the small-scale crisis.
",Physics
"  Maps on a parameter space for expressing distribution functions are exactly
derived from the Perron-Frobenius equations for a generalized Boole transform
family. Here the generalized Boole transform family is a one-parameter family
of maps where it is defined on a subset of the real line and its probability
distribution function is the Cauchy distribution with some parameters. With
this reduction, some relations between the statistical picture and the orbital
one are shown. From the viewpoint of information geometry, the parameter space
can be identified with a statistical manifold, and then it is shown that the
derived maps can be characterized. Also, with an induced symplectic structure
from a statistical structure, symplectic and information geometric aspects of
the derived maps are discussed.
",Physics
"  The high-energy non-thermal universe is dominated by power law-like spectra.
Therefore results in high-energy astronomy are often reported as parameters of
power law fits, or, in the case of a non-detection, as an upper limit assuming
the underlying unseen spectrum behaves as a power law. In this paper I
demonstrate a simple and powerful one-to-one relation of the integral upper
limit in the two dimensional power law parameter space into the spectrum
parameter space and use this method to unravel the so far convoluted question
of the sensitivity of astroparticle telescopes.
",Physics
"  Modern surveys have provided the astronomical community with a flood of
high-dimensional data, but analyses of these data often occur after their
projection to lower-dimensional spaces. In this work, we introduce a local
two-sample hypothesis test framework that an analyst may directly apply to data
in their native space. In this framework, the analyst defines two classes based
on a response variable of interest (e.g. higher-mass galaxies versus lower-mass
galaxies) and determines at arbitrary points in predictor space whether the
local proportions of objects that belong to the two classes significantly
differs from the global proportion.
Our framework has a potential myriad of uses throughout astronomy; here, we
demonstrate its efficacy by applying it to a sample of 2487 i-band-selected
galaxies observed by the HST ACS in four of the CANDELS program fields. For
each galaxy, we have seven morphological summary statistics along with an
estimated stellar mass and star-formation rate. We perform two studies: one in
which we determine regions of the seven-dimensional space of morphological
statistics where high-mass galaxies are significantly more numerous than
low-mass galaxies, and vice-versa, and another study where we use SFR in place
of mass. We find that we are able to identify such regions, and show how
high-mass/low-SFR regions are associated with concentrated and undisturbed
galaxies while galaxies in low-mass/high-SFR regions appear more extended
and/or disturbed than their high-mass/low-SFR counterparts.
",Physics
"  In this paper, we extend several time reversible numerical integrators to
solve the Lorentz force equations from second order accuracy to higher order
accuracy for relativistic charged particle tracking in electromagnetic fields.
A fourth order algorithm is given explicitly and tested with numerical
examples. Such high order numerical integrators can significantly save the
computational cost by using a larger step size in comparison to the second
order integrators.
",Physics
"  In this work, we make two improvements on the staggered grid hydrodynamics
(SGH) Lagrangian scheme for modeling 2-dimensional compressible multi-material
flows on triangular mesh. The first improvement is the construction of a
dynamic local remeshing scheme for preventing mesh distortion. The remeshing
scheme is similar to many published algorithms except that it introduces some
special operations for treating grids around multi-material interfaces. This
makes the simulation of extremely deforming and topology-variable
multi-material processes possible, such as the complete process of a heavy
fluid dipping into a light fluid. The second improvement is the construction of
an Euler-like flow on each edge of the mesh to count for the ""edge-bending""
effect, so as to mitigate the ""checkerboard"" oscillation that commonly exists
in Lagrangian simulations, especially the triangular mesh based simulations.
Several typical hydrodynamic problems are simulated by the improved staggered
grid Lagrangian hydrodynamic method to test its performance.
",Physics
"  An infinite chain of driven-dissipative condensate spins with uniform
nearest-neighbor coherent coupling is solved analytically and investigated
numerically. Above a critical occupation threshold the condensates undergo
spontaneous spin bifurcation (becoming magnetized) forming a binary chain of
spin-up or spin-down states. Minimization of the bifurcation threshold
determines the magnetic order as a function of the coupling strength. This
allows control of multiple magnetic orders via adiabatic (slow ramping of)
pumping. In addition to ferromagnetic and anti-ferromagnetic ordered states we
show the formation of a paired-spin ordered state $\left|\dots \uparrow
\uparrow \downarrow \downarrow \dots \right. \rangle$ as a consequence of the
phase degree of freedom between condensates.
",Physics
"  Coherent control of the resonant response in spatially extended
optomechanical structures is complicated by the fact that the optical drive is
affected by the back-action from the generated phonons. Here we report a new
approach to coherent control based on stimulated Raman-like scattering, in
which the optical pressure can remain unaffected by the induced vibrations even
in the regime of strong optomechanical interactions. We demonstrate
experimentally coherent control of flexural vibrations simultaneously along the
whole length of a dual-nanoweb fiber, by imprinting steps in the relative phase
between the components of a two-frequency pump signal,the beat frequency being
chosen to match a flexural resonance. Furthermore, sequential switching of the
relative phase at time intervals shorter than the lifetime of the vibrations
reduces their amplitude to a constant value that is fully adjustable by tuning
the phase-modulation depth and switching rate. The results may trigger new
developments in silicon photonics, since such coherent control uniquely
decouples the amplitude of optomechanical oscillations from power-dependent
thermal effects and nonlinear optical loss.
",Physics
"  The quantum Schrodinger-Newton equation is solved for a self-gravitating Bose
gas at zero temperature. It is derived that the density is non-uniform and a
central hollow cavity exists. The radial distribution of the particle momentum
is uniform. It is shown that a quantum black hole can be formed only above a
certain critical mass. The temperature effect is accounted for via the
Schrodinger-Poisson-Boltzmann equation, where low and high temperature
solutions are obtained. The theoretical analysis is extended to a strong
interacting gas via the Schrodinger-Yukawa equation, showing that the atomic
nuclei are also hollow. Hollow self-gravitating Fermi gases are described by
the Thomas-Fermi equation.
",Physics
"  The behavior of an interior test particle in the secular 3-body problem has
been studied extensively. A well-known feature is the Lidov-Kozai resonance in
which the test particle's argument of periapse librates about $\pm 90^\circ$
and large oscillations in eccentricity and inclination are possible. Less
explored is the inverse problem: the dynamics of an exterior test particle and
an interior perturber. We survey numerically the inverse secular problem,
expanding the potential to hexadecapolar order and correcting an error in the
published expansion. Four secular resonances are uncovered that persist in full
$N$-body treatments (in what follows, $\varpi$ and $\Omega$ are the longitudes
of periapse and of ascending node, $\omega$ is the argument of periapse, and
subscripts 1 and 2 refer to the inner perturber and outer test particle): (i)
an orbit-flipping quadrupole resonance requiring a non-zero perturber
eccentricity $e_1$, in which $\Omega_2-\varpi_1$ librates about $\pm 90^\circ$;
(ii) a hexadecapolar resonance (the ""inverse Kozai"" resonance) for perturbers
that are circular or nearly so and inclined by $I \simeq 63^\circ/117^\circ$,
in which $\omega_2$ librates about $\pm 90^\circ$ and which can vary the
particle eccentricity by $\Delta e_2 \simeq 0.2$ and lead to orbit crossing;
(iii) an octopole ""apse-aligned"" resonance at $I \simeq 46^\circ/107^\circ$
wherein $\varpi_2 - \varpi_1$ librates about $0^\circ$ and $\Delta e_2$ grows
with $e_1$; and (iv) an octopole resonance at $I \simeq 73^\circ/134^\circ$
wherein $\varpi_2 + \varpi_1 - 2 \Omega_2$ librates about $0^\circ$ and $\Delta
e_2$ can be as large as 0.3 for small $e_1 \neq 0$. The more eccentric the
perturber, the more the particle's eccentricity and inclination vary; also,
more polar orbits are more chaotic. Our inverse solutions may be applied to the
Kuiper belt and debris disks, circumbinary planets, and stellar systems.
",Physics
"  The use of computers in statistical physics is common because the sheer
number of equations that describe the behavior of an entire system particle by
particle often makes it impossible to solve them exactly. Monte Carlo methods
form a particularly important class of numerical methods for solving problems
in statistical physics. Although these methods are simple in principle, their
proper use requires a good command of statistical mechanics, as well as
considerable computational resources. The aim of this paper is to demonstrate
how the usage of widely accessible graphics cards on personal computers can
elevate the computing power in Monte Carlo simulations by orders of magnitude,
thus allowing live classroom demonstration of phenomena that would otherwise be
out of reach. As an example, we use the public goods game on a square lattice
where two strategies compete for common resources in a social dilemma
situation. We show that the second-order phase transition to an absorbing phase
in the system belongs to the directed percolation universality class, and we
compare the time needed to arrive at this result by means of the main processor
and by means of a suitable graphics card. Parallel computing on graphics
processing units has been developed actively during the last decade, to the
point where today the learning curve for entry is anything but steep for those
familiar with programming. The subject is thus ripe for inclusion in graduate
and advanced undergraduate curricula, and we hope that this paper will
facilitate this process in the realm of physics education. To that end, we
provide a documented source code for an easy reproduction of presented results
and for further development of Monte Carlo simulations of similar systems.
",Physics
"  We present the second release of value-added catalogues of the LAMOST
Spectroscopic Survey of the Galactic Anticentre (LSS-GAC DR2). The catalogues
present values of radial velocity $V_{\rm r}$, atmospheric parameters ---
effective temperature $T_{\rm eff}$, surface gravity log$g$, metallicity
[Fe/H], $\alpha$-element to iron (metal) abundance ratio [$\alpha$/Fe]
([$\alpha$/M]), elemental abundances [C/H] and [N/H], and absolute magnitudes
${\rm M}_V$ and ${\rm M}_{K_{\rm s}}$ deduced from 1.8 million spectra of 1.4
million unique stars targeted by the LSS-GAC since September 2011 until June
2014. The catalogues also give values of interstellar reddening, distance and
orbital parameters determined with a variety of techniques, as well as proper
motions and multi-band photometry from the far-UV to the mid-IR collected from
the literature and various surveys. Accuracies of radial velocities reach
5kms$^{-1}$ for late-type stars, and those of distance estimates range between
10 -- 30 per cent, depending on the spectral signal-to-noise ratios. Precisions
of [Fe/H], [C/H] and [N/H] estimates reach 0.1dex, and those of [$\alpha$/Fe]
and [$\alpha$/M] reach 0.05dex. The large number of stars, the contiguous sky
coverage, the simple yet non-trivial target selection function and the robust
estimates of stellar radial velocities and atmospheric parameters, distances
and elemental abundances, make the catalogues a valuable data set to study the
structure and evolution of the Galaxy, especially the solar-neighbourhood and
the outer disk.
",Physics
"  The statistical distribution of galaxies is a powerful probe to constrain
cosmological models and gravity. In particular the matter power spectrum $P(k)$
brings information about the cosmological distance evolution and the galaxy
clustering together. However the building of $P(k)$ from galaxy catalogues
needs a cosmological model to convert angles on the sky and redshifts into
distances, which leads to difficulties when comparing data with predicted
$P(k)$ from other cosmological models, and for photometric surveys like LSST.
The angular power spectrum $C_\ell(z_1,z_2)$ between two bins located at
redshift $z_1$ and $z_2$ contains the same information than the matter power
spectrum, is free from any cosmological assumption, but the prediction of
$C_\ell(z_1,z_2)$ from $P(k)$ is a costly computation when performed exactly.
The Angpow software aims at computing quickly and accurately the auto
($z_1=z_2$) and cross ($z_1 \neq z_2$) angular power spectra between redshift
bins. We describe the developed algorithm, based on developments on the
Chebyshev polynomial basis and on the Clenshaw-Curtis quadrature method. We
validate the results with other codes, and benchmark the performance. Angpow is
flexible and can handle any user defined power spectra, transfer functions, and
redshift selection windows. The code is fast enough to be embedded inside
programs exploring large cosmological parameter spaces through the
$C_\ell(z_1,z_2)$ comparison with data. We emphasize that the Limber's
approximation, often used to fasten the computation, gives wrong $C_\ell$
values for cross-correlations.
",Physics
"  Although the existence of quasi-bound rotational levels of the $X^+ \
^2\Sigma_g^+$ ground state of H$_2^+$ has been predicted a long time ago, these
states have never been observed. Calculated positions and widths of quasi-bound
rotational levels located close to the top of the centrifugal barriers have not
been reported either. Given the role that such states play in the recombination
of H(1s) and H$^+$ to form H$_2^+$, this lack of data may be regarded as one of
the largest unknown aspects of this otherwise accurately known fundamental
molecular cation. We present measurements of the positions and widths of the
lowest-lying quasi-bound rotational levels of H$_2^+$ and compare the
experimental results with the positions and widths we calculate using a
potential model for the $X^+$ state of H$_2^+$ which includes adiabatic,
nonadiabatic, relativistic and radiative corrections to the Born-Oppenheimer
approximation.
",Physics
"  A new Short-Orbit Spectrometer (SOS) has been constructed and installed
within the experimental facility of the A1 collaboration at Mainz Microtron
(MAMI), with the goal to detect low-energy pions. It is equipped with a
Browne-Buechner magnet and a detector system consisting of two helium-ethane
based drift chambers and a scintillator telescope made of five layers. The
detector system allows detection of pions in the momentum range of 50 - 147
MeV/c, which corresponds to 8.7 - 63 MeV kinetic energy. The spectrometer can
be placed at a distance range of 54 - 66 cm from the target center. Two
collimators are available for the measurements, one having 1.8 msr aperture and
the other having 7 msr aperture. The Short-Orbit Spectrometer has been
successfully calibrated and used in coincidence measurements together with the
standard magnetic spectrometers of the A1 collaboration.
",Physics
"  Gould's Belt is a flat local system composed of young OB stars, molecular
clouds and neutral hydrogen within 500 pc from the Sun. It is inclined about 20
degrees to the galactic plane and its velocity field significantly deviates
from rotation around the distant center of the Milky Way. We discuss possible
models of its origin: free expansion from a point or from a ring, expansion of
a shell, or a collision of a high velocity cloud with the plane of the Milky
Way. Currently, no convincing model exists. Similar structures are identified
in HI and CO distribution in our and other nearby galaxies.
",Physics
"  We study the formation of massive black holes in the first star clusters. We
first locate star-forming gas clouds in proto-galactic haloes of $\gtrsim
\!10^7\,{\rm M}_{\odot}$ in cosmological hydrodynamics simulations and use them
to generate the initial conditions for star clusters with masses of $\sim
\!10^5\,{\rm M}_{\odot}$. We then perform a series of direct-tree hybrid
$N$-body simulations to follow runaway stellar collisions in the dense star
clusters. In all the cluster models except one, runaway collisions occur within
a few million years, and the mass of the central, most massive star reaches
$\sim \!400-1900\,{\rm M}_{\odot}$. Such very massive stars collapse to leave
intermediate-mass black holes (IMBHs). The diversity of the final masses may be
attributed to the differences in a few basic properties of the host haloes such
as mass, central gas velocity dispersion, and mean gas density of the central
core. Finally, we derive the IMBH mass to cluster mass ratios, and compare them
with the observed black hole to bulge mass ratios in the present-day Universe.
",Physics
"  We present the first theoretical evidence of zero magnetic field topological
(anomalous) thermal Hall effect due to Weyl magnons. Here, we consider Weyl
magnons in stacked noncoplanar frustrated kagomé antiferromagnets recently
proposed by Owerre, [arXiv:1708.04240]. The Weyl magnons in this system result
from macroscopically broken time-reversal symmetry by the scalar spin chirality
of noncoplanar chiral spin textures. Most importantly, they come from the
lowest excitation, therefore they can be easily observed experimentally at low
temperatures due to the population effect. Similar to electronic Weyl nodes
close to the Fermi energy, Weyl magnon nodes in the lowest excitation are the
most important. Indeed, we show that the topological (anomalous) thermal Hall
effect in this system arises from nonvanishing Berry curvature due to Weyl
magnon nodes in the lowest excitation, and it depends on their distribution
(distance) in momentum space. The present result paves the way to directly
probe low excitation Weyl magnons and macroscopically broken time-reversal
symmetry in three-dimensional frustrated magnets with the anomalous thermal
Hall effect.
",Physics
"  Intersystem crossing is a radiationless process that can take place in a
molecule irradiated by UV-Vis light, thereby playing an important role in many
environmental, biological and technological processes. This paper reviews
different methods to describe intersystem crossing dynamics, paying attention
to semiclassical trajectory theories, which are especially interesting because
they can be applied to large systems with many degrees of freedom. In
particular, a general trajectory surface hopping methodology recently developed
by the authors, which is able to include non-adiabatic and spin-orbit couplings
in excited-state dynamics simulations, is explained in detail. This method,
termed SHARC, can in principle include any arbitrary coupling, what makes it
generally applicable to photophysical and photochemical problems, also those
including explicit laser fields. A step-by-step derivation of the main
equations of motion employed in surface hopping based on the fewest-switches
method of Tully, adapted for the inclusion of spin-orbit interactions, is
provided. Special emphasis is put on describing the different possible choices
of the electronic bases in which spin-orbit can be included in surface hopping,
highlighting the advantages and inconsistencies of the different approaches.
",Physics
"  Galaxy clustering on small scales is significantly under-predicted by
sub-halo abundance matching (SHAM) models that populate (sub-)haloes with
galaxies based on peak halo mass, $M_{\rm peak}$. SHAM models based on the peak
maximum circular velocity, $V_{\rm peak}$, have had much better success. The
primary reason $M_{\rm peak}$ based models fail is the relatively low abundance
of satellite galaxies produced in these models compared to those based on
$V_{\rm peak}$. Despite success in predicting clustering, a simple $V_{\rm
peak}$ based SHAM model results in predictions for galaxy growth that are at
odds with observations. We evaluate three possible remedies that could ""save""
mass-based SHAM: (1) SHAM models require a significant population of ""orphan""
galaxies as a result of artificial disruption/merging of sub-haloes in modern
high resolution dark matter simulations; (2) satellites must grow significantly
after their accretion; and (3) stellar mass is significantly affected by halo
assembly history. No solution is entirely satisfactory. However, regardless of
the particulars, we show that popular SHAM models based on $M_{\rm peak}$
cannot be complete physical models as presented. Either $V_{\rm peak}$ truly is
a better predictor of stellar mass at $z\sim 0$ and it remains to be seen how
the correlation between stellar mass and $V_{\rm peak}$ comes about, or SHAM
models are missing vital component(s) that significantly affect galaxy
clustering.
",Physics
"  High-dose-rate brachytherapy is a tumor treatment method where a highly
radioactive source is brought in close proximity to the tumor. In this paper we
develop a simulated annealing algorithm to optimize the dwell times at
preselected dwell positions to maximize tumor coverage under dose-volume
constraints on the organs at risk. Compared to existing algorithms, our
algorithm has advantages in terms of speed and objective value and does not
require an expensive general purpose solver. Its success mainly depends on
exploiting the efficiency of matrix multiplication and a careful selection of
the neighboring states. In this paper we outline its details and make an
in-depth comparison with existing methods using real patient data.
",Physics
"  Using atomic force microscopy (AFM) we investigated the interaction of
amyloid beta (Ab) (1 42) peptide with chemically modified surfaces in order to
better understand the mechanism of amyloid toxicity, which involves interaction
of amyloid with cell membrane surfaces. We compared the structure and density
of Ab fibrils on positively and negatively charged as well as hydrophobic
chemically modified surfaces at physiologically relevant conditions.
",Physics
"  For a given many-electron molecule, it is possible to define a corresponding
one-electron Schrödinger equation, using potentials derived from simple
atomic densities, whose solution predicts fairly accurate molecular orbitals
for single- and multi-determinant wavefunctions for the molecule. The energy is
not predicted and must be evaluated by calculating Coulomb and exchange
interactions over the predicted orbitals. Potentials are found by minimizing
the energy of predicted wavefunctions. There exist slightly less accurate
average potentials for first-row atoms that can be used without modification in
different molecules. For a test set of molecules representing different bonding
environments, these average potentials give wavefunctions with energies that
deviate from exact self-consistent field or configuration interaction energies
by less than 0.08 eV and 0.03 eV per bond or valence electron pair,
respectively.
",Physics
"  We introduce a new model for the formation and evolution of supermassive
black holes (SMBHs) in the RAMSES code using sink particles, improving over
previous work the treatment of gas accretion and dynamical evolution. This new
model is tested against a suite of high-resolution simulations of an isolated,
gas-rich, cooling halo. We study the effect of various feedback models on the
SMBH growth and its dynamics within the galaxy.
In runs without any feedback, the SMBH is trapped within a massive bulge and
is therefore able to grow quickly, but only if the seed mass is chosen larger
than the minimum Jeans mass resolved by the simulation. We demonstrate that, in
the absence of supernovae (SN) feedback, the maximum SMBH mass is reached when
Active Galactic Nucleus (AGN) heating balances gas cooling in the nuclear
region.
When our efficient SN feedback is included, it completely prevents bulge
formation, so that massive gas clumps can perturb the SMBH orbit, and reduce
the accretion rate significantly. To overcome this issue, we propose an
observationally motivated model for the joint evolution of the SMBH and a
parent nuclear star cluster (NSC), which allows the SMBH to remain in the
nuclear region, grow fast and resist external perturbations. In this scenario,
however, SN feedback controls the gas supply and the maximum SMBH mass now
depends on the balance between AGN heating and gravity. We conclude that
SMBH/NSC co-evolution is crucial for the growth of SMBH in high-z galaxies, the
progenitors of massive elliptical today.
",Physics
"  We present a theoretical assessment of the expected temporal rates of change
of periods ($\dot{\Pi}$) for low-mass ($M_{\star}/M_{\sun} \lesssim 0.45$) and
extremely low-mass (ELM, $M_{\star}/M_{\sun} \lesssim 0.18-0.20$) white-dwarf
stars, based on fully evolutionary low-mass He-core white dwarf and pre-white
dwarf models. Our analysis is based on a large set of adiabatic periods of
radial and nonradial pulsation modes computed on a suite of low-mass He-core
white dwarf and pre-white dwarf models with masses ranging from $0.1554$ to
$0.4352 M_{\sun}$. We compute the secular rates of period change of radial
($\ell= 0$) and nonradial ($\ell= 1, 2$) $g$ and $p$ modes for stellar models
representative of ELMV and pre-ELMV stars, as well as for stellar objects that
are evolving just before the occurrence of CNO flashes at the early cooling
branches. We found that the theoretically expected magnitude of $\dot{\Pi}$ of
$g$ modes for pre-ELMVs are by far larger than for ELMVs. In turn, $\dot{\Pi}$
of $g$ modes for models evolving before the occurrence of CNO flashes are
larger than the maximum values of the rates of period change predicted for
pre-ELMV stars. Regarding $p$ and radial modes, we found that the larger
absolute values of $\dot{\Pi}$ correspond to pre-ELMV models. We conclude that
any eventual measurement of a rate of period change for a given pulsating
low-mass pre-white dwarf or white dwarf star could shed light about its
evolutionary status. Also, in view of the systematic difficulties in the
spectroscopic classification of stars of the ELM Survey, an eventual
measurement of $\dot{\Pi}$ could help to confirm that a given pulsating star is
an authentic low-mass white dwarf and not a star from another stellar
population.
",Physics
"  Predicting the future state of a system has always been a natural motivation
for science and practical applications. Such a topic, beyond its obvious
technical and societal relevance, is also interesting from a conceptual point
of view. This owes to the fact that forecasting lends itself to two equally
radical, yet opposite methodologies. A reductionist one, based on the first
principles, and the naive inductivist one, based only on data. This latter view
has recently gained some attention in response to the availability of
unprecedented amounts of data and increasingly sophisticated algorithmic
analytic techniques. The purpose of this note is to assess critically the role
of big data in reshaping the key aspects of forecasting and in particular the
claim that bigger data leads to better predictions. Drawing on the
representative example of weather forecasts we argue that this is not generally
the case. We conclude by suggesting that a clever and context-dependent
compromise between modelling and quantitative analysis stands out as the best
forecasting strategy, as anticipated nearly a century ago by Richardson and von
Neumann.
",Physics
"  In several geophysical applications, such as full waveform inversion and data
modelling, we are facing the solution of inhomogeneous Helmholtz equation. The
difficulties of solving the Helmholtz equa- tion are two fold. Firstly, in the
case of large scale problems we cannot calculate the inverse of the Helmholtz
operator directly. Hence, iterative algorithms should be implemented. Secondly,
the Helmholtz operator is non-unitary and non-diagonalizable which in turn
deteriorates the performances of the iterative algorithms (especially for high
wavenumbers). To overcome this issue, we need to im- plement proper
preconditioners for a Krylov subspace method to solve the problem efficiently.
In this paper we incorporated shifted-Laplace operators to precondition the
system of equations and then generalized minimal residual (GMRES) method used
to solve the problem iteratively. The numerical results show the performance of
the preconditioning operator in improving the convergence rate of the GMRES
algorithm for data modelling case. In the companion paper we discussed the
application of preconditioned data modelling algorithm in the context of
frequency domain full waveform inversion. However, the analysis of the degree
of suitability of the preconditioners in the solution of Helmholtz equation is
an ongoing field of study.
",Physics
"  Dark matter with momentum- or velocity-dependent interactions with nuclei has
shown significant promise for explaining the so-called Solar Abundance Problem,
a longstanding discrepancy between solar spectroscopy and helioseismology. The
best-fit models are all rather light, typically with masses in the range of 3-5
GeV. This is exactly the mass range where dark matter evaporation from the Sun
can be important, but to date no detailed calculation of the evaporation of
such models has been performed. Here we carry out this calculation, for the
first time including arbitrary velocity- and momentum-dependent interactions,
thermal effects, and a completely general treatment valid from the optically
thin limit all the way through to the optically thick regime. We find that
depending on the dark matter mass, interaction strength and type, the mass
below which evaporation is relevant can vary from 1 to 4 GeV. This has the
effect of weakening some of the better-fitting solutions to the Solar Abundance
Problem, but also improving a number of others. As a by-product, we also
provide an improved derivation of the capture rate that takes into account
thermal and optical depth effects, allowing the standard result to be smoothly
matched to the well-known saturation limit.
",Physics
"  We present a thermal emission spectrum of the bloated hot Jupiter HAT-P-32Ab
from a single eclipse observation made in spatial scan mode with the Wide Field
Camera 3 (WFC3) aboard the Hubble Space Telescope (HST). The spectrum covers
the wavelength regime from 1.123 to 1.644 microns which is binned into 14
eclipse depths measured to an averaged precision of 104 parts-per million. The
spectrum is unaffected by a dilution from the close M-dwarf companion
HAT-P-32B, which was fully resolved. We complemented our spectrum with
literature results and performed a comparative forward and retrieval analysis
with the 1D radiative-convective ATMO model. Assuming solar abundance of the
planet atmosphere, we find that the measured spectrum can best be explained by
the spectrum of a blackbody isothermal atmosphere with Tp = 1995 +/- 17K, but
can equally-well be described by a spectrum with modest thermal inversion. The
retrieved spectrum suggests emission from VO at the WFC3 wavelengths and no
evidence of the 1.4 micron water feature. The emission models with temperature
profiles decreasing with height are rejected at a high confidence. An
isothermal or inverted spectrum can imply a clear atmosphere with an absorber,
a dusty cloud deck or a combination of both. We find that the planet can have
continuum of values for the albedo and recirculation, ranging from high albedo
and poor recirculation to low albedo and efficient recirculation. Optical
spectroscopy of the planet's day-side or thermal emission phase curves can
potentially resolve the current albedo with recirculation degeneracy.
",Physics
"  Semiconductor quantum dots (QDs) doped with magnetic impurities have been a
focus of continuous research for a couple of decades. A significant effort has
been devoted to studies of magnetic polarons (MP) in these nanostructures.
These collective states arise through exchange interaction between a carrier
confined in a QD and localized spins of the magnetic impurities (typically:
Mn). We discuss our theoretical description of various MP properties in
self-assembled QDs. We present a self-consistent, temperature-dependent
approach to MPs formed by a valence band hole. We use the Luttinger-Kohn k.p
Hamiltonian to account for the important effects of spin-orbit interaction.
",Physics
"  We present GAMER-2, a GPU-accelerated adaptive mesh refinement (AMR) code for
astrophysics. It provides a rich set of features, including adaptive
time-stepping, several hydrodynamic schemes, magnetohydrodynamics,
self-gravity, particles, star formation, chemistry and radiative processes with
GRACKLE, data analysis with yt, and memory pool for efficient object
allocation. GAMER-2 is fully bitwise reproducible. For the performance
optimization, it adopts hybrid OpenMP/MPI/GPU parallelization and utilizes
overlapping CPU computation, GPU computation, and CPU-GPU communication. Load
balancing is achieved using a Hilbert space-filling curve on a level-by-level
basis without the need to duplicate the entire AMR hierarchy on each MPI
process. To provide convincing demonstrations of the accuracy and performance
of GAMER-2, we directly compare with Enzo on isolated disk galaxy simulations
and with FLASH on galaxy cluster merger simulations. We show that the physical
results obtained by different codes are in very good agreement, and GAMER-2
outperforms Enzo and FLASH by nearly one and two orders of magnitude,
respectively, on the Blue Waters supercomputers using $1-256$ nodes. More
importantly, GAMER-2 exhibits similar or even better parallel scalability
compared to the other two codes. We also demonstrate good weak and strong
scaling using up to 4096 GPUs and 65,536 CPU cores, and achieve a uniform
resolution as high as $10{,}240^3$ cells. Furthermore, GAMER-2 can be adopted
as an AMR+GPUs framework and has been extensively used for the wave dark matter
($\psi$DM) simulations. GAMER-2 is open source (available at
this https URL) and new contributions are welcome.
",Physics
"  Efficient methods are proposed, for computing integrals appeaing in
electronic structure calculations. The methods consist of two parts: the first
part is to represent the integrals as contour integrals and the second one is
to evaluate the contour integrals by the Clenshaw-Curtis quadrature. The
efficiency of the proposed methods is demonstrated through numerical
experiments.
",Physics
"  Tensor network methods are taking a central role in modern quantum physics
and beyond. They can provide an efficient approximation to certain classes of
quantum states, and the associated graphical language makes it easy to describe
and pictorially reason about quantum circuits, channels, protocols, open
systems and more. Our goal is to explain tensor networks and some associated
methods as quickly and as painlessly as possible. Beginning with the key
definitions, the graphical tensor network language is presented through
examples. We then provide an introduction to matrix product states. We conclude
the tutorial with tensor contractions evaluating combinatorial counting
problems. The first one counts the number of solutions for Boolean formulae,
whereas the second is Penrose's tensor contraction algorithm, returning the
number of $3$-edge-colorings of $3$-regular planar graphs.
",Physics
"  We introduce the notion of a dynamical topological order parameter (DTOP)
that characterises dynamical quantum phase transitions (DQPTs) occurring in the
subsequent temporal evolution of ""two dimensional"" closed quantum systems,
following a quench (or ramping) of a parameter of the Hamiltonian, {which
generalizes the notion of DTOP introduced in Budich and Heyl, Phys. Rev. B 93,
085416 (2016) for one-dimensional situations}. This DTOP is obtained from the
""gauge-invariant"" Pancharatnam phase extracted from the Loschmidt overlap,
i.e., the modulus of the overlap between the initially prepared state and its
time evolved counterpart reached following a temporal evolution generated by
the time-independent final Hamiltonian. This generic proposal is illustrated
considering DQPTs occurring in the subsequent temporal evolution following a
sudden quench of the staggered mass of the topological Haldane model on a
hexagonal lattice where it stays fixed to zero or unity and makes a
discontinuous jump between these two values at critical times at which DQPTs
occur.
",Physics
"  The optical vortex coronagraph (OVC) is one of the promising ways for direct
imaging exoplanets because of its small inner working angle and high
throughput. This paper presents the design and laboratory demonstration
performance at 633nm and 1520nm of the OVC based on liquid crystal polymers
(LCP). Two LCPs has been manufactured in partnership with a commercial vendor.
The OVC can deliver a good performance in laboratory test and achieve the
contrast of the order 10^-6 at angular distance 3{\lambda}/D, which is able to
image the giant exoplanets at a young stage in combination with extreme
adaptive optics.
",Physics
"  El Nino is probably the most influential climate phenomenon on interannual
time scales. It affects the global climate system and is associated with
natural disasters and serious consequences in many aspects of human life.
However, the forecasting of the onset and in particular the magnitude of El
Nino are still not accurate, at least more than half a year in advance. Here,
we introduce a new forecasting index based on network links representing the
similarity of low frequency temporal temperature anomaly variations between
different sites in the El Nino 3.4 region. We find that significant upward
trends and peaks in this index forecast with high accuracy both the onset and
magnitude of El Nino approximately 1 year ahead. The forecasting procedure we
developed improves in particular the prediction of the magnitude of El Nino and
is validated based on several, up to more than a century long, datasets.
",Physics
"  Capable of reaching similar magnitudes to large megathrust earthquakes
($M_w>7$), slow slip events play a major role in accommodating tectonic motion
on plate boundaries. These slip transients are the slow release of built-up
tectonic stress that are geodetically imaged as a predominantly aseismic
rupture, which is smooth in both time and space. We demonstrate here that large
slow slip events are in fact a cluster of short-duration slow transients. Using
a dense catalog of low-frequency earthquakes as a guide, we investigate the
$M_w7.5$ slow slip event that occurred in 2006 along the subduction interface
40~km beneath Guerrero, Mexico. We show that while the long-period surface
displacement as recorded by GPS suggests a six month duration, motion in the
direction of tectonic release only sporadically occurs over 55 days and its
surface signature is attenuated by rapid relocking of the plate interface.These
results demonstrate that our current conceptual model of slow and continuous
rupture is an artifact of low-resolution geodetic observations of a
superposition of small, clustered slip events. Our proposed description of slow
slip as a cluster of slow transients implies that we systematically
overestimate the duration $T$ and underestimate the moment magnitude $M$ of
large slow slip events.
",Physics
"  We consider the long-term collisional and dynamical evolution of solid
material orbiting in a narrow annulus near the Roche limit of a white dwarf.
With orbital velocities of 300 km/sec, systems of solids with initial
eccentricity $e \gtrsim 10^{-3}$ generate a collisional cascade where objects
with radii $r \lesssim$ 100--300 km are ground to dust. This process converts
1-100 km asteroids into 1 $\mu$m particles in $10^2 - 10^6$ yr. Throughout this
evolution, the swarm maintains an initially large vertical scale height $H$.
Adding solids at a rate $\dot{M}$ enables the system to find an equilibrium
where the mass in solids is roughly constant. This equilibrium depends on
$\dot{M}$ and $r_0$, the radius of the largest solid added to the swarm. When
$r_0 \lesssim$ 10 km, this equilibrium is stable. For larger $r_0$, the mass
oscillates between high and low states; the fraction of time spent in high
states ranges from 100% for large $\dot{M}$ to much less than 1% for small
$\dot{M}$. During high states, the stellar luminosity reprocessed by the solids
is comparable to the excess infrared emission observed in many metallic line
white dwarfs.
",Physics
"  We investigate the Goos-Hanchen (G-H) shifts reflected and transmitted by a
yttrium-iron-garnet (YIG) film for both normal and oblique incidence. It is
found that the nonreciprocity effect of the MO material does not only result in
a nonvanishing reflected shift at normal incidence, but also leads to a
slab-thickness-independent term which breaks the symmetry between the reflected
and transmitted shifts at oblique incidence. The asymptotic behaviors of the
normal-incidence reflected shift are obtained in the vicinity of two
characteristic frequencies corresponding to a minimum reflectivity and a total
reflection, respectively. Moreover, the coexistence of two types of
negative-reflected-shift (NRS) at oblique incidence is discussed. We show that
the reversal of the shifts from positive to negative values can be realized by
tuning the magnitude of applied magnetic field, the frequency of incident wave
and the slab thickness as well as the incident angle. In addition, we further
investigate two special cases for practical purposes: the reflected shift with
a total reflection and the transmitted shift with a total transmission.
Numerical simulations are also performed to verify our analytical results.
",Physics
"  Electrons that are confined to a single Landau level in a two dimensional
electron gas realize the effects of strong electron-electron repulsion in its
purest form. The kinetic energy of individual electrons is completely quenched
and all physical properties are dictated solely by many-body effects. A
remarkable consequence is the emergence of new quasiparticles with fractional
charge and exotic quantum statistics of which the most exciting ones are
non-Abelian quasiparticles. A non-integer quantized thermal Hall conductance
$\kappa_{xy}$ (in units of temperature times the universal constant $\pi^2
k_B^2 /3 h$; $h$ is the Planck constant and $k_B$ the Boltzmann constant)
necessitates the existence of such quasiparticles. It has been predicted, and
verified numerically, that such states are realized in the clean half-filled
first Landau level of electrons with Coulomb repulsion, with $\kappa_{xy}$
being either $3/2$ or $7/2$. Excitingly, a recent experiment has indeed
observed a half-integer value, which was measured, however, to be
$\kappa_{xy}=5/2$. We resolve this contradiction within a picture where smooth
disorder results in the formation of mesoscopic puddles with locally
$\kappa_{xy}=3/2$ or $7/2$. Interactions between these puddles generate a
coherent macroscopic state, which is reflected in an extended plateau with
quantized $\kappa_{xy}=5/2$. The topological properties of quasiparticles at
large distances are determined by the macroscopic phase, and not by the
microscopic puddle where they reside. In principle, the same mechanism might
also allow non-Abelian quasiparticles to emerge from a system comprised of
microscopic Abelian puddles.
",Physics
"  We present an approach to testing the gravitational redshift effect using the
RadioAstron satellite. The experiment is based on a modification of the Gravity
Probe A scheme of nonrelativistic Doppler compensation and benefits from the
highly eccentric orbit and ultra-stable atomic hydrogen maser frequency
standard of the RadioAstron satellite. Using the presented techniques we expect
to reach an accuracy of the gravitational redshift test of order $10^{-5}$, a
magnitude better than that of Gravity Probe A. Data processing is ongoing, our
preliminary results agree with the validity of the Einstein Equivalence
Principle.
",Physics
"  Recent works on planetary migration show that the orbital structure of the
Kuiper belt can be very well reproduced if before the onset of the planetary
instability Neptune underwent a long-range planetesimal-driven migration up to
$\sim$28 au. However, considering that all giant planets should have been
captured in mean motion resonances among themselves during the gas-disk phase,
it is not clear whether such a very specific evolution for Neptune is possible,
nor whether the instability could have happened at late times. Here, we first
investigate which initial resonant configuration of the giant planets can be
compatible with Neptune being extracted from the resonant chain and migrating
to $\sim$28 au before that the planetary instability happened. We address the
late instability issue by investigating the conditions where the planets can
stay in resonance for about 400 My. Our results indicate that this can happen
only in the case where the planetesimal disk is beyond a specific minimum
distance $\delta_{stab}$ from Neptune. Then, if there is a sufficient amount of
dust produced in the planetesimal disk, that drifts inwards, Neptune can enter
in a slow dust-driven migration phase for hundreds of Mys until it reaches a
critical distance $\delta_{mig}$ from the disk. From that point, faster
planetesimal-driven migration takes over and Neptune continues migrating
outward until the instability happens. We conclude that, although an early
instability reproduces more easily the evolution of Neptune required to explain
the structure of the Kuiper belt, such evolution is also compatible with a late
instability.
",Physics
"  The stability against quench is one of the main issue to be pursued in a
superconducting material which should be able to perform at very high levels of
current densities. Here we focus on the connection between the critical current
$I_c$ and the quenching current $I^*$ associated to the so-called flux-flow
instability phenomenon, which sets in as an abrupt transition from the flux
flow state to the normal state. To this purpose, we analyze several
current-voltage characteristics of three types of iron-based thin films,
acquired at different temperature and applied magnetic field values. For these
samples, we discuss the impact of a possible coexistence of intrinsic
electronic mechanisms and extrinsic thermal effects on the quenching current
dependence upon the applied magnetic field. The differences between the
quenching current and the critical current are reported also in the case of
predominant intrinsic mechanisms. Carrying out a comparison with
high-temperature cuprate superconductors, we suggest which material can be the
best trade-off between maximum operating temperature, higher upper critical
field and stability under high current bias.
",Physics
"  We report a precise measurement of hyperfine structure in the $ \rm
{3\,S_{1/2}} $ state of the odd isotope of Li, namely $ \rm {^7Li} $. The state
is excited from the ground $ \rm {2\,S_{1/2}} $ state (which has the same
parity) using two single-photon transitions via the intermediate $ \rm
{2\,P_{3/2}} $ state. The value of the hyperfine constant we measure is $ A =
93.095(52)$ MHz, which resolves two discrepant values reported in the
literature measured using other techniques. Our value is also consistent with
theoretical calculations.
",Physics
"  Three dimensional magnetohydrodynamical simulations were carried out in order
to perform a new polarization study of the radio emission of the supernova
remnant SN 1006. These simulations consider that the remnant expands into a
turbulent interstellar medium (including both magnetic field and density
perturbations). Based on the referenced-polar angle technique, a statistical
study was done on observational and numerical magnetic field position-angle
distributions. Our results show that a turbulent medium with an adiabatic index
of 1.3 can reproduce the polarization properties of the SN 1006 remnant. This
statistical study reveals itself as a useful tool for obtaining the orientation
of the ambient magnetic field, previous to be swept up by the main supernova
remnant shock.
",Physics
"  We rewrite Poynting's theorem, already used in a previous publication
(Treumann & Baumjohann 2017) to derive relations between the turbulent magnetic
and electric power spectral densities, to make explicit where the mechanical
contributions enter. We then make explicit use of the relativistic
transformation of the turbulent electric fluctuations to obtain expressions
which depend only on the magnetic and velocity fluctuations. Any electric
fluctuations play just an intermediate role. Equations are constructed for the
turbulent conductivity spectrum in Alfvénic and non-Alfvénic turbulence in
extension of the results in the above citation. An observation-based discussion
of their use in application to solar wind turbulence is given. The inertial
range solar wind turbulence exhibits signs of chaos and self-organisation.
",Physics
"  We have discovered a novel candidate for a spin liquid state in a ruthenium
oxide composed of dimers of $S = $ 3/2 spins of Ru$^{5+}$,Ba$_3$ZnRu$_2$O$_9$.
This compound lacks a long range order down to 37 mK, which is a temperature
5000-times lower than the magnetic interaction scale of around 200 K. Partial
substitution for Zn can continuously vary the magnetic ground state from an
antiferromagnetic order to a spin-gapped state through the liquid state. This
indicates that the spin-liquid state emerges from a delicate balance of inter-
and intra-dimer interactions, and the spin state of the dimer plays a vital
role. This unique feature should realize a new type of quantum magnetism.
",Physics
"  Magnetic nanoparticles are promising systems for biomedical applications and
in particular for Magnetic Fluid Hyperthermia, a promising therapy that
utilizes the heat released by such systems to damage tumor cells. We present an
experimental study of the physical properties that influences the capability of
heat release, i.e. the Specific Loss Power, SLP, of three biocompatible
ferrofluid samples having a magnetic core of maghemite with different core
diameter d= 10.2, 14.6 and 19.7 nm. The SLP was measured as a function of
frequency f and intensity of the applied alternating magnetic field H, and it
turned out to depend on the core diameter, as expected. The results allowed us
to highlight experimentally that the physical mechanism responsible for the
heating is size-dependent and to establish, at applied constant frequency, the
phenomenological functional relationship SLP=cH^x, with 2<x<3 for all samples.
The x-value depends on sample size and field frequency/ intensity, here chosen
in the typical range of operating magnetic hyperthermia devices. For the
smallest sample, the effective relaxation time Teff=19.5 ns obtained from SLP
data is in agreement with the value estimated from magnetization data, thus
confirming the validity of the Linear Response Theory model for this system at
properly chosen field intensity and frequency.
",Physics
"  In this paper we use detailed Monte Carlo simulations to demonstrate that
liquid xenon (LXe) can be used to build a Cherenkov-based TOF-PET, with an
intrinsic coincidence resolving time (CRT) in the vicinity of 10 ps. This
extraordinary performance is due to three facts: a) the abundant emission of
Cherenkov photons by liquid xenon; b) the fact that LXe is transparent to
Cherenkov light; and c) the fact that the fastest photons in LXe have
wavelengths higher than 300 nm, therefore making it possible to separate the
detection of scintillation and Cherenkov light. The CRT in a Cherenkov LXe
TOF-PET detector is, therefore, dominated by the resolution (time jitter)
introduced by the photosensors and the electronics. However, we show that for
sufficiently fast photosensors (e.g, an overall 40 ps jitter, which can be
achieved by current micro-channel plate photomultipliers) the overall CRT
varies between 30 and 55 ps, depending of the detection efficiency. This is
still one order of magnitude better than commercial CRT devices and improves by
a factor 3 the best CRT obtained with small laboratory prototypes.
",Physics
"  Numerical simulations of the G.O. Roberts dynamo are presented. Dynamos both
with and without a significant mean field are obtained. Exact bounds are
derived for the total energy which conform with the Kolmogorov phenomenology of
turbulence. Best fits to numerical data show the same functional dependences as
the inequalities obtained from optimum theory.
",Physics
"  We report a methodology for measuring 85Kr/Kr isotopic abundances using Atom
Trap Trace Analysis (ATTA) that increases sample measurement throughput by over
an order of magnitude to 6 samples per 24 hours. The noble gas isotope 85Kr
(half-life = 10.7 yr) is a useful tracer for young groundwater in the age range
of 5-50 years. ATTA, an efficient and selective laser-based atom counting
method, has recently been applied to 85Kr/Kr isotopic abundance measurements,
requiring 5-10 microliters of krypton gas at STP extracted from 50-100 L of
water. Previously a single such measurement required 48 hours. Our new method
demonstrates that we can measure 85Kr/Kr ratios with 3-5% relative uncertainty
every 4 hours, on average, with the same sample requirements.
",Physics
"  We have investigated the electronic states and spin polarization of
half-metallic ferromagnet CrO$_2$ (100) epitaxial films by bulk-sensitive
spin-resolved photoemission spectroscopy with a focus on non-quasiparticle
(NQP) states derived from electron-magnon interactions. We found that the
averaged values of the spin polarization are approximately 100% and 40% at 40 K
and 300 K, respectively. This is consistent with the previously reported result
[H. Fujiwara et al., Appl. Phys. Lett. 106, 202404 (2015).]. At 100 K, peculiar
spin depolarization was observed at the Fermi level ($E_{F}$), which is
supported by theoretical calculations predicting NQP states. This suggests the
possible appearance of NQP states in CrO$_2$. We also compare the temperature
dependence of our spin polarizations with that of the magnetization.
",Physics
"  The article introduces a new concept of structure, defined, echoing J. A.
Wheeler's concept of ""law without law,"" as a ""structure without law,"" and a new
philosophical viewpoint, that of structural nnnrealism, and considers how this
concept and this viewpoint work in quantum theory in general and quantum
information theory in particular. It takes as its historical point of departure
W. Heisenberg's discovery of quantum mechanics, which, the article argues,
could, in retrospect, be considered in quantum-informational terms, while,
conversely, quantum information theory could be seen in Heisenbergian terms.
The article takes advantage of the circumstance that any instance of quantum
information is a ""structure""--an organization of elements, ultimately bits, of
classical information, manifested in measuring instruments. While, however,
this organization can, along with the observed behavior of measuring
instruments, be described by means of classical physics, it cannot be predicted
by means of classical physics, but only, probabilistically or statistically, by
means of quantum mechanics, or in high-energy physics, by means of quantum
field theory (or possibly some alternative theories within each scope). By
contrast, the emergences of this information and of this structure cannot, in
the present view, be described by either classical or quantum theory, or
possibly by any other means, which leads to the concept of ""structure without
law"" and the viewpoint of structural nnnrealism. The article also considers,
from this perspective, some recent work in quantum information theory.
",Physics
"  We characterize the response of the quiet time (no substorms or storms)
large-scale ionospheric transient equivalent currents to north-south and
south-north IMF turnings by using a dynamical network of ground-based
magnetometers. Canonical correlation between all pairs of SuperMAG magnetometer
stations in the Northern Hemisphere (magnetic latitude (MLAT) 50-82$^{\circ}$)
is used to establish the extent of near-simultaneous magnetic response between
regions of magnetic local time-MLAT. Parameters and maps that describe
spatial-temporal correlation are used to characterize the system and its
response to the turnings aggregated over several hundred events. We find that
regions that experience large increases in correlation post turning coincide
with typical locations of a two-cell convection system and are influenced by
the interplanetary magnetic field $\mathit{B}_{y}$. The time between the
turnings reaching the magnetopause and a network response is found to be
$\sim$8-10 min and correlation in the dayside occurs 2-8 min before that in the
nightside.
",Physics
"  The Mu2e experiment will search for coherent, neutrino-less conversion of
muons into electrons in the Coulomb field of an aluminum nucleus with a
sensitivity of four orders of magnitude better than previous experiments. The
signature of this process is an electron with energy nearly equal to the muon
mass. Mu2e relies on a precision (0.1%) measurement of the outgoing electron
momentum to separate signal from background. In order to achieve this goal,
Mu2e has chosen a very low-mass straw tracker, made of 20,736 5 mm diameter
thin-walled (15 $\mu$m) Mylar straws, held under tension to avoid the need for
supports within the active volume, and arranged in an approximately 3 m long by
0.7 m radius cylinder, operated in vacuum and a 1 T magnetic field. Groups of
96 straws are assembled into modules, called panels. We present the prototype
and the assembly procedure for a Mu2e tracker panel built at Fermilab
",Physics
"  Despite a long record of intense efforts, the basic mechanisms by which
dissipation emerges from the microscopic dynamics of a relativistic fluid still
elude a complete understanding. In particular, no unique pathway from kinetic
theory to hydrodynamics has been identified as yet, with different approaches
leading to different values of the transport coefficients. In this Letter, we
approach the problem by matching data from lattice kinetic simulations with
analytical predictions. Our numerical results provide neat evidence in favour
of the Chapman-Enskog procedure, as suggested by recently theoretical analyses,
along with qualitative hints at the basic reasons why the Chapman-Enskog
expansion might be better suited than Grad's method to capture the emergence of
dissipative effects in relativistic fluids.
",Physics
"  We report on a combined study of the de Haas-van Alphen effect and angle
resolved photoemission spectroscopy on single crystals of the metallic
delafossite PdRhO$_2$ rounded off by \textit{ab initio} band structure
calculations. A high sensitivity torque magnetometry setup with SQUID readout
and synchrotron-based photoemission with a light spot size of
$~50\,\mu\mathrm{m}$ enabled high resolution data to be obtained from samples
as small as $150\times100\times20\,(\mu\mathrm{m})^3$. The Fermi surface shape
is nearly cylindrical with a rounded hexagonal cross section enclosing a
Luttinger volume of 1.00(1) electrons per formula unit.
",Physics
"  When a vortex refracts surface waves, the momentum flux carried by the waves
changes direction and the waves induce a reaction force on the vortex. We study
experimentally the resulting vortex distortion. Incoming surface gravity waves
impinge on a steady vortex of velocity $U_0$ driven magneto-hydrodynamically at
the bottom of a fluid layer. The waves induce a shift of the vortex center in
the direction transverse to wave propagation, together with a decrease in
surface vorticity. We interpret these two phenomena in the framework introduced
by Craik and Leibovich (1976): we identify the dimensionless Stokes drift
$S=U_s/U_0$ as the relevant control parameter, $U_s$ being the Stokes drift
velocity of the waves. We propose a simple vortex line model which indicates
that the shift of the vortex center originates from a balance between vorticity
advection by the Stokes drift and self-advection of the vortex. The decrease in
surface vorticity is interpreted as a consequence of vorticity expulsion by the
fast Stokes drift, which confines it at depth. This purely hydrodynamic process
is analogous to the magnetohydrodynamic expulsion of magnetic field by a
rapidly moving conductor through the electromagnetic skin effect. We study
vorticity expulsion in the limit of fast Stokes drift and deduce that the
surface vorticity decreases as $1/S$, a prediction which is compatible with the
experimental data. Such wave-induced vortex distortions have important
consequences for the nonlinear regime of wave refraction: the refraction angle
rapidly decreases with wave intensity.
",Physics
"  From a super extension of the Wadati, Konno and Ichikawa scheme for
integrable systems and using a $\mathrm{osp(1,2)}$ valued connection 1-form we
obtain super generalizations for the Short Pulse equation as well for the
Elastic Beam equation.
",Physics
"  Using simulations with a whole-atmosphere chemistry-climate model nudged by
meteorological analyses, global satellite observations of nitrogen oxide (NO)
and water vapour by the Sub-Millimetre Radiometer instrument (SMR), of
temperature by the Microwave Limb Sounder (MLS), as well as local radar
observations, this study examines the recent major stratospheric sudden warming
accompanied by an elevated stratopause event (ESE) that occurred in January
2013. We examine dynamical processes during the ESE, including the role of
planetary wave, gravity wave and tidal forcing on the initiation of the descent
in the mesosphere-lower thermosphere (MLT) and its continuation throughout the
mesosphere and stratosphere, as well as the impact of model eddy diffusion. We
analyse the transport of NO and find the model underestimates the large descent
of NO compared to SMR observations. We demonstrate that the discrepancy arises
abruptly in the MLT region at a time when the resolved wave forcing and the
planetary wave activity increase, just before the elevated stratopause reforms.
The discrepancy persists despite doubling the model eddy diffusion. While the
simulations reproduce an enhancement of the semi-diurnal tide following the
onset of the 2013 SSW, corroborating new meteor radar observations at high
northern latitudes over Trondheim (63.4$^{\circ}$N), the modelled tidal
contribution to the forcing of the mean meridional circulation and to the
descent is a small portion of the resolved wave forcing, and lags it by about
ten days.
",Physics
"  Two-dimensional (2D) materials, such as graphene and MoS2, have been
attracting wide interest in surface enhancement Raman spectroscopy. This
perspective gives an overview of recent developments in 2D materials'
application in surface enhanced Raman spectroscopy. This review focuses on the
applications of using bare 2D materials and metal/2D material hybrid substrate
for Raman enhancement. The Raman enhancing mechanism of 2D materials will also
be discussed. The progress covered herein shows great promise for widespread
adoption of 2D materials in SERS application.
",Physics
"  It has been argued in [EPL {\bf 90} (2010) 50004], entitled {\it Essential
discreteness in generalized thermostatistics with non-logarithmic entropy},
that ""continuous Hamiltonian systems with long-range interactions and the
so-called q-Gaussian momentum distributions are seen to be outside the scope of
non-extensive statistical mechanics"". The arguments are clever and appealing.
We show here that, however, some mathematical subtleties render them
unconvincing
",Physics
"  The variational tensor network renormalization approach to two-dimensional
(2D) quantum systems at finite temperature is applied for the first time to a
model suffering the notorious quantum Monte Carlo sign problem --- the orbital
$e_g$ model with spatially highly anisotropic orbital interactions.
Coarse-graining of the tensor network along the inverse temperature $\beta$
yields a numerically tractable 2D tensor network representing the Gibbs state.
Its bond dimension $D$ --- limiting the amount of entanglement --- is a natural
refinement parameter. Increasing $D$ we obtain a converged order parameter and
its linear susceptibility close to the critical point. They confirm the
existence of finite order parameter below the critical temperature $T_c$,
provide a numerically exact estimate of~$T_c$, and give the critical exponents
within $1\%$ of the 2D Ising universality class.
",Physics
"  We investigated the physical properties of the comet-like objects 107P/(4015)
Wilson--Harrington (4015WH) and P/2006 HR30 (Siding Spring; HR30) by applying a
simple thermophysical model (TPM) to the near-infrared spectroscopy and
broadband observation data obtained by AKARI satellite of JAXA when they showed
no detectable comet-like activity. We selected these two targets since the
tendency of thermal inertia to decrease with the size of an asteroid, which has
been demonstrated in recent studies, has not been confirmed for comet-like
objects. It was found that 4015WH, which was originally discovered as a comet
but has not shown comet-like activity since its discovery, has effective size $
D= $ 3.74--4.39 km and geometric albedo $ p_V \approx $ 0.040--0.055 with
thermal inertia $ \Gamma = $ 100--250 J m$ ^{-2} $ K$ ^{-1} $ s$ ^{-1/2}$. The
corresponding grain size is estimated to 1--3 mm. We also found that HR30,
which was observed as a bare cometary nucleus at the time of our observation,
have $ D= $ 23.9--27.1 km and $ p_V= $0.035--0.045 with $ \Gamma= $ 250--1,000
J m$ ^{-2} $ K$ ^{-1} $ s$ ^{-1/2}$. We conjecture the pole latitude $ -
20^{\circ} \lesssim \beta_s \lesssim +60^{\circ}$. The results for both targets
are consistent with previous studies. Based on the results, we propose that
comet-like objects are not clearly distinguishable from asteroidal counterpart
on the $ D $--$ \Gamma $ plane.
",Physics
"  Taipan is a multi-object spectroscopic galaxy survey starting in 2017 that
will cover 2pi steradians over the southern sky, and obtain optical spectra for
about two million galaxies out to z<0.4. Taipan will use the newly-refurbished
1.2m UK Schmidt Telescope at Siding Spring Observatory with the new TAIPAN
instrument, which includes an innovative 'Starbugs' positioning system capable
of rapidly and simultaneously deploying up to 150 spectroscopic fibres (and up
to 300 with a proposed upgrade) over the 6-deg diameter focal plane, and a
purpose-built spectrograph operating from 370 to 870nm with resolving power
R>2000. The main scientific goals of Taipan are: (i) to measure the distance
scale of the Universe (primarily governed by the local expansion rate, H_0) to
1% precision, and the structure growth rate of structure to 5%; (ii) to make
the most extensive map yet constructed of the mass distribution and motions in
the local Universe, using peculiar velocities based on improved Fundamental
Plane distances, which will enable sensitive tests of gravitational physics;
and (iii) to deliver a legacy sample of low-redshift galaxies as a unique
laboratory for studying galaxy evolution as a function of mass and environment.
The final survey, which will be completed within 5 years, will consist of a
complete magnitude-limited sample (i<17) of about 1.2x10^6 galaxies,
supplemented by an extension to higher redshifts and fainter magnitudes
(i<18.1) of a luminous red galaxy sample of about 0.8x10^6 galaxies.
Observations and data processing will be carried out remotely and in a
fully-automated way, using a purpose-built automated 'virtual observer'
software and an automated data reduction pipeline. The Taipan survey is
deliberately designed to maximise its legacy value, by complementing and
enhancing current and planned surveys of the southern sky at wavelengths from
the optical to the radio.
",Physics
"  In this letter we study the mean sizes of Halpha clumps in turbulent disk
galaxies relative to kinematics, gas fractions, and Toomre Q. We use 100~pc
resolution HST images, IFU kinematics, and gas fractions of a sample of rare,
nearby turbulent disks with properties closely matched to z~1.5-2 main-sequence
galaxies (the DYNAMO sample). We find linear correlations of normalized mean
clump sizes with both the gas fraction and the velocity dispersion-to-rotation
velocity ratio of the host galaxy. We show that these correlations are
consistent with predictions derived from a model of instabilities in a
self-gravitating disk (the so-called ""violent disk instability model""). We also
observe, using a two-fluid model for Q, a correlation between the size of
clumps and self-gravity driven unstable regions. These results are most
consistent with the hypothesis that massive star forming clumps in turbulent
disks are the result of instabilities in self-gravitating gas-rich disks, and
therefore provide a direct connection between resolved clump sizes and this in
situ mechanism.
",Physics
"  We study the annealing stability of bottom-pinned perpendicularly magnetized
magnetic tunnel junctions based on dual MgO free layers and thin fixed systems
comprising a hard [Co/Ni] multilayer antiferromagnetically coupled to thin a Co
reference layer and a FeCoB polarizing layer. Using conventional magnetometry
and advanced broadband ferromagnetic resonance, we identify the properties of
each sub-unit of the magnetic tunnel junction and demonstrate that this
material option can ensure a satisfactory resilience to the 400$^\circ$C
thermal annealing needed in solid-state magnetic memory applications. The dual
MgO free layer possesses an anneal-robust 0.4 T effective anisotropy and
suffers only a minor increase of its Gilbert damping from 0.007 to 0.010 for
the toughest annealing conditions. Within the fixed system, the ferro-coupler
and texture-breaking TaFeCoB layer keeps an interlayer exchange above 0.8
mJ/m$^2$, while the Ru antiferrocoupler layer within the synthetic
antiferromagnet maintains a coupling above -0.5 mJ/m$^2$. These two strong
couplings maintain the overall functionality of the tunnel junction upon the
toughest annealing despite the gradual degradation of the thin Co layer
anisotropy that may reduce the operation margin in spin torque memory
applications. Based on these findings, we propose further optimization routes
for the next generation magnetic tunnel junctions.
",Physics
"  Classical plasma with arbitrary degree of degeneration of electronic gas is
considered. In plasma N (N>2) collinear electromagnatic waves are propagated.
It is required to find the response of plasma to these waves. Distribution
function in square-law approximation on quantities of two small parameters from
Vlasov equation is received. The formula for electric current calculation is
deduced. It is demonstrated that the nonlinearity account leads to occurrence
of the longitudinal electric current directed along a wave vector. This
longitudinal current is orthogonal to the known transversal current received at
the linear analysis. The case of small values of wave number is considered.
",Physics
"  One dimensional hybrid systems play an important role in the search for
topological superconductivity. Nevertheless, all one dimensional hybrid systems
so far have been externally defined. Here we show that one-dimensional domain
wall in a nematic superconductor can serve as an emergent hybrid system in the
presence of spin-orbit coupling. As a concrete setting we study the domain wall
between nematic domains in FeSe, which is well established to be a nematic
superconductor. We first show on the symmetry grounds that spin-triplet pairing
can be induced at the domain wall by constructing a Ginzburg-Landau theory. We
then demonstrate using Bogoliubov-de Gennes approach that such nematic domain
wall supports zero energy bound states which would satisfy Majorana condition.
Well-known existence of these domain walls at relatively high temperatures,
which can in principle be located and investigated with scanning tunneling
microscopy, presents new opportunities for a search for realization of Majorana
bound states.
",Physics
"  Refractory organic compounds formed in molecular clouds are among the
building blocks of the solar system objects and could be the precursors of
organic matter found in primitive meteorites and cometary materials. However,
little is known about the evolutionary pathways of molecular cloud organics
from dense molecular clouds to planetary systems. In this study, we focus on
the evolution of the morphological and viscoelastic properties of molecular
cloud refractory organic matter. We found that the organic residue,
experimentally synthesized at about 10 K from UV-irradiated H2O-CH3OH-NH3 ice,
changed significantly in terms of its nanometer- to micrometer-scale morphology
and viscoelastic properties after UV irradiation at room temperature. The dose
of this irradiation was equivalent to that experienced after short residence in
diffuse clouds (equal or less than 10,000 years) or irradiation in outer
protoplanetary disks. The irradiated organic residues became highly porous and
more rigid and formed amorphous nanospherules. These nanospherules are
morphologically similar to organic nanoglobules observed in the least-altered
chondrites, chondritic porous interplanetary dust particles, and cometary
samples, suggesting that irradiation of refractory organics could be a possible
formation pathway for such nanoglobules. The storage modulus (elasticity) of
photo-irradiated organic residues is about 100 MPa irrespective of vibrational
frequency, a value that is lower than the storage moduli of minerals and ice.
Dust grains coated with such irradiated organics would therefore stick together
efficiently, but growth to larger grains might be suppressed due to an increase
in aggregate brittleness caused by the strong connections between grains.
",Physics
"  In the Bak-Sneppen model, the lowest fitness particle and its two nearest
neighbors are renewed at each temporal step with a uniform (0,1) fitness
distribution. The model presents a critical value that depends on the
interaction criteria (two nearest neighbors) and on the update procedure
(uniform). Here we calculate the critical value for models where one or both
properties are changed. We study models with non-uniform updates, models with
random neighbors and models with binary fitness and obtain exact results for
the average fitness and for $p_c$.
",Physics
"  The quest to observe gravitational waves challenges our ability to
discriminate signals from detector noise. This issue is especially relevant for
transient gravitational waves searches with a robust eyes wide open approach,
the so called all- sky burst searches. Here we show how signal classification
methods inspired by broad astrophysical characteristics can be implemented in
all-sky burst searches preserving their generality. In our case study, we apply
a multivariate analyses based on artificial neural networks to classify waves
emitted in compact binary coalescences. We enhance by orders of magnitude the
significance of signals belonging to this broad astrophysical class against the
noise background. Alternatively, at a given level of mis-classification of
noise events, we can detect about 1/4 more of the total signal population. We
also show that a more general strategy of signal classification can actually be
performed, by testing the ability of artificial neural networks in
discriminating different signal classes. The possible impact on future
observations by the LIGO-Virgo network of detectors is discussed by analysing
recoloured noise from previous LIGO-Virgo data with coherent WaveBurst, one of
the flagship pipelines dedicated to all-sky searches for transient
gravitational waves.
",Physics
"  Molecular reflections on usual wall surfaces can be statistically described
by the Maxwell diffuse reflection model, which has been successfully applied in
the DSBGK simulations. We develop the DSBGK algorithm to implement the
Cercignani-Lampis-Lord (CLL) reflection model, which is widely applied to
polished surfaces and used particularly in modeling space shuttles to predict
the heat and force loads exerted by the high-speed flows around the surfaces.
We also extend the DSBGK method to simulate gas mixtures and high contrast of
number densities of different components can be handled at a cost of memory
usage much lower than that needed by the DSMC simulations because the average
numbers of simulated molecules of different components per cell can be equal in
the DSBGK simulations.
",Physics
"  Granular gases as dilute ensembles of particles in random motion are not only
at the basis of elementary structure-forming processes in the universe and
involved in many industrial and natural phenomena, but also excellent models to
study fundamental statistical dynamics. A vast number of theoretical and
numerical investigations have dealt with this apparently simple non-equilibrium
system. The essential difference to molecular gases is the energy dissipation
in particle collisions, a subtle distinction with immense impact on their
global dynamics. Its most striking manifestation is the so-called granular
cooling, the gradual loss of mechanical energy in absence of external
excitation.
We report an experimental study of homogeneous cooling of three-dimensional
(3D) granular gases in microgravity. Surprisingly, the asymptotic scaling
$E(t)\propto t^{-2}$ obtained by Haff's minimal model [J. Fluid Mech. 134, 401
(1983)] proves to be robust, despite the violation of several of its central
assumptions. The shape anisotropy of the grains influences the characteristic
time of energy loss quantitatively, but not qualitatively. We compare kinetic
energies in the individual degrees of freedom, and find a slight predominance
of the translational motions. In addition, we detect a certain preference of
the grains to align with their long axis in flight direction, a feature known
from active matter or animal flocks, and the onset of clustering.
",Physics
"  We describe high resolution observations of a GOES B-class flare
characterized by a circular ribbon at chromospheric level, corresponding to the
network at photospheric level. We interpret the flare as a consequence of a
magnetic reconnection event occurred at a three-dimensional (3D) coronal null
point located above the supergranular cell. The potential field extrapolation
of the photospheric magnetic field indicates that the circular chromospheric
ribbon is cospatial with the fan footpoints, while the ribbons of the inner and
outer spines look like compact kernels. We found new interesting observational
aspects that need to be explained by models: 1) a loop corresponding to the
outer spine became brighter a few minutes before the onset of the flare; 2) the
circular ribbon was formed by several adjacent compact kernels characterized by
a size of 1""-2""; 3) the kernels with stronger intensity emission were located
at the outer footpoint of the darker filaments departing radially from the
center of the supergranular cell; 4) these kernels start to brighten
sequentially in clockwise direction; 5) the site of the 3D null point and the
shape of the outer spine were detected by RHESSI in the low energy channel
between 6.0 and 12.0 keV. Taking into account all these features and the length
scales of the magnetic systems involved by the event we argued that the low
intensity of the flare may be ascribed to the low amount of magnetic flux and
to its symmetric configuration.
",Physics
"  We investigate the effect of the incommensurate potential on Weyl semimetal,
which is proposed to be realized in ultracold atomic systems trapped in
three-dimensional optical lattices. For the system without the Fermi arc, we
find that the Weyl points are robust against the incommensurate potential and
the system enters into a metallic phase only when the incommensurate potential
strength exceeds a critical value. We unveil the trastition by analysing the
properties of wave functions and the density of states as a function of the
incommensurate potential strength. We also study the system with Fermi arcs and
find the Fermi arcs are sensitive against the incommensurate potential and can
be destoryed by a weak incommensurate potential.
",Physics
"  We present the full results of our decade-long astrometric monitoring
programs targeting 31 ultracool binaries with component spectral types M7-T5.
Joint analysis of resolved imaging from Keck Observatory and Hubble Space
Telescope and unresolved astrometry from CFHT/WIRCam yields parallactic
distances for all systems, robust orbit determinations for 23 systems, and
photocenter orbits for 19 systems. As a result, we measure 38 precise
individual masses spanning 30-115 $M_{\rm Jup}$. We determine a
model-independent substellar boundary that is $\approx$70 $M_{\rm Jup}$ in mass
($\approx$L4 in spectral type), and we validate Baraffe et al. (2015)
evolutionary model predictions for the lithium-depletion boundary (60 $M_{\rm
Jup}$ at field ages). Assuming each binary is coeval, we test models of the
substellar mass-luminosity relation and find that in the L/T transition, only
the Saumon & Marley (2008) ""hybrid"" models accounting for cloud clearing match
our data. We derive a precise, mass-calibrated spectral type-effective
temperature relation covering 1100-2800 K. Our masses enable a novel direct
determination of the age distribution of field brown dwarfs spanning L4-T5 and
30-70 $M_{\rm Jup}$. We determine a median age of 1.3 Gyr, and our population
synthesis modeling indicates our sample is consistent with a constant star
formation history modulated by dynamical heating in the Galactic disk. We
discover two triple-brown-dwarf systems, the first with directly measured
masses and eccentricities. We examine the eccentricity distribution, carefully
considering biases and completeness, and find that low-eccentricity orbits are
significantly more common among ultracool binaries than solar-type binaries,
possibly indicating the early influence of long-lived dissipative gas disks.
Overall, this work represents a major advance in the empirical view of very
low-mass stars and brown dwarfs.
",Physics
"  The recently introduced mixed time-averaging semiclassical initial value
representation molecular dynamics method for spectroscopic calculations [M.
Buchholz, F. Grossmann, and M. Ceotto, J. Chem. Phys. 144, 094102 (2016)] is
applied to systems with up to 61 dimensions, ruled by a condensed phase
Caldeira-Leggett model potential. By calculating the ground state as well as
the first few excited states of the system Morse oscillator, changes of both
the harmonic frequency and the anharmonicity are determined. The method
faithfully reproduces blueshift and redshift effects and the importance of the
counter term, as previously suggested by other methods. Differently from
previous methods, the present semiclassical method does not take advantage of
the specific form of the potential and it can represent a practical tool that
opens the route to direct ab initio semiclassical simulation of condensed phase
systems.
",Physics
"  Recently, it has been claimed that inflationary models with an inflection
point in the scalar potential can produce a large resonance in the power
spectrum of curvature perturbation. In this paper however we show that the
previous analyses are incorrect. The reason is twofold: firstly, the inflaton
is over-shot from a stage of standard inflation and so deviates from the
slow-roll attractor before reaching the inflection. Secondly, on the (or close
to) the inflection point, the ultra-slow-roll trajectory supersede the
slow-roll one and thus, the slow-roll approximations used in the literature
cannot be used. We then reconsider the model and provide a recipe for how to
produce nevertheless a large peak in the matter power spectrum via fine-tuning
of parameters.
",Physics
"  In this work, we compare the thermophysical properties and particle sizes
derived from the Mars Science Laboratory (MSL) rover's Ground Temperature
Sensor (GTS) of the Bagnold dunes, specifically Namib dune, to those derived
orbitally from Thermal Emission Imaging System (THEMIS), ultimately linking
these measurements to ground-truth particle sizes determined from Mars Hand
Lens Imager (MAHLI) images. In general, we find that all three datasets report
consistent particle sizes for the Bagnold dunes (~110-350 microns, and are
within measurement and model uncertainties), indicating that particle sizes of
homogeneous materials determined from orbit are reliable. Furthermore, we
examine the effects of two physical characteristics that could influence the
modeled thermal inertia and particle sizes, including: 1) fine-scale (cm-m
scale) ripples, and 2) thin layering of indurated/armored materials. To first
order, we find small scale ripples and thin (approximately centimeter scale)
layers do not significantly affect the determination of bulk thermal inertia
from orbital thermal data determined from a single nighttime temperature.
Modeling of a layer of coarse or indurated material reveals that a thin layer
(< ~5 mm; similar to what was observed by the Curiosity rover) would not
significantly change the observed thermal properties of the surface and would
be dominated by the properties of the underlying material. Thermal inertia and
grain sizes of relatively homogeneous materials derived from nighttime orbital
data should be considered as reliable, as long as there are not significant
sub-pixel anisothermality effects (e.g. lateral mixing of multiple
thermophysically distinct materials).
",Physics
"  When the electron density of highly crystalline thin films is tuned by
chemical doping or ionic liq- uid gating, interesting effects appear including
unconventional superconductivity, sizeable spin-orbit coupling, competition
with charge-density waves, and a debated low-temperature metallic state that
seems to avoid the superconducting or insulating fate of standard
two-dimensional electron systems. Some experiments also find a marked tendency
to a negative electronic compressibility. We suggest that this indicates an
inclination for electronic phase separation resulting in a nanoscopic inhomo-
geneity. Although the mild modulation of the inhomogeneous landscape is
compatible with a high electron mobility in the metallic state, this
intrinsically inhomogeneous character is highlighted by the peculiar behaviour
of the metal-to-superconductor transition. Modelling the system with super-
conducting puddles embedded in a metallic matrix, we fit the peculiar
resistance vs. temperature curves of systems like TiSe2, MoS2, and ZrNCl. In
this framework also the low-temperature debated metallic state finds a natural
explanation in terms of the pristine metallic background embedding
non-percolating superconducting clusters. An intrinsically inhomogeneous
character naturally raises the question of the formation mechanism(s). We
propose a mechanism based on the interplay be- tween electrons and the charges
of the gating ionic liquid.
",Physics
"  In the real world, many complex systems interact with other systems. In
addition, the intra- or inter-systems for the spread of information about
infectious diseases and the transmission of infectious diseases are often not
random, but with direction. Hence, in this paper, we build epidemic model based
on an interconnected directed network, which can be considered as the
generalization of undirected networks and bipartite networks. By using the
mean-field approach, we establish the Susceptible-Infectious-Susceptible model
on this network. We theoretically analyze the model, and obtain the basic
reproduction number, which is also the generalization of the critical number
corresponding to undirected or bipartite networks. And we prove the global
stability of disease-free and endemic equilibria via the basic reproduction
number as a forward bifurcation parameter. We also give a condition for
epidemic prevalence only on a single subnetwork. Furthermore, we carry out
numerical simulations, and find that the independence between each node's in-
and out-degrees greatly reduce the impact of the network's topological
structure on disease spread.
",Physics
"  The way Quantum Mechanics (QM) is introduced to people used to Classical
Mechanics (CM) is by a complete change of the general methodology) despite QM
historically stemming from CM as a means to explain experimental results.
Therefore, it is desirable to build a bridge from CM to QM.
This paper presents a generalization of CM to QM. It starts from the
generalization of a point-like object and naturally arrives at the quantum
state vector of quantum systems in the complex valued Hilbert space, its time
evolution and quantum representation of a measurement apparatus of any size.
Each time, when generalization is performed, there is a possibility to develop
new theory giving up most simple generalizations. It is shown that a
measurement apparatus is a special case of a general quantum object. An example
of a measurement apparatus of an intermediate size is considered in the end.
",Physics
"  Space-borne low-to medium-resolution (R~10^2-10^3) transmission spectroscopy
of atmospheres detect the broadest spectral features (alkali doublets,
molecular bands, scattering), while high-resolution (R~10^5), ground-based
observations probe the sharpest features (cores of the alkali lines, molecular
lines).The two techniques differ by:(1) The LSF of ground-based observations is
10^3 times narrower than for space-borne observations;(2)Space-borne
transmission spectra probe up to the base of thermosphere, while ground-based
observations can reach pressures down to 10^(-11);(3)Space-borne observations
directly yield the transit depth of the planet, while ground-based observations
measure differences in the radius of the planet at different wavelengths.It is
challenging to combine both techniques.We develop a method to compare
theoretical models with observations at different resolutions.We introduce
PyETA, a line-by-line 1D radiative transfer code to compute transmission
spectra at R~10^6 (0.01 A) over a broad wavelength range.An hybrid forward
modeling/retrieval optimization scheme is devised to deal with the large
computational resources required by modeling a broad wavelength range (0.3-2
$\mu$m) at high resolution.We apply our technique to HD189733b.Here, HST
observations reveal a flattened spectrum due to scattering by aerosols, while
high-resolution ground-based HARPS observations reveal the sharp cores of
sodium lines.We reconcile these results by building models that reproduce
simultaneously both data sets, from the troposphere to the thermosphere. We
confirm:(1)the presence of scattering by tropospheric aerosols;(2)that the
sodium core feature is of thermospheric origin.Accounting for aerosols, the
sodium cores indicate T up to 10000K in the thermosphere.The precise value of
the thermospheric temperature is degenerate with the abundance of sodium and
altitude of the aerosol deck.
",Physics
"  Energy-conserving, angular momentum-changing collisions between protons and
highly excited Rydberg hydrogen atoms are important for precise understanding
of atomic recombination at the photon decoupling era, and the elemental
abundance after primordial nucleosynthesis. Early approaches to $\ell$-changing
collisions used perturbation theory for only dipole-allowed ($\Delta \ell=\pm
1$) transitions. An exact non-perturbative quantum mechanical treatment is
possible, but it comes at computational cost for highly excited Rydberg states.
In this note we show how to obtain a semi-classical limit that is accurate and
simple, and develop further physical insights afforded by the non-perturbative
quantum mechanical treatment.
",Physics
"  Simulations of tidal streams show that close encounters with dark matter
subhalos induce density gaps and distortions in on-sky path along the streams.
Accordingly, observing disrupted streams in the Galactic halo would
substantiate the hypothesis that dark matter substructure exists there, while
in contrast, observing collimated streams with smoothly varying density
profiles would place strong upper limits on the number density and mass
spectrum of subhalos. Here, we examine several measures of stream ""disruption""
and their power to distinguish between halo potentials with and without
substructure and with different global shapes. We create and evolve a
population of 1280 streams on a range of orbits in the Via Lactea II simulation
of a Milky Way-like halo, replete with a full mass range of {\Lambda}CDM
subhalos, and compare it to two control stream populations evolved in smooth
spherical and smooth triaxial potentials, respectively. We find that the number
of gaps observed in a stellar stream is a poor indicator of the halo potential,
but that (i) the thinness of the stream on-sky, (ii) the symmetry of the
leading and trailing tails, and (iii) the deviation of the tails from a
low-order polynomial path on-sky (""path regularity"") distinguish between the
three potentials more effectively. We find that globular cluster streams on
low-eccentricity orbits far from the galactic center (apocentric radius ~ 30-80
kpc) are most powerful in distinguishing between the three potentials. If they
exist, such streams will shortly be discoverable and mapped in high dimensions
with near-future photometric and spectroscopic surveys.
",Physics
"  We show that the evolution of two-component particles governed by a
two-dimensional spin-orbit lattice Hamiltonian can reveal transitions between
topological phases. A kink in the mean width of the particle distribution
signals the closing of the band gap, a prerequisite for a quantum phase
transition between topological phases. Furthermore, for realistic and
experimentally motivated Hamiltonians the density profile in topologically
non-trivial phases displays characteristic rings in the vicinity of the origin
that are absent in trivial phases. The results are expected to have immediate
application to systems of ultracold atoms and photonic lattices.
",Physics
"  Black hole X-ray transients show a variety of state transitions during their
outburst phases, characterized by changes in their spectral and timing
properties. In particular, power density spectra (PDS) show quasi periodic
oscillations (QPOs) that can be related to the accretion regime of the source.
We looked for type-C QPOs in the disc-dominated state (i.e. the high soft
state) and in the ultra-luminous state in the RXTE archival data of 12
transient black hole X-ray binaries known to show QPOs during their outbursts.
We detected 6 significant QPOs in the soft state that can be classified as
type-C QPOs. Under the assumption that the accretion disc in disc-dominated
states extends down or close to the innermost stable circular orbit (ISCO) and
that type-C QPOs would arise at the inner edge of the accretion flow, we use
the relativistic precession model (RPM) to place constraints on the black hole
spin. We were able to place lower limits on the spin value for all the 12
sources of our sample while we could place also an upper limit on the spin for
5 sources.
",Physics
"  We have designed and tested experimentally a morphing structure consisting of
a neutrally stable thin cylindrical shell driven by a multiparameter
piezoelectric actuation. The shell is obtained by plastically deforming an
initially flat copper disk, so as to induce large isotropic and almost uniform
inelastic curvatures. Following the plastic deformation, in a perfectly
isotropic system, the shell is theoretically neutrally stable, owning a
continuous manifold of stable cylindrical shapes corresponding to the rotation
of the axis of maximal curvature. Small imperfections render the actual
structure bistable, giving preferred orientations. A three-parameter
piezoelectric actuation, exerted through micro-fiber-composite actuators,
allows us to add a small perturbation to the plastic inelastic curvature and to
control the direction of maximal curvature. This actuation law is designed
through a geometrical analogy based on a fully non-linear inextensible
uniform-curvature shell model. We report on the fabrication, identification,
and experimental testing of a prototype and demonstrate the effectiveness of
the piezoelectric actuators in controlling its shape. The resulting motion is
an apparent rotation of the shell, controlled by the voltages as in a
""gear-less motor"", which is, in reality, a precession of the axis of principal
curvature.
",Physics
"  We propose new types of models of the appearance of small- and large scale
structures in media with memory, including a hyperbolic modification of the
Navier-Stokes equations and a class of dynamical low-dimensional models with
memory effects. On the basis of computer modeling, the formation of the
small-scale structures and collapses and the appearance of new chaotic
solutions are demonstrated. Possibilities of the application of some proposed
models to the description of the burst-type processes and collapses o nthe Sun
are discussed.
",Physics
"  We compare electronic structures of single FeSe layer films on SrTiO$_3$
substrate (FeSe/STO) and K$_x$Fe$_{2-y}$Se$_{2}$ superconductors obtained from
extensive LDA and LDA+DMFT calculations with the results of ARPES experiments.
It is demonstrated that correlation effects on Fe-3d states are sufficient in
principle to explain the formation of the shallow electron -- like bands at the
M(X)-point. However, in FeSe/STO these effects alone are apparently
insufficient for the simultaneous elimination of the hole -- like Fermi surface
around the $\Gamma$-point which is not observed in ARPES experiments. Detailed
comparison of ARPES detected and calculated quasiparticle bands shows
reasonable agreement between theory and experiment. Analysis of the bands with
respect to their origin and orbital composition shows, that for FeSe/STO system
the experimentally observed ""replica"" quasiparticle band at the M-point
(usually attributed to forward scattering interactions with optical phonons in
SrTiO$_3$ substrate) can be reasonably understood just as the LDA calculated
Fe-3d$_{xy}$ band, renormalized by electronic correlations. The only
manifestation of the substrate reduces to lifting the degeneracy between
Fe-3d$_{xz}$ and Fe-3d$_{yz}$ bands in the vicinity of M-point. For the case of
K$_x$Fe$_{2-y}$Se$_{2}$ most bands observed in ARPES can also be understood as
correlation renormalized Fe-3d LDA calculated bands, with overall semi --
quantitative agreement with LDA+DMFT calculations.
",Physics
"  Unique among alkali-doped $\textit {A}$$_3$C$_{60}$ fullerene compounds, the
A15 and fcc forms of Cs$_3$C$_{60}$ exhibit superconducting states varying
under hydrostatic pressure with highest transition temperatures at $T_\textrm
{C}$$^\textrm {meas}$ = 38.3 and 35.2 K, respectively. Herein it is argued that
these two compounds under pressure represent the optimal materials of the
$\textit {A}$$_3$C$_{60}$ family, and that the C$_{60}$-associated
superconductivity is mediated through Coulombic interactions with charges on
the alkalis. A derivation of the interlayer Coulombic pairing model of
high-$T_\textrm {C}$ superconductivity employing non-planar geometry is
introduced, generalizing the picture of two interacting layers to an
interaction between charge reservoirs located on the C$_{60}$ and alkali ions.
The optimal transition temperature follows the algebraic expression, $T_\textrm
{C0}$ = (12.474 nm$^2$ K)/$\ell$${\zeta}$, where $\ell$ relates to the mean
spacing between interacting surface charges on the C$_{60}$ and ${\zeta}$ is
the average radial distance between the C$_{60}$ surface and the neighboring Cs
ions. Values of $T_\textrm {C0}$ for the measured cation stoichiometries of
Cs$_{3-\textrm{x}}$C$_{60}$ with x $\approx$ 0 are found to be 38.19 and 36.88
K for the A15 and fcc forms, respectively, with the dichotomy in transition
temperature reflecting the larger ${\zeta}$ and structural disorder in the fcc
form. In the A15 form, modeled interacting charges and Coulomb potential
e$^2$/${\zeta}$ are shown to agree quantitatively with findings from
nuclear-spin relaxation and mid-infrared optical conductivity. In the fcc form,
suppression of $T_\textrm {C}$$^\textrm {meas}$ below $T_\textrm {C0}$ is
ascribed to native structural disorder. Phononic effects in conjunction with
Coulombic pairing are discussed.
",Physics
"  On the 29 March 2014 NOAA active region (AR) 12017 produced an X1 flare which
was simultaneously observed by an unprecedented number of observatories. We
have investigated the pre-flare period of this flare from 14:00 UT until 19:00
UT using joint observations made by the Interface Region Imaging Spectrometer
(IRIS) and the Hinode Extreme Ultraviolet Imaging Spectrometer (EIS). Spectral
lines providing coverage of the solar atmosphere from chromosphere to the
corona were analysed to investigate pre-flare activity within the AR. The
results of the investigation have revealed evidence of strongly blue-shifted
plasma flows, with velocities up to 200 km/s, being observed 40 minutes prior
to flaring. These flows are located along the filament present in the active
region and are both spatially discrete and transient. In order to constrain the
possible explanations for this activity, we undertake non-potential magnetic
field modelling of the active region. This modelling indicates the existence of
a weakly twisted flux rope along the polarity inversion line in the region
where a filament and the strong pre-flare flows are observed. We then discuss
how these observations relate to the current models of flare triggering. We
conclude that the most likely drivers of the observed activity are internal
reconnection in the flux rope, early onset of the flare reconnection, or tether
cutting reconnection along the filament.
",Physics
"  The time evolution of the energy transport triggered in a strongly coupled
system by a temperature gradient is holographically related to the evolution of
an asymptotically AdS black brane. We study the far-from-equilibrium properties
of such a system by using the AdS/CFT correspondence. In particular, we
describe the appearance of a steady state, and study the information flow by
computing the time evolution of the holographic entanglement entropy. Some
universal properties of the quenching process are presented.
",Physics
"  In standard general relativity the universe cannot be started with arbitrary
initial conditions, because four of the ten components of the Einstein's field
equations (EFE) are constraints on initial conditions. In the previous work it
was proposed to extend the gravity theory to allow free initial conditions,
with a motivation to solve the cosmological constant problem. This was done by
setting four constraints on metric variations in the action principle, which is
reasonable because the gravity's physical degrees of freedom are at most six.
However, there are two problems about this theory; the three constraints in
addition to the unimodular condition were introduced without clear physical
meanings, and the flat Minkowski spacetime is unstable against perturbations.
Here a new set of gravitational field equations is derived by replacing the
three constraints with new ones requiring that geodesic paths remain geodesic
against metric variations. The instability problem is then naturally solved.
Implications for the cosmological constant $\Lambda$ are unchanged; the theory
converges into EFE with nonzero $\Lambda$ by inflation, but $\Lambda$ varies on
scales much larger than the present Hubble horizon. Then galaxies are formed
only in small $\Lambda$ regions, and the cosmological constant problem is
solved by the anthropic argument. Because of the increased degrees of freedom
in metric dynamics, the theory predicts new non-oscillatory modes of metric
anisotropy generated by quantum fluctuation during inflation, and CMB B-mode
polarization would be observed differently from the standard predictions by
general relativity.
",Physics
"  We have developed a recently proposed Josephson traveling-wave parametric
amplifier with three-wave mixing [A. B. Zorin, Phys. Rev. Applied 6, 034006,
2016]. The amplifier consists of a microwave transmission line formed by a
serial array of nonhysteretic one-junction SQUIDs. These SQUIDs are flux-biased
in a way that the phase drops across the Josephson junctions are equal to 90
degrees and the persistent currents in the SQUID loops are equal to the
Josephson critical current values. Such a one-dimensional metamaterial
possesses a maximal quadratic nonlinearity and zero cubic (Kerr) nonlinearity.
This property allows phase matching and exponential power gain of traveling
microwaves to take place over a wide frequency range. We report the
proof-of-principle experiment performed at a temperature of T = 4.2 K on Nb
trilayer samples, which has demonstrated that our concept of a practical
broadband Josephson parametric amplifier is valid and very promising for
achieving quantum-limited operation.
",Physics
"  We use a secular model to describe the non-resonant dynamics of
trans-Neptunian objects in the presence of an external ten-earth-mass
perturber. The secular dynamics is analogous to an ""eccentric Kozai mechanism""
but with both an inner component (the four giant planets) and an outer one (the
eccentric distant perturber). By the means of Poincaré sections, the cases of
a non-inclined or inclined outer planet are successively studied, making the
connection with previous works. In the inclined case, the problem is reduced to
two degrees of freedom by assuming a non-precessing argument of perihelion for
the perturbing body.
The size of the perturbation is typically ruled by the semi-major axis of the
small body: we show that the classic integrable picture is still valid below
about 70 AU, but it is progressively destroyed when we get closer to the
external perturber. In particular, for a>150 AU, large-amplitude orbital flips
become possible, and for a>200 AU, the Kozai libration islands are totally
submerged by the chaotic sea. Numerous resonance relations are highlighted. The
most large and persistent ones are associated to apsidal alignments or
anti-alignments with the orbit of the distant perturber.
",Physics
"  The aim of Galactic Archaeology is to recover the evolutionary history of the
Milky Way from its present day kinematical and chemical state. Because stars
move away from their birth sites, the current dynamical information alone is
not sufficient for this task. The chemical composition of stellar atmospheres,
on the other hand, is largely preserved over the stellar lifetime and, together
with accurate ages, can be used to recover the birthplaces of stars currently
found at the same Galactic radius. In addition to the availability of large
stellar samples with accurate 6D kinematics and chemical abundance
measurements, this requires detailed modeling with both dynamical and chemical
evolution taken into account. An important first step is to understand the
variety of dynamical processes that can take place in the Milky Way, including
the perturbative effects of both internal (bar and spiral structure) and
external (infalling satellites) agents. We discuss here (1) how to constrain
the Galactic bar, spiral structure, and merging satellites by their effect on
the local and global disc phase-space, (2) the effect of multiple patterns on
the disc dynamics, and (3) the importance of radial migration and merger
perturbations for the formation of the Galactic thick disc. Finally, we discuss
the construction of Milky Way chemo-dynamical models and relate to
observations.
",Physics
"  K$_3$Cu$_3$AlO$_2$(SO$_4$)$_4$ is a highly one-dimensional spin-1/2
inequilateral diamond-chain antiferromagnet. Spinon continuum and spin-singlet
dimer excitations are observed in the inelastic neutron scattering spectra,
which is in excellent agreement with a theoretical prediction: a dimer-monomer
composite structure, where the dimer is caused by strong antiferromagnetic
(AFM) coupling and the monomer forms an almost isolated quantum AFM chain
controlling low-energy excitations. Moreover, muon spin rotation/relaxation
spectroscopy shows no long-range ordering down to 90~mK, which is roughly three
orders of magnitude lower than the exchange interaction of the quantum AFM
chain. K$_3$Cu$_3$AlO$_2$(SO$_4$)$_4$ is, thus, regarded as a compound that
exhibits a Tomonaga-Luttinger spin liquid behavior at low temperatures close to
the ground state.
",Physics
"  Surface stress and surface energy are fundamental quantities which
characterize the interface between two materials. Although these quantities are
identical for interfaces involving only fluids, the Shuttleworth effect
demonstrates that this is not the case for most interfaces involving solids,
since their surface energies change with strain. Crystalline materials are
known to have strain dependent surface energies, but in amorphous materials,
such as polymeric glasses and elastomers, the strain dependence is debated due
to a dearth of direct measurements. Here, we utilize contact angle measurements
on strained glassy and elastomeric solids to address this matter. We show
conclusively that interfaces involving polymeric glasses exhibit strain
dependent surface energies, and give strong evidence for the absence of such a
dependence for incompressible elastomers. The results provide fundamental
insight into our understanding of the interfaces of amorphous solids and their
interaction with contacting liquids.
",Physics
"  In this work thin magnetite films were deposited on SrTiO$_3$ via reactive
molecular beam epitaxy at different substrate temperatures. The growth process
was monitored in-situ during deposition by means of x-ray diffraction. While
the magnetite film grown at 400$^\circ$C shows a fully relaxed vertical lattice
constant already in the early growth stages, the film deposited at 270$^\circ$C
exhibits a strong vertical compressive strain and relaxes towards the bulk
value with increasing film thickness. Furthermore, a lateral tensile strain was
observed under these growth conditions although the inverse behavior is
expected due to the lattice mismatch of -7.5%. Additionally, the occupancy of
the A and B sublattices of magnetite with tetrahedral and octahedral sites was
investigated showing a lower occupancy of the A sites compared to an ideal
inverse spinel structure. The occupation of A sites decreases for a higher
growth temperature. Thus, we assume a relocation of the iron ions from
tetrahedral sites to octahedral vacancies forming a deficient rock salt
lattice.
",Physics
"  The positive definite Kohn-Sham kinetic energy(KS-KE) density plays crucial
role in designing semilocal meta generalized gradient approximations(meta-GGAs)
for low dimensional quantum systems. It has been rigorously shown that near
nucleus and at the asymptotic region, the KE-KS differ from its von
Weizsäcker(VW) counterpart as contributions from different orbitals (i.e.,
s and p orbitals) play important role. This has been explored using two
dimensional isotropic quantum harmonic oscillator as a test case. Several
meta-GGA ingredients with different physical behaviors are also constructed and
further used to design an accurate semilocal functionals at meta-GGA level. In
the asymptotic region, a new exchange energy functional is constructed using
the meta-GGA ingredients with formally exact properties of the enhancement
factor. Also, it has been shown that exact asymptotic behavior of the exchange
energy density and potential can be attained by choosing accurately the
enhancement factor as a functional of meta-GGA ingredients.
",Physics
"  We propose the existence of a new universality in classical chaotic systems
when the number of degrees of freedom is large: the statistical property of the
Lyapunov spectrum is described by Random Matrix Theory. We demonstrate it by
studying the finite-time Lyapunov exponents of the matrix model of a stringy
black hole and the mass deformed models. The massless limit, which has a dual
string theory interpretation, is special in that the universal behavior can be
seen already at t=0, while in other cases it sets in at late time. The same
pattern is demonstrated also in the product of random matrices.
",Physics
"  There does not exist a general positive correlation between important
life-supporting properties and the entropy production rate. The simple reason
is that nondissipative and time-symmetric kinetic aspects are also relevant for
establishing optimal functioning. In fact those aspects are even crucial in the
nonlinear regimes around equilibrium where we find biological processing on
mesoscopic scales. We make these claims specific via examples of molecular
motors, of circadian cycles and of sensory adaptation, whose performance in
some regimes is indeed spoiled by increasing the dissipated power. We use the
relation between dissipation and the amount of time-reversal breaking to keep
the discussion quantitative also in effective models where the physical entropy
production is not clearly identifiable.
",Physics
"  We use the LDA+U approach to search for possible ordered ground states of
LaSrCoO$_4$. We find a staggered arrangement of magnetic multipoles to be
stable over a broad range of Co $3d$ interaction parameters. This ordered state
can be described as a spin-denity-wave-type condensate of $d_{xy} \otimes
d_{x^2-y^2}$ excitons carrying spin $S=1$. Further, we construct an effective
strong-coupling model, calculate the exciton dispersion and investigate closing
of the exciton gap, which marks the exciton condensation instability. Comparing
the layered LaSrCoO$_4$ with its pseudo cubic analog LaCoO$_3$, we find that
for the same interaction parameters the excitonic gap is smaller (possibly
vanishing) in the layered cobaltite.
",Physics
"  The effects of high pressure on the crystal structure of orthorhombic (Pnma)
perovskite type cerium scandate have been studied in situ under high pressure
by means of synchrotron x-ray powder diffraction, using a diamond anvil cell.
We have found that the perovskite type crystal structure remains stable up to
40 GPa, the highest pressure reached in the experiments. The evolution of
unit-cell parameters with pressure has indicated an anisotropic compression.
The room-temperature pressure-volume equation of state is obtained from the
experiments. From the evolution of microscopic structural parameters like bond
distances and coordination polyhedra of cerium and scandium, the macroscopic
behavior of CeScO3 under compression has been explained and reasoned for its
large pressure stability. The reported results are discussed in comparison with
high-pressure results from other perovskites.
",Physics
"  Generalizations of classical theta functions are proposed that include any
even number of analytic parameters for which conditions of quasi-periodicity
are fulfilled and that are representations of extended Heisenberg group.
Differential equations for generalized theta functions and finite non-unitary
representations of extended Heisenberg group are presented so as other
properties and possible applications are pointed out such as a projective
embedding of tori by means of generalized theta functions.
",Physics
"  Understanding the nature of the turbulent fluctuations below the ion
gyroradius in solar-wind turbulence is a great challenge. Recent studies have
been mostly in favor of kinetic Alfvén wave (KAW) type of fluctuations, but
other kinds of fluctuations with characteristics typical of magnetosonic,
whistler and ion Bernstein modes, could also play a role depending on the
plasma parameters. Here we investigate the properties of the sub-proton-scale
cascade with high-resolution hybrid-kinetic simulations of freely-decaying
turbulence in 3D3V phase space, including electron inertia effects. Two proton
plasma beta are explored: the ""intermediate"" $\beta_p=1$ and ""low""
$\beta_p=0.2$ regimes, both typically observed in solar wind and corona. The
magnetic energy spectum exhibits $k_\perp^{-8/3}$ and $k_\|^{-7/2}$ power laws
at $\beta_p=1$, while they are slightly steeper at $\beta_p=0.2$. Nevertheless,
both regimes develop a spectral anisotropy consistent with $k_\|\sim
k_\perp^{2/3}$ at $k_\perp\rho_p>1$, and pronounced small-scale intermittency.
In this context, we find that the kinetic-scale cascade is dominated by
KAW-like fluctuations at $\beta_p=1$, whereas the low-$\beta$ case presents a
more complex scenario suggesting the simultaneous presence of different types
of fluctuations. In both regimes, however, a non-negligible role of ion
Bernstein type of fluctuations at the smallest scales seems to emerge.
",Physics
"  We examine the velocity profile of coherent vortices appearing as a
consequence of the inverse cascade of two-dimensional turbulence in a finite
box in the case of static pumping. We demonstrate that in the passive regime
the flat velocity profile is realized, as in the case of pumping short
correlated in time. However, in the static case the energy flux to large scales
is dependent on the system parameters. We demonstrate that it is proportional
to $f^{4/3}$ where $f$ is the characteristic force exciting turbulence.
",Physics
"  Inelastic neutron scattering has been used to study the magneto-elastic
excitations in the multiferroic manganite hexagonal YMnO$_3$. An avoided
crossing is found between magnon and phonon modes close to the Brillouin zone
boundary in the $(a,b)$-plane. Neutron polarization analysis reveals that this
mode has mixed magnon-phonon character. An external magnetic field along the
$c$-axis is observed to cause a linear field-induced splitting of one of the
spin wave branches. A theoretical description is performed, using a Heisenberg
model of localized spins, acoustic phonon modes and a magneto-elastic coupling
via the single-ion magnetostriction. The model quantitatively reproduces the
dispersion and intensities of all modes in the full Brillouin zone, describes
the observed magnon-phonon hybridized modes, and quantifies the magneto-elastic
coupling. The combined information, including the field-induced magnon
splitting, allows us to exclude several of the earlier proposed models and
point to the correct magnetic ground state symmetry, and provides an effective
dynamic model relevant for the multiferroic hexagonal manganites.
",Physics
"  A model of ice floe breakup under ocean wave forcing in the marginal ice zone
(MIZ) is proposed to investigate how floe size distribution (FSD) evolves under
repeated wave breakup events. A three-dimensional linear model of ocean wave
scattering by a finite array of compliant circular ice floes is coupled to a
flexural failure model, which breaks a floe into two floes provided the
two-dimensional stress field satisfies a breakup criterion. A closed-feedback
loop algorithm is devised, which (i)~solves wave scattering problem for a given
FSD under time-harmonic plane wave forcing, (ii)~computes the stress field in
all the floes, (iii)~fractures the floes satisfying the breakup criterion and
(iv)~generates an updated FSD, initialising the geometry for the next iteration
of the loop.The FSD after 50 breakup events is uni-modal and near normal, or
bi-modal. Multiple scattering is found to enhance breakup for long waves and
thin ice, but to reduce breakup for short waves and thick ice. A breakup front
marches forward in the latter regime, as wave-induced fracture weakens the ice
cover allowing waves to travel deeper into the MIZ.
",Physics
"  In young starburst galaxies, the X-ray population is expected to be dominated
by the relics of the most massive and short-lived stars, black-hole and
neutron-star high mass X-ray binaries (XRBs). In the closest such galaxy, IC
10, we have made a multi-wavelength census of these objects. Employing a novel
statistical correlation technique, we have matched our list of 110 X-ray point
sources, derived from a decade of Chandra observations, against published
photometric data. We report an 8 sigma correlation between the celestial
coordinates of the two catalogs, with 42 X-ray sources having an optical
counterpart. Applying an optical color-magnitude selection to isolate blue
supergiant (SG) stars in IC 10, we find 16 matches. Both cases show a
statistically significant overabundance versus the expectation value for chance
alignments. The blue objects also exhibit systematically higher fx/fv ratios
than other stars in the same magnitude range. Blue SG-XRBs include a major
class of progenitors of double-degenerate binaries, hence their numbers are an
important factor in modeling the rate of gravitational wave sources. We suggest
that the anomalous features of the IC 10 stellar population are explained if
the age of the IC 10 starburst is close to the time of the peak of interaction
for massive binaries.
",Physics
"  We show that in the presence of magnetic field, two superconducting phases
with the center-of-mass momentum of Cooper pair parallel to the magnetic field
are induced in spin-orbit-coupled superconductor Li$_2$Pd$_3$B. Specifically,
at small magnetic field, the center-of-mass momentum is induced due to the
energy-spectrum distortion and no unpairing region with vanishing singlet
correlation appears. We refer to this superconducting state as the drift-BCS
state. By further increasing the magnetic field, the superconducting state
falls into the Fulde-Ferrell-Larkin-Ovchinnikov state with the emergence of the
unpairing regions. The observed abrupt enhancement of the center-of-mass
momenta and suppression on the order parameters during the crossover indicate
the first-order phase transition. Enhanced Pauli limit and hence enlarged
magnetic-field regime of the Fulde-Ferrell-Larkin-Ovchinnikov state, due to the
spin-flip terms of the spin-orbit coupling, are revealed. We also address the
triplet correlations induced by the spin-orbit coupling, and show that the
Cooper-pair spin polarizations, generated by the magnetic field and
center-of-mass momentum with the triplet correlations, exhibit totally
different magnetic-field dependences between the drift-BCS and
Fulde-Ferrell-Larkin-Ovchinnikov states.
",Physics
"  We suggest that ultra-high-energy (UHE) cosmic rays (CRs) may be accelerated
in ultra-relativistic flows via a one-shot mechanism, the ""espresso""
acceleration, in which already-energetic particles are generally boosted by a
factor of $\sim\Gamma^2$ in energy, where $\Gamma$ is the flow Lorentz factor.
More precisely, we consider blazar-like jets with $\Gamma\gtrsim 30$
propagating into a halo of ""seed"" CRs produced in supernova remnants, which can
accelerate UHECRs up to $10^{20}$\,eV. Such a re-acceleration process naturally
accounts for the chemical composition measured by the Pierre Auger
Collaboration, which resembles the one around and above the knee in the CR
spectrum, and is consistent with the distribution of potential sources in the
local universe, particularly intriguing is the coincidence of the powerful
blazar Mrk 421 with the hotspot reported by the Telescope Array Collaboration.
",Physics
"  A search for instability of nucleons bound in $^{136}$Xe nuclei is reported
with 223 kg$\cdot$yr exposure of $^{136}$Xe in the EXO-200 experiment. Lifetime
limits of 3.3$\times 10^{23}$ and 1.9$\times 10^{23}$ yrs are established for
nucleon decay to $^{133}$Sb and $^{133}$Te, respectively. These are the most
stringent to date, exceeding the prior decay limits by a factor of 9 and 7,
respectively.
",Physics
"  Magnetic frustration and low dimensionality can prevent long range magnetic
order and lead to exotic correlated ground states. SrDy$_2$O$_4$ consists of
magnetic Dy$^{3+}$ ions forming magnetically frustrated zig-zag chains along
the c-axis and shows no long range order to temperatures as low as $T=60$ mK.
We carried out neutron scattering and AC magnetic susceptibility measurements
using powder and single crystals of SrDy$_2$O$_4$. Diffuse neutron scattering
indicates strong one-dimensional (1D) magnetic correlations along the chain
direction that can be qualitatively accounted for by the axial next-nearest
neighbour Ising (ANNNI) model with nearest-neighbor and next-nearest-neighbor
exchange $J_1=0.3$ meV and $J_2=0.2$ meV, respectively. Three-dimensional (3D)
correlations become important below $T^*\approx0.7$ K. At $T=60$ mK, the short
range correlations are characterized by a putative propagation vector
$\textbf{k}_{1/2}=(0,\frac{1}{2},\frac{1}{2})$. We argue that the absence of
long range order arises from the presence of slowly decaying 1D domain walls
that are trapped due to 3D correlations. This stabilizes a low-temperature
phase without long range magnetic order, but with well-ordered chain segments
separated by slowly-moving domain walls.
",Physics
"  We analyze isolated resonance curves (IRCs) in a single-degree-of-freedom
system with nonlinear damping. The adopted procedure exploits singularity
theory in conjunction with the harmonic balance method. The analysis unveils a
geometrical connection between the topology of the damping force and IRCs.
Specifically, we demonstrate that extremas and zeros of the damping force
correspond to the appearance and merging of IRCs.
",Physics
"  The velocity dispersion of cold interstellar gas, sigma, is one of the
quantities that most radically affect the onset of gravitational instabilities
in galaxy discs, and the quantity that is most drastically approximated in
stability analyses. Here we analyse the stability of a large sample of nearby
star-forming spirals treating molecular gas, atomic gas and stars as three
distinct components, and using radial profiles of sigma_CO and sigma_HI derived
from HERACLES and THINGS observations. We show that the radial variations of
sigma_CO and sigma_HI have a weak effect on the local stability level of galaxy
discs, which remains remarkably flat and well above unity, but is low enough to
ensure (marginal) instability against non-axisymmetric perturbations and gas
dissipation. More importantly, the radial variation of sigma_CO has a strong
impact on the size of the regions over which gravitational instabilities
develop, and results in a characteristic instability scale that is one order of
magnitude larger than the Toomre length of molecular gas. Disc instabilities
are driven, in fact, by the self-gravity of stars at kpc scales. This is true
across the entire optical disc of every galaxy in the sample, with few
exceptions. In the linear phase of the disc instability process, stars and
molecular gas are strongly coupled, and it is such a coupling that ultimately
triggers local gravitational collapse/fragmentation in the molecular gas.
",Physics
"  The main properties of the climate of waves in the seasonally ice-covered
Baltic Sea and its decadal changes since 1990 are estimated from satellite
altimetry data. The data set of significant wave heights (SWH) from all
existing nine satellites, cleaned and cross-validated against in situ
measurements, shows overall a very consistent picture. A comparison with visual
observations shows a good correspondence with correlation coefficients of
0.6-0.8. The annual mean SWH reveals a tentative increase of 0.005 m yr-1, but
higher quantiles behave in a cyclic manner with a timescale of 10-15 yr.
Changes in the basin-wide average SWH have a strong meridional pattern: an
increase in the central and western parts of the sea and decrease in the east.
This pattern is likely caused by a rotation of wind directions rather than by
an increase in the wind speed.
",Physics
"  The spectra of 413 star-forming (or HII) regions in M33 (NGC 598) were
observed by using the multifiber spectrograph of Hectospec at the 6.5-m
Multiple Mirror Telescope (MMT). By using this homogeneous spectra sample, we
measured the intensities of emission lines and some physical parameters, such
as electron temperatures, electron densities, and metallicities. Oxygen
abundances were derived via the direct method (when available) and two
empirical strong-line methods, namely, O3N2 and N2. In the high-metallicity
end, oxygen abundances derived from O3N2 calibration were higher than those
derived from N2 index, indicating an inconsistency between O3N2 and N2
calibrations. We presented a detailed analysis of the spatial distribution of
gas-phase oxygen abundances in M33 and confirmed the existence of the
axisymmetric global metallicity distribution widely assumed in literature.
Local variations were also observed and subsequently associated with spiral
structures to provide evidence of radial migration driven by arms. Our O/H
gradient fitted out to 1.1 $R_{25}$ resulted in slopes of $-0.17\pm0.03$,
$-0.19\pm0.01$, and $-0.16\pm0.17$ dex $R_{25}^{-1}$ utilizing abundances from
O3N2, N2 diagnostics, and direct method, respectively.
",Physics
"  The studying of anomalous diffusion by pulsed field gradient (PFG) diffusion
technique still faces challenges. Two different research groups have proposed
modified Bloch equation for anomalous diffusion. However, these equations have
different forms and, therefore, yield inconsistent results. The discrepancy in
these reported modified Bloch equations may arise from different ways of
combining the fractional diffusion equation with the precession equation where
the time derivatives have different derivative orders and forms. Moreover, to
the best of my knowledge, the general PFG signal attenuation expression
including finite gradient pulse width (FGPW) effect for time-space fractional
diffusion based on the fractional derivative has yet to be reported by other
methods. Here, based on different combination strategy, two new modified Bloch
equations are proposed, which belong to two significantly different types: a
differential type based on the fractal derivative and an integral type based on
the fractional derivative. The merit of the integral type modified Bloch
equation is that the original properties of the contributions from linear or
nonlinear processes remain unchanged at the instant of the combination. The
general solutions including the FGPW effect were derived from these two
equations as well as from two other methods: a method observing the signal
intensity at the origin and the recently reported effective phase shift
diffusion equation method. The relaxation effect was also considered. It is
found that the relaxation behavior influenced by fractional diffusion based on
the fractional derivative deviates from that of normal diffusion. The general
solution agrees perfectly with continuous-time random walk (CTRW) simulations
as well as reported literature results. The new modified Bloch equations is a
valuable tool to describe PFG anomalous diffusion in NMR and MRI.
",Physics
"  A Large Size air Cherenkov Telescope (LST) prototype, proposed for the
Cherenkov Telescope Array (CTA), is under construction at the Canary Island of
La Palma (Spain) this year. The LST camera, which comprises an array of about
500 photomultipliers (PMTs), requires a precise and regular calibration over a
large dynamic range, up to $10^3$ photo-electrons (pe's), for each PMT. We
present a system built to provide the optical calibration of the camera
consisting of a pulsed laser (355 nm wavelength, 400 ps pulse width), a set of
filters to guarantee a large dynamic range of photons on the sensors, and a
diffusing sphere to uniformly spread the laser light, with flat fielding within
3%, over the camera focal plane 28 m away. The prototype of the system
developed at INFN is hermetically closed and filled with dry air to make the
system completely isolated from the external environment. In the paper we
present the results of the tests for the evaluation of the photon density at
the camera plane, the system isolation from the environment, and the shape of
the signal as detected by the PMTs. The description of the communication of the
system with the rest of detector is also given.
",Physics
"  We present ALMA CO (2-1) detections in 11 gas-rich cluster galaxies at z~1.6,
constituting the largest sample of molecular gas measurements in z>1.5 clusters
to date. The observations span three galaxy clusters, derived from the Spitzer
Adaptation of the Red-sequence Cluster Survey. We augment the >5sigma
detections of the CO (2-1) fluxes with multi-band photometry, yielding stellar
masses and infrared-derived star formation rates, to place some of the first
constraints on molecular gas properties in z~1.6 cluster environments. We
measure sizable gas reservoirs of 0.5-2x10^11 solar masses in these objects,
with high gas fractions and long depletion timescales, averaging 62% and 1.4
Gyr, respectively. We compare our cluster galaxies to the scaling relations of
the coeval field, in the context of how gas fractions and depletion timescales
vary with respect to the star-forming main sequence. We find that our cluster
galaxies lie systematically off the field scaling relations at z=1.6 toward
enhanced gas fractions, at a level of ~4sigma, but have consistent depletion
timescales. Exploiting CO detections in lower-redshift clusters from the
literature, we investigate the evolution of the gas fraction in cluster
galaxies, finding it to mimic the strong rise with redshift in the field. We
emphasize the utility of detecting abundant gas-rich galaxies in high-redshift
clusters, deeming them as crucial laboratories for future statistical studies.
",Physics
"  Light carries momentum which induces on atoms a recoil for each photon
absorbed. In vacuum, for a monochromatic beam of frequency $\nu$, the global
momentum per photon is bounded by general principles and is smaller than $h
\nu/c$ leading to a limit on the recoil. However, locally this limit can be
broken. In this paper, we give a general formula to calculate the recoil in
vacuum. We show that in a laser beam with a distorted optical field, there are
regions where the recoil can be higher than this limit. Using atoms placed in
those regions we are able to measure directly the extra recoil.
",Physics
"  We theoretically investigate a scheme in which backward coherent anti-Stokes
Raman scattering (CARS) is significantly enhanced by using slow light.
Specifically, we reduce the group velocity of the Stokes excitation pulse by
introducing a coupling laser that causes electromagnetically induced
transparency (EIT). When the Stokes pulse has a spatial length shorter than the
CARS wavelength, the backward CARS emission is significantly enhanced. We also
investigated the possibility of applying this scheme as a CARS lidar with O2 or
N2 as the EIT medium. We found that if nanosecond laser with large pulse energy
(>1 J) and a telescope with large aperture (~10 m) are equipped in the lidar
system, a CARS lidar could become much more sensitive than a spontaneous Raman
lidar.
",Physics
"  The anisotropy of the Fe-based superconductors is much smaller than that of
the cuprates and the theoretical calculations. A credible understanding for
this experimental fact is still lacking up to now. Here we experimentally study
the magnetic-field-angle dependence of electronic resistivity in the
superconducting phase of iron-based superconductor
CaFe$_{0.882}$Co$_{0.118}$AsF, and find the strongest anisotropy effect of the
upper critical field among the iron-based superconductors based on the
framework of Ginzburg-Landau theory. The evidences of energy band structure and
charge density distribution from electronic structure calculations demonstrate
that the observed strong anisotropic effect mainly comes from the strong ionic
bonding in between the ions of Ca$^{2+}$ and F$^-$, which weakens the
interlayer coupling between the layers of FeAs and CaF. This finding provides a
significant insight into the nature of experimentally observed strong
anisotropic effect of electronic resistivity, and also paves an avenue to
design exotic two dimensional artificial unconventional superconductors in
future.
",Physics
"  The stabilization of lasers to absolute frequency references is a fundamental
requirement in several areas of atomic, molecular and optical physics. A range
of techniques are available to produce a suitable reference onto which one can
'lock' the laser, many of which depend on the specific internal structure of
the reference or are sensitive to laser intensity noise. We present a novel
method using the frequency modulation of an acousto-optic modulator's carrier
(drive) signal to generate two spatially separated beams, with a frequency
difference of only a few MHz. These beams are used to probe a narrow absorption
feature and the difference in their detected signals leads to a dispersion-like
feature suitable for wavelength stabilization of a diode laser. This simple and
versatile method only requires a narrow absorption line and is therefore
suitable for both atomic and cavity based stabilization schemes. To demonstrate
the suitability of this method we lock an external cavity diode laser near the
$^{85}\mathrm{Rb}\,5S_{1/2}\rightarrow5P_{3/2}, F=3\rightarrow F^{\prime}=4$
using sub-Doppler pump probe spectroscopy and also demonstrate excellent
agreement between the measured signal and a theoretical model.
",Physics
"  Molecular dynamics (MD) simulations allow the exploration of the phase space
of biopolymers through the integration of equations of motion of their
constituent atoms. The analysis of MD trajectories often relies on the choice
of collective variables (CVs) along which the dynamics of the system is
projected. We developed a graphical user interface (GUI) for facilitating the
interactive choice of the appropriate CVs. The GUI allows: defining
interactively new CVs; partitioning the configurations into microstates
characterized by similar values of the CVs; calculating the free energies of
the microstates for both unbiased and biased (metadynamics) simulations;
clustering the microstates in kinetic basins; visualizing the free energy
landscape as a function of a subset of the CVs used for the analysis. A simple
mouse click allows one to quickly inspect structures corresponding to specific
points in the landscape.
",Physics
"  We present a set of full evolutionary sequences for white dwarfs with
hydrogen-deficient atmospheres. We take into account the evolutionary history
of the progenitor stars, all the relevant energy sources involved in the
cooling, element diffusion in the very outer layers, and outer boundary
conditions provided by new and detailed non-gray white dwarf model atmospheres
for pure helium composition. These model atmospheres are based on the most
up-to-date physical inputs. Our calculations extend down to very low effective
temperatures, of $\sim 2\,500$~K, provide a homogeneous set of evolutionary
cooling tracks that are appropriate for mass and age determinations of old
hydrogen-deficient white dwarfs, and represent a clear improvement over
previous efforts, which were computed using gray atmospheres.
",Physics
"  We use $>$9400 $\log(m/M_{\odot})>10$ quiescent and star-forming galaxies at
$z\lesssim2$ in COSMOS/UltraVISTA to study the average size evolution of these
systems, with focus on the rare, ultra-massive population at
$\log(m/M_{\odot})>11.4$. The large 2-square degree survey area delivers a
sample of $\sim400$ such ultra-massive systems. Accurate sizes are derived
using a calibration based on high-resolution images from the Hubble Space
Telescope. We find that, at these very high masses, the size evolution of
star-forming and quiescent galaxies is almost indistinguishable in terms of
normalization and power-law slope. We use this result to investigate possible
pathways of quenching massive $m>M^*$ galaxies at $z<2$. We consistently model
the size evolution of quiescent galaxies from the star-forming population by
assuming different simple models for the suppression of star-formation. These
models include an instantaneous and delayed quenching without altering the
structure of galaxies and a central starburst followed by compaction. We find
that instantaneous quenching reproduces well the observed mass-size relation of
massive galaxies at $z>1$. Our starburst$+$compaction model followed by
individual growth of the galaxies by minor mergers is preferred over other
models without structural change for $\log(m/M_{\odot})>11.0$ galaxies at
$z>0.5$. None of our models is able to meet the observations at $m>M^*$ and
$z<1$ with out significant contribution of post-quenching growth of individual
galaxies via mergers. We conclude that quenching is a fast process in galaxies
with $ m \ge 10^{11} M_\odot$, and that major mergers likely play a major role
in the final steps of their evolution.
",Physics
"  Following the selection of The Gravitational Universe by ESA, and the
successful flight of LISA Pathfinder, the LISA Consortium now proposes a 4 year
mission in response to ESA's call for missions for L3. The observatory will be
based on three arms with six active laser links, between three identical
spacecraft in a triangular formation separated by 2.5 million km.
LISA is an all-sky monitor and will offer a wide view of a dynamic cosmos
using Gravitational Waves as new and unique messengers to unveil The
Gravitational Universe. It provides the closest ever view of the infant
Universe at TeV energy scales, has known sources in the form of verification
binaries in the Milky Way, and can probe the entire Universe, from its smallest
scales near the horizons of black holes, all the way to cosmological scales.
The LISA mission will scan the entire sky as it follows behind the Earth in its
orbit, obtaining both polarisations of the Gravitational Waves simultaneously,
and will measure source parameters with astrophysically relevant sensitivity in
a band from below $10^{-4}\,$Hz to above $10^{-1}\,$Hz.
",Physics
"  The global gyrokinetic toroidal code (GTC) has been recently upgraded to do
simulations in non-axisymmetric equilibrium configuration, such as
stellarators. Linear simulation of ion temperature gradient (ITG) driven
instabilities has been done in Wendelstein7-X (W7-X) and Large Helical Device
(LHD) stellarators using GTC. Several results are discussed to study
characteristics of ITG in stellarators, including toroidal grids convergence,
nmodes number convergence, poloidal and parallel spectrums, and electrostatic
potential mode structure on flux surface.
",Physics
"  This work is focused on searching a geodesic interpretation of the dynamics
of a particle under the effects of a Snyder like deformation in the background
of the Kepler problem. In order to accomplish that task, a newtonian spacetime
is used. Newtonian spacetime is not a metric manifold, but allows to introduce
a torsion free connection in order to interpret the dynamic equations of the
deformed Kepler problem as geodesics in a curved spacetime. These geodesics and
the curvature terms of the Riemann and Ricci tensors show a mass and a
fundamental length dependence as expected, but are velocity independent. In
this sense, the effect of introducing a deformed algebra is examinated and the
corresponding curvature terms calculated, as well as the modifications of the
integrals of motion.
",Physics
"  The first systematic comparison between Swarm-C accelerometer-derived
thermospheric density and both empirical and physics-based model results using
multiple model performance metrics is presented. This comparison is performed
at the satellite's high temporal 10-s resolution, which provides a meaningful
evaluation of the models' fidelity for orbit prediction and other space weather
forecasting applications. The comparison against the physical model is
influenced by the specification of the lower atmospheric forcing, the
high-latitude ionospheric plasma convection, and solar activity. Some insights
into the model response to thermosphere-driving mechanisms are obtained through
a machine learning exercise. The results of this analysis show that the
short-timescale variations observed by Swarm-C during periods of high solar and
geomagnetic activity were better captured by the physics-based model than the
empirical models. It is concluded that Swarm-C data agree well with the
climatologies inherent within the models and are, therefore, a useful data set
for further model validation and scientific research.
",Physics
"  Three types of orbits are theoretically possible in autonomous Hamiltonian
systems with three degrees of freedom: fully chaotic (they only obey the energy
integral), partially chaotic (they obey an additional isolating integral
besides energy) and regular (they obey two isolating integrals besides energy).
The existence of partially chaotic orbits has been denied by several authors,
however, arguing either that there is a sudden transition from regularity to
full chaoticity, or that a long enough follow up of a supposedly partially
chaotic orbit would reveal a fully chaotic nature. This situation needs
clarification, because partially chaotic orbits might play a significant role
in the process of chaotic diffusion. Here we use numerically computed Lyapunov
exponents to explore the phase space of a perturbed three dimensional cubic
force toy model, and a generalization of the Poincaré maps to show that
partially chaotic orbits are actually present in that model. They turn out to
be double orbits joined by a bifurcation zone, which is the most likely source
of their chaos, and they are encapsulated in regions of phase space bounded by
regular orbits similar to each one of the components of the double orbit.
",Physics
"  We consider a strongly interacting quantum dot connected to two leads held at
quite different temperatures. Our aim is to study the behavior of the Kondo
effect in the presence of large thermal biases. We use three different
approaches, namely, a perturbation formalism based on the Kondo Hamiltonian, a
slave-boson mean-field theory for the Anderson model at large charging energies
and a truncated equation-of-motion approach beyond the Hartree-Fock
approximation. The two former formalisms yield a suppression of the Kondo peak
for thermal gradients above the Kondo temperature, showing a remarkably good
agreement despite their different ranges of validity. The third technique
allows us to analyze the full density of states within a wide range of
energies. Additionally, we have investigated the quantum transport properties
(electric current and thermocurrent) beyond linear response. In the
voltage-driven case, we reproduce the split differential conductance due to the
presence of different electrochemical potentials. In the temperature-driven
case, we observe a strongly nonlinear thermocurrent as a function of the
applied thermal gradient. Depending on the parameters, we can find nontrivial
zeros in the electric current for finite values of the temperature bias.
Importantly, these thermocurrent zeros yield direct access to the system's
characteristic energy scales (Kondo temperature and charging energy).
",Physics
"  We present a study on the impact of Mn$^{3+}$ substitution in the
geometrically frustrated Ising garnet Ho$_3$Ga$_5$O$_{12}$ using bulk magnetic
measurements and low temperature powder neutron diffraction. We find that the
transition temperature, $T_N$ = 5.8 K, for Ho$_3$MnGa$_4$O$_{12}$ is raised by
almost 20 when compared to Ho$_3$Ga$_5$O$_{12}$. Powder neutron diffraction on
Ho$_3$Mn$_x$Ga$_{5-x}$O$_{12}$ ($x$ = 0.5, 1) below $T_N$ shows the formation
of a long range ordered ordered state with $\mathbf{k}$ = (0,0,0). Ho$^{3+}$
spins are aligned antiferromagnetically along the six crystallographic axes
with no resultant moment while the Mn$^{3+}$ spins are oriented along the body
diagonals, such that there is a net moment along [111]. The magnetic structure
can be visualised as ten-membered rings of corner-sharing triangles of
Ho$^{3+}$ spins with the Mn$^{3+}$ spins ferromagnetically coupled to each
individual Ho$^{3+}$ spin in the triangle. Substitution of Mn$^{3+}$ completely
relieves the magnetic frustration with $f = \theta_{CW}/T_N \approx 1.1$ for
Ho$_3$MnGa$_4$O$_{12}$.
",Physics
"  Galaxy clusters are thought to grow by accreting mass through large-scale,
strong, yet elusive, virial shocks. Such a shock is expected to accelerate
relativistic electrons, thus generating a spectrally-flat leptonic virial-ring.
However, until now, only the nearby Coma cluster has shown evidence for a
$\gamma$-ray virial ring. We stack Fermi-LAT data for the 112 most massive,
high latitude, extended clusters, enhancing the ring sensitivity by rescaling
clusters to their virial radii and utilizing the expected flat energy spectrum.
In addition to a central unresolved, hard signal (detected at the $\sim
5.8\sigma$ confidence level), probably dominated by AGN, we identify (at the
$5.8\sigma$ confidence level) a bright, spectrally-flat $\gamma$-ray ring at
the expected virial shock position. The ring signal implies that the shock
deposits $\sim 0.6\%$ (with an interpretation uncertainty factor $\sim2$) of
the thermal energy in relativistic electrons over a Hubble time. This result,
consistent with the Coma signal, validates and calibrates the virial shock
model, and indicates that the cumulative emission from such shocks
significantly contributes to the diffuse extragalactic $\gamma$-ray and
low-frequency radio backgrounds.
",Physics
"  Nanotubes of various kinds have been prepared in the last decade, starting
from the discovery of carbon nanotubes. Recently other types of nanotubes
including metallic (Au), inorganic (TiO2, HfS2, V7O16, CdSe, MoS2), and
polymeric (polyaniline, polyacrylonitrile) have been produced. Herein we
present a novel synthetic procedure leading to a new kind of porous,
high-surface-area nanoparticle nanotubes (NPNTs). This study characterizes the
synthesized silver nanotubes at optical wavelengths. The absorption spectrum of
PAN washed silver nanotubes shows an extended absorption peak at visible
wavelengths ranging from 350 to 700 nm. In addition, the absorption spectrum of
randomly oriented silver nanotubes showed plasmonic behavior, indicating high
efficient surface enhanced Raman scattering (SERS) performance.
",Physics
"  Using a high-frequency expansion in periodically driven extended Hubbard
models, where the strengths and ranges of density-density interactions are
arbitrary, we obtain the effective interactions and bandwidth, which depend
sensitively on the polarization of the driving field. Then, we numerically
calculate modulations of correlation functions in a quarter-filled extended
Hubbard model with nearest-neighbor interactions on a triangular lattice with
trimers after monocycle pulse excitation. We discuss how the resultant
modulations are compatible with the effective interactions and bandwidth
derived above on the basis of their dependence on the polarization of
photoexcitation, which is easily accessible by experiments. Some correlation
functions after monocycle pulse excitation are consistent with the effective
interactions, which are weaker or stronger than the original ones. However, the
photoinduced enhancement of anisotropic charge correlations previously
discussed for the three-quarter-filled organic conductor
$\alpha$-(bis[ethylenedithio]-tetrathiafulvalene)$_2$I$_3$
[$\alpha$-(BEDT-TTF)$_2$I$_3$] in the metallic phase is not fully explained by
the effective interactions or bandwidth, which are derived independently of the
filling.
",Physics
"  In this work, we study the nonlinear traveling waves in density stratified
fluids with depth varying shear currents. Beginning the formulation of the
water-wave problem due to [1], we extend the work of [4] and [18] to examine
the interface between two fluids of differing densities and varying linear
shear. We derive as systems of equations depending only on variables at the
interface, and numerically solve for periodic traveling wave solutions using
numerical continuation. Here we consider only branches which bifurcate from
solutions where there is no slip in the tangential velocity at the interface
for the trivial flow. The spectral stability of these solutions is then
determined using a numerical Fourier-Floquet technique. We find that the
strength of the linear shear in each fluid impacts the stability of the
corresponding traveling wave solutions. Specifically, opposing shears may
amplify or suppress instabilities.
",Physics
"  Chondrules are the dominant bulk silicate constituent of chondritic
meteorites and originate from highly energetic, local processes during the
first million years after the birth of the Sun. So far, an astrophysically
consistent chondrule formation scenario, explaining major chemical, isotopic
and textural features, remains elusive. Here, we examine the prospect of
forming chondrules from planetesimal collisions. We show that intensely melted
bodies with interior magma oceans became rapidly chemically equilibrated and
physically differentiated. Therefore, collisional interactions among such
bodies would have resulted in chondrule-like but basaltic spherules, which are
not observed in the meteoritic record. This inconsistency with the expected
dynamical interactions hints at an incomplete understanding of the planetary
growth regime during the protoplanetary disk phase. To resolve this conundrum,
we examine how the observed chemical and isotopic features of chondrules
constrain the dynamical environment of accreting chondrite parent bodies by
interpreting the meteoritic record as an impact-generated proxy of
planetesimals that underwent repeated collision and reaccretion cycles. Using a
coupled evolution-collision model we demonstrate that the vast majority of
collisional debris feeding the asteroid main belt must be derived from
planetesimals which were partially molten at maximum. Therefore, the precursors
of chondrite parent bodies either formed primarily small, from sub-canonical
aluminum-26 reservoirs, or collisional destruction mechanisms were efficient
enough to shatter planetesimals before they reached the magma ocean phase.
Finally, we outline the window in parameter space for which chondrule formation
from planetesimal collisions can be reconciled with the meteoritic record and
how our results can be used to further constrain early solar system dynamics.
",Physics
"  Based on the KP hierarchy reduction method, the general bright-dark mixed
multi-soliton solution of the multi-component Maccari system is constructed.
The multi-component Maccari system considered comprised of multiple (say $M$)
short-wave components and one long-wave component with all possible
combinations of nonlinearities including all-focusing, all-defocusing and mixed
types. We firstly derive the two-bright-one-dark (2-b-1-d) and
one-bright-two-dark (1-b-2-d) mixed multi-soliton solutions to the
three-component Maccari system in detail. For the interaction between two
solitons, the asymptotic analysis shows that inelastic collision can take place
in a $M$-component Maccari system with $M \geq 3$ only if the bright parts of
the mixed solitons appear at least in two short-wave components. The
energy-exchanging inelastic collision characterized by an intensity
redistribution among the bright parts of the mixed solitons. While the dark
parts of the mixed solitons and the solitons in the long-wave component always
undergo elastic collision which just accompanied by a position shift. In the
end, we extend the corresponding analysis to the $M$-component Maccari system
to obtain its mixed multi-soliton solution. The formula obtained unifies the
all-bright, all-dark and mixed multi-soliton solutions.
",Physics
"  Buoyancy-thermocapillary convection in a layer of volatile liquid driven by a
horizontal temperature gradient arises in a variety of situations. Recent
studies have shown that the composition of the gas phase, which is typically a
mixture of vapour and air, has a noticeable effect on the critical Marangoni
number describing the onset of convection as well as on the observed convection
pattern. Specifically, as the total pressure or, equivalently, the average
concentration of air is decreased, the threshold of the instability leading to
the emergence of convective rolls is found to increase rather significantly. We
present a linear stability analysis of the problem which shows that this trend
can be readily understood by considering the transport of heat and vapour
through the gas phase. In particular, we show that transport in the gas phase
has a noticeable effect even at atmospheric conditions, when phase change is
greatly suppressed.
",Physics
"  Kitaev quantum spin liquid is a topological magnetic quantum state
characterized by Majorana fermions of fractionalized spin excitations, which
are identical to their own antiparticles. Here, we demonstrate emergence of
Majorana fermions thermally fractionalized in the Kitaev honeycomb spin lattice
{\alpha}-RuCl3. The specific heat data unveil the characteristic two-stage
release of magnetic entropy involving localized and itinerant Majorana
fermions. The inelastic neutron scattering results further corroborate these
two distinct fermions by exhibiting quasielastic excitations at low energies
around the Brillouin zone center and Y-shaped magnetic continuum at high
energies, which are evident for the ferromagnetic Kitaev model. Our results
provide an opportunity to build a unified conceptual framework of
fractionalized excitations, applicable also for the quantum Hall states,
superconductors, and frustrated magnets.
",Physics
"  Electronic friction and the ensuing nonadiabatic energy loss play an
important role in chemical reaction dynamics at metal surfaces. Using molecular
dynamics with electronic friction evaluated on-the-fly from Density Functional
Theory, we find strong mode dependence and a dominance of nonadiabatic energy
loss along the bond stretch coordinate for scattering and dissociative
chemisorption of H$_2$ on the Ag(111) surface. Exemplary trajectories with
varying initial conditions indicate that this mode-specificity translates into
modulated energy loss during a dissociative chemisorption event. Despite minor
nonadiabatic energy loss of about 5\%, the directionality of friction forces
induces dynamical steering that affects individual reaction outcomes,
specifically for low-incidence energies and vibrationally excited molecules.
Mode-specific friction induces enhanced loss of rovibrational rather than
translational energy and will be most visible in its effect on final energy
distributions in molecular scattering experiments.
",Physics
"  The geodetic VLBI technique is capable of measuring the Sun's gravity light
deflection from distant radio sources around the whole sky. This light
deflection is equivalent to the conventional gravitational delay used for the
reduction of geodetic VLBI data. While numerous tests based on a global set of
VLBI data have shown that the parameter 'gamma' of the post-Newtonian
approximation is equal to unity with a precision of about 0.02 percent, more
detailed analysis reveals some systematic deviations depending on the angular
elongation from the Sun. In this paper a limited set of VLBI observations near
the Sun were adjusted to obtain the estimate of the parameter 'gamma' free of
the elongation angle impact. The parameter 'gamma' is still found to be close
to unity with precision of 0.06 percent, two subsets of VLBI data measured at
short and long baselines produce some statistical inconsistency.
",Physics
"  When deriving a master equation for a multipartite weakly-interacting open
quantum systems, dissipation is often addressed \textit{locally} on each
component, i.e. ignoring the coherent couplings, which are later added `by
hand'. Although simple, the resulting local master equation (LME) is known to
be thermodynamically inconsistent. Otherwise, one may always obtain a
consistent \textit{global} master equation (GME) by working on the energy basis
of the full interacting Hamiltonian. Here, we consider a two-node `quantum
wire' connected to two heat baths. The stationary solution of the LME and GME
are obtained and benchmarked against the exact result. Importantly, in our
model, the validity of the GME is constrained by the underlying secular
approximation. Whenever this breaks down (for resonant weakly-coupled nodes),
we observe that the LME, in spite of being thermodynamically flawed: (a)
predicts the correct steady state, (b) yields the exact asymptotic heat
currents, and (c) reliably reflects the correlations between the nodes. In
contrast, the GME fails at all three tasks. Nonetheless, as the inter-node
coupling grows, the LME breaks down whilst the GME becomes correct. Hence, the
global and local approach may be viewed as \textit{complementary} tools, best
suited to different parameter regimes.
",Physics
"  Spring-antispring systems have been investigated as possible low-frequency
seismic isolation in high-precision optical experiments. These systems provide
the possibility to tune the fundamental resonance frequency to, in principle,
arbitrarily low values, and at the same time maintain a compact design of the
isolation system. It was argued though that thermal noise in spring-antispring
systems would not be as small as one may naively expect from lowering the
fundamental resonance frequency. In this paper, we present a detailed
calculation of the suspension thermal noise for a specific spring-antispring
system, namely the Roberts linkage. We find a concise expression of the
suspension thermal noise spectrum, which assumes a form very similar to the
well-known expression for a simple pendulum. It is found that while the Roberts
linkage can provide strong seismic isolation due to a very low fundamental
resonance frequency, its thermal noise is rather determined by the dimension of
the system. We argue that this is true for all horizontal mechanical isolation
systems with spring-antispring dynamics. This imposes strict requirements on
mechanical spring-antispring systems for the seismic isolation in potential
future low-frequency gravitational-wave detectors as we discuss for the four
main concepts: atom-interferometric, superconducting, torsion-bars, and
conventional laser interferometer.
",Physics
"  H$_3^+$ is a ubiquitous and important astronomical species whose spectrum has
been observed in the interstellar medium, planets and tentatively in the
remnants of supernova SN1897a. Its role as a cooler is important for gas giant
planets and exoplanets, and possibly the early Universe. All this makes the
spectral properties, cooling function and partition function of H$_3^+$ key
parameters for astronomical models and analysis. A new high-accuracy, very
extensive line list for H$_3^+$ called MiZATeP was computed as part of the
ExoMol project alongside a temperature-dependent cooling function and partition
function as well as lifetimes for %individual excited states. These data are
made available in electronic form as supplementary data to this article and at
this http URL
",Physics
"  The most general expressions of the stored energies for time-harmonic
electromagnetic fields are derived from the time-domain Poynting theorem, and
are valuable in characterizing the energy storage and transport properties of
complex media. A new energy conservation law for the time-harmonic
electromagnetic fields, which involves the derived general expressions of the
stored energies, is introduced. In contrast to the well-established Poynting
theorem for time-harmonic fields, the real part of the new energy conservation
law gives an equation for the sum of stored electric and magnetic field
energies; the imaginary part involves an equation related to the difference
between the dissipated electric and magnetic field energies. In a lossless
isotropic and homogeneous medium, the new energy conservation law has a clear
physical implication: the stored electromagnetic field energy of a radiating
system enclosed by a surface is equal to the total field energy inside the
surface subtracted by the field energy flowing out of the surface.
",Physics
"  The current fleet of space-based solar observatories offers us a wealth of
opportunities to study solar flares over a range of wavelengths. Significant
advances in our understanding of flare physics often come from coordinated
observations between multiple instruments. Consequently, considerable efforts
have been, and continue to be made to coordinate observations among instruments
(e.g. through the Max Millennium Program of Solar Flare Research). However,
there has been no study to date that quantifies how many flares have been
observed by combinations of various instruments. Here we describe a technique
that retrospectively searches archival databases for flares jointly observed by
RHESSI, SDO/EVE (MEGS-A and -B), Hinode/(EIS, SOT, and XRT), and IRIS. Out of
the 6953 flares of GOES magnitude C1 or greater that we consider over the 6.5
years after the launch of SDO, 40 have been observed by six or more instruments
simultaneously. Using each instrument's individual rate of success in observing
flares, we show that the numbers of flares co-observed by three or more
instruments are higher than the number expected under the assumption that the
instruments operated independently of one another. In particular, the number of
flares observed by larger numbers of instruments is much higher than expected.
Our study illustrates that these missions often acted in cooperation, or at
least had aligned goals. We also provide details on an interactive widget now
available in SSWIDL that allows a user to search for flaring events that have
been observed by a chosen set of instruments. This provides access to a broader
range of events in order to answer specific science questions. The difficulty
in scheduling coordinated observations for solar-flare research is discussed
with respect to instruments projected to begin operations during Solar Cycle
25, such as DKIST, Solar Orbiter, and Parker Solar Probe.
",Physics
"  In this work we report the synthesis and structural, electronic and magnetic
properties of La1.5Ca0.5CoMnO6 double-perovskite. This is a re-entrant spin
cluster material which exhibits a non-negligible negative exchange bias effect
when it is cooled in zero magnetic field from an unmagnetized state down to low
temperature. X-ray powder diffraction, X-ray photoelectron spectroscopy and
magnetometry results indicate mixed valence state at Co site, leading to
competing magnetic phases and uncompensated spins at the magnetic interfaces.
We compare the results for this Ca-doped material with those reported for the
resemblant compound La1.5Sr0.5CoMnO6, and discuss the much smaller spontaneous
exchange bias effect observed for the former in terms of its structural and
magnetic particularities. For La1.5Ca0.5CoMnO6, when successive magnetization
loops are carried, the spontaneous exchange bias field inverts its sign from
negative to positive from the first to the second measurement. We discuss this
behavior based on the disorder at the magnetic interfaces, related to the
presence of a glassy phase. This compound also exhibits a large conventional
exchange bias, for which there is no sign inversion of the exchange bias field
for consecutive cycles.
",Physics
"  Incommensurately modulated twin structure of nyerereite Na1.64K0.36Ca(CO3)2
has been first determined in the (3+1)D symmetry group Cmcm({\alpha}00)00s with
modulation vector q = 0.383a*. Unit-cell values are a = 5.062(1), b = 8.790(1),
c = 12.744(1) {\AA}. Three orthorhombic components are related by threefold
rotation about [001]. Discontinuous crenel functions are used to describe
occupation modulation of Ca and some CO3 groups. Strong displacive modulation
of the oxygen atoms in vertexes of such CO3 groups is described using
x-harmonics in crenel intervals. The Na, K atoms occupy mixed sites whose
occupation modulation is described by two ways using either complementary
harmonic functions or crenels. The nyerereite structure has been compared both
with commensurately modulated structure of K-free Na2Ca(CO3)2 and with widely
known incommensurately modulated structure of {\gamma}-Na2CO3.
",Physics
"  Robustness of any statistics depends upon the number of assumptions it makes
about the measured data. We point out the advantages of median statistics using
toy numerical experiments and demonstrate its robustness, when the number of
assumptions we can make about the data are limited. We then apply the median
statistics technique to obtain estimates of two constants of nature, Hubble
Constant ($H_0$) and Newton's Gravitational Constant($G$), both of which show
significant differences between different measurements. For $H_0$, we update
the analysis done by Chen and Ratra (2011) and Gott et al. (2001) using $576$
measurements. We find after grouping the different results according to their
primary type of measurement, the median estimates are given by
$H_0=72.5^{+2.5}_{-8}$ km/sec/Mpc with errors corresponding to 95% c.l.
(2$\sigma$) and $G=6.674702^{+0.0014}_{-0.0009} \times 10^{-11} \mathrm{N
m^{2}kg^{-2}}$ corresponding to 68% c.l. (1$\sigma$).
",Physics
"  The total mass M_GCS in the globular cluster (GC) system of a galaxy is
empirically a near-constant fraction of the total mass M_h = M_bary + M_dark of
the galaxy, across a range of 10^5 in galaxy mass. This trend is radically
unlike the strongly nonlinear behavior of total stellar mass M_star versus M_h.
We discuss extensions of this trend to two more extreme situations: (a) entire
clusters of galaxies, and (b) the Ultra-Diffuse Galaxies (UDGs) recently
discovered in Coma and elsewhere. Our calibration of the ratio \eta_M = M_GCS /
M_h from normal galaxies, accounting for new revisions in the adopted
mass-to-light ratio for GCs, now gives \eta_M = 2.9 \times 10^{-5} as the mean
absolute mass fraction. We find that the same ratio appears valid for galaxy
clusters and UDGs. Estimates of \eta_M in the four clusters we examine tend to
be slightly higher than for individual galaxies, butmore data and better
constraints on the mean GC mass in such systems are needed to determine if this
difference is significant. We use the constancy of \eta_M to estimate total
masses for several individual cases; for example, the total mass of the Milky
Way is calculated to be M_h = 1.1 \times 10^{12} M_sun. Physical explanations
for the uniformity of \eta_M are still descriptive, but point to a picture in
which massive, dense star clusters in their formation stages were relatively
immune to the feedback that more strongly influenced lower-density regions
where most stars form.
",Physics
"  We report on the experimental realization of a state-dependent lattice for a
two-orbital fermionic quantum gas with strong interorbital spin exchange. In
our state-dependent lattice, the ground and metastable excited electronic
states of $^{173}$Yb take the roles of itinerant and localized magnetic
moments, respectively. Repulsive on-site interactions in conjunction with the
tunnel mobility lead to spin exchange between mobile and localized particles,
modeling the coupling term in the well-known Kondo Hamiltonian. In addition, we
find that this exchange process can be tuned resonantly by varying the on-site
confinement. We attribute this to a resonant coupling to center-of-mass excited
bound states of one interorbital scattering channel.
",Physics
"  A systematic first-principles study has been performed to understand the
magnetism of thin film SrRuO$_3$ which lots of research efforts have been
devoted to but no clear consensus has been reached about its ground state
properties. The relative t$_{2g}$ level difference, lattice distortion as well
as the layer thickness play together in determining the spin order. In
particular, it is important to understand the difference between two standard
approximations, namely LDA and GGA, in describing this metallic magnetism.
Landau free energy analysis and the magnetization-energy-ratio plot clearly
show the different tendency of favoring the magnetic moment formation, and it
is magnified when applied to the thin film limit where the experimental
information is severely limited. As a result, LDA gives a qualitatively
different prediction from GGA in the experimentally relevant region of strain
whereas both approximations give reasonable results for the bulk phase. We
discuss the origin of this difference and the applicability of standard methods
to the correlated oxide and the metallic magnetic systems.
",Physics
"  The evolution from superconducting LiTi2O4-delta to insulating Li4Ti5O12 thin
films has been studied by precisely adjusting the oxygen pressure during the
sample fabrication process. In the superconducting LiTi2O4-delta films, with
the increase of oxygen pressure, the oxygen vacancies are filled, and the
c-axis lattice constant decreases gradually. With the increase of the oxygen
pressure to a certain critical value, the c-axis lattice constant becomes
stable, which implies that the Li4Ti5O12 phase comes into being. The process of
oxygen filling is manifested by the angular bright-field images of the scanning
transmission electron microscopy techniques. The temperature of
magnetoresistance changed from positive and negative shows a non-monotonous
behavior with the increase of oxygen pressure. The theoretical explanation of
the oxygen effects on the structure and superconductivity of LiTi2O4-delta has
also been discussed in this work.
",Physics
"  The CHIME telescope (the Canadian Hydrogen Intensity Mapping Experiment)
recently built in Penticton, Canada, is currently being commissioned.
Originally designed as a cosmology experiment, it was soon recognized that
CHIME has the potential to simultaneously serve as an incredibly useful radio
telescope for pulsar science. CHIME operates across a wide bandwidth of 400-800
MHz and will have a collecting area and sensitivity comparable to that of the
100-m class radio telescopes. CHIME has a huge field of view of ~250 square
degrees. It will be capable of observing 10 pulsars simultaneously, 24-hours
per day, every day, while still accomplishing its missions to study Baryon
Acoustic Oscillations and Fast Radio Bursts. It will carry out daily monitoring
of roughly half of all pulsars in the northern hemisphere, including all
NANOGrav pulsars employed in the Pulsar Timing Array project. It will cycle
through all pulsars in the northern hemisphere with a range of cadence of no
more than 10 days.
",Physics
"  A stochastic minimization method for a real-space wavefunction, $\Psi({\bf
r}_{1},{\bf r}_{2}\ldots{\bf r}_{n})$, constrained to a chosen density,
$\rho({\bf r})$, is developed. It enables the explicit calculation of the Levy
constrained search
$F[\rho]=\min_{\Psi\rightarrow\rho}\langle\Psi|\hat{T}+\hat{V}_{ee}|\Psi\rangle$
(Proc. Natl. Acad. Sci. 76 6062 (1979)), that gives the exact functional of
density functional theory. This general method is illustrated in the evaluation
of $F[\rho]$ for two-electron densities in one dimension with a soft-Coulomb
interaction. Additionally, procedures are given to determine the first and
second functional derivatives, $\frac{\delta F}{\delta\rho({\bf r})}$ and
$\frac{\delta^{2}F}{\delta\rho({\bf r})\delta\rho({\bf r}')}$. For a chosen
external potential, $v({\bf r})$, the functional and its derivatives are used
in minimizations only over densities to give the exact energy, $E_{v}$ without
needing to solve the Schrödinger equation.
",Physics
"  Purpose: The analysis of optimized spin ensemble trajectories for relaxometry
in the hybrid state.
Methods: First, we constructed visual representations to elucidate the
differential equation that governs spin dynamics in hybrid state. Subsequently,
numerical optimizations were performed to find spin ensemble trajectories that
minimize the Cramér-Rao bound for $T_1$-encoding, $T_2$-encoding, and their
weighted sum, respectively, followed by a comparison of the Cramér-Rao bounds
obtained with our optimized spin-trajectories, as well as Look-Locker and
multi-spin-echo methods. Finally, we experimentally tested our optimized spin
trajectories with in vivo scans of the human brain.
Results: After a nonrecurring inversion segment on the southern hemisphere of
the Bloch sphere, all optimized spin trajectories pursue repetitive loops on
the northern half of the sphere in which the beginning of the first and the end
of the last loop deviate from the others. The numerical results obtained in
this work align well with intuitive insights gleaned directly from the
governing equation. Our results suggest that hybrid-state sequences outperform
traditional methods. Moreover, hybrid-state sequences that balance $T_1$- and
$T_2$-encoding still result in near optimal signal-to-noise efficiency. Thus,
the second parameter can be encoded at virtually no extra cost.
Conclusion: We provide insights regarding the optimal encoding processes of
spin relaxation times in order to guide the design of robust and efficient
pulse sequences. We find that joint acquisitions of $T_1$ and $T_2$ in the
hybrid state are substantially more efficient than sequential encoding
techniques.
",Physics
"  We study the asymmetry in the two-point cross-correlation function of two
populations of galaxies focusing in particular on the relativistic effects that
include the gravitational redshift. We derive the cross-correlation function on
small and large scales using two different approaches: General Relativistic and
Newtonian perturbation theory. Following recent work by Bonvin et al.,
Gaztanaga et al. and Croft, we calculate the dipole and the shell estimator
with the two procedures and we compare our results. We find that while General
Relativistic Perturbation Theory (GRPT) is able to make predictions of
relativistic effects on very large, obviously linear scales (r > 50 Mpc/h), the
presence of non-linearities physically occurring on much smaller scales (down
to those describing galactic potential wells) can strongly affect the asymmetry
estimators. These can lead to cancellations of the relativistic terms, and sign
changes in the estimators on scales up to r ~ 50 Mpc/h. On the other hand, with
an appropriate non-linear gravitational potential, the results obtained using
Newtonian theory can successfully describe the asymmetry on smaller, non-linear
scales (r < 20 Mpc/h) where gravitational redshift is the dominant term. On
larger scales the asymmetry is much smaller in magnitude, and measurement is
not within reach of current observations. This is in agreement with the
observational results obtained by Gaztnaga et al. and the first detection of
relativistic effects (on (r < 20 Mpc/h) scales) by Alam et al.
",Physics
"  In Kinetic Inductance Detectors (KIDs) and other similar applications of
superconducting microresonators, both the large and small-signal behaviour of
the device may be affected by electrothermal feedback. Microwave power applied
to read out the device is absorbed by and heats the superconductor
quasiparticles, changing the superconductor conductivity and hence the readout
power absorbed in a positive or negative feedback loop. In this work, we
explore numerically the implications of an extensible theoretical model of a
generic superconducting microresonator device for a typical KID, incorporating
recent work on the power flow between superconductor quasiparticles and
phonons. This model calculates the large-signal (changes in operating point)
and small-signal behaviour of a device, allowing us to determine the effect of
electrothermal feedback on device responsivity and noise characteristics under
various operating conditions. We also investigate how thermally isolating the
device from the bath, for example by designing the device on a membrane only
connected to the bulk substrate by thin legs, affects device performance. We
find that at a typical device operating point, positive electrothermal feedback
reduces the effective thermal conductance from the superconductor
quasiparticles to the bath, and so increases responsivity to signal
(pair-breaking) power, increases noise from temperature fluctuations, and
decreases the Noise Equivalent Power (NEP). Similarly, increasing the thermal
isolation of the device while keeping the quasiparticle temperature constant
decreases the NEP, but also decreases the device response bandwidth.
",Physics
"  Magnetic skyrmions are topological spin structures having immense potential
for energy efficient spintronic devices. However, observations of skyrmions at
room temperature are limited to patterned nanostructures. Here, we report the
observation of stable skyrmions in unpatterned Ta/Co2FeAl(CFA)/MgO thin film
heterostructures at room temperature and in zero external magnetic field
employing magnetic force microscopy. The skyrmions are observed in a trilayer
structure comprised of heavy metal (HM)/ferromagnet (FM)/Oxide interfaces which
result in strong interfacial Dzyaloshinskii-Moriya interaction (i-DMI) as
evidenced by Brillouin light scattering measurements, in agreement with the
results of micromagnetic simulations. We also emphasize on room temperature
observation of multiple skyrmions which can be stabilized for suitable choices
of CFA layer thickness, perpendicular magnetic anisotropy, and i-DMI. These
results open up a new paradigm for designing room temperature spintronic
devices based on skyrmions in FM continuous thin films.
",Physics
"  High-resolution observations of the solar chromosphere and transition region
often reveal surge-like oscillatory activities above sunspot light bridges.
These oscillations are often interpreted as intermittent plasma jets produced
by quasi-periodic magnetic reconnection. We have analyzed the oscillations
above a light bridge in a sunspot using data taken by the Interface Region
Imaging Spectrograph (IRIS). The chromospheric 2796\AA{}~images show surge-like
activities above the entire light bridge at any time, forming an oscillating
wall. Within the wall we often see that the Mg~{\sc{ii}}~k 2796.35\AA{}~line
core first experiences a large blueshift, and then gradually decreases to zero
shift before increasing to a red shift of comparable magnitude. Such a behavior
suggests that the oscillations are highly nonlinear and likely related to
shocks. In the 1400\AA{}~passband which samples emission mainly from the
Si~{\sc{iv}}~ion, the most prominent feature is a bright oscillatory front
ahead of the surges. We find a positive correlation between the acceleration
and maximum velocity of the moving front, which is consistent with numerical
simulations of upward propagating slow-mode shock waves. The Si~{\sc{iv}}
1402.77\AA{}~line profile is generally enhanced and broadened in the bright
front, which might be caused by turbulence generated through compression or by
the shocks. These results, together with the fact that the oscillation period
stays almost unchanged over a long duration, lead us to propose that the
surge-like oscillations above light bridges are caused by shocked p-mode waves
leaked from the underlying photosphere.
",Physics
"  Composite materials comprised of ferroelectric nanoparticles in a dielectric
matrix are being actively investigated for a variety of functional properties
attractive for a wide range of novel electronic and energy harvesting devices.
However, the dependence of these functionalities on shapes, sizes, orientation
and mutual arrangement of ferroelectric particles is currently not fully
understood. In this study, we utilize a time-dependent Ginzburg-Landau approach
combined with coupled-physics finite-element-method based simulations to
elucidate the behavior of polarization in isolated spherical PbTiO3 or BaTiO3
nanoparticles embedded in a dielectric medium, including air. The equilibrium
polarization topology is strongly affected by particle diameter, as well as the
choice of inclusion and matrix materials, with monodomain, vortex-like and
multidomain patterns emerging for various combinations of size and materials
parameters. This leads to radically different polarization vs electric field
responses, resulting in highly tunable size-dependent dielectric properties
that should be possible to observe experimentally. Our calculations show that
there is a critical particle size below which ferroelectricity vanishes. For
the PbTiO3 particle, this size is 2 and 3.4 nm, respectively, for high- and
low-permittivity media. For the BaTiO3 particle, it is ~3.6 nm regardless of
the medium dielectric strength.
",Physics
"  In this paper, we describe the optical imaging data processing pipeline
developed for the Subaru Telescope's Hyper Suprime-Cam (HSC) instrument. The
HSC Pipeline builds on the prototype pipeline being developed by the Large
Synoptic Survey Telescope's Data Management system, adding customizations for
HSC, large-scale processing capabilities, and novel algorithms that have since
been reincorporated into the LSST codebase. While designed primarily to reduce
HSC Subaru Strategic Program (SSP) data, it is also the recommended pipeline
for reducing general-observer HSC data. The HSC pipeline includes high level
processing steps that generate coadded images and science-ready catalogs as
well as low-level detrending and image characterizations.
",Physics
"  This paper describes a simple yet novel system for generating a highly
viscous microjet. The jet is produced inside a wettable thin tube partially
submerged in a liquid. The gas-liquid interface inside the tube, which is
initially concave, is kept much deeper than that outside the tube. An impulsive
force applied at the bottom of a liquid container leads to significant
acceleration of the liquid inside the tube followed by flow-focusing due to the
concave interface. The jet generation process can be divided into two parts
that occur in different time scales, i.e. the Impact time (impact duration $\le
O(10^{-4})$ s) and Focusing time (focusing duration $\gg O(10^{-4})$ s). In
Impact time, the liquid accelerates suddenly due to the impact. In Focusing
time, the microjet emerges due to flow-focusing. In order to explain the sudden
acceleration inside the tube in Impact time, we develop a physical model based
on a pressure impulse approach. Numerical simulations confirm the proposed
model, indicating that the basic mechanism of the acceleration of the liquid
due to the impulsive force is elucidated. Remarkably, the viscous effect is
negligible in Impact time. In contrast, in Focusing time, the viscosity plays
an important role in the microjet generation. We experimentally and numerically
investigate the velocity of microjets with various viscosities. We find that
higher viscosities lead to reduction of the jet velocity, which can be
described by using Reynolds number (the ratio between the inertia force and the
viscous force). This novel device may be a starting point for next-generation
technologies, such as high-viscosity inkjet printers including bioprinters and
needle-free injection devices for minimally invasive medical treatments.
",Physics
"  We show, in the case of a special dipolar source, that electromagnetic fields
in fractional quantum mechanics have an unexpected space dependence:
propagating fields may have non-transverse components, and the distinction
between near-field zone and wave zone is blurred. We employ an extension of
Maxwell theory, Aharonov-Bohm electrodynamics, which is compatible with
currents $j^\nu$ conserved globally but not locally, we have derived in another
work the field equation $\partial_\mu F^{\mu \nu}=j^\nu+i^\nu$, where $i^\nu$
is a non-local function of $j^\nu$, called ""secondary current"". Y.\ Wei has
recently proved that the probability current in fractional quantum mechanics is
in general not locally conserved. We compute this current for a Gaussian wave
packet with fractional parameter $a=3/2$ and find that in a suitable limit it
can be approximated by our simplified dipolar source. Currents which are not
locally conserved may be present also in other quantum systems whose wave
functions satisfy non-local equations. The combined electromagnetic effects of
such sources and their secondary currents are very interesting both
theoretically and for potential applications.
",Physics
"  We present a compact current sensor based on a superconducting microwave
lumped-element resonator with a nanowire kinetic inductor, operating at 4.2 K.
The sensor is suitable for multiplexed readout in GHz range of large-format
arrays of cryogenic detectors. The device consists of a lumped-element resonant
circuit, fabricated from a single 4-nm-thick superconducting layer of niobium
nitride. Thus, the fabrication and operation is significantly simplified in
comparison to state-of-the-art approaches. Because the resonant circuit is
inductively coupled to the feed line the current to be measured can directly be
injected without having the need of an impedance matching circuit, reducing the
system complexity. With the proof-of-concept device we measured a current noise
floor {\delta}Imin of 10 pA/Hz1/2 at 10 kHz. Furthermore, we demonstrate the
ability of our sensor to amplify a pulsed response of a superconducting
nanowire single-photon detector using a GHz-range carrier for effective
frequency-division multiplexing.
",Physics
"  We report on the design and performance of a mixed-signal application
specific integrated circuit (ASIC) dedicated to avalanche photodiodes (APDs) in
order to detect hard X-ray emissions in a wide energy band onboard the
International Space Station. To realize wide-band detection from 20 keV to 1
MeV, we use Ce:GAGG scintillators, each coupled to an APD, with low-noise
front-end electronics capable of achieving a minimum energy detection threshold
of 20 keV. The developed ASIC has the ability to read out 32-channel APD
signals using 0.35 $\mu$m CMOS technology, and an analog amplifier at the input
stage is designed to suppress the capacitive noise primarily arising from the
large detector capacitance of the APDs. The ASIC achieves a performance of 2099
e$^{-}$ + 1.5 e$^{-}$/pF at root mean square (RMS) with a wide 300 fC dynamic
range. Coupling a reverse-type APD with a Ce:GAGG scintillator, we obtain an
energy resolution of 6.7% (FWHM) at 662 keV and a minimum detectable energy of
20 keV at room temperature (20 $^{\circ}$C). Furthermore, we examine the
radiation tolerance for space applications by using a 90 MeV proton beam,
confirming that the ASIC is free of single-event effects and can operate
properly without serious degradation in analog and digital processing.
",Physics
"  We discuss a low energy $e^+e^-$ collider for production of the not yet
observed ($\mu^+\mu^-$) bound system (dimuonium). Collider with large crossing
angle for $e^+e^-$ beams intersection produces dimuonium with non-zero
momentum, therefore, its decay point is shifted from the beam collision area
providing effective suppression of the elastic $e^+e^-$ scattering background.
The experimental constraints define subsequent collider specifications. We show
preliminary layout of the accelerator and obtained main parameters. High
luminosity in chosen beam energy range allows to study $\pi^\pm$ and $\eta$
-mesons.
",Physics
"  We consider a modification to the standard cosmological history consisting of
introducing a new species $\phi$ whose energy density red-shifts with the scale
factor $a$ like $\rho_\phi \propto a^{-(4+n)}$. For $n>0$, such a red-shift is
faster than radiation, hence the new species dominates the energy budget of the
universe at early times while it is completely negligible at late times. If
equality with the radiation energy density is achieved at low enough
temperatures, dark matter can be produced as a thermal relic during the new
cosmological phase. Dark matter freeze-out then occurs at higher temperatures
compared to the standard case, implying that reproducing the observed abundance
requires significantly larger annihilation rates. Here, we point out a
completely new phenomenon, which we refer to as $\textit{relentless}$ dark
matter: for large enough $n$, unlike the standard case where annihilation ends
shortly after the departure from thermal equilibrium, dark matter particles
keep annihilating long after leaving chemical equilibrium, with a significant
depletion of the final relic abundance. Relentless annihilation occurs for $n
\geq 2$ and $n \geq 4$ for s-wave and p-wave annihilation, respectively, and it
thus occurs in well motivated scenarios such as a quintessence with a kination
phase. We discuss a few microscopic realizations for the new cosmological
component and highlight the phenomenological consequences of our calculations
for dark matter searches.
",Physics
"  The optical memory effect is a well-known type of wave correlation that is
observed in coherent fields that scatter through thin and diffusive materials,
like biological tissue. It is a fundamental physical property of scattering
media that can be harnessed for deep-tissue microscopy or 'through-the-wall'
imaging applications. Here we show that the optical memory effect is a special
case of a far more general class of wave correlation. Our new theoretical
framework explains how waves remain correlated over both space and angle when
they are jointly shifted and tilted inside scattering media of arbitrary
geometry. We experimentally demonstrate the existence of such coupled
correlations and describe how they can be used to optimize the scanning range
in adaptive optics microscopes.
",Physics
"  By means of first-principles calculations, we investigate the thermal
properties of silica as it evolves, under hydrostatic compression, from a
stishovite phase into a CaCl$_2$-type structure. We compute the thermal
conductivity tensor by solving the linearized Boltzmann transport equation
iteratively in a wide temperature range, using for this the pressure-dependent
harmonic and anharmonic interatomic couplings obtained from first principles.
Most remarkably, we find that, at low temperatures, SiO$_2$ displays a large
peak in the in-plane thermal conductivity and a highly anisotropic behavior
close to the structural transformation. We trace back the origin of these
features by analyzing the phonon contributions to the conductivity. We discuss
the implications of our results in the general context of continuous structural
transformations in solids, as well as the potential geological interest of our
results for silica.
",Physics
"  Controlling nanocircuits at the single electron spin level is a possible
route for large-scale quantum information processing. In this context,
individual electron spins have been identified as versatile quantum information
carriers to interconnect different nodes of a spin-based semiconductor quantum
circuit. Despite important experimental efforts to control the electron
displacement over long distances, keeping the electron spin coherence after
transfer remained up to now elusive. Here we demonstrate that individual
electron spins can be displaced coherently over a distance of 5 micrometers.
This displacement is realized on a closed path made of three tunnel-coupled
lateral quantum dots. Using fast quantum dot control, the electrons tunnel from
one dot to another at a speed approaching 100 m/s. We find that the spin
coherence length is 8 times longer than expected from the electron spin
coherence without displacement. Such an enhanced spin coherence points at a
process similar to motional narrowing observed in nuclear magnetic resonance
experiments6. The demonstrated coherent displacement will enable long-range
interaction between distant spin-qubits and will open the route towards
non-abelian and holonomic manipulation of a single electron spin.
",Physics
"  We present a model to generate power spectrum noise with intensity
proportional to 1/f as a function of frequency f. The model arises from a
broken-symmetry variable which corresponds to absolute pitch, where
fluctuations occur in an attempt to restore that symmetry, influenced by
interactions in the creation of musical melodies.
",Physics
"  Observations of diffuse starlight in the outskirts of galaxies are thought to
be a fundamental source of constraints on the cosmological context of galaxy
assembly in the $\Lambda$CDM model. Such observations are not trivial because
of the extreme faintness of such regions. In this work, we investigate the
photometric properties of six massive early type galaxies (ETGs) in the VEGAS
sample (NGC 1399, NGC 3923, NGC 4365, NGC 4472, NGC 5044, and NGC 5846) out to
extremely low surface brightness levels, with the goal of characterizing the
global structure of their light profiles for comparison to state-of-the-art
galaxy formation models. We carry out deep and detailed photometric mapping of
our ETG sample taking advantage of deep imaging with VST/OmegaCAM in the g and
i bands. By fitting the light profiles, and comparing the results to
simulations of elliptical galaxy assembly, we identify signatures of a
transition between ""relaxed"" and ""unrelaxed"" accreted components and can
constrain the balance between in situ and accreted stars. The very good
agreement of our results with predictions from theoretical simulations
demonstrates that the full VEGAS sample of $\sim 100$ ETGs will allow us to use
the distribution of diffuse light as a robust statistical probe of the
hierarchical assembly of massive galaxies.
",Physics
"  We present results from a 100 ks XMM-Newton observation of galaxy cluster
XLSSC 122, the first massive cluster discovered through its X-ray emission at
$z\approx2$. The data provide the first precise constraints on the bulk
thermodynamic properties of such a distant cluster, as well as an X-ray
spectroscopic confirmation of its redshift. We measure an average temperature
of $kT=5.0\pm0.7$ keV; a metallicity with respect to solar of
$Z/Z_{\odot}=0.33^{+0.19}_{-0.17}$, consistent with lower-redshift clusters;
and a redshift of $z=1.99^{+0.07}_{-0.06}$, consistent with the earlier photo-z
estimate. The measured gas density profile leads to a mass estimate at
$r_{500}$ of $M_{500}=(6.3\pm1.5)\times10^{13}M_{\odot}$. From CARMA 30 GHz
data, we measure the spherically integrated Compton parameter within $r_{500}$
to be $Y_{500}=(3.6\pm0.4)\times10^{-12}$. We compare the measured properties
of XLSSC 122 to lower-redshift cluster samples, and find good agreement when
assuming the simplest (self-similar) form for the evolution of cluster scaling
relations. While a single cluster provides limited information, this result
suggests that the evolution of the intracluster medium in the most massive,
well developed clusters is remarkably simple, even out to the highest redshifts
where they have been found. At the same time, our data reaffirm the previously
reported spatial offset between the centers of the X-ray and SZ signals for
XLSSC 122, suggesting a disturbed configuration. Higher spatial resolution data
could thus provide greater insights into the internal dynamics of this system.
",Physics
"  We study the effect of a uniform external magnetization on p-wave
superconductivity on the (001) surface of the crystalline topological
insulator(TCI) Pb$_{1-x}$Sn$_{x}$Te. It was shown by us in an earlier work that
a chiral p-wave finite momentum pairing (FFLO) state can be stabilized in this
system in the presence of weak repulsive interparticle interactions. In
particular, the superconducting instability is very sensitive to the Hund's
interaction in the multiorbital TCI, and no instabilities are found to be
possible for the ""wrong"" sign of the Hund's splitting. Here we show that for a
finite Hund's splitting of interactions, a significant value of the external
magnetization is needed to degrade the surface superconductivity, while in the
absence of the Hund's interaction, an arbitrarily small external magnetization
can destroy the superconductivity. This implies that multiorbital effects in
this system play an important role in stabilizing electronic order on the
surface.
",Physics
"  We have performed realistic atomistic simulations at finite temperatures
using Monte Carlo and atomistic spin dynamics simulations incorporating quantum
(Bose-Einstein) statistics. The description is much improved at low
temperatures compared to classical (Boltzmann) statistics normally used in
these kind of simulations, while at higher temperatures the classical
statistics are recovered. This corrected low-temperature description is
reflected in both magnetization and the magnetic specific heat, the latter
allowing for improved modeling of the magnetic contribution to free energies. A
central property in the method is the magnon density of states at finite
temperatures and we have compared several different implementations for
obtaining it. The method has no restrictions regarding chemical and magnetic
order of the considered materials. This is demonstrated by applying the method
to elemental ferromagnetic systems, including Fe and Ni, as well as Fe-Co
random alloys and the ferrimagnetic system GdFe$_3$ .
",Physics
"  The large majority of high energy sources detected with Fermi-LAT are
blazars, which are known to be very variable sources. High cadence long-term
monitoring simultaneously at different wavelengths being prohibitive, the study
of their transient activities can help shedding light on our understanding of
these objects. The early detection of such potentially fast transient events is
the key for triggering follow-up observations at other wavelengths. A Python
tool, FLaapLUC, built on top of the Science Tools provided by the Fermi Science
Support Center and the Fermi-LAT collaboration, has been developed using a
simple aperture photometry approach. This tool can effectively detect relative
flux variations in a set of predefined sources and alert potential users. Such
alerts can then be used to trigger target of opportunity observations with
other facilities. It is shown that FLaapLUC is an efficient tool to reveal
transient events in Fermi-LAT data, providing quick results which can be used
to promptly organise follow-up observations. Results from this simple aperture
photometry method are also compared to full likelihood analyses. The FLaapLUC
package is made available on GitHub and is open to contributions by the
community.
",Physics
"  A two-dimensional bidisperse granular fluid is shown to exhibit pronounced
long-ranged dynamical heterogeneities as dynamical arrest is approached. Here
we focus on the most direct approach to study these heterogeneities: we
identify clusters of slow particles and determine their size, $N_c$, and their
radius of gyration, $R_G$. We show that $N_c\propto R_G^{d_f}$, providing
direct evidence that the most immobile particles arrange in fractal objects
with a fractal dimension, $d_f$, that is observed to increase with packing
fraction $\phi$. The cluster size distribution obeys scaling, approaching an
algebraic decay in the limit of structural arrest, i.e., $\phi\to\phi_c$.
Alternatively, dynamical heterogeneities are analyzed via the four-point
structure factor $S_4(q,t)$ and the dynamical susceptibility $\chi_4(t)$.
$S_4(q,t)$ is shown to obey scaling in the full range of packing fractions,
$0.6\leq\phi\leq 0.805$, and to become increasingly long-ranged as
$\phi\to\phi_c$. Finite size scaling of $\chi_4(t)$ provides a consistency
check for the previously analyzed divergences of $\chi_4(t)\propto
(\phi-\phi_c)^{-\gamma_{\chi}}$ and the correlation length $\xi\propto
(\phi-\phi_c)^{-\gamma_{\xi}}$. We check the robustness of our results with
respect to our definition of mobility. The divergences and the scaling for
$\phi\to\phi_c$ suggest a non-equilibrium glass transition which seems
qualitatively independent of the coefficient of restitution.
",Physics
"  Spin-relaxation is conventionally discussed using two different approaches
for materials with and without inversion symmetry. The former is known as the
Elliott-Yafet (EY) theory and for the latter the D'yakonov-Perel' (DP) theory
applies, respectively. We discuss herein a simple and intuitive approach to
demonstrate that the two seemingly disparate mechanisms are closely related. A
compelling analogy between the respective Hamiltonian is presented and that the
usual derivation of spin-relaxation times, in the respective frameworks of the
two theories, can be performed. The result also allows to obtain the less
canonical spin-relaxation regimes; the generalization of the EY when the
material has a large quasiparticle broadening and the DP mechanism in ultrapure
semiconductors. The method also allows a practical and intuitive numerical
implementation of the spin-relaxation calculation, which is demonstrated for
MgB$_2$ that has anomalous spin-relaxation properties.
",Physics
"  Silicon single-photon detectors (SPDs) are the key devices for detecting
single photons in the visible wavelength range. Here we present high detection
efficiency silicon SPDs dedicated to the generation of multiphoton entanglement
based on the technique of high-frequency sine wave gating. The silicon
single-photon avalanche diodes (SPADs) components are acquired by disassembling
6 commercial single-photon counting modules (SPCMs). Using the new quenching
electronics, the average detection efficiency of SPDs is increased from 68.6%
to 73.1% at a wavelength of 785 nm. These sine wave gating SPDs are then
applied in a four-photon entanglement experiment, and the four-fold coincidence
count rate is increased by 30% without degrading its visibility compared with
the original SPCMs.
",Physics
"  Modulating the amplitude and phase of light is at the heart of many
applications such as wavefront shaping, transformation optics, phased arrays,
modulators and sensors. Performing this task with high efficiency and small
footprint is a formidable challenge. Metasurfaces and plasmonics are promising
, but metals exhibit weak electro-optic effects. Two-dimensional materials,
such as graphene, have shown great performance as modulators with small drive
voltages. Here we show a graphene plasmonic phase modulator which is capable of
tuning the phase between 0 and 2{\pi} in situ. With a footprint of 350nm it is
more than 30 times smaller than the 10.6$\mu$m free space wavelength. The
modulation is achieved by spatially controlling the plasmon phase velocity in a
device where the spatial carrier density profile is tunable. We provide a
scattering theory for plasmons propagating through spatial density profiles.
This work constitutes a first step towards two-dimensional transformation
optics for ultra-compact modulators and biosensing.
",Physics
"  We present a measurement of baryon acoustic oscillations (BAO) in the
cross-correlation of quasars with the Ly$\alpha$-forest flux-transmission at a
mean redshift $z=2.40$. The measurement uses the complete SDSS-III data sample:
168,889 forests and 234,367 quasars from the SDSS Data Release DR12. In
addition to the statistical improvement on our previous study using DR11, we
have implemented numerous improvements at the analysis level allowing a more
accurate measurement of this cross-correlation. We also developed the first
simulations of the cross-correlation allowing us to test different aspects of
our data analysis and to search for potential systematic errors in the
determination of the BAO peak position. We measure the two ratios
$D_{H}(z=2.40)/r_{d} = 9.01 \pm 0.36$ and $D_{M}(z=2.40)/r_{d} = 35.7 \pm 1.7$,
where the errors include marginalization over the non-linear velocity of
quasars and the metal - quasar cross-correlation contribution, among other
effects. These results are within $1.8\sigma$ of the prediction of the
flat-$\Lambda$CDM model describing the observed CMB anisotropies. We combine
this study with the Ly$\alpha$-forest auto-correlation function
[2017A&A...603A..12B], yielding $D_{H}(z=2.40)/r_{d} = 8.94 \pm 0.22$ and
$D_{M}(z=2.40)/r_{d} = 36.6 \pm 1.2$, within $2.3\sigma$ of the same
flat-$\Lambda$CDM model.
",Physics
"  It has recently been discovered that some, if not all, classical novae emit
GeV gamma rays during outburst, but the mechanisms involved in the production
of the gamma rays are still not well understood. We present here a
comprehensive multi-wavelength dataset---from radio to X-rays---for the most
gamma-ray luminous classical nova to-date, V1324 Sco. Using this dataset, we
show that V1324 Sco is a canonical dusty Fe-II type nova, with a maximum ejecta
velocity of 2600 km s$^{-1}$ and an ejecta mass of few $\times 10^{-5}$
M$_{\odot}$. There is also evidence for complex shock interactions, including a
double-peaked radio light curve which shows high brightness temperatures at
early times. To explore why V1324~Sco was so gamma-ray luminous, we present a
model of the nova ejecta featuring strong internal shocks, and find that higher
gamma-ray luminosities result from higher ejecta velocities and/or mass-loss
rates. Comparison of V1324~Sco with other gamma-ray detected novae does not
show clear signatures of either, and we conclude that a larger sample of
similarly well-observed novae is needed to understand the origin and variation
of gamma rays in novae.
",Physics
"  We have studied the impact of low-frequency magnetic flux noise upon
superconducting transmon qubits with various levels of tunability. We find that
qubits with weaker tunability exhibit dephasing that is less sensitive to flux
noise. This insight was used to fabricate qubits where dephasing due to flux
noise was suppressed below other dephasing sources, leading to flux-independent
dephasing times T2* ~ 15 us over a tunable range of ~340 MHz. Such tunable
qubits have the potential to create high-fidelity, fault-tolerant qubit gates
and fundamentally improve scalability for a quantum processor.
",Physics
"  We propose a high signal-to-noise extended depth-range three-dimensional (3D)
profilometer projecting two linear-fringes with close phase-sensitivity. We use
temporal phase-shifting algorithms (PSAs) to phase-demodulate the two close
sensitivity phases. Then we calculate their phase-difference and their
phase-sum. If the sensitivity between the two phases is close enough, their
phase-difference is not-wrapped. The non-wrapped phase-difference as
extended-range profilometry is well known and has been widely used. However as
this paper shows, the closeness between the two demodulated phases makes their
difference quite noisy. On the other hand, as we show, their phase-sum has a
much higher phase-sensitivity and signal-to-noise ratio but it is highly
wrapped. Spatial unwrapping of the phase-sum is precluded for separate or
highly discontinuous objects. However it is possible to unwrap the phase-sum by
using the phase-difference as first approximation and our previously published
2-step temporal phase-unwrapping. Therefore the proposed profilometry technique
allows unwrapping the higher sensitivity phase-sum using the noisier
phase-difference as stepping stone. Due to the non-linear nature of the
extended 2-steps temporal-unwrapper, the harmonics and noise errors in the
phase-difference do not propagate towards the unwrapping phase-sum. To the best
of our knowledge this is the highest signal-to-noise ratio, extended
depth-range, 3D digital profilometry technique reported to this date.
",Physics
"  The fundamental theory of energy networks in different energy forms is
established following an in-depth analysis of the nature of energy for
comprehensive energy utilization. The definition of an energy network is given.
Combining the generalized balance equation of energy in space and the Pfaffian
equation, the generalized transfer equations of energy in lines (pipes) are
proposed. The energy variation laws in the transfer processes are investigated.
To establish the equations of energy networks, the Kirchhoff's Law in electric
networks is extended to energy networks, which is called the Generalized
Kirchhoff""s Law. According to the linear phenomenological law, the generalized
equivalent energy transfer equations with lumped parameters are derived in
terms of the characteristic equations of energy transfer in lines(pipes).The
equations are finally unified into a complete energy network equation system
and its solvability is further discussed. Experiments are carried out on a
combined cooling, heating and power(CCHP) system in engineering, the energy
network theory proposed in this paper is used to model and analyze this system.
By comparing the theoretical results obtained by our modeling approach and the
data measured in experiments, the energy equations are validated.
",Physics
"  Using the Fenchel-Eggleston theorem for convex hulls (an extension of the
Caratheodory theorem), we prove that any likelihood can be maximized by either
a dark matter 1- speed distribution $F(v)$ in Earth's frame or 2- Galactic
velocity distribution $f^{\rm gal}(\vec{u})$, consisting of a sum of delta
functions. The former case applies only to time-averaged rate measurements and
the maximum number of delta functions is $({\mathcal N}-1)$, where ${\mathcal
N}$ is the total number of data entries. The second case applies to any
harmonic expansion coefficient of the time-dependent rate and the maximum
number of terms is ${\mathcal N}$. Using time-averaged rates, the
aforementioned form of $F(v)$ results in a piecewise constant unmodulated halo
function $\tilde\eta^0_{BF}(v_{\rm min})$ (which is an integral of the speed
distribution) with at most $({\mathcal N}-1)$ downward steps. The authors had
previously proven this result for likelihoods comprised of at least one
extended likelihood, and found the best-fit halo function to be unique. This
uniqueness, however, cannot be guaranteed in the more general analysis applied
to arbitrary likelihoods. Thus we introduce a method for determining whether
there exists a unique best-fit halo function, and provide a procedure for
constructing either a pointwise confidence band, if the best-fit halo function
is unique, or a degeneracy band, if it is not. Using measurements of modulation
amplitudes, the aforementioned form of $f^{\rm gal}(\vec{u})$, which is a sum
of Galactic streams, yields a periodic time-dependent halo function
$\tilde\eta_{BF}(v_{\rm min}, t)$ which at any fixed time is a piecewise
constant function of $v_{\rm min}$ with at most ${\mathcal N}$ downward steps.
In this case, we explain how to construct pointwise confidence and degeneracy
bands from the time-averaged halo function. Finally, we show that requiring an
isotropic ...
",Physics
"  Debris disk morphology is wavelength dependent due to the wide range of
particle sizes and size-dependent dynamics influenced by various forces.
Resolved images of nearby debris disks reveal complex disk structures that are
difficult to distinguish from their spectral energy distributions. Therefore,
multi-wavelength resolved images of nearby debris systems provide an essential
foundation to understand the intricate interplay between collisional,
gravitational, and radiative forces that govern debris disk structures. We
present the SOFIA 35 um resolved disk image of epsilon Eri, the closest debris
disk around a star similar to the early Sun. Combining with the Spitzer
resolved image at 24 um and 15-38 um excess spectrum, we examine two proposed
origins of the inner debris in epsilon Eri: (1) in-situ planetesimal belt(s)
and (2) dragged-in grains from the cold outer belt. We find that the presence
of in-situ dust-producing planetesmial belt(s) is the most likely source of the
excess emission in the inner 25 au region. Although a small amount of
dragged-in grains from the cold belt could contribute to the excess emission in
the inner region, the resolution of the SOFIA data is high enough to rule out
the possibility that the entire inner warm excess results from dragged-in
grains, but not enough to distinguish one broad inner disk from two narrow
belts.
",Physics
"  We study the elementary characteristics of turbulence in a quantum ferrofluid
through the context of a dipolar Bose gas condensing from a highly
non-equilibrium thermal state. Our simulations reveal that the dipolar
interactions drive the emergence of polarized turbulence and density
corrugations. The superfluid vortex lines and density fluctuations adopt a
columnar or stratified configuration, depending on the sign of the dipolar
interactions, with the vortices tending to form in the low density regions to
minimize kinetic energy. When the interactions are dominantly dipolar, the
decay of vortex line length is enhanced, closely following a $t^{-3/2}$
behaviour. This system poses exciting prospects for realizing stratified
quantum turbulence and new levels of generating and controlling turbulence
using magnetic fields.
",Physics
"  A semicalssical method based on surface-hopping techniques is developed to
model the dynamics of radiative association with electronic transitions in
arbitrary polyatomic systems. It can be proven that our method is an extension
of the established semiclassical formula used in the characterization of
diatomic molecule- formation. Our model is tested for diatomic molecules. It
gives the same cross sections as the former semiclassical formula, but contrary
to the former method it allows us to follow the fate of the trajectories after
the emission of a photon. This means that we can characterize the rovibrational
states of the stabilized molecules: using semiclassial quantization we can
obtain quantum state resolved cross sections or emission spectra for the
radiative association process. The calculated semiclassical state resolved
spectra show good agreement with the result of quantum mechanical perturbation
theory. Furthermore our surface-hopping model is not only applicable for the
description of radiative association but it can be use for semiclassical
characterization of any molecular process where spontaneous emission occurs.
",Physics
"  We revisit the relation between the neutrino masses and the spontaneous
breaking of the B-L gauge symmetry. We discuss the main scenarios for Dirac and
Majorana neutrinos and point out two simple mechanisms for neutrino masses. In
this context the neutrino masses can be generated either at tree level or at
quantum level and one predicts the existence of very light sterile neutrinos
with masses below the eV scale. The predictions for lepton number violating
processes such as mu to e and mu to e gamma are discussed in detail. The impact
from the cosmological constraints on the effective number of relativistic
degree of freedom is investigated.
",Physics
"  We present late-time optical $R$-band imaging data from the Palomar Transient
Factory (PTF) for the nearby type Ia supernova SN 2011fe. The stacked PTF light
curve provides densely sampled coverage down to $R\simeq22$ mag over 200 to 620
days past explosion. Combining with literature data, we estimate the
pseudo-bolometric light curve for this event from 200 to 1600 days after
explosion, and constrain the likely near-infrared contribution. This light
curve shows a smooth decline consistent with radioactive decay, except over
~450 to ~600 days where the light curve appears to decrease faster than
expected based on the radioactive isotopes presumed to be present, before
flattening at around 600 days. We model the 200-1600d pseudo-bolometric light
curve with the luminosity generated by the radioactive decay chains of
$^{56}$Ni, $^{57}$Ni and $^{55}$Co, and find it is not consistent with models
that have full positron trapping and no infrared catastrophe (IRC); some
additional energy escape other than optical/near-IR photons is required.
However, the light curve is consistent with models that allow for positron
escape (reaching 75% by day 500) and/or an IRC (with 85% of the flux emerging
in non-optical wavelengths by day 600). The presence of the $^{57}$Ni decay
chain is robustly detected, but the $^{55}$Co decay chain is not formally
required, with an upper mass limit estimated at 0.014 M$_{\odot}$. The
measurement of the $^{57}$Ni/$^{56}$Ni mass ratio is subject to significant
systematic uncertainties, but all of our fits require a high ratio >0.031 (>1.3
in solar abundances).
",Physics
"  Platinum diselenide (PtSe2) is an exciting new member of the two-dimensional
(2D) transition metal dichalcogenide (TMD) family. it has a semimetal to
semiconductor transition when approaching monolayer thickness and has already
shown significant potential for use in device applications. Notably, PtSe2 can
be grown at low temperature making it potentially suitable for industrial
usage. Here, we address thickness dependent transport properties and
investigate electrical contacts to PtSe2, a crucial and universal element of
TMD-based electronic devices. PtSe2 films have been synthesized at various
thicknesses and structured to allow contact engineering and the accurate
extraction of electrical properties. Contact resistivity and sheet resistance
extracted from transmission line method (TLM) measurements are compared for
different contact metals and different PtSe2 film thicknesses. Furthermore, the
transition from semimetal to semiconductor in PtSe2 has been indirectly
verified by electrical characterization of field-effect devices. Finally, the
influence of edge contacts at the metal - PtSe2 interface has been studied by
nanostructuring the contact area using electron beam lithography. By increasing
the edge contact length, the contact resistivity was improved by up to 70%
compared to devices with conventional top contacts. The results presented here
represent crucial steps towards realizing high-performance nanoelectronic
devices based on group-10 TMDs.
",Physics
"  We present a one-parameter family of mathematical models describing the
dynamics of polarons in linear periodic structures such as polypeptides. By
tuning the parameter, we are able to recover the Davydov and the Scott models.
We describe the physical significance of this parameter. In the continuum
limit, we derive analytical solutions which represent stationary polarons. On a
discrete lattice, we compute stationary polaron solutions numerically. We
investigate polaron propagation induced by several external forcing mechanisms.
We show that an electric field consisting of a constant and a periodic
component can induce polaron motion with minimal energy loss. We also show that
thermal fluctuations can facilitate the onset of polaron motion. Finally, we
discuss the bio-physical implications of our results.
",Physics
"  The response of an electron system to electromagnetic fields with sharp
spatial variations is strongly dependent on quantum electronic properties, even
in ambient conditions, but difficult to access experimentally. We use
propagating graphene plasmons, together with an engineered dielectric-metallic
environment, to probe the graphene electron liquid and unveil its detailed
electronic response at short wavelengths.The near-field imaging experiments
reveal a parameter-free match with the full theoretical quantum description of
the massless Dirac electron gas, in which we identify three types of quantum
effects as keys to understanding the experimental response of graphene to
short-ranged terahertz electric fields. The first type is of single-particle
nature and is related to shape deformations of the Fermi surface during a
plasmon oscillations. The second and third types are a many-body effect
controlled by the inertia and compressibility of the interacting electron
liquid in graphene. We demonstrate how, in principle, our experimental approach
can determine the full spatiotemporal response of an electron system.
",Physics
"  The New Horizons spacecraft's nominal trajectory crosses the planet's
satellite plane at $\sim 10,000\ \rm{km}$ from the barycenter, between the
orbits of Pluto and Charon. I have investigated the risk to the spacecraft
based on observational limits of rings and dust within this region, assuming
various particle size distributions. The best limits are placed by 2011 and
2012 HST observations, which significantly improve on the limits from stellar
occultations, although they do not go as close to the planet. From the HST data
and assuming a `reasonable worst case' for the size distribution, we place a
limit of $N < 20$ damaging impacts by grains of radius $> 0.2\ \textrm{mm}$
onto the spacecraft during the encounter. The number of hits is $\approx$
200$\times$ above the NH mission requirement, and $\approx$ $2000\times$ above
the mission's desired level. Stellar occultations remain valuable because they
are able to measure $N$ closer to the Pluto surface than direct imaging,
although with a sensitivity limit several orders of magnitude higher than that
from HST imaging. Neither HST nor occultations are sensitive enough to place
limits on $N$ at or below the mission requirements.
",Physics
"  Dielectric lined waveguides are under extensive study as accelerating
structures that can be excited by electron beams. Rectangular dielectric
structures are used both in proof of principle experiments for new accelerating
schemes and for studying the electronic properties of the structure loading
material. Analysis of Cherenkov radiation generated by high current
relativistic electron bunch passing through a rectangular waveguide with
transversal isotropic dielectric loading has been carried out. Some of the
materials used for the waveguide loading of accelerating structures (sapphire,
ceramic films) possess significant anisotropic properties. In turn, it can
influence excitation parameters of the wakefields generated by an electron
beam. General solutions for the fields generated by a relativistic electron
beam propagating in a rectangular dielectric waveguide have been derived using
the orthogonal eigenmode decomposition method for the transverse operators of
the Helmholtz equation. The analytical expression for the combined Cherenkov
and Coulomb fields in terms of a superposition of LSM and LSE-modes of
rectangular waveguide with transversal isotropic dielectric loading has been
obtained. Numerical modelling of the longitudinal and transverse (deflecting)
wakefields has been carried out as well. It is shown that the dielectric
anisotropy causes frequency shift in comparison to the dielectric-lined
waveguide with the isotropic dielectric loading.
",Physics
"  The Greek aperitif Ouzo is not only famous for its specific anise-flavored
taste, but also for its ability to turn from a transparent miscible liquid to a
milky-white colored emulsion when water is added. Recently, it has been shown
that this so-called Ouzo effect, i.e. the spontaneous emulsification of oil
microdroplets, can also be triggered by the preferential evaporation of ethanol
in an evaporating sessile Ouzo drop, leading to an amazingly rich drying
process with multiple phase transitions [H. Tan et al., Proc. Natl. Acad. Sci.
USA 113(31) (2016) 8642]. Due to the enhanced evaporation near the contact
line, the nucleation of oil droplets starts at the rim which results in an oil
ring encircling the drop. Furthermore, the oil droplets are advected through
the Ouzo drop by a fast solutal Marangoni flow. In this article, we investigate
the evaporation of mixture droplets in more detail, by successively increasing
the mixture complexity from pure water over a binary water-ethanol mixture to
the ternary Ouzo mixture (water, ethanol and anise oil). In particular,
axisymmetric and full three-dimensional finite element method simulations have
been performed on these droplets to discuss thermal effects and the complicated
flow in the droplet driven by an interplay of preferential evaporation,
evaporative cooling and solutal and thermal Marangoni flow. By using image
analysis techniques and micro-PIV measurements, we are able to compare the
numerically predicted volume evolutions and velocity fields with experimental
data. The Ouzo droplet is furthermore investigated by confocal microscopy. It
is shown that the oil ring predominantly emerges due to coalescence.
",Physics
"  We investigate the time evolution of the entanglement entropy of coupled
single-mode Bose-Einstein condensates in a double well potential at $T=0$
temperature, by combining numerical results with analytical approximations. We
find that the coherent oscillations of the condensates result in entropy
oscillations on the top of a linear entropy generation at short time scales.
Due to dephasing, the entropy eventually saturates to a stationary value, in
spite of the lack of equilibration. We show that this long time limit of the
entropy reflects the semiclassical dynamics of the system, revealing the
self-trapping phase transition of the condensates at large interaction strength
by a sudden entropy jump. We compare the stationary limit of the entropy to the
prediction of a classical microcanonical ensemble, and find surprisingly good
agreement in spite of the non-equilibrium state of the system. Our predictions
should be experimentally observable on a Bose-Einstein condensate in a double
well potential or on a two-component condensate with inter-state coupling.
",Physics
"  Monolayers of transition metal dichalcogenides (TMDCs) exhibit excellent
electronic and optical properties. However, the performance of these
two-dimensional (2D) devices are often limited by the large resistance offered
by the metal contact interface. Till date, the carrier injection mechanism from
metal to 2D TMDC layers remains unclear, with widely varying reports of
Schottky barrier height (SBH) and contact resistance (Rc), particularly in the
monolayer limit. In this work, we use a combination of theory and experiments
in Au and Ni contacted monolayer MoS2 device to conclude the following points:
(i) the carriers are injected at the source contact through a cascade of two
potential barriers - the barrier heights being determined by the degree of
interaction between the metal and the TMDC layer; (ii) the conventional
Richardson equation becomes invalid due to the multi-dimensional nature of the
injection barriers, and using Bardeen-Tersoff theory, we derive the appropriate
form of the Richardson equation that describes such composite barrier; (iii) we
propose a novel transfer length method (TLM) based SBH extraction methodology,
to reliably extract SBH by eliminating any confounding effect of temperature
dependent channel resistance variation; (iv) we derive the Landauer limit of
the contact resistance achievable in such devices. A comparison of the limits
with the experimentally achieved contact resistance reveals plenty of room for
technological improvements.
",Physics
"  Intensive studies for more than three decades have elucidated multiple
superconducting phases and odd-parity Cooper pairs in a heavy fermion
superconductor UPt$_3$. We identify a time-reversal invariant superconducting
phase of UPt$_3$ as a recently proposed topological nonsymmorphic
superconductivity. Combining the band structure of UPt$_3$, order parameter of
$E_{\rm 2u}$ representation allowed by $P6_3/mmc$ space group symmetry, and
topological classification by $K$-theory, we demonstrate the nontrivial
$Z_2$-invariant of three-dimensional DIII class enriched by glide symmetry.
Correspondingly, double Majorana cone surface states appear at the surface
Brillouin zone boundary. Furthermore, we show a variety of surface states and
clarify the topological protection by crystal symmetry. Majorana arcs
corresponding to tunable Weyl points appear in the time-reversal symmetry
broken B-phase. Majorana cone protected by mirror Chern number and Majorana
flat band by glide-winding number are also revealed.
",Physics
"  The magnetic-field-temperature phase diagram of solid oxygen is investigated
by the adiabatic magnetocaloric effect (MCE) measurement with pulsed magnetic
fields. Relatively large temperature decrease with hysteresis is observed at
just below the $\beta$-$\gamma$ and $\alpha$-$\beta$ phase transition
temperatures owing to the field-induced transitions. The magnetic field
dependences of these phase boundaries are obtained as
$T_\mathrm{\beta\gamma}(H)=43.8-1.55\times10^{-3}H^2$ K and
$T_\mathrm{\alpha\beta}(H)=23.9-0.73\times10^{-3}H^2$ K. The magnetic
Clausius-Clapeyron equation quantitatively explains the $H$ dependence of
$T_\mathrm{\beta\gamma}$, meanwhile, does not $T_\mathrm{\alpha\beta}$. The MCE
curve at $T_\mathrm{\beta\gamma}$ is of typical first-order, while the curve at
$T_\mathrm{\alpha\beta}$ seems to have both characteristics of first- and
second-order transitions. We discuss the order of the $\alpha$-$\beta$ phase
transition and propose possible reasons for the unusual behavior.
",Physics
"  The X-ray emission spectrum of liquid ethanol was calculated using density
functional theory and a semi-classical approximation to the Kramers-Heisenberg
formula including core-hole-induced dynamics. Our spectrum agrees well with the
experimental spectrum. We found that the intensity ratio between the two peaks
at 526 and 527 eV assigned as 10a' and 3a"" depends not only on the hydrogen
bonding network around the target molecule, but also on the intramolecular
conformation. This effect is absent in liquid methanol and demonstrates the
high sensitivity of X-ray emission to molecular structure. The dependence of
spectral features on hydrogen-bonding as well as on dynamical effects following
core-excitation are also discussed.
",Physics
"  We demonstrate creation of electroforming-free TaOx memristive devices using
focused ion beam irradiations to locally define conductive filaments in TaOx
films. Electrical characterization shows that these irradiations directly
create fully functional memristors without the need for electroforming. Ion
beam forming of conductive filaments combined with state-of-the-art
nano-patterning presents a CMOS compatible approach to wafer level fabrication
of fully formed and operational memristors.
",Physics
"  A promising route to the realization of Majorana fermions is in
non-centrosymmetric superconductors, in which spin-orbit-coupling lifts the
spin degeneracy of both bulk and surface bands. A detailed assessment of the
electronic structure is critical to evaluate their suitability for this through
establishing the topological properties of the electronic structure. This
requires correct identification of the time-reversal-invariant momenta. One
such material is BiPd, a recently rediscovered non-centrosymmetric
superconductor which can be grown in large, high-quality single crystals and
has been studied by several groups using angular resolved photoemission to
establish its surface electronic structure. Many of the published electronic
structure studies on this material are based on a reciprocal unit cell which is
not the actual Brillouin zone of the material. We show here the consequences of
this for the electronic structures and show how the inferred topological nature
of the material is affected.
",Physics
"  We consider a gated one-dimensional (1D) quantum wire disturbed in a
contactless manner by an alternating electric field produced by a tip of a
scanning probe microscope. In this schematic 1D electrons are driven not by a
pulling electric field but rather by a non-stationary spin-orbit interaction
(SOI) created by the tip. We show that a charge current appears in the wire in
the presence of the Rashba SOI produced by the gate net charge and image
charges of 1D electrons induced on the gate (iSOI). The iSOI contributes to the
charge susceptibility by breaking the spin-charge separation between the
charge- and spin collective excitations, generated by the probe. The velocity
of the excitations is strongly renormalized by SOI, which opens a way to
fine-tune the charge and spin response of 1D electrons by changing the gate
potential. One of the modes softens upon increasing the gate potential to
enhance the current response as well as the power dissipated in the system.
",Physics
"  Complex mathematical models of interaction networks are routinely used for
prediction in systems biology. However, it is difficult to reconcile network
complexities with a formal understanding of their behavior. Here, we propose a
simple procedure (called $\bar \varphi$) to reduce biological models to
functional submodules, using statistical mechanics of complex systems combined
with a fitness-based approach inspired by $\textit{in silico}$ evolution. $\bar
\varphi$ works by putting parameters or combination of parameters to some
asymptotic limit, while keeping (or slightly improving) the model performance,
and requires parameter symmetry breaking for more complex models. We illustrate
$\bar \varphi$ on biochemical adaptation and on different models of immune
recognition by T cells. An intractable model of immune recognition with close
to a hundred individual transition rates is reduced to a simple two-parameter
model. $\bar \varphi$ extracts three different mechanisms for early immune
recognition, and automatically discovers similar functional modules in
different models of the same process, allowing for model classification and
comparison. Our procedure can be applied to biological networks based on rate
equations using a fitness function that quantifies phenotypic performance.
",Physics
"  Chaos and ergodicity are the cornerstones of statistical physics and
thermodynamics. While classically even small systems like a particle in a
two-dimensional cavity, can exhibit chaotic behavior and thereby relax to a
microcanonical ensemble, quantum systems formally can not. Recent theoretical
breakthroughs and, in particular, the eigenstate thermalization hypothesis
(ETH) however indicate that quantum systems can also thermalize. In fact ETH
provided us with a framework connecting microscopic models and macroscopic
phenomena, based on the notion of highly entangled quantum states. Such
thermalization was beautifully demonstrated experimentally by A. Kaufman et.
al. who studied relaxation dynamics of a small lattice system of interacting
bosonic particles. By directly measuring the entanglement entropy of
subsystems, as well as other observables, they showed that after the initial
transient time the system locally relaxes to a thermal ensemble while globally
maintaining a zero-entropy pure state.
",Physics
"  Self-consistent treatment of cosmological structure formation and expansion
within the context of classical general relativity may lead to ""extra""
expansion above that expected in a structureless universe. We argue that in
comparison to an early-epoch, extrapolated Einstein-de Sitter model, about
10-15% ""extra"" expansion is sufficient at the present to render superfluous the
""dark energy"" 68% contribution to the energy density budget, and that this is
observationally realistic.
",Physics
"  We present theoretical calculations to interpret optical and mechanical
properties of Ag@Fe3O4 nanoflowers. The microstructures and nature of optical
peaks of nanoflowers are determined by means of the Mie theory associated with
effective dielectric approximation and the experimental absorption spectrum.
Under laser illumination, the thermal strain fields inside and outside the
structure due to the absorbed optical energy are studied using continuum
mechanics approach. Our findings provide simple but comprehensive description
of the elastic behaviors of previous experiments.
",Physics
"  Internal gravity waves play a primary role in geophysical fluids: they
contribute significantly to mixing in the ocean and they redistribute energy
and momentum in the middle atmosphere. Until recently, most studies were
focused on plane wave solutions. However, these solutions are not a
satisfactory description of most geophysical manifestations of internal gravity
waves, and it is now recognized that internal wave beams with a confined
profile are ubiquitous in the geophysical context.
We will discuss the reason for the ubiquity of wave beams in stratified
fluids, related to the fact that they are solutions of the nonlinear governing
equations. We will focus more specifically on situations with a constant
buoyancy frequency. Moreover, in light of recent experimental and analytical
studies of internal gravity beams, it is timely to discuss the two main
mechanisms of instability for those beams. i) The Triadic Resonant Instability
generating two secondary wave beams. ii) The streaming instability
corresponding to the spontaneous generation of a mean flow.
",Physics
"  This comprehensive study of comet C/1995 O1 focuses first on investigating
its orbital motion over a period of 17.6 yr (1993-2010). The comet is suggested
to have approached Jupiter to 0.005 AU on -2251 November 7, in general
conformity with Marsden's (1999) proposal of a Jovian encounter nearly 4300 yr
ago. The variations of sizable nongravitational effects with heliocentric
distance correlate with the evolution of outgassing, asymmetric relative to
perihelion. The future orbital period will shorten to ~1000 yr because of
orbital-cascade resonance effects. We find that the sublimation curves of
parent molecules are fitted with the type of a law used for the
nongravitational acceleration, determine their orbit-integrated mass loss, and
conclude that the share of water ice was at most 57%, and possibly less than
50%, of the total outgassed mass. Even though organic parent molecules (many
still unidentified) had very low abundances relative to water individually,
their high molar mass and sheer number made them, summarily, important
potential mass contributors to the total production of gas. The mass loss of
dust per orbit exceeded that of water ice by a factor of ~12, a dust loading
high enough to imply a major role for heavy organic molecules of low volatility
in accelerating the minuscule dust particles in the expanding halos to terminal
velocities as high as 0.7 km s^{-1}. In Part II, the comet's nucleus will be
modeled as a compact cluster of massive fragments to conform to the integrated
nongravitational effect.
",Physics
"  We report magnetotransport measurements on magnetically doped
(Bi,Sb)$_2$Te$_3$ films grown by molecular beam epitaxy. In Hallbar devices,
logarithmic dependence on temperature and bias voltage are obseved in both the
longitudinal and anomalous Hall resistance. The interplay of disorder and
electron-electron interactions is found to explain quantitatively the observed
logarithmic singularities and is a dominant scattering mechanism in these
samples. Submicron scale devices exhibit intriguing quantum oscillations at
high magnetic fields with dependence on bias voltage. The observed quantum
oscillations can be attributed to bulk and surface transport.
",Physics
"  The critical behavior of the random transverse-field Ising model in finite
dimensional lattices is governed by infinite disorder fixed points, several
properties of which have already been calculated by the use of the strong
disorder renormalization group (SDRG) method. Here we extend these studies and
calculate the connected transverse-spin correlation function by a numerical
implementation of the SDRG method in $d=1,2$ and $3$ dimensions. At the
critical point an algebraic decay of the form $\sim r^{-\eta_t}$ is found, with
a decay exponent being approximately $\eta_t \approx 2+2d$. In $d=1$ the
results are related to dimer-dimer correlations in the random AF XX-chain and
have been tested by numerical calculations using free-fermionic techniques.
",Physics
"  Exoplanet research is carried out at the limits of the capabilities of
current telescopes and instruments. The studied signals are weak, and often
embedded in complex systematics from instrumental, telluric, and astrophysical
sources. Combining repeated observations of periodic events, simultaneous
observations with multiple telescopes, different observation techniques, and
existing information from theory and prior research can help to disentangle the
systematics from the planetary signals, and offers synergistic advantages over
analysing observations separately. Bayesian inference provides a
self-consistent statistical framework that addresses both the necessity for
complex systematics models, and the need to combine prior information and
heterogeneous observations. This chapter offers a brief introduction to
Bayesian inference in the context of exoplanet research, with focus on time
series analysis, and finishes with an overview of a set of freely available
programming libraries.
",Physics
"  Using Brownian motion in periodic potentials $V(x)$ tilted by a force $f$, we
provide physical insight into the thermodynamic uncertainty relation, a
recently conjectured principle for statistical errors and irreversible heat
dissipation in nonequilibrium steady states. According to the relation,
nonequilibrium output generated from dissipative processes necessarily incurs
an energetic cost or heat dissipation $q$, and in order to limit the output
fluctuation within a relative uncertainty $\epsilon$, at least
$2k_BT/\epsilon^2$ of heat must be dissipated. Our model shows that this bound
is attained not only at near-equilibrium ($f\ll V'(x)$) but also at
far-from-equilibrium $(f\gg V'(x))$, more generally when the dissipated heat is
normally distributed. Furthermore, the energetic cost is maximized near the
critical force when the barrier separating the potential wells is about to
vanish and the fluctuation of Brownian particle is maximized. These findings
indicate that the deviation of heat distribution from Gaussianity gives rise to
the inequality of the uncertainty relation, further clarifying the meaning of
the uncertainty relation. Our derivation of the uncertainty relation also
recognizes a new bound of nonequilibrium fluctuations that the variance of
dissipated heat ($\sigma_q^2$) increases with its mean ($\mu_q$) and cannot be
smaller than $2k_BT\mu_q$.
",Physics
"  We report the $4 \, \sigma$ detection of a faint object with a flux of ~ 0.3
mJy, in the vicinity of the quadruply lensed QSO MG0414+0534 using the Atacama
Large Millimeter/submillimeter array (ALMA) Band 7. The object is most probably
a dusty dark dwarf galaxy, which has not been detected in either the optical,
near-infrared (NIR) or radio (cm) bands. An anomaly in the flux ratio of the
lensed images observed in Band 7 and the mid-infrared (MIR) band and the
reddening of the QSO light color can be simultaneously explained if we consider
the object as a lensing substructure with an ellipticity ~ 0.7 at a redshift of
$0.5 \lesssim z \lesssim 1$. Using the best-fit lens models with three lenses,
we find that the dark matter plus baryon mass associated with the object is
$\sim 10^9\, M_{\odot}$, the dust mass is $\sim 10^7\,M_{\odot}$ and the linear
size is $\gtrsim 5\,$kpc. Thus our findings suggest that the object is a dusty
dark dwarf galaxy. A substantial portion of faint submillimeter galaxies (SMGs)
in the universe may be attributed to such dark objects.
",Physics
"  The exploitation of the excellent intrinsic electronic properties of graphene
for device applications is hampered by a large contact resistance between the
metal and graphene. The formation of edge contacts rather than top contacts is
one of the most promising solutions for realizing low ohmic contacts. In this
paper the fabrication and characterization of edge contacts to large area
CVD-grown monolayer graphene by means of optical lithography using CMOS
compatible metals, i.e. Nickel and Aluminum is reported. Extraction of the
contact resistance by Transfer Line Method (TLM) as well as the direct
measurement using Kelvin Probe Force Microscopy demonstrates a very low width
specific contact resistance.
",Physics
"  We consider the ground-state properties of Rashba spin-orbit-coupled
pseudo-spin-1/2 Bose-Einstein condensates (BECs) in a rotating two-dimensional
(2D) toroidal trap. In the absence of spin-orbit coupling (SOC), the increasing
rotation frequency enhances the creation of giant vortices for the initially
miscible BECs, while it can lead to the formation of semiring density patterns
with irregular hidden vortex structures for the initially immiscible BECs.
Without rotation, strong 2D isotropic SOC yields a heliciform-stripe phase for
the initially immiscible BECs. Combined effects of rotation, SOC, and
interatomic interactions on the vortex structures and typical spin textures of
the ground state of the system are discussed systematically. In particular, for
fixed rotation frequency above the critical value, the increasing isotropic SOC
favors a visible vortex ring in each component which is accompanied by a hidden
giant vortex plus a (several) hidden vortex ring(s) in the central region. In
the case of 1D anisotropic SOC, large SOC strength results in the generation of
hidden linear vortex string and the transition from initial phase separation
(phase mixing) to phase mixing (phase separation). Furthermore, the peculiar
spin textures including skyrmion lattice, skyrmion pair and skyrmion string are
revealed in this system.
",Physics
"  The dependence of the mass accretion rate on the stellar properties is a key
constraint for star formation and disk evolution studies. Here we present a
study of a sample of stars in the Chamaeleon I star forming region carried out
using the VLT/X-Shooter spectrograph. The sample is nearly complete down to
M~0.1Msun for the young stars still harboring a disk in this region. We derive
the stellar and accretion parameters using a self-consistent method to fit the
broad-band flux-calibrated medium resolution spectrum. The correlation between
the accretion luminosity to the stellar luminosity, and of the mass accretion
rate to the stellar mass in the logarithmic plane yields slopes of 1.9 and 2.3,
respectively. These slopes and the accretion rates are consistent with previous
results in various star forming regions and with different theoretical
frameworks. However, we find that a broken power-law fit, with a steeper slope
for stellar luminosity smaller than ~0.45 Lsun and for stellar masses smaller
than ~ 0.3 Msun, is slightly preferred according to different statistical
tests, but the single power-law model is not excluded. The steeper relation for
lower mass stars can be interpreted as a faster evolution in the past for
accretion in disks around these objects, or as different accretion regimes in
different stellar mass ranges. Finally, we find two regions on the mass
accretion versus stellar mass plane empty of objects. One at high mass
accretion rates and low stellar masses, which is related to the steeper
dependence of the two parameters we derived. The second one is just above the
observational limits imposed by chromospheric emission. This empty region is
located at M~0.3-0.4Msun, typical masses where photoevaporation is known to be
effective, and at mass accretion rates ~10^-10 Msun/yr, a value compatible with
the one expected for photoevaporation to rapidly dissipate the inner disk.
",Physics
"  Context. Planet formation with pebbles has been proposed to solve a couple of
long-standing issues in the classical formation model. Some sophisticated
simulations have been done to confirm the efficiency of pebble accretion.
However, there has not been any global N-body simulations that compare the
outcomes of planet formation via pebble accretion with observed extrasolar
planetary systems. Aims. In this paper, we study the effects of a range of
initial parameters of planet formation via pebble accretion, and present the
first results of our simulations. Methods. We incorporate the pebble accretion
model by Ida et al. (2016) in the N-body code SyMBA (Duncan et al. 1998), along
with the effects of gas accretion, eccentricity and inclination damping and
planet migration in the disc. Results. We confirm that pebble accretion leads
to a variety of planetary systems, but have difficulty in reproducing observed
properties of exoplanetary systems, such as planetary mass, semimajor axis, and
eccentricity distributions. The main reason behind this is a too-efficient type
I migration, which sensitively depends on the disc model. However, our
simulations also lead to a few interesting predictions. First, we find that
formation efficiencies of planets depend on the stellar metallicities, not only
for giant planets, but also for Earths (Es) and Super-Earths (SEs). The
dependency for Es/SEs is subtle. Although higher metallicity environments lead
to faster formation of a larger number of Es/SEs, they also tend to be lost
later via dynamical instability. Second, our results indicate that a wide range
of bulk densities observed for Es and SEs is a natural consequence of dynamical
evolution of planetary systems. Third, the ejection trend of our simulations
suggest that one free-floating E/SE may be expected for two smaller-mass
planets.
",Physics
"  We present the results of an optical spectroscopic monitoring program
targeting NGC 5548 as part of a larger multi-wavelength reverberation mapping
campaign. The campaign spanned six months and achieved an almost daily cadence
with observations from five ground-based telescopes. The H$\beta$ and He II
$\lambda$4686 broad emission-line light curves lag that of the 5100 $\AA$
optical continuum by $4.17^{+0.36}_{-0.36}$ days and $0.79^{+0.35}_{-0.34}$
days, respectively. The H$\beta$ lag relative to the 1158 $\AA$ ultraviolet
continuum light curve measured by the Hubble Space Telescope is roughly
$\sim$50% longer than that measured against the optical continuum, and the lag
difference is consistent with the observed lag between the optical and
ultraviolet continua. This suggests that the characteristic radius of the
broad-line region is $\sim$50% larger than the value inferred from optical data
alone. We also measured velocity-resolved emission-line lags for H$\beta$ and
found a complex velocity-lag structure with shorter lags in the line wings,
indicative of a broad-line region dominated by Keplerian motion. The responses
of both the H$\beta$ and He II $\lambda$4686 emission lines to the driving
continuum changed significantly halfway through the campaign, a phenomenon also
observed for C IV, Ly $\alpha$, He II(+O III]), and Si IV(+O IV]) during the
same monitoring period. Finally, given the optical luminosity of NGC 5548
during our campaign, the measured H$\beta$ lag is a factor of five shorter than
the expected value implied by the $R_\mathrm{BLR} - L_\mathrm{AGN}$ relation
based on the past behavior of NGC 5548.
",Physics
"  The ablation of solid tin surfaces by an 800-nanometer-wavelength laser is
studied for a pulse length range from 500 fs to 4.5 ps and a fluence range
spanning 0.9 to 22 J/cm^2. The ablation depth and volume are obtained employing
a high-numerical-aperture optical microscope, while the ion yield and energy
distributions are obtained from a set of Faraday cups set up under various
angles. We found a slight increase of the ion yield for an increasing pulse
length, while the ablation depth is slightly decreasing. The ablation volume
remained constant as a function of pulse length. The ablation depth follows a
two-region logarithmic dependence on the fluence, in agreement with the
available literature and theory. In the examined fluence range, the ion yield
angular distribution is sharply peaked along the target normal at low fluences
but rapidly broadens with increasing fluence. The total ionization fraction
increases monotonically with fluence to a 5-6% maximum, which is substantially
lower than the typical ionization fractions obtained with nanosecond-pulse
ablation. The angular distribution of the ions does not depend on the laser
pulse length within the measurement uncertainty. These results are of
particular interest for the possible utilization of fs-ps laser systems in
plasma sources of extreme ultraviolet light for nanolithography.
",Physics
"  Why is it difficult to refold a previously folded sheet of paper? We show
that even crease patterns with only one designed folding motion inevitably
contain an exponential number of `distractor' folding branches accessible from
a bifurcation at the flat state. Consequently, refolding a sheet requires
finding the ground state in a glassy energy landscape with an exponential
number of other attractors of higher energy, much like in models of protein
folding (Levinthal's paradox) and other NP-hard satisfiability (SAT) problems.
As in these problems, we find that refolding a sheet requires actuation at
multiple carefully chosen creases. We show that seeding successful folding in
this way can be understood in terms of sub-patterns that fold when cut out
(`folding islands'). Besides providing guidelines for the placement of active
hinges in origami applications, our results point to fundamental limits on the
programmability of energy landscapes in sheets.
",Physics
"  We present a quantu spin liquid state in a spin-1/2 honeycomb lattice with
randomness in the exchange interaction. That is, we successfully introduce
randomness into the organic radial-based complex and realize a random-singlet
(RS) state. All magnetic and thermodynamic experimental results indicate the
liquid-like behaviors, which are consistent with those expected in the RS
state. These results demonstrate that the randomness or inhomogeneity in the
actual systems stabilize the RS state and yield liquid-like behavior.
",Physics
"  Initial RV characterisation of the enigmatic planet Kepler-10c suggested a
mass of $\sim17$ M$_\oplus$, which was remarkably high for a planet with radius
$2.32$ R$_\oplus$; further observations and subsequent analysis hinted at a
(possibly much) lower mass, but masses derived using RVs from two different
spectrographs (HARPS-N and HIRES) were incompatible at a $3\sigma$-level. We
demonstrate here how such mass discrepancies may readily arise from sub-optimal
sampling and/or neglecting to model even a single coherent signal (stellar,
planetary, or otherwise) that may be present in RVs. We then present a
plausible resolution of the mass discrepancy, and ultimately characterise
Kepler-10c as having mass $7.37_{-1.19}^{+1.32}$ M$_\oplus$, and mean density
$3.14^{+0.63}_{-0.55}$ g cm$^{-3}$.
",Physics
"  Using the formalism of the classical nucleation theory, we derive an
expression for the reversible work $W_*$ of formation of a binary crystal
nucleus in a liquid binary solution of non-stoichiometric composition
(incongruent crystallization). Applied to the crystallization of aqueous nitric
acid (NA) droplets, the new expression more adequately takes account of the
effect of nitric acid vapor compared to the conventional expression of
MacKenzie, Kulmala, Laaksonen, and Vesala (MKLV) [J.Geophys.Res. 102, 19729
(1997)]. The predictions of both MKLV and modified expressions for the average
liquid-solid interfacial tension $\sigma^{ls}$ of nitric acid dihydrate (NAD)
crystals are compared by using existing experimental data on the incongruent
crystallization of aqueous NA droplets of composition relevant to polar
stratospheric clouds (PSCs). The predictions based on the MKLV expression are
higher by about 5% compared to predictions based on our modified expression.
This results in similar differences between the predictions of both expressions
for the solid-vapor interfacial tension $\sigma^{sv}$ of NAD crystal nuclei.
The latter can be obtained by analyzing of experimental data on crystal
nucleation rates in aqueous NA droplets and exploiting the dominance of the
surface-stimulated mode of crystal nucleation in small droplets and its
negligibility in large ones. Applying that method, our expression for $W_*$
provides an estimate for $\sigma^{sv}$ of NAD in the range from 92 dyn/cm to
100 dyn/cm, while the MKLV expression predicts it in the range from 95 dyn/cm
to 105 dyn/cm. The predictions of both expressions for $W_*$ become identical
in the case of congruent crystallization; this was also demonstrated by
applying our method to the nucleation of nitric acid trihydrate (NAT) crystals
in PSC droplets of stoichiometric composition.
",Physics
"  We report the observation of magnetic domains in the exotic,
antiferromagnetically ordered all-in-all-out state of Nd$_2$Zr$_2$O$_7$,
induced by spin canting. The all-in-all-out state can be realized by Ising-like
spins on a pyrochlore lattice and is established in Nd$_2$Zr$_2$O$_7$ below
0.31 K for external magnetic fields up to 0.14 T. Two different spin
arrangements can fulfill this configuration which leads to the possibility of
magnetic domains. The all-in-all-out domain structure can be controlled by an
external magnetic field applied parallel to the [111] direction. This is a
result of different spin canting mechanism for the two all-in-all-out
configurations for such a direction of the magnetic field. The change of the
domain structure is observed through a hysteresis in the magnetic
susceptibility. No hysteresis occurs, however, in case the external magnetic
field is applied along [100].
",Physics
"  The barocaloric effect is still an incipient scientific topic, but it has
been attracting an increasing attention in the last years due to the promising
perspectives for its application in alternative cooling devices. Here, we
present giant values of barocaloric entropy change and temperature change
induced by low pressures in PDMS elastomer around room temperature. Adiabatic
temperature changes of 12.0 K and 28.5 K were directly measured for pressure
changes of 173 MPa and 390 MPa, respectively, associated with large normalized
temperature changes (~70 K GPa-1). From adiabatic temperature change data, we
obtained entropy change values larger than 140 J kg-1 K-1. We found barocaloric
effect values that exceed those previously reported for any promising
barocaloric materials from direct measurements of temperature change around
room temperature. Our results stimulate the study of the barocaloric effect in
elastomeric polymers and broaden the pathway to use this effect in solid-state
cooling technologies.
",Physics
"  The present study investigates a way to design dykes which can filter the
wavelengths of ocean surface waves. This offers the possibility to achieve a
structure that can attenuate waves associated with storm swell, without
affecting coastline in other conditions. Our approach is based on low frequency
resonances in metamaterials combined with Bragg frequencies for which waves
cannot propagate in periodic lattices.
",Physics
"  Dual Fabry-Perot cavity based optical refractometry (DFPC-OR) has a high
potential for assessments of gas density. However, drifts of the FP cavity
often limit its performance. We show that by the use of two narrow-linewidth
fiber lasers locked to two high finesse cavities and Allan-Werle plots that
drift-free DFPC-OR can be obtained for short measurement times (for which the
drifts of the cavity can be disregarded). Based on this, a novel strategy,
termed fast switching DFPC-OR (FS-DFPC-OR), is presented. A set of novel
methodologies for assessment of both gas density and flow rates (in particular
from small leaks) that are not restricted by the conventional limitations
imposed by the drifts of the cavity are presented. The methodologies deal with
assessments in both open and closed (finite-sized) compartments. They
circumvent the problem with volumetric expansion, i.e. that the gas density in
a measurement cavity is not the same as that in the closed external compartment
that should be assessed, by performing a pair of measurements in rapid
succession; the first one serves the purpose of assessing the density of the
gas that has been transferred into the measurement cavity by the gas
equilibration process, while the 2nd is used to automatically calibrate the
system with respect to the relative volumes of the measurement cavity and the
external compartment. The methodologies for assessments of leak rates comprise
triple cavity evacuation assessments, comprising two measurements performed in
rapid succession, supplemented by a 3rd measurement a certain time thereafter.
A clear explanation of why the technique has such a small temperature
dependence is given. It is concluded that FS-DFPC-OR constitutes a novel
strategy that can be used for precise and accurate assessment of gas number
density and gas flows under a variety of conditions, in particular
non-temperature stabilized ones.
",Physics
"  A physical model of a three-dimensional flow of a viscous bubbly fluid in an
intermediate regime between bubble formation and breakage is presented. The
model is based on mechanics and thermodynamics of a single bubble coupled to
the dynamics of a viscous fluid as a whole, and takes into account multiple
physical effects, including gravity, viscosity, and surface tension.
Dimensionless versions of the resulting nonlinear model are obtained, and
values of dimensionless parameters are estimated for typical magma flows in
horizontal subaerial lava fields and vertical volcanic conduits.
Exact solutions of the resulting system of nonlinear equations corresponding
to equilibrium flows and traveling waves are analyzed in the one-dimensional
setting. Generalized Su-Gardner-type perturbation analysis is employed to study
approximate solutions of the model in the long-wave ansatz. Simplified
nonlinear partial differential equations (PDE) satisfied by the leading terms
of the perturbation solutions are systematically derived. It is shown that for
specific classes of perturbations, approximate solutions of the bubbly fluid
model arise from solutions of the classical diffusion, Burgers,
variable-coefficient Burgers, and Korteweg-de Vries equations.
",Physics
"  Neutronic performance is investigated for a potential accident tolerant fuel
(ATF),which consists of U$_3$Si$_2$ fuel and FeCrAl cladding. In comparison
with current UO$_2$-Zr system, FeCrAl has a better oxidation resistance but a
larger thermal neutron absorption cross section. U$_3$Si$_2$ has a higher
thermal conductivity and a higher uranium density, which can compensate the
reactivity suppressed by FeCrAl. Based on neutronic investigations, a possible
U$_3$Si$_2$-FeCrAl fuel-cladding systemis taken into consideration. Fundamental
properties of the suggested fuel-cladding combination are investigated in a
fuel assembly.These properties include moderator and fuel temperature
coefficients, control rods worth, radial power distribution (in a fuel rod),
and different void reactivity coefficients. The present work proves that the
new combination has less reactivity variation during its service lifetime.
Although, compared with the current system, it has a little larger deviation on
power distribution and a little less negative temperature coefficient and void
reactivity coefficient and its control rods worth is less important, variations
of these parameters are less important during the service lifetime of fuel.
Hence, U$_3$Si$_2$-FeCrAl system is a potential ATF candidate from a neutronic
view.
",Physics
"  Optimal estimation of signal amplitude, background level, and photocentre
location is crucial to the combined extraction of astrometric and photometric
information from focal plane images, and in particular from the one-dimensional
measurements performed by Gaia on intermediate to faint magnitude stars. Our
goal is to define a convenient maximum likelihood framework, suited to
efficient iterative implementation and to assessment of noise level, bias, and
correlation among variables. The analytical model is investigated numerically
and verified by simulation over a range of magnitude and background values. The
estimates are unbiased, with a well-understood correlation between amplitude
and background, and with a much lower correlation of either of them with
location, further alleviated in case of signal symmetry. Two versions of the
algorithm are implemented and tested against each other, respectively, for
independent and combined parameter estimation. Both are effective and provide
consistent results, but the latter is more efficient because it takes into
account the flux-background estimate correlation.
",Physics
"  Despite decades of inquiry, the origin of giant planets residing within a few
tenths of an astronomical unit from their host stars remains unclear.
Traditionally, these objects are thought to have formed further out before
subsequently migrating inwards. However, the necessity of migration has been
recently called into question with the emergence of in-situ formation models of
close-in giant planets. Observational characterization of the transiting
sub-sample of close-in giants has revealed that ""warm"" Jupiters, possessing
orbital periods longer than roughly 10 days more often possess close-in,
co-transiting planetary companions than shorter period ""hot"" Jupiters, that are
usually lonely. This finding has previously been interpreted as evidence that
smooth, early migration or in situ formation gave rise to warm Jupiter-hosting
systems, whereas more violent, post-disk migration pathways sculpted hot
Jupiter-hosting systems. In this work, we demonstrate that both classes of
planet may arise via early migration or in-situ conglomeration, but that the
enhanced loneliness of hot Jupiters arises due to a secular resonant
interaction with the stellar quadrupole moment. Such an interaction tilts the
orbits of exterior, lower mass planets, removing them from transit surveys
where the hot Jupiter is detected. Warm Jupiter-hosting systems, in contrast,
retain their coplanarity due to the weaker influence of the host star's
quadrupolar potential relative to planet-disk interactions. In this way, hot
Jupiters and warm Jupiters are placed within a unified theoretical framework
that may be readily validated or falsified using data from upcoming missions
such as TESS.
",Physics
"  We present a model of contagion that unifies and generalizes existing models
of the spread of social influences and micro-organismal infections. Our model
incorporates individual memory of exposure to a contagious entity (e.g., a
rumor or disease), variable magnitudes of exposure (dose sizes), and
heterogeneity in the susceptibility of individuals. Through analysis and
simulation, we examine in detail the case where individuals may recover from an
infection and then immediately become susceptible again (analogous to the
so-called SIS model). We identify three basic classes of contagion models which
we call \textit{epidemic threshold}, \textit{vanishing critical mass}, and
\textit{critical mass} classes, where each class of models corresponds to
different strategies for prevention or facilitation. We find that the
conditions for a particular contagion model to belong to one of the these three
classes depend only on memory length and the probabilities of being infected by
one and two exposures respectively. These parameters are in principle
measurable for real contagious influences or entities, thus yielding empirical
implications for our model. We also study the case where individuals attain
permanent immunity once recovered, finding that epidemics inevitably die out
but may be surprisingly persistent when individuals possess memory.
",Physics
"  We present spectra of 5 ultra-diffuse galaxies (UDGs) in the vicinity of the
Coma Cluster obtained with the Multi-Object Double Spectrograph on the Large
Binocular Telescope. We confirm 4 of these as members of the cluster,
quintupling the number of spectroscopically confirmed systems. Like the
previously confirmed large (projected half light radius $>$ 4.6 kpc) UDG, DF44,
the systems we targeted all have projected half light radii $> 2.9$ kpc. As
such, we spectroscopically confirm a population of physically large UDGs in the
Coma cluster. The remaining UDG is located in the field, about $45$ Mpc behind
the cluster. We observe Balmer and Ca II H \& K absorption lines in all of our
UDG spectra. By comparing the stacked UDG spectrum against stellar population
synthesis models, we conclude that, on average, these UDGs are composed of
metal-poor stars ([Fe/H] $\lesssim -1.5$). We also discover the first UDG with
[OII] and [OIII] emission lines within a clustered environment, demonstrating
that not all cluster UDGs are devoid of gas and sources of ionizing radiation.
",Physics
"  A critical challenge in the observation of the redshifted 21-cm line is its
separation from bright Galactic and extragalactic foregrounds. In particular,
the instrumental leakage of polarized foregrounds, which undergo significant
Faraday rotation as they propagate through the interstellar medium, may
harmfully contaminate the 21-cm power spectrum. We develop a formalism to
describe the leakage due to instrumental widefield effects in visibility-based
power spectra measured with redundant arrays, extending the delay-spectrum
approach presented in Parsons et al. (2012). We construct polarized sky models
and propagate them through the instrument model to simulate realistic full-sky
observations with the Precision Array to Probe the Epoch of Reionization. We
find that the leakage due to a population of polarized point sources is
expected to be higher than diffuse Galactic polarization at any $k$ mode for a
30~m reference baseline. For the same reference baseline, a foreground-free
window at $k > 0.3 \, h$~Mpc$^{-1}$ can be defined in terms of leakage from
diffuse Galactic polarization even under the most pessimistic assumptions. If
measurements of polarized foreground power spectra or a model of polarized
foregrounds are given, our method is able to predict the polarization leakage
in actual 21-cm observations, potentially enabling its statistical subtraction
from the measured 21-cm power spectrum.
",Physics
"  Area law violations for entanglement entropy in the form of a square root has
recently been studied for one-dimensional frustration-free quantum systems
based on the Motzkin walks and their variations. Here we consider a Motzkin
walk with a different Hilbert space on each step of the walk spanned by
elements of a {\it Symmetric Inverse Semigroup} with the direction of each step
governed by its algebraic structure. This change alters the number of paths
allowed in the Motzkin walk and introduces a ground state degeneracy sensitive
to boundary perturbations. We study the frustration-free spin chains based on
three symmetric inverse semigroups, $\cS^3_1$, $\cS^3_2$ and $\cS^2_1$. The
system based on $\cS^3_1$ and $\cS^3_2$ provide examples of quantum phase
transitions in one dimensions with the former exhibiting a transition between
the area law and a logarithmic violation of the area law and the latter
providing an example of transition from logarithmic scaling to a square root
scaling in the system size, mimicking a colored $\cS^3_1$ system. The system
with $\cS^2_1$ is much simpler and produces states that continue to obey the
area law.
",Physics
"  We present an experimental study of the local and collective magnetism of
$\mathrm{EuFe_2As_2}$, that is isostructural with the high temperature
superconductor parent compound $\mathrm{BaFe_2As_2}$. In contrast to
$\mathrm{BaFe_2As_2}$, where only Fe spins order, $\mathrm{EuFe_2As_2}$ has an
additional magnetic transition below 20 K due to the ordering of the Eu$^{2+}$
spins ($J =7/2$, with $L=0$ and $S=7/2$) in an A-type antiferromagnetic texture
(ferromagnetic layers stacked antiferromagnetically). This may potentially
affect the FeAs layer and its local and correlated magnetism. Fe-K$_\beta$
x-ray emission experiments on $\mathrm{EuFe_2As_2}$ single crystals reveal a
local magnetic moment of 1.3$\pm0.15~\mu_B$ at 15 K that slightly increases to
1.45$\pm0.15~\mu_B$ at 300 K. Resonant inelastic x-ray scattering (RIXS)
experiments performed on the same crystals show dispersive broad (in energy)
magnetic excitations along $\mathrm{(0, 0)\rightarrow(1, 0)}$ and $\mathrm{(0,
0)\rightarrow(1, 1)}$ with a bandwidth on the order of 170-180 meV. These
results on local and collective magnetism are in line with other parent
compounds of the $\mathrm{AFe_2As_2}$ series ($A=$ Ba, Ca, and Sr), especially
the well characterized $\mathrm{BaFe_2As_2}$. Thus, our experiments lead us to
the conclusion that the effect of the high magnetic moment of Eu on the
magnitude of both Fe local magnetic moment and spin excitations is small and
confined to low energy excitations.
",Physics
"  This paper presents the model-based design and evaluation of an instrument
that estimates incident neutron direction using the kinematics of neutron
scattering by hydrogen-1 nuclei in an organic scintillator. The instrument
design uses a single, nearly contiguous volume of organic scintillator that is
internally subdivided only as necessary to create optically isolated pillars.
Scintillation light emitted in a given pillar is confined to that pillar by a
combination of total internal reflection and a specular reflector applied to
the four sides of the pillar transverse to its long axis. The scintillation
light is collected at each end of the pillar using a photodetector. In this
optically segmented design, the (x, y) position of scintillation light emission
(where the x and y coordinates are transverse to the long axis of the pillars)
is estimated as the pillar's (x, y) position in the scintillator ""block"", and
the z-position (the position along the pillar's long axis) is estimated from
the amplitude and relative timing of the signals produced by the photodetectors
at each end of the pillar. For proton recoils greater than 1 MeV, we show that
the (x, y, z)-position of neutron-proton scattering can be estimated with < 1
cm root-mean-squared [RMS] error and the proton recoil energy can be estimated
with < 50 keV RMS error by fitting the photodetectors' response time history to
models of optical photon transport within the scintillator pillars. Finally, we
evaluate several alternative designs of this proposed single-volume scatter
camera made of pillars of plastic scintillator (SVSC-PiPS), studying the effect
of pillar dimensions, scintillator material, and photodetector response vs.
time. Specifically, we conclude that an SVSC-PiPS constructed using EJ-204 and
an MCP-PM will produce the most precise estimates of incident neutron direction
and energy.
",Physics
"  In an imaginary conversation with Guido Altarelli, I express my views on the
status of particle physics beyond the Standard Model and its future prospects.
",Physics
"  Time crystals, a phase showing spontaneous breaking of time-translation
symmetry, has been an intriguing subject for systems far away from equilibrium.
Recent experiments found such a phase both in the presence and absence of
localization, while in theories localization by disorder is usually assumed a
priori. In this work, we point out that time crystals can generally exist in
systems without disorder. A series of clean quasi-one-dimensional models under
Floquet driving are proposed to demonstrate this unexpected result in
principle. Robust time crystalline orders are found in the strongly interacting
regime along with the emergent integrals of motion in the dynamical system,
which can be characterized by level statistics and the out-of-time-ordered
correlators. We propose two cold atom experimental schemes to realize the clean
Floquet time crystals, one by making use of dipolar gases and another by
synthetic dimensions.
",Physics
"  Segmented aperture telescopes require an alignment procedure with successive
steps from coarse alignment to monitoring process in order to provide very high
optical quality images for stringent science operations such as exoplanet
imaging. The final step, referred to as fine phasing, calls for a high
sensitivity wavefront sensing and control system in a diffraction-limited
regime to achieve segment alignment with nanometric accuracy. In this context,
Zernike wavefront sensors represent promising options for such a calibration. A
concept called the Zernike unit for segment phasing (ZEUS) was previously
developed for ground-based applications to operate under seeing-limited images.
Such a concept is, however, not suitable for fine cophasing with
diffraction-limited images. We revisit ZELDA, a Zernike sensor that was
developed for the measurement of residual aberrations in exoplanet direct
imagers, to measure segment piston, tip, and tilt in the diffraction-limited
regime. We introduce a novel analysis scheme of the sensor signal that relies
on piston, tip, and tilt estimators for each segment, and provide probabilistic
insights to predict the success of a closed-loop correction as a function of
the initial wavefront error. The sensor unambiguously and simultaneously
retrieves segment piston and tip-tilt misalignment. Our scheme allows for
correction of these errors in closed-loop operation down to nearly zero
residuals in a few iterations. This sensor also shows low sensitivity to
misalignment of its parts and high ability for operation with a relatively
bright natural guide star. Our cophasing sensor relies on existing mask
technologies that make the concept already available for segmented apertures in
future space missions.
",Physics
"  A method for constructing the Lax pairs for nonlinear integrable models is
suggested. First we look for a nonlinear invariant manifold to the
linearization of the given equation. Examples show that such invariant manifold
does exist and can effectively be found. Actually it is defined by a quadratic
form. As a result we get a nonlinear Lax pair consisting of the linearized
equation and the invariant manifold. Our second step consists of finding an
appropriate change of the variables to linearize the found nonlinear Lax pair.
The desired change of the variables is again defined by a quadratic form. The
method is illustrated by the well-known KdV equation and the modified Volterra
chain. New Lax pairs are found. The formal asymptotic expansions for their
eigenfunctions are constructed around the singular values of the spectral
parameter. By applying the method of the formal diagonalization to these Lax
pairs the infinite series of the local conservation laws are obtained for the
corresponding nonlinear models.
",Physics
"  We investigated transport, magnetotransport, and broadband optical properties
of the half-Heusler compound YbPtBi. Hall measurements evidence two types of
charge carriers: highly mobile electrons with a temperature-dependent
concentration and low-mobile holes; their concentration stays almost constant
within the investigated temperature range from 2.5 to 300 K. The optical
spectra (10 meV - 2.7 eV) can be naturally decomposed into contributions from
intra- and interband absorption processes, the former manifesting themselves as
two Drude bands with very different scattering rates, corresponding to the
charges with different mobilities. These results of the optical measurements
allow us to separate the contributions from electrons and holes to the total
conductivity and to implement a two-channel-conduction model for description of
the magnetotransport data. In this approach, the electron and hole mobilities
are found to be around 50000 and 10 cm$^{2}$/Vs at the lowest temperatures (2.5
K), respectively.
",Physics
"  The need to analyze the available large synoptic multi-band surveys drives
the development of new data-analysis methods. Photometric redshift estimation
is one field of application where such new methods improved the results,
substantially. Up to now, the vast majority of applied redshift estimation
methods have utilized photometric features. We aim to develop a method to
derive probabilistic photometric redshift directly from multi-band imaging
data, rendering pre-classification of objects and feature extraction obsolete.
A modified version of a deep convolutional network was combined with a mixture
density network. The estimates are expressed as Gaussian mixture models
representing the probability density functions (PDFs) in the redshift space. In
addition to the traditional scores, the continuous ranked probability score
(CRPS) and the probability integral transform (PIT) were applied as performance
criteria. We have adopted a feature based random forest and a plain mixture
density network to compare performances on experiments with data from SDSS
(DR9). We show that the proposed method is able to predict redshift PDFs
independently from the type of source, for example galaxies, quasars or stars.
Thereby the prediction performance is better than both presented reference
methods and is comparable to results from the literature. The presented method
is extremely general and allows us to solve of any kind of probabilistic
regression problems based on imaging data, for example estimating metallicity
or star formation rate of galaxies. This kind of methodology is tremendously
important for the next generation of surveys.
",Physics
"  An improved wetting boundary implementation strategy is proposed based on
lattice Boltzmann color-gradient model in this paper. In this strategy, an
extra interface force condition is demonstrated based on the diffuse interface
assumption and is employed in contact line region. It has been validated by
three benchmark problems: static droplet wetting on a flat surface and a curved
surface, and dynamic capillary filling. Good performances are shown in all
three cases. Relied on the strict validation to our scheme, the viscous
fingering phenomenon of immiscible fluids displacement in a two-dimensional
channel has been restudied in this paper. High viscosity ratio, wide range
contact angle, accurate moving contact line and mutual independence between
surface tension and viscosity are the obvious advantages of our model. We find
the linear relationship between the contact angle and displacement velocity or
variation of finger length. When the viscosity ratio is smaller than 20, the
displacement velocity is increasing with increasing viscosity ratio and
reducing capillary number, and when the viscosity ratio is larger than 20, the
displacement velocity tends to a specific constant. A similar conclusion is
obtained on the variation of finger length.
",Physics
"  Large-scale vortices in protoplanetary disks are thought to form and survive
for long periods of time. Hence, they can significantly change the global disk
evolution and particularly the distribution of the solid particles embedded in
the gas, possibly explaining asymmetries and dust concentrations recently
observed at sub-millimeter and millimeter wavelengths. We investigate the
spatial distribution of dust grains using a simple model of protoplanetary disk
hosted by a giant gaseous vortex. We explore the dependence of the results on
grain size and deduce possible consequences and predictions for observations of
the dust thermal emission at sub-millimeter and millimeter wavelengths. Global
2D simulations with a bi-fluid code are used to follow the evolution of a
single population of solid particles aerodynamically coupled to the gas.
Possible observational signatures of the dust thermal emission are obtained
using simulators of ALMA and ngVLA observations. We find that a giant vortex
not only captures dust grains with Stokes number St < 1 but can also affect the
distribution of larger grains (with St '~' 1) carving a gap associated to a
ring composed of incompletely trapped particles. The results are presented for
different particle size and associated to their possible signatures in disk
observations. Gap clearing in the dust spatial distribution could be due to the
interaction with a giant gaseous vortex and their associated spiral waves,
without the gravitational assistance of a planet. Hence, strong dust
concentrations at short sub-mm wavelengths associated with a gap and an
irregular ring at longer mm and cm wavelengths could indicate the presence of
an unseen gaseous vortex.
",Physics
"  Double Dirac fermions have recently been identified as possible
quasiparticles hosted by three-dimensional crystals with particular
non-symmorphic point group symmetries. Applying a combined approach of
ab-initio methods and dynamical mean field theory, we investigate how
interactions and double Dirac band topology conspire to form the electronic
quantum state of Bi$_2$CuO$_4$. We derive a downfolded eight-band model of the
pristine material at low energies around the Fermi level. By tuning the model
parameters from the free band structure to the realistic strongly correlated
regime, we find a persistence of the double Dirac dispersion until its
constituting time reveral symmetry is broken due to the onset of magnetic
ordering at the Mott transition. We analyze pressure as a promising route to
realize a double-Dirac metal in Bi$_2$CuO$_4$.
",Physics
"  Nuclear starburst discs (NSDs) are star-forming discs that may be residing in
the nuclear regions of active galaxies at intermediate redshifts. One
dimensional (1D) analytical models developed by Thompson et al. (2005) show
that these discs can possess an inflationary atmosphere when dust is sublimated
on parsec scales. This make NSDs a viable source for AGN obscuration. We model
the two dimensional (2D) structure of NSDs using an iterative method in order
to compute the explicit vertical solutions for a given annulus. These solutions
satisfy energy and hydrostatic balance, as well as the radiative transfer
equation. In comparison to the 1D model, the 2D calculation predicts a less
extensive expansion of the atmosphere by orders of magnitude at the
parsec/sub-parsec scale, but the new scale-height $h$ may still exceed the
radial distance $R$ for various physical conditions. A total of 192 NSD models
are computed across the input parameter space in order to predict distributions
of a line of sight column density $N_H$. Assuming a random distribution of
input parameters, the statistics yield 56% of Type 1, 23% of Compton-thin Type
2s (CN), and 21% of Compton-thick (CK) AGNs. Depending on a viewing angle
($\theta$) of a particular NSD (fixed physical conditions), any central AGN can
appear to be Type 1, CN, or CK which is consistent with the basic unification
theory of AGNs. Our results show that $\log[N_H(\text{cm}^{-2})]\in$ [23,25.5]
can be oriented at any $\theta$ from 0$^\circ$ to $\approx$80$^\circ$ due to
the degeneracy in the input parameters.
",Physics
"  The linear growth of operators in local quantum systems leads to an effective
lightcone even if the system is non-relativistic. We show that consistency of
diffusive transport with this lightcone places an upper bound on the
diffusivity: $D \lesssim v^2 \tau_\text{eq}$. The operator growth velocity $v$
defines the lightcone and $\tau_\text{eq}$ is the local equilibration
timescale, beyond which the dynamics of conserved densities is diffusive. We
verify that the bound is obeyed in various weakly and strongly interacting
theories. In holographic models this bound establishes a relation between the
hydrodynamic and leading non-hydrodynamic quasinormal modes of planar black
holes. Our bound relates transport data --- including the electrical
resistivity and the shear viscosity --- to the local equilibration time, even
in the absence of a quasiparticle description. In this way, the bound sheds
light on the observed $T$-linear resistivity of many unconventional metals, the
shear viscosity of the quark-gluon plasma and the spin transport of unitary
fermions.
",Physics
"  Polarization-based filtering in fiber lasers is well-known to enable spectral
tunability and a wide range of dynamical operating states. This effect is
rarely exploited in practical systems, however, because optimization of cavity
parameters is non-trivial and evolves due to environmental sensitivity. Here,
we report a genetic algorithm-based approach, utilizing electronic control of
the cavity transfer function, to autonomously achieve broad wavelength tuning
and the generation of Q-switched pulses with variable repetition rate and
duration. The practicalities and limitations of simultaneous spectral and
temporal self-tuning from a simple fiber laser are discussed, paving the way to
on-demand laser properties through algorithmic control and machine learning
schemes.
",Physics
"  By analyzing spin-spin correlation functions at relatively short distances,
we show that equilibrium near-critical properties can be extracted at short
times after quenches into the vicinity of a quantum critical point. The time
scales after which equilibrium properties can be extracted are sufficiently
short so that the proposed scheme should be viable for quantum simulators of
spin models based on ultracold atoms or trapped ions. Our results, analytic as
well as numeric, are for one-dimensional spin models, either integrable or
nonintegrable, but we expect our conclusions to be valid in higher dimensions
as well.
",Physics
"  Kepler photometry of the hot Neptune host star HAT-P-11 suggests that its
spot latitude distribution is comparable to the Sun's near solar maximum. We
search for evidence of an activity cycle in the CaII H & K chromospheric
emission $S$-index with archival Keck/HIRES spectra and observations from the
echelle spectrograph on the ARC 3.5 m Telescope at APO. The chromospheric
emission of HAT-P-11 is consistent with a $\gtrsim 10$ year activity cycle,
which plateaued near maximum during the Kepler mission. In the cycle that we
observed, the star seemed to spend more time near active maximum than minimum.
We compare the $\log R^\prime_{HK}$ normalized chromospheric emission index of
HAT-P-11 with other stars. HAT-P-11 has unusually strong chromospheric emission
compared to planet-hosting stars of similar effective temperature and rotation
period, perhaps due to tides raised by its planet.
",Physics
"  We examine the 2008-2016 $\gamma$-ray and optical light curves of three
bright BL Lac objects, 0716+714, MRK 421, BL Lac, which exhibit large
structured variability. We searched for periodicities by using a fully Bayesian
approach. For two out of three sources investigated no significant periodic
variability was found. In the case of BL Lac we detected a periodicity of ~ 680
days. Although the signal related to this is modest, the coincidence of the
periods in both gamma and optical bands is indicative of a physical relevance.
Considering previous literature results, possibly related $\gamma$-ray and
optical periodicities of about one year time scale are proposed in 4 bright
$\gamma$-ray blazars out of the 10 examined in detail. Comparing with results
from periodicity search of optical archives of quasars, the presence of
quasi-periodicities in blazars might be more frequent by a large factor. This
suggests the intriguing possibility that the basic conditions for their
observability are related to the relativistic jet in the observer direction,
but the overall picture remains uncertain.
",Physics
"  We present the detection of long-period RV variations in HD 36384, HD 52030,
and HD 208742 by using the high-resolution, fiber-fed Bohyunsan Observatory
Echelle Spectrograph (BOES) for the precise radial velocity (RV) survey of
about 200 northern circumpolar stars. Analyses of RV data, chromospheric
activity indicators, and bisector variations spanning about five years suggest
that the RV variations are compatible with planet or brown dwarf companions in
Keplerian motion. However, HD 36384 shows photometric variations with a period
very close to that of RV variations as well as amplitude variations in the
weighted wavelet Z-transform (WWZ) analysis, which argues that the RV
variations in HD~36384 are from the stellar pulsations. Assuming that the
companion hypothesis is correct, HD~52030 hosts a companion with minimum mass
13.3 M_Jup$ orbiting in 484 days at a distance of 1.2 AU. HD~208742 hosts a
companion of 14.0 M_Jup at 1.5 AU with a period of 602 days. All stars are
located at the asymptotic giant branch (AGB) stage on the H-R diagram after
undergone the helium flash and left the giant clump.With stellar radii of 53.0
R_Sun and 57.2 R_Sun for HD 52030 and HD 208742, respectively, these stars may
be the largest yet, in terms of stellar radius, found to host sub-stellar
companions. However, given possible RV amplitude variations and the fact that
these are highly evolved stars the planet hypothesis is not yet certain.
",Physics
"  Efficient electro-optic (EO) modulators crucially rely on advanced materials
that exhibit strong electro-optic activity and that can be integrated into
high-speed and efficient phase shifter structures. In this paper, we
demonstrate ultra-high in-device EO figures of merit of up to n3r33 = 2300 pm/V
achieved in a silicon-organic hybrid (SOH) Mach-Zehnder Modulator (MZM) using
the EO chromophore JRD1. This is the highest material-related in-device EO
figure of merit hitherto achieved in a high-speed modulator at any operating
wavelength. The {\pi}-voltage of the 1.5 mm-long device amounts to 210 mV,
leading to a voltage-length product of U{\pi}L = 320 V{\mu}m - the lowest value
reported for MZM that are based on low-loss dielectric waveguides. The
viability of the devices is demonstrated by generating high-quality
on-off-keying (OOK) signals at 40 Gbit/s with Q factors in excess of 8 at a
drive voltage as low as 140 mVpp. We expect that efficient high-speed EO
modulators will not only have major impact in the field of optical
communications, but will also open new avenues towards ultra-fast
photonic-electronic signal processing.
",Physics
"  We present a statistical analysis of the variability of broad absorption
lines (BALs) in quasars using the large multi-epoch spectroscopic dataset of
the Sloan Digital Sky Survey Data Release 12 (SDSS DR12). We divide the sample
into two groups according to the pattern of the variation of C iv BAL with
respect to that of continuum: the equivalent widths (EW) of the BAL decreases
(increases) when the continuum brightens (dims) as group T1; and the variation
of EW and continuum in the opposite relation as group T2. We find that T2 has
significantly (P_T<10-6 , Students T Test) higher EW ratios (R) of Si iv to C
iv BAL than T1. Our result agrees with the prediction of photoionization models
that C +3 column density increases (decreases) if there is a (or no) C +3
ionization front while R decreases with the incident continuum. We show that
BAL variabilities in at least 80% quasars are driven by the variation of
ionizing continuum while other models that predict uncorrelated BAL and
continuum variability contribute less than 20%. Considering large uncertainty
in the continuum flux calibration, the latter fraction may be much smaller.
When the sample is binned into different time interval between the two
observations, we find significant difference in the distribution of R between
T1 and T2 in all time-bins down to a deltaT < 6 days, suggesting that BAL
outflow in a fraction of quasars has a recombination time scale of only a few
days.
",Physics
"  We performed simulations for solid molecular hydrogen at high pressures
(250GPa$\leq$P$\leq$500GPa) along two isotherms at T=200 K (phases III and VI)
and at T=414 K (phase IV). At T=200K we considered likely candidates for phase
III, the C2c and Cmca12 structures, while at T=414K in phase IV we studied the
Pc48 structure. We employed both Coupled Electron-Ion Monte Carlo (CEIMC) and
Path Integral Molecular Dynamics (PIMD) based on Density Functional Theory
(DFT) using the vdW-DF approximation. The comparison between the two methods
allows us to address the question of the accuracy of the xc approximation of
DFT for thermal and quantum protons without recurring to perturbation theories.
In general, we find that atomic and molecular fluctuations in PIMD are larger
than in CEIMC which suggests that the potential energy surface from vdW-DF is
less structured than the one from Quantum Monte Carlo. We find qualitatively
different behaviors for systems prepared in the C2c structure for increasing
pressure. Within PIMD the C2c structure is dynamically partially stable for
P$\leq$250GPa only: it retains the symmetry of the molecular centers but not
the molecular orientation; at intermediate pressures it develops layered
structures like Pbcn or Ibam and transforms to the metallic Cmca-4 structure at
P$\geq$450GPa. Instead, within CEIMC, the C2c structure is found to be
dynamically stable at least up to 450GPa; at increasing pressure the molecular
bond length increases and the nuclear correlation decreases. For the other two
structures the two methods are in qualitative agreement although quantitative
differences remain. We discuss various structural properties and the electrical
conductivity. We find these structures become conducting around 350GPa but the
metallic Drude-like behavior is reached only at around 500GPa, consistent with
recent experimental claims.
",Physics
"  The galaxy data provided by COSMOS survey for 1 by 1 degree field of sky are
analysed by methods of complex networks. Three galaxy samples (slices) with
redshifts ranging within intervals 0.88-0.91, 0.91-0.94 and 0.94-0.97 are
studied as two-dimensional projections for the spatial distributions of
galaxies. We construct networks and calculate network measures for each sample,
in order to analyse the network similarity of different samples, distinguish
various topological environments, and find associations between galaxy
properties (colour index and stellar mass) and their topological environments.
Results indicate a high level of similarity between geometry and topology for
different galaxy samples and no clear evidence of evolutionary trends in
network measures. The distribution of local clustering coefficient C manifests
three modes which allow for discrimination between stand-alone singlets and
dumbbells (0 <= C <= 0.1), intermediately (0 < C < 0.9) and clique (0.9 <= C <=
1) like galaxies. Analysing astrophysical properties of galaxies (colour index
and stellar masses), we show that distributions are similar in all slices,
however weak evolutionary trends can also be seen across redshift slices. To
specify different topological environments we have extracted selections of
galaxies from each sample according to different modes of C distribution. We
have found statistically significant associations between evolutionary
parameters of galaxies and selections of C: the distribution of stellar mass
for galaxies with interim C differ from the corresponding distributions for
stand-alone and clique galaxies, and this difference holds for all redshift
slices. The colour index realises somewhat different behaviour.
",Physics
"  The most distant AGN, within the allowed GZK cut-off radius, have been
recently candidate by many authors as the best location for observed UHECR
origination. Indeed, the apparent homogeneity and isotropy of recent UHECR
signals seems to require a far cosmic isotropic and homogeneous scenario
involving a proton UHECR courier: our galaxy or nearest local group or super
galactic plane (ruled by Virgo cluster) are too much near and apparently too
much anisotropic in disagreement with PAO and TA almost homogeneous sample
data. However, the few and mild observed UHECR clustering, the North and South
Hot Spots, are smeared in wide solid angles. Their consequent random walk
flight from most far GZK UHECR sources, nearly at 100 Mpc, must be delayed
(with respect to a straight AGN photon gamma flaring arrival trajectory) at
least by a million years. During this time, the AGN jet blazing signal, its
probable axis deflection (such as the helical jet in Mrk501), its miss
alignment or even its almost certain exhaust activity may lead to a complete
misleading correlation between present UHECR events and a much earlier active
AGN ejection. UHECR maps maybe anyway related to galactic or nearest (Cen A,
M82) AGN extragalactic UHECR sources shining in twin Hot Spot. Therefore we
defend our (quite different) scenarios where UHECR are mostly made by lightest
UHECR nuclei originated by nearby AGN sources, or few galactic sources, whose
delayed signals reach us within few thousand years in the observed smeared sky
areas.
",Physics
"  Here we discuss blackbody radiation within the context of classical theory.
We note that nonrelativistic classical mechanics and relativistic classical
electrodynamics have contrasting scaling symmetries which influence the
scattering of radiation. Also, nonrelativistic mechanical systems can be
accurately combined with relativistic electromagnetic radiation only provided
the nonrelativistic mechanical systems are the low-velocity limits of fully
relativistic systems. Application of the no-interaction theorem for
relativistic systems limits the scattering mechanical systems for thermal
radiation to relativistic classical electrodynamic systems, which involve the
Coulomb potential. Whereas the naive use of nonrelativistic scatterers or
nonrelativistic classical statistical mechanics leads to the Rayleigh-Jeans
spectrum, the use of fully relativistic scatterers leads to the Planck spectrum
for blackbody radiation within classical physics.
",Physics
"  The aim of our study is to investigate the dynamics of possible comets in the
HD 10180 system. This investigation is motivated by the discovery of exocomets
in various systems, especially $\beta$ Pictoris, as well as in at least ten
other systems. Detailed theoretical studies about the formation and evolution
of star--planet systems indicate that exocomets should be quite common. Further
observational results are expected in the foreseeable future, in part due to
the availability of the Large Synoptic Survey Telescope. Nonetheless, the Solar
System represents the best studied example for comets, thus serving as a prime
motivation for investigating comets in HD 10180 as well. HD 10180 is strikingly
similar to the Sun. This system contains six confirmed planets and (at least)
two additional planets subject to final verification. In our studies, we
consider comets of different inclinations and eccentricities and find an array
of different outcomes such as encounters with planets, captures, and escapes.
Comets with relatively large eccentricities are able to enter the inner region
of the system facing early planetary encounters. Stable comets experience
long-term evolution of orbital elements, as expected. We also tried to
distinguish cometary families akin to our Solar System but no clear distinction
between possible families was found. Generally, theoretical and observational
studies of exoplanets have a large range of ramifications, involving the
origin, structure and evolution of systems as well as the proliferation of
water and prebiotic compounds to terrestrial planets, which will increase their
chances of being habitable.
",Physics
"  We demonstrate that an applied electric field causes piezoelectric distortion
across single molecular monolayers of oligopeptides. We deposited
self-assembled monolayers ~1.5 nm high onto smooth gold surfaces. These
monolayers exhibit strong piezoelectric response that varies linearly with
applied bias (1-3V), measured using piezoresponse force microscopy (PFM). The
response is markedly greater than control experiments with rigid alkanethiols
and correlates with surface spectroscopy and theoretical predictions of
conformational change from applied electric fields. Unlike existing
piezoelectric oxides, our peptide monolayers are intrinsically flexible, easily
fabricated, aligned and patterned without poling.
",Physics
"  We consider longitudinal nonlinear atomic vibrations in uniformly strained
carbon chains with the cumulene structure ($=C=C=)_{n}$. With the aid of ab
initio simulations, based on the density functional theory, we have revealed
the phenomenon of the $\pi$-mode softening in a certain range of its amplitude
for the strain above the critical value $\eta_{c}\approx 11\,{\%}$.
Condensation of this soft mode induces the structural transformation of the
carbon chain with doubling of its unit cell. This is the Peierls phase
transition in the strained cumulene, which was previously revealed in [Nano
Lett. 14, 4224 (2014)]. The Peierls transition leads to appearance of the
energy gap in the electron spectrum of the strained carbyne, and this material
transforms from the conducting state to semiconducting or insulating states.
The authors of the above paper emphasize that such phenomenon can be used for
construction of various nanodevices. The $\pi$-mode softening occurs because
the old equilibrium positions (EQPs), around which carbon atoms vibrate at
small strains, lose their stability and these atoms begin to vibrate in the new
potential wells located near old EQPs. We study the stability of the new EQPs,
as well as stability of vibrations in their vicinity. In previous paper
[Physica D 203, 121(2005)], we proved that only three symmetry-determined
Rosenberg nonlinear normal modes can exist in monoatomic chains with arbitrary
interparticle interactions. They are the above-discussed $\pi$-mode and two
other modes, which we call $\sigma$-mode and $\tau$-mode. These modes
correspond to the multiplication of the unit cell of the vibrational state by
two, three or four times compared to that of the equilibrium state. We study
properties of these modes in the chain model with arbitrary pair potential of
interparticle interactions.
",Physics
"  High-pressure neutron powder diffraction, muon-spin rotation and
magnetization studies of the structural, magnetic and the superconducting
properties of the Ce-underdoped superconducting (SC) electron-doped cuprate
system T'-Pr_1.3-xLa_0.7Ce_xCuO_4 with x = 0.1 are reported. A strong reduction
of the lattice constants a and c is observed under pressure. However, no
indication of any pressure induced phase transition from T' to T structure is
observed up to the maximum applied pressure of p = 11 GPa. Large and non-linear
increase of the short-range magnetic order temperature T_so in
T'-Pr_1.3-xLa_0.7Ce_xCuO_4 (x = 0.1) was observed under pressure.
Simultaneously pressure causes a non-linear decrease of the SC transition
temperature T_c. All these experiments establish the short-range magnetic order
as an intrinsic and a new competing phase in SC T'-Pr_1.2La_0.7Ce_0.1CuO_4. The
observed pressure effects may be interpreted in terms of the improved nesting
conditions through the reduction of the in-plane and out-of-plane lattice
constants upon hydrostatic pressure.
",Physics
"  We point out that current textbooks of modern physics are a century
out-of-date in their treatment of blackbody radiation within classical physics.
Relativistic classical electrodynamics including classical electromagnetic
zero-point radiation gives the Planck spectrum with zero-point radiation as the
blackbody radiation spectrum. In contrast, nonrelativistic mechanics cannot
support the idea of zero-point energy; therefore if nonrelativistic classical
statistical mechanics or nonrelativistic mechanical scatterers are invoked for
radiation equilibrium, one arrives at only the low-frequency Rayleigh-Jeans
part of the spectrum which involves no zero-point energy, and does not include
the high-frequency part of the spectrum involving relativistically-invariant
classical zero-point radiation. Here we first discuss the correct understanding
of blackbody radiation within relativistic classical physics, and then we
review the historical treatment. Finally, we point out how the presence of
Lorentz-invariant classical zero-point radiation and the use of relativistic
particle interactions transform the previous historical arguments so as now to
give the Planck spectrum including classical zero-point radiation. Within
relativistic classical electromagnetic theory, Planck's constant h appears as
the scale of source-free zero-point radiation.
",Physics
"  We study the $f(R)$ theory of gravity in an anisotropic metric and its effect
on the baryon number to entropy ratio. The mechanism of gravitational
baryogenesis based on the CPT-violating gravitational interaction between
derivative of the Ricci scalar curvature and the baryon-number current is
investigated in the context of the $f(R)$ gravity. The gravitational
baryogenesis in the Bianchi type I universe is examined. We survey the effect
of anisotropy of the universe on the baryon asymmetry from point of view the
$f(R)$-theories of gravity and its effect on $n_{b}/s$ for radiation dominant
regime.
",Physics
"  We present ALMA detections of the [CI] 1-0, CO J=3-2, and CO J=4-3 emission
lines, as well as the ALMA band 4 continuum for a compact star-forming galaxy
(cSFG) at z=2.225, 3D-HST GS30274. As is typical for cSFGs, this galaxy has a
stellar mass of $1.89 \pm 0.47\,\times 10^{11}\,\rm{M}_\odot$, with a star
formation rate of $214\pm44\,\rm{M}_\odot\,\rm{yr}^{-1}$ putting it on the
star-forming `main-sequence', but with an H-band effective radius of 2.5 kpc,
making it much smaller than the bulk of `main-sequence' star-forming galaxies.
The intensity ratio of the line detections yield an ISM density (~ 6 $\times
10^{4}\,\rm{cm}^{-3}$) and a UV-radiation field ( ~2 $\times 10^4\,\rm{G}_0$),
similar to the values in local starburst and ultra-luminous infrared galaxy
environments. A starburst phase is consistent with the short depletion times
($t_{\rm H2, dep} \leq 140$ Myr) we find using three different proxies for the
H2 mass ([CI], CO, dust mass). This depletion time is significantly shorter
than in more extended SFGs with similar stellar masses and SFRs. Moreover, the
gas fraction of 3D-HST GS30274 is smaller than typically found in extended
galaxies. We measure the CO and [CI] kinematics and find a FWHM line width of
~$750 \pm 41 $ km s$^{-1}$. The CO and [CI] FWHM are consistent with a
previously measured H$\alpha$ FWHM for this source. The line widths are
consistent with gravitational motions, suggesting we are seeing a compact
molecular gas reservoir. A previous merger event, as suggested by the
asymmetric light profile, may be responsible for the compact distribution of
gas and has triggered a central starburst event. This event gives rise to the
starburst-like ISM properties and short depletion times. The centrally located
and efficient star formation is quickly building up a dense core of stars,
responsible for the compact distribution of stellar light in 3D-HST GS30274.
",Physics
"  The coupled evolution of an eroding cylinder immersed in a fluid within the
subcritical Reynolds range is explored with scale resolving simulations.
Erosion of the cylinder is driven by fluid shear stress. Kármán vortex
shedding features in the wake and these oscillations occur on a significantly
smaller time scale compared to the slowly eroding cylinder boundary. Temporal
and spatial averaging across the cylinder span allows mean wall statistics such
as wall shear to be evaluated; with geometry evolving in 2-D and the flow field
simulated in 3-D. The cylinder develops into a rounded triangular body with
uniform wall shear stress which is in agreement with existing theory and
experiments. We introduce a node shuffle algorithm to reposition nodes around
the cylinder boundary with a uniform distribution such that the mesh quality is
preserved under high boundary deformation. A cylinder is then modelled within
an infinite array of other cylinders by simulating a repeating unit cell and
their profile evolution is studied. A similar terminal form is discovered for
large cylinder spacings with consistent flow conditions and an intermediate
profile was found with a closely packed lattice before reaching the common
terminal form.
",Physics
"  This work presents a joint and self-consistent Bayesian treatment of various
foreground and target contaminations when inferring cosmological power-spectra
and three dimensional density fields from galaxy redshift surveys. This is
achieved by introducing additional block sampling procedures for unknown
coefficients of foreground and target contamination templates to the previously
presented ARES framework for Bayesian large scale structure analyses. As a
result the method infers jointly and fully self-consistently three dimensional
density fields, cosmological power-spectra, luminosity dependent galaxy biases,
noise levels of respective galaxy distributions and coefficients for a set of a
priori specified foreground templates. In addition this fully Bayesian approach
permits detailed quantification of correlated uncertainties amongst all
inferred quantities and correctly marginalizes over observational systematic
effects. We demonstrate the validity and efficiency of our approach in
obtaining unbiased estimates of power-spectra via applications to realistic
mock galaxy observations subject to stellar contamination and dust extinction.
While simultaneously accounting for galaxy biases and unknown noise levels our
method reliably and robustly infers three dimensional density fields and
corresponding cosmological power-spectra from deep galaxy surveys. Further our
approach correctly accounts for joint and correlated uncertainties between
unknown coefficients of foreground templates and the amplitudes of the
power-spectrum. An effect amounting up to $10$ percent correlations and
anti-correlations across large ranges in Fourier space.
",Physics
"  Generalized-ensemble Monte Carlo simulations such as the multicanonical
method and similar techniques are among the most efficient approaches for
simulations of systems undergoing discontinuous phase transitions or with
rugged free- energy landscapes. As Markov chain methods, they are inherently
serial computationally. It was demonstrated recently, however, that a
combination of independent simulations that communicate weight updates at
variable intervals allows for the efficient utilization of parallel
computational resources for multicanonical simulations. Implementing this
approach for the many-thread architecture provided by current generations of
graphics processing units (GPUs), we show how it can be efficiently employed
with of the order of $10^4$ parallel walkers and beyond, thus constituting a
versatile tool for Monte Carlo simulations in the era of massively parallel
computing. We provide the fully documented source code for the approach applied
to the paradigmatic example of the two-dimensional Ising model as starting
point and reference for practitioners in the field.
",Physics
"  In this paper I will present a short scientific biography of Guido Altarelli,
briefly describing some of his most important seminal works. I will analyze in
great details the paper of the $q^2$ evolution of the effective quark
distribution: I will put this paper in a historical perspective, describing our
theoretical understanding at that time and the reasons why the paper was so
successful.
",Physics
"  Hamiltonian Truncation (a.k.a. Truncated Spectrum Approach) is an efficient
numerical technique to solve strongly coupled QFTs in d=2 spacetime dimensions.
Further theoretical developments are needed to increase its accuracy and the
range of applicability. With this goal in mind, here we present a new variant
of Hamiltonian Truncation which exhibits smaller dependence on the UV cutoff
than other existing implementations, and yields more accurate spectra. The key
idea for achieving this consists in integrating out exactly a certain class of
high energy states, which corresponds to performing renormalization at the
cubic order in the interaction strength. We test the new method on the strongly
coupled two-dimensional quartic scalar theory. Our work will also be useful for
the future goal of extending Hamiltonian Truncation to higher dimensions d >=
3.
",Physics
"  Tests of gravity at the galaxy scale are in their infancy. As a first step to
systematically uncovering the gravitational significance of galaxies, we map
three fundamental gravitational variables -- the Newtonian potential,
acceleration and curvature -- over the galaxy environments of the local
universe to a distance of approximately 200 Mpc. Our method combines the
contributions from galaxies in an all-sky redshift survey, halos from an N-body
simulation hosting low-luminosity objects, and linear and quasi-linear modes of
the density field. We use the ranges of these variables to determine the extent
to which galaxies expand the scope of generic tests of gravity and are capable
of constraining specific classes of model for which they have special
significance. Finally, we investigate the improvements afforded by upcoming
galaxy surveys.
",Physics
"  We consider multi-time correlators for output signals from linear detectors,
continuously measuring several qubit observables at the same time. Using the
quantum Bayesian formalism, we show that for unital (symmetric) evolution in
the absence of phase backaction, an $N$-time correlator can be expressed as a
product of two-time correlators when $N$ is even. For odd $N$, there is a
similar factorization, which also includes a single-time average. Theoretical
predictions agree well with experimental results for two detectors, which
simultaneously measure non-commuting qubit observables.
",Physics
"  We study the two-dimensional topology of the galactic distribution when
projected onto two-dimensional spherical shells. Using the latest Horizon Run 4
simulation data, we construct the genus of the two-dimensional field and
consider how this statistic is affected by late-time nonlinear effects --
principally gravitational collapse and redshift space distortion (RSD). We also
consider systematic and numerical artifacts such as shot noise, galaxy bias,
and finite pixel effects. We model the systematics using a Hermite polynomial
expansion and perform a comprehensive analysis of known effects on the
two-dimensional genus, with a view toward using the statistic for cosmological
parameter estimation. We find that the finite pixel effect is dominated by an
amplitude drop and can be made less than $1\%$ by adopting pixels smaller than
$1/3$ of the angular smoothing length. Nonlinear gravitational evolution
introduces time-dependent coefficients of the zeroth, first, and second Hermite
polynomials, but the genus amplitude changes by less than $1\%$ between $z=1$
and $z=0$ for smoothing scales $R_{\rm G} > 9 {\rm Mpc/h}$. Non-zero terms are
measured up to third order in the Hermite polynomial expansion when studying
RSD. Differences in shapes of the genus curves in real and redshift space are
small when we adopt thick redshift shells, but the amplitude change remains a
significant $\sim {\cal O}(10\%)$ effect. The combined effects of galaxy
biasing and shot noise produce systematic effects up to the second Hermite
polynomial. It is shown that, when sampling, the use of galaxy mass cuts
significantly reduces the effect of shot noise relative to random sampling.
",Physics
"  We present the concept of magnetic gas detection by the Extraordinary Hall
effect (EHE). The technique is compatible with the existing conductometric gas
detection technologies and allows simultaneous measurement of two independent
parameters: resistivity and magnetization affected by the target gas.
Feasibility of the approach is demonstrated by detecting low concentration
hydrogen using thin CoPd films as the sensor material. The Hall effect
sensitivity of the optimized samples exceeds 240% per 104 ppm at hydrogen
concentrations below 0.5% in the hydrogen/nitrogen atmosphere, which is more
than two orders of magnitude higher than the sensitivity of the conductance
detection.
",Physics
"  We determine the abundances of neutron-capture elements from Sr to Eu for
five very-metal-poor stars (-3<[Fe/H]<-2) in the Milky Way halo to reveal the
origin of light neutron-capture elements. Previous spectroscopic studies have
shown evidence of at least two components in the r-process; one referred to as
the ""main r-process"" and the other as the ""weak r-process,"" which is mainly
responsible for producing heavy and light neutron-capture elements,
respectively. Observational studies of metal-poor stars suggest that there is a
universal pattern in the main r-process, similar to the abundance pattern of
the r-process component of solar-system material. Still, it is uncertain
whether the abundance pattern of the weak r-process shows universality or
diversity, due to the sparseness of measured light neutron-capture elements. We
have detected the key elements, Mo, Ru, and Pd, in five target stars to give an
answer to this question. The abundance patterns of light neutron-capture
elements from Sr to Pd suggest a diversity in the weak r-process. In
particular, scatter in the abundance ratio between Ru and Pd is significant
when the abundance patterns are normalized at Zr. Our results are compared with
the elemental abundances predicted by nucleosynthesis models of supernovae with
parameters such as electron fraction or proto-neutron-star mass, to investigate
sources of such diversity in the abundance patterns of light neutron-capture
elements. This paper presents that the variation in the abundances of observed
stars can be explained with a small range of parameters, which can serve as
constraints on future modeling of supernova models.
",Physics
"  Using a membrane-driven diamond anvil cell and both ac magnetic
susceptibility and electrical resistivity measurements, we have characterized
the superconducting phase diagram of elemental barium to pressures as high as
65 GPa. We have determined the superconducting properties of the recently
discovered Ba-VI crystal structure, which can only be accessed via the
application of pressure at low temperature. We find that Ba-VI exhibits a
maximum Tc near 8 K, which is substantially higher than the maximum Tc found
when pressure is applied at room temperature.
",Physics
"  For primordial black holes (PBH) to be the dark matter in single-field
inflation, the slow-roll approximation must be violated by at least ${\cal
O}(1)$ in order to enhance the curvature power spectrum within the required
number of efolds between CMB scales and PBH mass scales. Power spectrum
predictions which rely on the inflaton remaining on the slow-roll attractor can
fail dramatically leading to qualitatively incorrect conclusions in models like
an inflection potential and misestimate the mass scale in a running mass model.
We show that an optimized temporal evaluation of the Hubble slow-roll
parameters to second order remains a good description for a wide range of PBH
formation models where up to a $10^7$ amplification of power occurs in $10$
efolds or more.
",Physics
"  We demonstrate that a weakly disordered metal with short-range interactions
exhibits a transition in the quantum chaotic dynamics when changing the
temperature or the interaction strength. For weak interactions, the system
displays exponential growth of the out-of-time-ordered correlator (OTOC) of the
current operator. The Lyapunov exponent of this growth is
temperature-independent in the limit of vanishing interaction. With increasing
the temperature or the interaction strength, the system undergoes a transition
to a non-chaotic behaviour, for which the exponential growth of the OTOC is
absent. We conjecture that the transition manifests itself in the quasiparticle
energy-level statistics and also discuss ways of its explicit observation in
cold-atom setups.
",Physics
"  Orion KL is one of the most frequently observed sources in the Galaxy, and
the site where many molecular species have been discovered for the first time.
With the availability of powerful wideband backends, it is nowadays possible to
complete spectral surveys in the entire mm-range to obtain a spectroscopically
unbiased chemical picture of the region. In this paper we present a sensitive
spectral survey of Orion KL, made with one of the 34m antennas of the Madrid
Deep Space Communications Complex in Robledo de Chavela, Spain. The spectral
range surveyed is from 41.5 to 50 GHz, with a frequency spacing of 180 kHz
(equivalent to about 1.2 km/s, depending on the exact frequency). The rms
achieved ranges from 8 to 12 mK. The spectrum is dominated by the J=1-0 SiO
maser lines and by radio recombination lines (RRLs), which were detected up to
Delta_n=11. Above a 3-sigma level, we identified 66 RRLs and 161 molecular
lines corresponding to 39 isotopologues from 20 molecules; a total of 18 lines
remain unidentified, two of them above a 5-sigma level. Results of radiative
modelling of the detected molecular lines (excluding masers) are presented. At
this frequency range, this is the most sensitive survey and also the one with
the widest band. Although some complex molecules like CH_3CH_2CN and CH_2CHCN
arise from the hot core, most of the detected molecules originate from the low
temperature components in Orion KL.
",Physics
"  To make research of chaos more friendly with discrete equations, we introduce
the concept of an unpredictable sequence as a specific unpredictable function
on the set of integers. It is convenient to be verified as a solution of a
discrete equation. This is rigorously proved in this paper for quasilinear
systems, and we demonstrate the result numerically for linear systems in the
critical case with respect to the stability of the origin. The completed
research contributes to the theory of chaos as well as to the theory of
discrete equations, considering unpredictable solutions.
",Physics
"  Understanding planetary interiors is directly linked to our ability of
simulating exotic quantum mechanical systems such as hydrogen (H) and
hydrogen-helium (H-He) mixtures at high pressures and temperatures. Equations
of State (EOSs) tables based on Density Functional Theory (DFT), are commonly
used by planetary scientists, although this method allows only for a
qualitative description of the phase diagram, due to an incomplete treatment of
electronic interactions. Here we report Quantum Monte Carlo (QMC) molecular
dynamics simulations of pure H and H-He mixture. We calculate the first QMC EOS
at 6000 K for an H-He mixture of a proto-solar composition, and show the
crucial influence of He on the H metallization pressure. Our results can be
used to calibrate other EOS calculations and are very timely given the accurate
determination of Jupiter's gravitational field from the NASA Juno mission and
the effort to determine its structure.
",Physics
"  In order to understand the mechanisms behind the emergence of
superconductivity by the chemical pressure effect in REO0.5F0.5BiS2 (RE = La,
Ce, Pr, and Nd), where bulk superconductivity is induced by the substitutions
with a smaller-radius RE, we performed synchrotron powder X-ray diffraction,
and analyzed the crystal structure and anisotropic displacement parameters.
With the decrease of the RE3+ ionic radius, the in-plane disorder of the S1
sites significantly decreased, very similar to the trend observed in the
Se-substituted systems: LaO0.5F0.5BiS2-xSex and Eu0.5La0.5FBiS2-xSex.
Therefore, the emergence of bulk superconductivity upon the suppression of the
in-plane disorder at the chalcogen sites is a universal scenario for the
BiCh2-based superconductors. In addition, we indicated that the amplitude of
vibration along the c-axis of the in-plane chalcogen sites may be related to
the Tc in the BiCh2-based superconductors.
",Physics
"  Viscoelasticity has been described since the time of Maxwell as an
interpolation of purely viscous and purely elastic response, but its
microscopic atomic-level mechanism in solids has remained elusive. We studied
three model disordered solids: a random lattice, the bond-depleted fcc lattice,
and the fcc lattice with vacancies. Within the harmonic approximation for
central-force lattices, we applied sum-rules for viscoelastic response derived
on the basis of non-affine atomic motions. The latter motions are a direct
result of local structural disorder, and in particular, of the lack of
inversion-symmetry in disordered lattices. By defining a suitable quantitative
and general atomic-level measure of nonaffinity and inversion-symmetry, we show
that the viscoelastic responses of all three systems collapse onto a master
curve upon normalizing by the overall strength of inversion-symmetry breaking
in each system. Close to the isostatic point for central-force lattices,
power-law creep $G(t)\sim t^{-1/2}$ emerges as a consequence of the interplay
between soft vibrational modes and non-affine dynamics, and various analytical
scalings, supported by numerical calculations, are predicted by the theory.
",Physics
"  In general, small bodies of the solar system, e.g., asteroids and comets,
have a very irregular shape. This feature affects significantly the
gravitational potential around these irregular bodies, which hinders dynamical
studies. The Poincaré surface of sec- tion technique is often used to look
for stable and chaotic regions in two-dimensional dynamic cases. In this work,
we show that this tool can be useful for exploring the surroundings of
irregular bodies such as the asteroid 4179 Toutatis. Considering a rotating
system with a particle, under the effect of the gravitational field computed
three-dimensionally, we define a plane in the phase space to build the
Poincaré surface of sections. Despite the extra dimension, the sections
created allow us to find trajec- tories and classify their stabilities. Thus,
we have also been able to map stable and chaotic regions, as well as to find
correlations between those regions and the contri- bution of the third
dimension of the system to the trajectory dynamics as well. As examples, we
show details of periodic(resonant or not) and quasi-periodic trajectories.
",Physics
"  In this paper we investigate the convection phenomenon in the intracluster
medium (the weakly-collisional magnetized inhomogeneous plasma permeating
galaxy clusters) where the concentration gradient of the Helium ions is not
ignorable. To this end, we build upon the general machinery employed to study
the salt finger instability found in the oceans. The salt finger instability is
a form of double diffusive convection where the diffusions of two physical
quantities---heat and salt concentrations---occur with different diffusion
rates. The analogous instability in the intracluster medium may result owing to
the magnetic field mediated anisotropic diffusions of the heat and the Helium
ions (in the sea of the Hydrogen ions and the free electrons). These two
diffusions have inherently different diffusion rates. Hence the convection
caused by the onset of this instability is an example of double diffusive
convection in the astrophysical settings. A consequence of this instability is
the formation of the vertical filamentary structures having more concentration
of the Helium ions with respect to the immediate neighbourhoods of the
filaments. We term these structures as Helium fingers in analogy with the salt
fingers found in the case of the salt finger instability. Here we show that the
width of a Helium finger scales as one-fourth power of the radius of the inner
region of the intracluster medium in the supercritical regime. We also
determine the explicit mathematical expression of the criterion for the onset
of the heat-flux-driven buoyancy instability modified by the presence of
inhomogeneously distributed Helium ions.
",Physics
"  We study a possible connection between different non-thermal emissions from
the inner few parsecs of the Galaxy. We analyze the origin of the gamma-ray
source 2FGL J1745.6-2858 (or 3FGL J1745.6-2859c) in the Galactic Center and the
diffuse hard X-ray component recently found by NuSTAR, as well as the radio
emission and processes of hydrogen ionization from this area. We assume that a
source in the GC injected energetic particles with power-law spectrum into the
surrounding medium in the past or continues to inject until now. The energetic
particles may be protons, electrons or a combination of both. These particles
diffuse to the surrounding medium and interact with gas, magnetic field and
background photons to produce non-thermal emissions. We study the spectral and
spatial features of the hard X-ray emission and gamma-ray emission by the
particles from the central source. Our goal is to examine whether the hard
X-ray and gamma-ray emissions have a common origin. Our estimations show that
in the case of pure hadronic models the expected flux of hard X-ray emission is
too low. Despite protons can produce a non-zero contribution in gamma-ray
emission, it is unlikely that they and their secondary electrons can make a
significant contribution in hard X-ray flux. In the case of pure leptonic
models it is possible to reproduce both X-ray and gamma-ray emissions for both
transient and continuous supply models. However, in the case of continuous
supply model the ionization rate of molecular hydrogen may significantly exceed
the observed value.
",Physics
"  An instability of a liquid droplet traversed by an energetic ion is explored.
This instability is brought about by the predicted shock wave induced by the
ion. An observation of multifragmentation of small droplets traversed by ions
with high linear energy transfer is suggested to demonstrate the existence of
shock waves. A number of effects are analysed in effort to find the conditions
for such an experiment to be signifying. The presence of shock waves crucially
affects the scenario of radiation damage with ions since the shock waves
significantly contribute to the thermomechanical damage of biomolecules as well
as the transport of reactive species. While the scenario has been upheld by
analyses of biological experiments, the shock waves have not yet been observed
directly, regardless of a number of ideas of experiments to detect them were
exchanged at conferences.
",Physics
"  We study the generation of the matter-antimatter asymmetry during bosonic
preheating, focusing on the sources of the asymmetry. If the asymmetry appears
in the multiplication factor of the resonant particle production, the
matter-antimatter ratio will grow during preheating. On the other hand, if the
asymmetry does not grow during preheating, one has to find out another reason.
We consider several scenarios for the asymmetric preheating to distinguish the
sources of the asymmetry. We also discuss a new baryogenesis scenario, in which
the asymmetry is generated without introducing neither loop corrections nor
rotation of a field.
",Physics
"  A rectangular grid formed by liquid filaments on a partially wetting
substrate evolves in a series of breakups leading to arrays of drops with
different shapes distributed in a rather regular bidimensional pattern. Our
study is focused on the configuration produced when two long parallel filaments
of silicone oil, which are placed upon a glass substrate previously coated with
a fluorinated solution, are crossed perpendicularly by another pair of long
parallel filaments. A remarkable feature of this kind of grids is that there
are two qualitatively different types of drops. While one set is formed at the
crossing points, the rest are consequence of the breakup of shorter filaments
formed between the crossings. Here, we analyze the main geometric features of
all types of drops, such as shape of the footprint and contact angle
distribution along the drop periphery. The formation of a series of short
filaments with similar geometric and physical properties allows us to have
simultaneously quasi identical experiments to study the subsequent breakups. We
develop a simple hydrodynamic model to predict the number of drops that results
from a filament of given initial length and width. This model is able to yield
the length intervals corresponding to a small number of drops and its
predictions are successfully compared with the experimental data as well as
with numerical simulations of the full Navier--Stokes equation that provide a
detailed time evolution of the dewetting motion of the filament till the
breakup into drops. Finally, the prediction for finite filaments is contrasted
with the existing theories for infinite ones.
",Physics
"  Carbon solubility in face-centered cubic Ni-W alloys and the phase diagram of
C-Ni-W are investigated by means of first principle calculations and semi-grand
canonical Monte Carlo simulations. With density functional theory (DFT) total
energies as fitting data, we build a superatom model for efficient simulation.
Multi-histogram analysis is utilized to predict free energies for different
compositions and temperatures. By comparing free energies of competing phases,
we are able to predict carbon solubility and phase diagrams of C-Ni-W at
different temperatures. A simple ideal mixing approximation gives qualitatively
similar predictions.
",Physics
"  The aim of the study is to investigate the reason for the low productivity of
high-energy SEPs in the present solar cycle. We employ scaling laws derived
from diffusive shock acceleration theory and simulation studies including
proton-generated upstream Alfvén waves to find out how the changes observed
in the long-term average properties of the erupting and ambient coronal and/or
solar wind plasma would affect the ability of shocks to accelerate particles to
the highest energies. Provided that self-generated turbulence dominates
particle transport around coronal shocks, it is found that the most crucial
factors controlling the diffusive shock acceleration process are the number
density of seed particles and the plasma density of the ambient medium.
Assuming that suprathermal populations provide a fraction of the particles
injected to shock acceleration in the corona, we show that the lack of most
energetic particle events as well as the lack of low charge-to-mass ratio ion
species in the present cycle can be understood as a result of the reduction of
average coronal plasma and suprathermal densities in the present cycle over the
previous one.
",Physics
"  We present a quantitative analysis on the response of a dilute active
suspension of self-propelled rods (swimmers) in a planar channel subjected to
an imposed shear flow. To best capture the salient features of shear-induced
effects, we consider the case of an imposed Couette flow, providing a constant
shear rate across the channel. We argue that the steady-state behavior of
swimmers can be understood in the light of a population splitting phenomenon,
occurring as the shear rate exceeds a certain threshold, initiating the
reversal of swimming direction for a finite fraction of swimmers from down- to
upstream or vice versa, depending on swimmer position within the channel.
Swimmers thus split into two distinct, statistically significant and oppositely
swimming majority and minority populations. The onset of population splitting
translates into a transition from a self-propulsion-dominated regime to a
shear-dominated regime, corresponding to a unimodal-to-bimodal change in the
probability distribution function of the swimmer orientation. We present a
phase diagram in terms of the swim and flow Peclet numbers showing the
separation of these two regimes by a discontinuous transition line. Our results
shed further light on the behavior of swimmers in a shear flow and provide an
explanation for the previously reported non-monotonic behavior of the mean,
near-wall, parallel-to-flow orientation of swimmers with increasing shear
strength.
",Physics
"  We derive equations of motion for the reduced density matrix of a molecular
system which undergoes energy transfer dynamics competing with fast internal
conversion channels. Environmental degrees of freedom of such a system have no
time to relax to quasi-equilibrium in the electronic excited state of the donor
molecule, and thus the conditions of validity of Foerster and Modified Redfield
theories in their standard formulations do not apply. We derive non-equilibrium
versions of the two well-known rate theories and apply them to the case of
carotenoid-chlorophyll energy transfer. Although our reduced density matrix
approach does not account for the formation of vibronic excitons, it still
confirms the important role of the donor ground-state vibrational states in
establishing the resonance energy transfer conditions. We show that it is
essential to work with a theory valid in strong system-bath interaction regime
to obtain correct dependence of the rates on donor-acceptor energy gap.
",Physics
"  The paper aims to apply the complex octonion to explore the influence of the
energy gradient on the Eotvos experiment, impacting the gravitational mass in
the ultra-strong magnetic fields. Until now the Eotvos experiment has never
been validated under the ultra-strong magnetic field. It is aggravating the
existing serious qualms about the Eotvos experiment. According to the
electromagnetic and gravitational theory described with the complex octonions,
the ultra-strong magnetic field must result in a tiny variation of the
gravitational mass. The magnetic field with the gradient distribution will
generate the energy gradient. These influencing factors will exert an influence
on the state of equilibrium in the Eotvos experiment. That is, the
gravitational mass will depart from the inertial mass to a certain extent, in
the ultra-strong magnetic fields. Only under exceptional circumstances,
especially in the case of the weak field strength, the gravitational mass may
be equal to the inertial mass approximately. The paper appeals intensely to
validate the Eotvos experiment in the ultra-strong electromagnetic strengths.
It is predicted that the physical property of gravitational mass will be
distinct from that of inertial mass.
",Physics
"  We report temperature (T) dependence of dc magnetization, electrical
resistivity (rho(T)), and heat-capacity of rare-earth (R) compounds, Gd3RuSn6
and Tb3RuSn6, which are found to crystallize in the Yb3CoSn6-type orthorhombic
structure (space group: Cmcm). The results establish that there is an onset of
antiferromagnetic order near (T_N) 19 and 25 K respectively. In addition, we
find that there is another magnetic transition for both the cases around 14 and
17 K respectively. In the case of the Gd compound, the spin-scattering
contribution to rho is found to increase below 75 K as the material is cooled
towards T_N, thereby resulting in a minimum in the plot of rho(T) unexpected
for Gd based systems. Isothermal magnetization at 1.8 K reveals an upward
curvature around 50 kOe. Isothermal magnetoresistance plots show interesting
anomalies in the magnetically ordered state. There are sign reversals in the
plot of isothermal entropy change versus T in the magnetically ordered state,
indicating subtle changes in the spin reorientation with T. The results reveal
that these compounds exhibit interesting magnetic properties.
",Physics
"  Dutch book arguments have been applied to beliefs about the outcomes of
measurements of quantum systems, but not to beliefs about quantum objects prior
to measurement. In this paper, we prove a quantum version of the probabilists'
Dutch book theorem that applies to both sorts of beliefs: roughly, if ideal
beliefs are given by vector states, all and only Born-rule probabilities avoid
Dutch books. This theorem and associated results have implications for
operational and realist interpretations of the logic of a Hilbert lattice. In
the latter case, we show that the defenders of the eigenstate-value orthodoxy
face a trilemma. Those who favor vague properties avoid the trilemma, admitting
all and only those beliefs about quantum objects that avoid Dutch books.
",Physics
"  I propose to use high brightness electron beam with 1 to 100 MeV energy as
tool to combat tumor or cancerous tissues in deep part of body. The method is
to directly deliver the electron beam to the tumor site via a small tube that
connected to a high brightness electron beam accelerator that is commonly
available around the world. Here I gave a basic scheme on the principle, I
believe other issues people raises will be solved easily for those who are
interested in solving the problems.
",Physics
"  The ancient phrase, ""All roads lead to Rome"" applies to Chemistry and
Physics. Both are highly evolved sciences, with their own history, traditions,
language, and approaches to problems. Despite all these differences, these two
roads generally lead to the same place. For high temperature cuprate
superconductors however, the Chemistry and Physics roads do not meet or even
come close to each other. In this paper, we analyze the physics and chemistry
approaches to the doped electronic structure of cuprates and find the chemistry
doped hole (out-of-the-CuO$\mathrm{_2}$-planes) leads to explanations of a vast
array of normal state cuprate phenomenology using simple counting arguments.
The chemistry picture suggests that phonons are responsible for
superconductivity in cuprates. We identify the important phonon modes, and show
that the observed T$\mathrm{_c} \sim 100$ K, the T$\mathrm{_c}$-dome as a
function of hole doping, the change in T$\mathrm{_c}$ as a function of the
number of CuO$\mathrm{_2}$ layers per unit cell, the lack of an isotope effect
at optimal T$\mathrm{_c}$ doping, and the D-wave symmetry of the
superconducting Cooper pair wavefunction are all explained by the chemistry
picture. Finally, we show that ""crowding"" the dopants in cuprates leads to a
pair wavefunction with S-wave symmetry and T$\mathrm{_c}\approx280-390$ K.
Hence, we believe there is enormous ""latent"" T$\mathrm{_c}$ remaining in the
cuprate class of superconductors.
",Physics
"  Two-dimensional materials have significant potential for the development of
new devices. Here we report the electronic and structural properties of
$\beta$-GeSe, a previously unreported polymorph of GeSe, with a unique crystal
structure that displays strong two-dimensional structural features.
$\beta$-GeSe is made at high pressure and temperature and is stable under
ambient conditions. We compare it to its structural and electronic relatives
$\alpha$-GeSe and black phosphorus. The $\beta$ form of GeSe displays a boat
conformation for its Ge-Se six-ring, while the previously known $\alpha$ form,
and black phosphorus, display the more common chair conformation for their
six-rings. Electronic structure calculations indicate that $\beta$-GeSe is a
semiconductor, with an approximate bulk band gap of $\Delta~\approx$ 0.5 eV,
and, in its monolayer form, $\Delta~\approx$ 0.9 eV. These values fall between
those of $\alpha$-GeSe and black phosphorus, making $\beta$-GeSe a promising
candidate for future applications. The resistivity of our $\beta$-GeSe crystals
measured in-plane is on the order of $\rho \approx$ 1 $\Omega$cm, while being
essentially temperature independent.
",Physics
"  Ultracold atomic physics experiments offer a nearly ideal context for the
investigation of quantum systems far from equilibrium. We describe three
related emerging directions of research into extreme non-equilibrium phenomena
in atom traps: quantum emulation of ultrafast atom-light interactions, coherent
phasonic spectroscopy in tunable quasicrystals, and realization of Floquet
matter in strongly-driven lattice systems. We show that all three should enable
quantum emulation in parameter regimes inaccessible in solid-state experiments,
facilitating a complementary approach to open problems in non-equilibrium
condensed matter.
",Physics
"  The discovery of topological insulators has reformed modern materials
science, promising to be a platform for tabletop relativistic physics,
electronic transport without scattering, and stable quantum computation.
Topological invariants are used to label distinct types of topological
insulators. But it is not generally known how many or which invariants can
exist in any given crystalline material. Using a new and efficient counting
algorithm, we study the topological invariants that arise in time-reversal
symmetric crystals. This results in a unified picture that explains the
relations between all known topological invariants in these systems. It also
predicts new topological phases and one entirely new topological invariant. We
present explicitly the classification of all two-dimensional crystalline
fermionic materials, and give a straightforward procedure for finding the
analogous result in any three-dimensional structure. Our study represents a
single, intuitive physical picture applicable to all topological invariants in
real materials, with crystal symmetries.
",Physics
"  Ultraviolet self-interaction energies in field theory sometimes contain
meaningful physical quantities. The self-energies in such as classical
electrodynamics are usually subtracted from the rest mass. For the consistent
treatment of energies as sources of curvature in the Einstein field equations,
this study includes these subtracted self-energies into vacuum energy expressed
by the constant Lambda (used in such as Lambda-CDM). In this study, the
self-energies in electrodynamics and macroscopic classical Einstein field
equations are examined, using the formalisms with the ultraviolet cutoff
scheme. One of the cutoff formalisms is the field theory in terms of the
step-function-type basis functions, developed by the present authors. The other
is a continuum theory of a fundamental particle with the same cutoff length.
Based on the effectiveness of the continuum theory with the cutoff length shown
in the examination, the dominant self-energy is the quadratic term of the Higgs
field at a quantum level (classical self-energies are reduced to logarithmic
forms by quantum corrections). The cutoff length is then determined to
reproduce today's tiny value of Lambda for vacuum energy. Additionally, a field
with nonperiodic vanishing boundary conditions is treated, showing that the
field has no zero-point energy.
",Physics
"  Square arrays of sub-micrometer columnar defects in thin
YBa$_{2}$Cu$_{3}$O$_{7-\delta}$ (YBCO) films with spacings down to 300 nm have
been fabricated by a He ion beam projection technique. Pronounced peaks in the
critical current and corresponding minima in the resistance demonstrate the
commensurate arrangement of flux quanta with the artificial pinning landscape,
despite the strong intrinsic pinning in epitaxial YBCO films. Whereas these
vortex matching signatures are exactly at predicted values in field-cooled
experiments, they are displaced in zero-field cooled, magnetic-field ramped
experiments, conserving the equidistance of the matching peaks and minima.
These observations reveal an unconventional critical state in a cuprate
superconductor with an artificial, periodic pinning array. The long-term
stability of such out-of-equilibrium vortex arrangements paves the way for
electronic applications employing fluxons.
",Physics
"  Fermion localization functions are used to discuss electronic and nucleonic
shell structure effects in the superheavy element oganesson, the heaviest
element discovered to date. Spin-orbit splitting in the $7p$ electronic shell
becomes so large ($\sim$ 10 eV) that Og is expected to show uniform-gas-like
behavior in the valence region with a rather large dipole polarizability
compared to the lighter rare gas elements. The nucleon localization in Og is
also predicted to undergo a transition to the Thomas-Fermi gas behavior in the
valence region. This effect, particularly strong for neutrons, is due to the
high density of single-particle orbitals.
",Physics
"  Nonlinear dynamics of the free surface of an ideal incompressible
non-conducting fluid with high dielectric constant subjected by strong
horizontal electric field is simulated on the base of the method of conformal
transformations. It is demonstrated that interaction of counter-propagating
waves leads to formation of regions with steep wave front at the fluid surface;
angles of the boundary inclination tend to {\pi}/2, and the curvature of
surface extremely increases. A significant concentration of the energy of the
system occurs at these points. From the physical point of view, the appearance
of these singularities corresponds to formation of regions at the fluid surface
where pressure exerted by electric field undergoes a discontinuity and
dynamical pressure increases almost an order of magnitude.
",Physics
"  We developed general approach to the calculation of power-law infrared
asymptotics of spin-spin correlation functions in the Kitaev honeycomb model
with different types of perturbations. We have shown that in order to find
these correlation functions, one can perform averaging of some bilinear forms
composed out of free Majorana fermions, and we presented the method for
explicit calculation of these fermionic densities. We demonstrated how to
derive an effective Hamiltonian for the Majorana fermions, including the
effects of perturbations. For specific application of the general theory, we
have studied the effect of the Dzyaloshinskii-Moriya anisotropic spin-spin
interaction; we demonstrated that it leads, already in the second order over
its relative magnitude $D/K$, to a power-law spin correlation functions, and
calculated dynamical spin structure factor of the system. We have shown that an
external magnetic field $h$ in presence of the DM interaction, opens a gap in
the excitation spectrum of magnitude $\Delta \propto D h$.
",Physics
"  The interplay between superconductivity and charge density waves (CDW) in
$H$-NbSe2 is not fully understood despite decades of study. Artificially
introduced disorder can tip the delicate balance between two competing forms of
long-range order, and reveal the underlying interactions that give rise to
them. Here we introduce disorders by electron irradiation and measure in-plane
resistivity, Hall resistivity, X-ray scattering, and London penetration depth.
With increasing disorder, $T_{\textrm{c}}$ varies nonmonotonically, whereas
$T_{\textrm{CDW}}$ monotonically decreases and becomes unresolvable above a
critical irradiation dose where $T_{\textrm{c}}$ drops sharply. Our results
imply that CDW order initially competes with superconductivity, but eventually
assists it. We argue that at the transition where the long-range CDW order
disappears, the cooperation with superconductivity is dramatically suppressed.
X-ray scattering and Hall resistivity measurements reveal that the short-range
CDW survives above the transition. Superconductivity persists to much higher
dose levels, consistent with fully gapped superconductivity and moderate
interband pairing.
",Physics
"  Multilayer MoS2 possesses highly anisotropic thermal conductivities along
in-plane and cross-plane directions that could hamper heat dissipation in
electronics. With about 9% cross-plane compressive strain created by
hydrostatic pressure in a diamond anvil cell, we observed about 12 times
increase in the cross-plane thermal conductivity of multilayer MoS2. Our
experimental and theoretical studies reveal that this drastic change arises
from the greatly strengthened interlayer interaction and heavily modified
phonon dispersions along cross-plane direction, with negligible contribution
from electronic thermal conductivity, despite its enhancement of 4 orders of
magnitude. The anisotropic thermal conductivity in the multilayer MoS2 at
ambient environment becomes almost isotropic under highly compressive strain,
effectively transitioning from 2D to 3D heat dissipation. This strain tuning
approach also makes possible parallel tuning of structural, thermal and
electrical properties, and can be extended to the whole family of 2D Van der
Waals solids, down to two layer systems.
",Physics
"  The amount of ultraviolet irradiation and ablation experienced by a planet
depends strongly on the temperature of its host star. Of the thousands of
extra-solar planets now known, only four giant planets have been found that
transit hot, A-type stars (temperatures of 7300-10,000K), and none are known to
transit even hotter B-type stars. WASP-33 is an A-type star with a temperature
of ~7430K, which hosts the hottest known transiting planet; the planet is
itself as hot as a red dwarf star of type M. The planet displays a large heat
differential between its day-side and night-side, and is highly inflated,
traits that have been linked to high insolation. However, even at the
temperature of WASP-33b's day-side, its atmosphere likely resembles the
molecule-dominated atmospheres of other planets, and at the level of
ultraviolet irradiation it experiences, its atmosphere is unlikely to be
significantly ablated over the lifetime of its star. Here we report
observations of the bright star HD 195689, which reveal a close-in (orbital
period ~1.48 days) transiting giant planet, KELT-9b. At ~10,170K, the host star
is at the dividing line between stars of type A and B, and we measure the
KELT-9b's day-side temperature to be ~4600K. This is as hot as stars of stellar
type K4. The molecules in K stars are entirely dissociated, and thus the
primary sources of opacity in the day-side atmosphere of KELT-9b are likely
atomic metals. Furthermore, KELT-9b receives ~700 times more extreme
ultraviolet radiation (wavelengths shorter than 91.2 nanometers) than WASP-33b,
leading to a predicted range of mass-loss rates that could leave the planet
largely stripped of its envelope during the main-sequence lifetime of the host
star.
",Physics
"  The spin Peltier effect (SPE), heat-current generation due to spin-current
injection, in various metal (Pt, W, and Au single layers and Pt/Cu
bilayer)/ferrimagnetic insulator (yttrium iron garnet: YIG) junction systems
has been investigated by means of a lock-in thermography (LIT) method. The SPE
is excited by a spin current across the metal/YIG interface, which is generated
by applying a charge current to the metallic layer via the spin Hall effect.
The LIT method enables the thermal imaging of the SPE free from the
Joule-heating contribution. Importantly, we observed spin-current-induced
temperature modulation not only in the Pt/YIG and W/YIG systems but also in the
Au/YIG and Pt/Cu/YIG systems, excluding the possible contamination by anomalous
Ettingshausen effects due to proximity-induced ferromagnetism near the
metal/YIG interface. As demonstrated in our previous study, the SPE signals are
confined only in the vicinity of the metal/YIG interface; we buttress this
conclusion by reducing a spatial blur due to thermal diffusion in an infrared
emission layer on the sample surface used for the LIT measurements. We also
found that the YIG-thickness dependence of the SPE is similar to that of the
spin Seebeck effect measured in the same Pt/YIG sample, implying the reciprocal
relation between them.
",Physics
"  We present a stabilized microwave-frequency transfer technique that is based
on optical phase-sensing and optical phase-actuation. This technique shares
several attributes with optical-frequency transfer and therefore exhibits
several advantages over other microwave-frequency transfer techniques. We
demonstrated stabilized transfer of an 8,000 MHz microwave-frequency signal
over a 166 km metropolitan optical fiber network, achieving a fractional
frequency stability of 6.8x10^-14 Hz/Hz at 1 s integration, and 5.0x10^-16
Hz/Hz at 1.6x10^4 s. This technique is being considered for use on the Square
Kilometre Array SKA1-mid radio telescope.
",Physics
"  We present the first discoveries from a survey of $z\gtrsim6$ quasars using
imaging data from the DECam Legacy Survey (DECaLS) in the optical, the UKIRT
Deep Infrared Sky Survey (UKIDSS) and a preliminary version of the UKIRT
Hemisphere Survey (UHS) in the near-IR, and ALLWISE in the mid-IR. DECaLS will
image 9000 deg$^2$ of sky down to $z_{\rm AB}\sim23.0$, and UKIDSS and UHS,
which will map the northern sky at $0<DEC<+60^{\circ}$, reaching $J_{\rm
VEGA}\sim19.6$ (5-$\sigma$). The combination of these datasets allows us to
discover quasars at redshift $z\gtrsim7$ and to conduct a complete census of
the faint quasar population at $z\gtrsim6$. In this paper, we report on the
selection method of our search, and on the initial discoveries of two new,
faint $z\gtrsim6$ quasars and one new $z=6.63$ quasar in our pilot
spectroscopic observations. The two new $z\sim6$ quasars are at $z=6.07$ and
$z=6.17$ with absolute magnitudes at rest-frame wavelength 1450 \AA\ being
$M_{1450}=-25.83$ and $M_{1450}=-25.76$, respectively. These discoveries
suggest that we can find quasars close to or fainter than the break magnitude
of the Quasar Luminosity Function (QLF) at $z\gtrsim6$. The new $z=6.63$ quasar
has an absolute magnitude of $M_{1450}=-25.95$. This demonstrates the potential
of using the combined DECaLS and UKIDSS/UHS datasets to find $z\gtrsim7$
quasars. Extrapolating from previous QLF measurements, we predict that these
combined datasets will yield $\sim200$ $z\sim6$ quasars to $z_{\rm AB} < 21.5$,
$\sim1{,}000$ $z\sim6$ quasars to $z_{\rm AB}<23$, and $\sim 30$ quasars at
$z>6.5$ to $J_{\rm VEGA}<19.5$.
",Physics
"  The decline of Mars' global magnetic field some 3.8-4.1 billion years ago is
thought to reflect the demise of the dynamo that operated in its liquid core.
The dynamo was probably powered by planetary cooling and so its termination is
intimately tied to the thermochemical evolution and present-day physical state
of the Martian core. Bottom-up growth of a solid inner core, the
crystallization regime for Earth's core, has been found to produce a long-lived
dynamo leading to the suggestion that the Martian core remains entirely liquid
to this day. Motivated by the experimentally-determined increase in the Fe-S
liquidus temperature with decreasing pressure at Martian core conditions, we
investigate whether Mars' core could crystallize from the top down. We focus on
the ""iron snow"" regime, where newly-formed solid consists of pure Fe and is
therefore heavier than the liquid. We derive global energy and entropy
equations that describe the long-timescale thermal and magnetic history of the
core from a general theory for two-phase, two-component liquid mixtures,
assuming that the snow zone is in phase equilibrium and that all solid falls
out of the layer and remelts at each timestep. Formation of snow zones occurs
for a wide range of interior and thermal properties and depends critically on
the initial sulfur concentration, x0. Release of gravitational energy and
latent heat during growth of the snow zone do not generate sufficient entropy
to restart the dynamo unless the snow zone occupies at least 400 km of the
core. Snow zones can be 1.5-2 Gyrs old, though thermal stratification of the
uppermost core, not included in our model, likely delays onset. Models that
match the available magnetic and geodetic constraints have x0~10% and snow
zones that occupy approximately the top 100 km of the present-day Martian core.
",Physics
"  Topological states of matter are at the root of some of the most fascinating
phenomena in condensed matter physics. Here we argue that skyrmions in the
pseudo-spin space related to an emerging SU(2) symmetry enlighten many
mysterious properties of the pseudogap phase in under-doped cuprates. We detail
the role of the SU(2) symmetry in controlling the phase diagram of the
cuprates, in particular how a cascade of phase transitions explains the arising
of the pseudogap, superconducting and charge modulation phases seen at low
temperature. We specify the structure of the charge modulations inside the
vortex core below $T_{c}$, as well as in a wide temperature region above
$T_{c}$, which is a signature of the skyrmion topological structure. We argue
that the underlying SU(2) symmetry is the main structure controlling the
emergent complexity of excitations at the pseudogap scale $T^{*}$. The theory
yields a gapping of a large part of the anti-nodal region of the Brillouin
zone, along with $q=0$ phase transitions, of both nematic and loop currents
characters.
",Physics
"  Chapter 11 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
",Physics
"  Current and upcoming radio interferometric experiments are aiming to make a
statistical characterization of the high-redshift 21cm fluctuation signal
spanning the hydrogen reionization and X-ray heating epochs of the universe.
However, connecting 21cm statistics to underlying physical parameters is
complicated by the theoretical challenge of modeling the relevant physics at
computational speeds quick enough to enable exploration of the high dimensional
and weakly constrained parameter space. In this work, we use machine learning
algorithms to build a fast emulator that mimics expensive simulations of the
21cm signal across a wide parameter space to high precision. We embed our
emulator within a Markov-Chain Monte Carlo framework, enabling it to explore
the posterior distribution over a large number of model parameters, including
those that govern the Epoch of Reionization, the Epoch of X-ray Heating, and
cosmology. As a worked example, we use our emulator to present an updated
parameter constraint forecast for the Hydrogen Epoch of Reionization Array
experiment, showing that its characterization of a fiducial 21cm power spectrum
will considerably narrow the allowed parameter space of reionization and
heating parameters, and could help strengthen Planck's constraints on
$\sigma_8$. We provide both our generalized emulator code and its
implementation specifically for 21cm parameter constraints as publicly
available software.
",Physics
"  Molecular adsorption on surfaces plays an important part in catalysis,
corrosion, desalination, and various other processes that are relevant to
industry and in nature. As a complement to experiments, accurate adsorption
energies can be obtained using various sophisticated electronic structure
methods that can now be applied to periodic systems. The adsorption energy of
water on boron nitride substrates, going from zero to 2-dimensional
periodicity, is particularly interesting as it calls for an accurate treatment
of polarizable electrostatics and dispersion interactions, as well as posing a
practical challenge to experiments and electronic structure methods. Here, we
present reference adsorption energies, static polarizabilities, and dynamic
polarizabilities, for water on BN substrates of varying size and dimension.
Adsorption energies are computed with coupled cluster theory, fixed-node
quantum Monte Carlo (FNQMC), the random phase approximation (RPA), and second
order M{\o}ller-Plesset (MP2) theory. These explicitly correlated methods are
found to agree in molecular as well as periodic systems. The best estimate of
the water/h-BN adsorption energy is $-107\pm7$ meV from FNQMC. In addition, the
water adsorption energy on the BN substrates could be expected to grow
monotonically with the size of the substrate due to increased dispersion
interactions but interestingly, this is not the case here. This peculiar
finding is explained using the static polarizabilities and molecular dispersion
coefficients of the systems, as computed from time-dependent density functional
theory (DFT). Dynamic as well as static polarizabilities are found to be highly
anisotropic in these systems. In addition, the many-body dispersion method in
DFT emerges as a particularly useful estimation of finite size effects for
other expensive, many-body wavefunction based methods.
",Physics
"  Following the advent of electromagnetic metamaterials at the turn of the
century, researchers working in other areas of wave physics have translated
concepts of electromagnetic metamaterials to acoustics, elastodynamics, as well
as to heat, mass and light diffusion processes. In elastodynamics, seismic
metamaterials have emerged in the last decade for soft soils structured at the
meter scale, and have been tested thanks to full-scale experiments on holey
soils five years ago. Born in the soil, seismic metamaterials grow
simultaneously on the field of tuned-resonators buried in the soil, around
building's foundations or near the soil-structure's interface, and on the field
of above-surface resonators. In this perspective article, we quickly recall
some research advances made in all these types of seismic metamaterials and we
further dress an inventory of which material parameters can be achieved and
which cannot, notably from the effective medium theory perspective. We finally
envision perspectives on future developments of large scale auxetic
metamaterials for building's foundations, forests of trees for seismic
protection and metamaterial-like transformed urbanism at the city scale.
",Physics
"  We tabulate spontaneous emission rates for all possible 811
electric-dipole-allowed transitions between the 75 lowest-energy states of Ca
I. These involve the $4sns$ ($n=4-8$), $4snp$ ($n=4-7$), $4snd$ ($n=3-6$),
$4snf$ ($n=4-6$), $4p^2$, and $3d4p$ electronic configurations. We compile the
transition rates by carrying out ab initio relativistic calculations using the
combined method of configuration interaction and many-body perturbation theory.
The results are compared to the available literature values. The tabulated
rates can be useful in various applications, such as optimizing laser cooling
in magneto-optical traps, estimating various systematic effects in optical
clocks and evaluating static or dynamic polarizabilities and long-range
atom-atom interaction coefficients and related atomic properties.
",Physics
"  Motivated by recent experiments on $\alpha$-RuCl$_3$, we investigate a
possible quantum spin liquid ground state of the honeycomb-lattice spin model
with bond-dependent interactions. We consider the $K-\Gamma$ model, where $K$
and $\Gamma$ represent the Kitaev and symmetric-anisotropic interactions
between spin-1/2 moments on the honeycomb lattice. Using the infinite density
matrix renormalization group (iDMRG), we provide compelling evidence for the
existence of quantum spin liquid phases in an extended region of the phase
diagram. In particular, we use transfer matrix spectra to show the evolution of
two-particle excitations with well-defined two-dimensional dispersion, which is
a strong signature of quantum spin liquid. These results are compared with
predictions from Majorana mean-field theory and used to infer the quasiparticle
excitation spectra. Further, we compute the dynamical structure factor using
finite size cluster computations and show that the results resemble the
scattering continuum seen in neutron scattering experiments on
$\alpha$-RuCl$_3$. We discuss these results in light of recent and future
experiments.
",Physics
"  Exchange hole is the principle constituent in density functional theory,
which can be used to accurately design exchange energy functional and range
separated hybrid functionals coupled with some appropriate correlation.
Recently, density matrix expansion (DME) based semi-local exchange hole
proposed by Tao-Mo gained attention due to its fulfillment of some exact
constraints. We propose a new long-range corrected (LC) scheme that combines
meta-generalized gradient approximation (meta-GGA) exchange functionals
designed from DME exchange hole coupled with the ab-initio Hartree-Fock (HF)
exchange integral by separating the Coulomb interaction operator using standard
error function. Associate with Lee-Yang-Parr (LYP) correlation functional,
assessment and benchmarking of our functional using well-known test set shows
that it performs remarkably well for a broad range of molecular properties,
such as thermochemistry, noncovalent interaction and barrier height of chemical
reactions.
",Physics
"  Encouraged by recent studies on the performance of tidal turbine arrays, we
extend the classical momentum actuator disc theory to include the free surface
effects and allow the vertical arrangement of turbines. Most existing
literatures concern one dimensional arrays with single turbine in the vertical
direction, while the arrays in this work are two dimensional (with turbines in
both the vertical and lateral directions) and also partially block the channel
which width is far larger than height. The vertical mixing of array scale flow
is assumed to take place much faster than lateral one. This assumption has been
verified by numerical simulations. Fixing the total turbine area and utilized
width, the comparison between two-dimensional and traditional one-dimensional
arrays is investigated. The results suggest that the two dimensional
arrangements of smaller turbines are preferred to one dimensional arrays from
both the power coefficient and efficiency perspectives. When channel dynamics
are considered, the power increase would be partly offset according to the
parameters of the channel but the optimal arrangement is unchangeable.
Furthermore, we consider how to arrange finite number of turbines in a channel.
It is shown that an optimal distribution of turbines in two directions is
found. Finally, the scenario of arranging turbines in infinite flow, which is
the limiting condition of small blockages, is analysed. A new maximum power
coefficient 0.869 occurs when $Fr=0.2$, greatly increasing the peak power
compared with existing results.
",Physics
"  Droplet evaporation in turbulent sprays involves unsteady, multiscale and
multiphase processes which make its comprehension and model capabilities still
limited. The present work aims to investigate droplet vaporization dynamics
within a turbulent spatial developing jet in dilute, non-reacting conditions.
We address the problem using a Direct Numerical Simulation of jet laden with
acetone droplets using an hybrid Eulerian/Lagrangian approach based on the
point droplet approximation. A detailed statistical analysis of both phases is
presented. In particular, we show how crucial is the preferential sampling of
the vapour phase induced by the inhomogeneous localization of the droplets
through the flow. The preferential segregation of droplets develops suddenly
downstream the inlet both within the turbulent core and in the mixing layer.
Two distinct mechanisms have been found to drive these phenomena, the inertial
small-scale clustering in the jet core and the intermittent dynamics of
droplets across the turbulent/non-turbulent interface in the mixing layer where
dry air entrainment occurs. These phenomenologies strongly affect the overall
vaporization process and lead to a spectacular widening of droplets size and
vaporization rate distributions in the downstream evolution of the turbulent
spray.
",Physics
"  The recent experimental discovery of three-dimensional (3D) materials hosting
a strong Rashba spin-orbit coupling calls for the theoretical investigation of
their transport properties. Here we study the zero temperature dc conductivity
of a 3D Rashba metal in the presence of static diluted impurities. We show
that, at variance with the two-dimensional case, in 3D systems spin-orbit
coupling affects dc charge transport in all density regimes. We find in
particular that the effect of spin-orbit interaction strongly depends on the
direction of the current, and we show that this yields strongly anisotropic
transport characteristics. In the dominant spin-orbit coupling regime where
only the lowest band is occupied, the SO-induced conductivity anisotropy is
governed entirely by the anomalous component of the renormalized current. We
propose that measurements of the conductivity anisotropy in bulk Rashba metals
may give a direct experimental assessment of the spin-orbit strength.
",Physics
"  Magnetosphere at ion kinetic scales, or mini-magnetosphere, possesses unusual
features as predicted by numerical simulations. However, there are practically
no data on the subject from space observations and the data which are available
are far too incomplete. In the present work we describe results of laboratory
experiment on interaction of plasma flow with magnetic dipole with parameters
such that ion inertia length is smaller than a size of observed magnetosphere.
A detailed structure of non-coplanar or out-of-plane component of magnetic
field has been obtained in meridian plane. Independence of this component on
dipole moment reversal, as was reported in previous work, has been verified. In
the tail distinct lobes and central current sheet have been observed. It was
found that lobe regions adjacent to boundary layer are dominated by
non-coplanar component of magnetic field. Tail-ward oriented electric current
in plasma associated with that component appears to be equal to ion current in
the frontal part of magnetosphere and in the tail current sheet implying that
electrons are stationary in those regions while ions flow by. Obtained data
strongly support the proposed model of mini-magnetosphere based on two-fluid
effects as described by the Hall term.
",Physics
"  We report on the first comparison of distant caesium fountain primary
frequency standards (PFSs) via an optical fiber link. The 1415 km long optical
link connects two PFSs at LNE-SYRTE (Laboratoire National de métrologie et
d'Essais - SYstème de Références Temps-Espace) in Paris (France)
with two at PTB (Physikalisch-Technische Bundesanstalt) in Braunschweig
(Germany). For a long time, these PFSs have been major contributors to accuracy
of the International Atomic Time (TAI), with stated accuracies of around
$3\times 10^{-16}$. They have also been the references for a number of absolute
measurements of clock transition frequencies in various optical frequency
standards in view of a future redefinition of the second. The phase coherent
optical frequency transfer via a stabilized telecom fiber link enables far
better resolution than any other means of frequency transfer based on satellite
links. The agreement for each pair of distant fountains compared is well within
the combined uncertainty of a few 10$^{-16}$ for all the comparisons, which
fully supports the stated PFSs' uncertainties. The comparison also includes a
rubidium fountain frequency standard participating in the steering of TAI and
enables a new absolute determination of the $^{87}$Rb ground state hyperfine
transition frequency with an uncertainty of $3.1\times 10^{-16}$.
This paper is dedicated to the memory of André Clairon, who passed away
on the 24$^{th}$ of December 2015, for his pioneering and long-lasting efforts
in atomic fountains. He also pioneered optical links from as early as 1997.
",Physics
"  Amyloid beta peptides (A\b{eta}), implicated in Alzheimers disease (AD),
interact with the cellular membrane and induce amyloid toxicity. The
composition of cellular membranes changes in aging and AD. We designed multi
component lipid models to mimic healthy and diseased states of the neuronal
membrane. Using atomic force microscopy (AFM), Kelvin probe force microscopy
(KPFM) and black lipid membrane (BLM) techniques, we demonstrated that these
model membranes differ in their nanoscale structure and physical properties,
and interact differently with A\b{eta}. Based on our data, we propose a new
hypothesis that changes in lipid membrane due to aging and AD may trigger
amyloid toxicity through electrostatic mechanisms, similar to the accepted
mechanism of antimicrobial peptide action. Understanding the role of the
membrane changes as a key activating amyloid toxicity may aid in the
development of a new avenue for the prevention and treatment of AD.
",Physics
"  Tangles of quantized vortex line of initial density ${\cal L}(0) \sim 6\times
10^3$\,cm$^{-2}$ and variable amplitude of fluctuations of flow velocity $U(0)$
at the largest length scale were generated in superfluid $^4$He at $T=0.17$\,K,
and their free decay ${\cal L}(t)$ was measured. If $U(0)$ is small, the excess
random component of vortex line length firstly decays as ${\cal L} \propto
t^{-1}$ until it becomes comparable with the structured component responsible
for the classical velocity field, and the decay changes to ${\cal L} \propto
t^{-3/2}$. The latter regime always ultimately prevails, provided the classical
description of $U$ holds. A quantitative model of coexisting cascades of
quantum and classical energies describes all regimes of the decay.
",Physics
"  The interplay between electrochemical surface charges and bulk
ferroelectricity in thin films gives rise to a continuum of coupled ferro-ionic
states. These states are exquisitely sensitive to chemical and electric
conditions at the surfaces, applied voltage, and oxygen pressure. Using the
analytical approach combining the Ginzburg-Landau-Devonshire description of the
ferroelectricity with Langmuir adsorption isotherm for the ions at the film
surface, we have studied the temperature-, time- and field- dependent
polarization changes and electromechanical response of the ferro-ionic states.
The responses are found to be inseparable in thermodynamic equilibrium and at
low frequencies of applied voltage. The states become separable in high
frequency dynamic mode due to the several orders of magnitude difference in the
relaxation times of ferroelectric polarization and surface ions charge density.
These studies provide an insight into dynamic behavior of nanoscale
ferroelectrics with open surface exposed to different kinds of
electrochemically active gaseous surrounding.
",Physics
"  We study the electron and phonon thermalization in simple metals excited by a
laser pulse. The thermalization is investigated numerically by solving the
Boltzmann transport equation taking into account all the relevant scattering
mechanism: the electron-electron, electron-phonon (e-ph), phonon-electron
(ph-e), and phonon-phonon (ph-ph) scatterings. In the initial stage of the
relaxation, most of the excitation energy is transferred from the electrons to
phonons through the e-ph scattering. This creates hot high-frequency phonons
due to the ph-e scatterings, followed by an energy redistribution between
phonon subsystems through the ph-ph scatterings. This yields an overshoot of
the total longitudinal-acoustic phonon energy at a time, across which a
crossover occurs from a nonequilibrium state, where the e-ph and ph-e
scatterings frequently occur, to a state, where the ph-ph scattering occurs to
reach a thermal equilibrium. This picture is quite different from the scenario
of the well-known two-temperature model (2TM). The behavior of the relaxation
dynamics is compared with those calculated by several models, including the
2TM, the four-temperature model, and nonequilibrium electron or phonon models.
The relationship between the relaxation time and the initial distribution
function is also discussed.
",Physics
"  In this paper, we design, fabricate and experimentally characterize a
broadband acoustic right-angle bend device in air. Perforated panels with
various hole-sizes are used to construct the bend structure. Both the simulated
and the experimental results verify that acoustic beam can be rotated
effectively through the acoustic bend in a wide frequency range. This model may
have potential applications in some areas such as sound absorption and acoustic
detection in pipeline.
",Physics
"  The study of single-crystal Raman spectra of a series of crystalline
secondary amides (acetanilide, methacetin, phenacetine, orthorhombic and
monoclinic polymorphs of paracetamol) as well as simple amides formanilide and
benzanilide in the temperature range 5-300 K was carried out. The series of
compounds with the same molecular fragment, i.e. acetamide group, can serve as
a model system to study the interrelation between the latter and the properties
of the intermolecular ""peptide-type"" NH...O=C hydrogen bonds. For all the
""acetamide family"" of compounds, similar changes in the Raman spectra were
observed on cooling the samples: an appearance of new Amide I(-) and Amide I(+)
bands that are red and blue shifted respectively from the conventional Amide I
band by around of 5-10 inverse centimeters. An appropriated changes in the same
temperature range were observed for the N-H out-of-plane bending (Amide V) and
N-H stretching vibrations of the N-H...O=C hydrogen bond. All the spectral
changes on cooling the samples can be supposed to result from delocalization of
the Amide I and N-H modes and appearance of dynamical splitting at low
temperature.
",Physics
"  The optical properties of a multilayer system of dielectric media with
arbitrary $N$ layers is investigated. Each layer is one of two dielectric
media, with thickness one-quarter the wavelength of light in that medium,
corresponding to a central frequency. Using the transfer matrix method, the
transmittance $T$ is calculated for all possible $2^N$ sequences for small $N$.
Unexpectedly, it is found that instead of $2^N$ different values of $T$ at the
central frequency ($T_0$), there are either $(N/2+1)$ or $(N+1)$ discrete
values of $T_0$ for even or odd $N$, respectively. We explain the high
degeneracy in the $T_0$ values by defining new symmetry operations that do not
change $T_0$. Analytical formulae were derived for the $T_0$ values and their
degeneracy as functions of $N$ and an integer parameter for each sequence we
call ""charge"". Additionally, the bandwidth of the transmission spectra at $f_0$
is investigated, revealing some asymptotic behavior at large $N$.
",Physics
"  Plasma turbulence at scales of the order of the ion inertial length is
mediated by several mechanisms, including linear wave damping, magnetic
reconnection, formation and dissipation of thin current sheets, stochastic
heating. It is now understood that the presence of localized coherent
structures enhances the dissipation channels and the kinetic features of the
plasma. However, no formal way of quantifying the relationship between
scale-to-scale energy transfer and the presence of spatial structures has so
far been presented. In this letter we quantify such relationship analyzing the
results of a two-dimensional high-resolution Hall-MHD simulation. In
particular, we employ the technique of space-filtering to derive a spectral
energy flux term which defines, in any point of the computational domain, the
signed flux of spectral energy across a given wavenumber. The characterization
of coherent structures is performed by means of a traditional two-dimensional
wavelet transformation. By studying the correlation between the spectral energy
flux and the wavelet amplitude, we demonstrate the strong relationship between
scale-to-scale transfer and coherent structures. Furthermore, by conditioning
one quantity with respect to the other, we are able for the first time to
quantify the inhomogeneity of the turbulence cascade induced by topological
structures in the magnetic field. Taking into account the low filling-factor of
coherent structures (i.e. they cover a small portion of space), it emerges that
80% of the spectral energy transfer (both in the direct and inverse cascade
directions) is localized in about 50% of space, and 50% of the energy transfer
is localized in only 25% of space.
",Physics
"  (Abridged) Low-luminosity, gas-rich blue compact galaxies (BCG) are ideal
laboratories to investigate many aspects of the star formation in galaxies. We
study the morphology, stellar content, kinematics, and the nebular excitation
and ionization mechanism in the BCG Haro 14 by means of integral field
observations with VIMOS in the VLT. From these data we build maps in continuum
and in the brighter emission lines, produce line-ratio maps, and obtain the
velocity and velocity dispersion fields. We also generate the integrated
spectrum of the major HII regions and young stellar clusters identified in the
maps to determine reliable physical parameters and oxygen abundances. We find
as follows: i) the current star formation in Haro 14 is spatially extended with
the major HII regions placed along a linear structure, elongated in the
north-south direction, and in a horseshoe-like curvilinear feature that extends
about 760 pc eastward; the continuum emission is more concentrated and peaks
close to the galaxy center; ii) two different episodes of star formation are
present: the recent starburst, with ages $\leq$ 6 Myrs and the intermediate-age
clusters, with ages between 10 and 30 Myrs; these stellar components rest on a
several Gyr old underlying host galaxy; iii) the H$\alpha$/H$\beta$ pattern is
inhomogeneous, with excess color values varying from E(B-V)=0.04 up to
E(B-V)=1.09; iv) shocks play a significant role in the galaxy; and v) the
velocity field displays a complicated pattern with regions of material moving
toward us in the east and north galaxy areas. The morphology of Haro 14, its
irregular velocity field, and the presence of shocks speak in favor of a
scenario of triggered star formation. Ages of the knots are consistent with the
ongoing burst being triggered by the collective action of stellar winds and
supernovae originated in the central clusters.
",Physics
"  We study the dynamics of overdamped Brownian particles diffusing in
conservative force fields and undergoing stochastic resetting to a given
location with a generic space-dependent rate of resetting. We present a
systematic approach involving path integrals and elements of renewal theory
that allows to derive analytical expressions for a variety of statistics of the
dynamics such as (i) the propagator prior to first reset; (ii) the distribution
of the first-reset time, and (iii) the spatial distribution of the particle at
long times. We apply our approach to several representative and hitherto
unexplored examples of resetting dynamics. A particularly interesting example
for which we find analytical expressions for the statistics of resetting is
that of a Brownian particle trapped in a harmonic potential with a rate of
resetting that depends on the instantaneous energy of the particle. We find
that using energy-dependent resetting processes is more effective in achieving
spatial confinement of Brownian particles on a faster timescale than by
performing quenches of parameters of the harmonic potential.
",Physics
"  (This is a general physics level overview article about hidden sectors, and
how they motivate searches for long-lived particles. Intended for publication
in Physics Today.)
Searches for new physics at the Large Hadron Collider have so far come up
empty, but we just might not be looking in the right place. Spectacular bursts
of particles appearing seemingly out of nowhere could shed light on some of
nature's most profound mysteries.
",Physics
"  A systematic experimental study of Gilbert damping is performed via
ferromagnetic resonance for the disordered crystalline binary 3d transition
metal alloys Ni-Co, Ni-Fe and Co-Fe over the full range of alloy compositions.
After accounting for inhomogeneous linewidth broadening, the damping shows
clear evidence of both interfacial damping enhancement (by spin pumping) and
radiative damping. We quantify these two extrinsic contributions and thereby
determine the intrinsic damping. The comparison of the intrinsic damping to
multiple theoretical calculations yields good qualitative and quantitative
agreement in most cases. Furthermore, the values of the damping obtained in
this study are in good agreement with a wide range of published experimental
and theoretical values. Additionally, we find a compositional dependence of the
spin mixing conductance.
",Physics
"  We further progress along the line of Ref. [Phys. Rev. {\bf A 94}, 043614
(2016)] where a functional for Fermi systems with anomalously large $s$-wave
scattering length $a_s$ was proposed that has no free parameters. The
functional is designed to correctly reproduce the unitary limit in Fermi gases
together with the leading-order contributions in the s- and p-wave channels at
low density. The functional is shown to be predictive up to densities
$\sim0.01$ fm$^{-3}$ that is much higher densities compared to the Lee-Yang
functional, valid for $\rho < 10^{-6}$ fm$^{-3}$. The form of the functional
retained in this work is further motivated. It is shown that the new functional
corresponds to an expansion of the energy in $(a_s k_F)$ and $(r_e k_F)$ to all
orders, where $r_e$ is the effective range and $k_F$ is the Fermi momentum. One
conclusion from the present work is that, except in the extremely low--density
regime, nuclear systems can be treated perturbatively in $-(a_s k_F)^{-1}$ with
respect to the unitary limit. Starting from the functional, we introduce
density--dependent scales and show that scales associated to the bare
interaction are strongly renormalized by medium effects. As a consequence, some
of the scales at play around saturation are dominated by the unitary gas
properties and not directly to low-energy constants. For instance, we show that
the scale in the s-wave channel around saturation is proportional to the
so-called Bertsch parameter $\xi_0$ and becomes independent of $a_s$. We also
point out that these scales are of the same order of magnitude than those
empirically obtained in the Skyrme energy density functional. We finally
propose a slight modification of the functional such that it becomes accurate
up to the saturation density $\rho\simeq 0.16$ fm$^{-3}$.
",Physics
"  The system of dynamic equations for Bose-Einstein condensate at zero
temperature with account of pair correlations is obtained. The spectrum of
small oscillations of the condensate in a spatially homogeneous state is
explored. It is shown that this spectrum has two branches: the sound wave
branch and branch with an energy gap.
",Physics
"  Anisotropic displacement parameters (ADPs) are commonly used in
crystallography, chemistry and related fields to describe and quantify thermal
motion of atoms. Within the very recent years, these ADPs have become
predictable by lattice dynamics in combination with first-principles theory.
Here, we study four very different molecular crystals, namely urea,
bromomalonic aldehyde, pentachloropyridine, and naphthalene, by
first-principles theory to assess the quality of ADPs calculated in the
quasi-harmonic approximation. In addition, we predict both thermal expansion
and thermal motion within the quasi-harmonic approximation and compare the
predictions with experimental data. Very reliable ADPs are calculated within
the quasi-harmonic approximation for all four cases up to at least 200 K, and
they turn out to be in better agreement with experiment than the harmonic ones.
In one particular case, ADPs can even reliably be predicted up to room
temperature. Our results also hint at the importance of normal-mode
anharmonicity in the calculation of ADPs.
",Physics
"  In this work, we derive a new kind of rainbow functions, which has
generalized uncertainty principle parameter. Then, we investigate modified
thermodynamic quantities and phase transition of rainbow Schwarzschild black
hole by employing this new kind of rainbow functions. Our results demonstrate
that the effect of rainbow gravity and generalized uncertainty principle have a
great effect on the picture of Hawking radiation. It prevents black holes from
total evaporation and causes the remnant. In addition, after analyzing the the
modified local thermodynamic quantities, we find that effect of rainbow gravity
and generalized uncertainty principle lead to one first-order phase transition,
two second-order phase transitions, and two Hawking-Page-type phase transitions
in the thermodynamic system of rainbow Schwarzschild black hole.
",Physics
"  The influence of the B-site ion substitutions in
(1-x)(Bi1/2Na1/2)TiO3-xBaTiO3 system of solid solutions on the relative
stability of the ferroelectric and antiferroelectric phases has been studied.
The ions of zirconium, tin, along with (In0.5Nb0.5), (Fe0.5Nb0.5), (Al0.5V0.5)
ion complexes have been used as substituting elements. An increase in the
concentration of the substituting ion results in a near linear variation in the
size of the crystal lattice cell. Along with the cell size variation a change
in the relative stability of the ferroelectric and antiferroelectric phases
takes place according to the changes of the tolerance factor of the solid
solution. An increase in the tolerance factor leads to the increase in the
temperature of the ferroelectric-antiferroelectric phase transition, and vice
versa. All obtained results demonstrate the predominant influence of the ion
size factor on the relative stability of the ferroelectric and
antiferroelectric states in the (Na0.5Bi0.5)TiO3-based solid solutions and
indicate the way for raising the temperature of the
ferroelectric-antiferroelectric phase transition.
",Physics
"  This paper is a continuation of our recent paper devoted to refining the
parameters of three component (bulge, disk, halo) axisymmetric model Galactic
gravitational potentials differing by the expression for the dark matter halo
using the velocities of distant objects. In all models the bulge and disk
potentials are described by the Miyamoto-Nagai expressions. In our previous
paper we used the Allen-Santill'an (I), Wilkinson--Evans (II), and
Navarro-Frenk-White (III) models to describe the halo. In this paper we use a
spherical logarithmic Binney potential (model IV), a Plummer sphere (model V),
and a Hernquist potential (model VI) to describe the halo. A set of present-day
observational data in the range of Galactocentric distances R from 0 to 200 kpc
is used to refine the parameters of the listed models, which are employed most
commonly at present. The model rotation curves are fitted to the observed
velocities by taking into account the constraints on the local matter density
and the vertical force . Model VI looks best among the three models considered
here from the viewpoint of the achieved accuracy of fitting the model rotation
curves to the measurements. This model is close to the Navarro-Frenk-White
model III refined and considered best in our previous paper, which is shown
using the integration of the orbits of two globular clusters, Lynga 7 and NGC
5053, as an example.
",Physics
"  We investigate the role of transition metal atoms of group V-b (V, Nb, and
Ta) and VI-b (Cr, Mo, and W) as n- or p-type dopants in anatase TiO2 using
thermodynamic principles and density functional theory with the
Heyd-Scuseria-Ernzerhof HSE06 hybrid functional. The HSE06 functional provides
a realistic value for the band gap, which ensures a correct classification of
dopants as shallow or deep donors or acceptors. Defect formation energies and
thermodynamic transition levels are calculated taking into account the
constraints imposed by the stability of TiO2 and the solubility limit of the
impurities. Nb, Ta, W and Mo are identified as shallow donors. Although W
provides two electrons, Nb and Ta show a considerably lower formation energy,
in particular under O-poor conditions. Mo donates in principle one electron,
but under specific conditions can turn into a double donor. V impurities are
deep donors and Cr shows up as an amphoteric defect, thereby acting as an
electron trapping center in n-type TiO2 especially under O-rich conditions. A
comparison with the available experimental data yields excellent agreement.
",Physics
"  We present recent improvements in the simulation of regolith sampling
processes in microgravity using the numerical particle method smooth particle
hydrodynamics (SPH). We use an elastic-plastic soil constitutive model for
large deformation and failure flows for dynamical behaviour of regolith. In the
context of projected small body (asteroid or small moons) sample return
missions, we investigate the efficiency and feasibility of a particular
material sampling method: Brushes sweep material from the asteroid's surface
into a collecting tray. We analyze the influence of different material
parameters of regolith such as cohesion and angle of internal friction on the
sampling rate. Furthermore, we study the sampling process in two environments
by varying the surface gravity (Earth's and Phobos') and we apply different
rotation rates for the brushes. We find good agreement of our sampling
simulations on Earth with experiments and provide estimations for the influence
of the material properties on the collecting rate.
",Physics
"  In this work, we study the spin Hall effect and Rashba-Edelstein effect of a
2D Weyl fermion system in the clean limit using the Kubo formalism. Spin
transport is solely due to the spin-torque current in this strongly spin-orbit
coupled (SOC) system, and chiral spin-flip scattering off non-SOC scalar
impurities, with potential strength $V$ and size $a$, gives rise to a
skew-scattering mechanism for the spin Hall effect. The key result is that the
resultant spin-Hall angle has a fixed sign, with $\theta^{SH} \sim O
\left(\tfrac{V^2}{v_F^2/a^2} (k_F a)^4 \right)$ being a strongly-dependent
function of $k_F a$, with $k_F$ and $v_F$ being the Fermi wave-vector and Fermi
velocity respectively. This, therefore, allows for the possibility of tuning
the SHE by adjusting the Fermi energy or impurity size.
",Physics
"  We describe a method of reconstructing air showers induced by cosmic rays
using deep learning techniques. We simulate an observatory consisting of
ground-based particle detectors with fixed locations on a regular grid. The
detector's responses to traversing shower particles are signal amplitudes as a
function of time, which provide information on transverse and longitudinal
shower properties. In order to take advantage of convolutional network
techniques specialized in local pattern recognition, we convert all information
to the image-like grid of the detectors. In this way, multiple features, such
as arrival times of the first particles and optimized characterizations of time
traces, are processed by the network. The reconstruction quality of the cosmic
ray arrival direction turns out to be competitive with an analytic
reconstruction algorithm. The reconstructed shower direction, energy and shower
depth show the expected improvement in resolution for higher cosmic ray energy.
",Physics
"  We start with the recently conjectured 3d bosonization dualities and gauge
global symmetries to generate an infinite sequence of new dualities. These
equate theories with non-Abelian product gauge groups and bifundamental matter.
We uncover examples of Bose/Bose and Fermi/Fermi dualities, as well as a
sequence of dualities between theories with scalar matter in two-index
representations. Our conjectures are consistent with level/rank duality in
massive phases.
",Physics
"  Gradient reconstruction is a key process for the spatial accuracy and
robustness of finite volume method, especially in industrial aerodynamic
applications in which grid quality affects reconstruction methods
significantly. A novel gradient reconstruction method for cell-centered finite
volume scheme is introduced. This method is composed of two successive steps.
First, a vertex-based weighted-least-squares procedure is implemented to
calculate vertex gradients, and then the cell-centered gradients are calculated
by an arithmetic averaging procedure. By using these two procedures, extended
stencils are implemented in the calculations, and the accuracy of gradient
reconstruction is improved by the weighting procedure. In the given test cases,
the proposed method is showing improvement on both the accuracy and
convergence. Furthermore, the method could be extended to the calculation of
viscous fluxes.
",Physics
"  It is known that gas bubbles on the surface bounding a fluid flow can change
the coefficient of friction and affect the parameters of the boundary layer. In
this paper, we propose a method that allows us to create, in the near-wall
region, a thin layer of liquid filled with bubbles. It will be shown that if
there is an oscillating piezoelectric plate on the surface bounding a liquid,
then, under certain conditions, cavitation develops in the boundary layer. The
relationship between the parameters of cavitation and the characteristics of
the piezoelectric plate oscillations is obtained. Possible applications are
discussed.
",Physics
"  The $n$-fold Darboux transformation $T_{n}$ of the focusing real mo\-di\-fied
Kor\-te\-weg-de Vries (mKdV) equation is expressed in terms of the determinant
representation. Using this representation, the $n$-soliton solutions of the
mKdV equation are also expressed by determinants whose elements consist of the
eigenvalues $\lambda_{j}$ and the corresponding eigenfunctions of the
associated Lax equation. The nonsingular $n$-positon solutions of the focusing
mKdV equation are obtained in the special limit
$\lambda_{j}\rightarrow\lambda_{1}$, from the corresponding $n$-soliton
solutions and by using the associated higher-order Taylor expansion.
Furthermore, the decomposition method of the $n$-positon solution into $n$
single-soliton solutions, the trajectories, and the corresponding ""phase
shifts"" of the multi-positons are also investigated.
",Physics
"  In this contribution, we summarize the progress made in the investigation of
binary candidates with an RR Lyrae component in 2016. We also discuss the
actual status of the RRLyrBinCan database.
",Physics
"  The radial drift problem constitutes one of the most fundamental problems in
planet formation theory, as it predicts particles to drift into the star before
they are able to grow to planetesimal size. Dust-trapping vortices have been
proposed as a possible solution to this problem, as they might be able to trap
particles over millions of years, allowing them to grow beyond the radial drift
barrier. Here, we present ALMA 0.04""-resolution imaging of the pre-transitional
disk of V1247 Orionis that reveals an asymmetric ring as well as a
sharply-confined crescent structure, resembling morphologies seen in
theoretical models of vortex formation. The asymmetric ring (at 0.17""=54 au
separation from the star) and the crescent (at 0.38""=120 au) seem smoothly
connected through a one-armed spiral arm structure that has been found
previously in scattered light. We propose a physical scenario with a planet
orbiting at $\sim0.3$""$\approx$100 au, where the one-armed spiral arm detected
in polarised light traces the accretion stream feeding the protoplanet. The
dynamical influence of the planet clears the gap between the ring and the
crescent and triggers two vortices that trap mm-sized particles, namely the
crescent and the bright asymmetry seen in the ring. We conducted dedicated
hydrodynamics simulations of a disk with an embedded planet, which results in
similar spiral-arm morphologies as seen in our scattered light images. At the
position of the spiral wake and the crescent we also observe $^{12}$CO (3-2)
and H$^{12}$CO$^{+}$ (4-3) excess line emission, likely tracing the increased
scale-height in these disk regions.
",Physics
"  We examine dense self-gravitating stellar systems dominated by a central
potential, such as nuclear star clusters hosting a central supermassive black
hole. Different dynamical properties of these systems evolve on vastly
different timescales. In particular, the orbital-plane orientations are
typically driven into internal thermodynamic equilibrium by vector resonant
relaxation before the orbital eccentricities or semimajor axes relax. We show
that the statistical mechanics of such systems exhibit a striking resemblance
to liquid crystals, with analogous ordered-nematic and disordered-isotropic
phases. The ordered phase consists of bodies orbiting in a disk in both
directions, with the disk thickness depending on temperature, while the
disordered phase corresponds to a nearly isotropic distribution of the orbit
normals. We show that below a critical value of the total angular momentum, the
system undergoes a first-order phase transition between the ordered and
disordered phases. At the critical point the phase transition becomes
second-order while for higher angular momenta there is a smooth crossover. We
also find metastable equilibria containing two identical disks with mutual
inclinations between $90^{\circ}$ and $180^\circ$.
",Physics
"  A stress is applied at the flat face and the apex of a prismatic
piezoelectric crystal. The voltage generated at these points differs in order
of magnitude. The result may be used to nondestructively test the uniformity of
surfaces of piezoelectric crystals.
",Physics
"  This paper extends the method introduced in Rivi et al. (2016b) to measure
galaxy ellipticities in the visibility domain for radio weak lensing surveys.
In that paper we focused on the development and testing of the method for the
simple case of individual galaxies located at the phase centre, and proposed to
extend it to the realistic case of many sources in the field of view by
isolating visibilities of each source with a faceting technique. In this second
paper we present a detailed algorithm for source extraction in the visibility
domain and show its effectiveness as a function of the source number density by
running simulations of SKA1-MID observations in the band 950-1150 MHz and
comparing original and measured values of galaxies' ellipticities. Shear
measurements from a realistic population of 10^4 galaxies randomly located in a
field of view of 1 deg^2 (i.e. the source density expected for the current
radio weak lensing survey proposal with SKA1) are also performed. At SNR >= 10,
the multiplicative bias is only a factor 1.5 worse than what found when
analysing individual sources, and is still comparable to the bias values
reported for similar measurement methods at optical wavelengths. The additive
bias is unchanged from the case of individual sources, but is significantly
larger than typically found in optical surveys. This bias depends on the shape
of the uv coverage and we suggest that a uv-plane weighting scheme to produce a
more isotropic shape could reduce and control additive bias.
",Physics
"  How the information microscopically processed by individual neurons is
integrated and used in organising the macroscopic behaviour of an animal is a
central question in neuroscience. Coherence of dynamics over different scales
has been suggested as a clue to the mechanisms underlying this integration.
Balanced excitation and inhibition amplify microscopic fluctuations to a
macroscopic level and may provide a mechanism for generating coherent dynamics
over the two scales. Previous theories of brain dynamics, however, have been
restricted to cases in which population-averaged activities have been
constrained to constant values, that is, to cases with no macroscopic degrees
of freedom. In the present study, we investigate balanced neuronal networks
with a nonzero number of macroscopic degrees of freedom coupled to microscopic
degrees of freedom. In these networks, amplified microscopic fluctuations drive
the macroscopic dynamics, while the macroscopic dynamics determine the
statistics of the microscopic fluctuations. We develop a novel type of
mean-field theory applicable to this class of interscale interactions, for
which an analytical approach has previously been unknown. Irregular macroscopic
rhythms similar to those observed in the brain emerge spontaneously as a result
of such interactions. Microscopic inputs to a small number of neurons
effectively entrain the whole network through the amplification mechanism.
Neuronal responses become coherent as the magnitude of either the balanced
excitation and inhibition or the external inputs is increased. Our mean-field
theory successfully predicts the behaviour of the model. Our numerical results
further suggest that the coherent dynamics can be used for selective read-out
of information. In conclusion, our results show a novel form of neuronal
information processing that bridges different scales, and advance our
understanding of the brain.
",Physics
"  Rechargeable redox flow batteries with serpentine flow field designs have
been demonstrated to deliver higher current density and power density in medium
and large-scale stationary energy storage applications. Nevertheless, the
fundamental mechanisms involved with improved current density in flow batteries
with flow field designs have not been understood. Here we report a maximum
current density concept associated with stoichiometric availability of
electrolyte reactant flow penetration through the porous electrode that can be
achieved in a flow battery system with a ""zero-gap""serpentine flow field
architecture. This concept can explain a higher current density achieved within
allowing reactions of all species soluble in the electrolyte. Further
validations with experimental data are confirmed by an example of a vanadium
flow battery with a serpentine flow structure over carbon paper electrode.
",Physics
"  Infectious disease outbreaks recapitulate biology: they emerge from the
multi-level interaction of hosts, pathogens, and their shared environment. As a
result, predicting when, where, and how far diseases will spread requires a
complex systems approach to modeling. Recent studies have demonstrated that
predicting different components of outbreaks--e.g., the expected number of
cases, pace and tempo of cases needing treatment, demand for prophylactic
equipment, importation probability etc.--is feasible. Therefore, advancing both
the science and practice of disease forecasting now requires testing for the
presence of fundamental limits to outbreak prediction. To investigate the
question of outbreak prediction, we study the information theoretic limits to
forecasting across a broad set of infectious diseases using permutation entropy
as a model independent measure of predictability. Studying the predictability
of a diverse collection of historical outbreaks--including, chlamydia, dengue,
gonorrhea, hepatitis A, influenza, measles, mumps, polio, and whooping
cough--we identify a fundamental entropy barrier for infectious disease time
series forecasting. However, we find that for most diseases this barrier to
prediction is often well beyond the time scale of single outbreaks. We also
find that the forecast horizon varies by disease and demonstrate that both
shifting model structures and social network heterogeneity are the most likely
mechanisms for the observed differences across contagions. Our results
highlight the importance of moving beyond time series forecasting, by embracing
dynamic modeling approaches, and suggest challenges for performing model
selection across long time series. We further anticipate that our findings will
contribute to the rapidly growing field of epidemiological forecasting and may
relate more broadly to the predictability of complex adaptive systems.
",Physics
"  A new method to improve the accuracy and efficiency of characteristic mode
(CM) decomposition for perfectly conducting bodies is presented. The method
uses the expansion of the Green dyadic in spherical vector waves. This
expansion is utilized in the method of moments (MoM) solution of the electric
field integral equation to factorize the real part of the impedance matrix. The
factorization is then employed in the computation of CMs, which improves the
accuracy as well as the computational speed. An additional benefit is a rapid
computation of far fields. The method can easily be integrated into existing
MoM solvers. Several structures are investigated illustrating the improved
accuracy and performance of the new method.
",Physics
"  Monte Carlo simulations using MCNP6.1 were performed to study the effect of
neutron activation in Ar/CO$_{2}$ neutron detector counting gas. A general MCNP
model was built and validated with simple analytical calculations. Simulations
and calculations agree that only the $^{40}$Ar activation can have a
considerable effect. It was shown that neither the prompt gamma intensity from
the $^{40}$Ar neutron capture nor the produced $^{41}$Ar activity have an
impact in terms of gamma dose rate around the detector and background level.
",Physics
"  A laser heterodyne polarimeter (LHP) designed for the measurement of the
birefringence of dielectric super-mirrors is described and initial results are
reported. The LHP does not require an optical resonator and so promises
unprecedented accuracy in the measurement of the birefringence of individual
mirrors. The working principle of the LHP can be applied to the measurement of
vacuum birefringence and potentially ALPS (Any Light Particle Search).
",Physics
"  The ground-state magnetic response of fullerene molecules with up to 36
vertices is calculated, when spins classical or with magnitude $s=\frac{1}{2}$
are located on their vertices and interact according to the nearest-neighbor
antiferromagnetic Heisenberg model. The frustrated topology, which originates
in the pentagons of the fullerenes and is enhanced by their close proximity,
leads to a significant number of classical magnetization and susceptibility
discontinuities, something not expected for a model lacking magnetic
anisotropy. This establishes the classical discontinuities as a generic feature
of fullerene molecules irrespective of their symmetry. The largest number of
discontinuities have the molecule with 26 sites, four of the magnetization and
two of the susceptibility, and an isomer with 34 sites, which has three each.
In addition, for several of the fullerenes the classical zero-field lowest
energy configuration has finite magnetization, which is unexpected for
antiferromagnetic interactions between an even number of spins and with each
spin having the same number of nearest-neighbors. The molecules come in
different symmetries and topologies and there are only a few patterns of
magnetic behavior that can be detected from such a small sample of relatively
small fullerenes. Contrary to the classical case, in the full quantum limit
$s=\frac{1}{2}$ there are no discontinuities for a subset of the molecules that
was considered. This leaves the icosahedral symmetry fullerenes as the only
ones known supporting ground-state magnetization discontinuities for
$s=\frac{1}{2}$. It is also found that a molecule with 34 sites has a
doubly-degenerate ground state when $s=\frac{1}{2}$.
",Physics
"  Recent theoretical predictions of ""unprecedented proximity"" of the electronic
ground state of iridium fluorides to the SU(2) symmetric $j_{\mathrm{eff}}=1/2$
limit, relevant for superconductivity in iridates, motivated us to investigate
their crystal and electronic structure. To this aim, we performed
high-resolution x-ray powder diffraction, Ir L$_3$-edge resonant inelastic
x-ray scattering, and quantum chemical calculations on Rb$_2$[IrF$_6$] and
other iridium fluorides. Our results are consistent with the Mott insulating
scenario predicted by Birol and Haule [Phys. Rev. Lett. 114, 096403 (2015)],
but we observe a sizable deviation of the $j_{\mathrm{eff}}=1/2$ state from the
SU(2) symmetric limit. Interactions beyond the first coordination shell of
iridium are negligible, hence the iridium fluorides do not show any magnetic
ordering down to at least 20 K. A larger spin-orbit coupling in iridium
fluorides compared to oxides is ascribed to a reduction of the degree of
covalency, with consequences on the possibility to realize spin-orbit-induced
strongly correlated physics in iridium fluorides.
",Physics
"  We report measurements of the $^{115}$In $7p_{1/2}$ and $7p_{3/2}$ scalar and
tensor polarizabilities using two-step diode laser spectroscopy in an atomic
beam. The scalar polarizabilities are one to two orders of magnitude larger
than for lower lying indium states due to the close proximity of the $7p$ and
$6d$ states. For the scalar polarizabilities, we find values (in atomic units)
of $1.811(4) \times 10^5$ $a_0^3$ and $2.876(6) \times 10^5$ $a_0^3$ for the
$7p_{1/2}$ and $7p_{3/2}$ states respectively. We estimate the smaller tensor
polarizability component of the $7p_{3/2}$ state to be $-1.43(18) \times 10^4$
$a_0^3$. These measurements represent the first high-precision benchmarks of
transition properties of such high excited states of trivalent atomic systems.
We also present new ab initio calculations of these quantities and other In
polarizabilities using two high-precision relativistic methods to make a global
comparison of the accuracies of the two approaches. The precision of the
experiment is sufficient to differentiate between the two theoretical methods
as well as to allow precise determination of the indium $7p-6d$ matrix
elements. The results obtained in this work are applicable to other heavier and
more complicated systems, and provide much needed guidance for the development
of even more precise theoretical approaches.
",Physics
"  The SCUBA-2 Ambitious Sky Survey (SASSy) is composed of shallow 850-$\umu$m
imaging using the Sub-millimetre Common-User Bolometer Array 2 (SCUBA-2) on the
James Clerk Maxwell Telescope. Here we describe the extraction of a catalogue
of beam-sized sources from a roughly $120\,{\rm deg}^2$ region of the Galactic
plane mapped uniformly (to an rms level of about 40\,mJy), covering longitude
120\degr\,$<$\,\textit{l}\,$<$\,140\degr\ and latitude
$\abs{\textit{b}}$\,$<$\,2.9\degr. We used a matched-filtering approach to
increase the signal-to-noise (S/N) ratio in these noisy maps and tested the
efficiency of our extraction procedure through estimates of the false discovery
rate, as well as by adding artificial sources to the real images. The primary
catalogue contains a total of 189 sources at 850\,$\umu$m, down to a S/N
threshold of approximately 4.6. Additionally, we list 136 sources detected down
to ${\rm S/N}=4.3$, but recognise that as we go lower in S/N, the reliability
of the catalogue rapidly diminishes. We perform follow-up observations of some
of our lower significance sources through small targeted SCUBA-2 images, and
list 265 sources detected in these maps down to ${\rm S/N}=5$. This illustrates
the real power of SASSy: inspecting the shallow maps for regions of 850-$\umu$m
emission and then using deeper targeted images to efficiently find fainter
sources. We also perform a comparison of the SASSy sources with the Planck
Catalogue of Compact Sources and the \textit{IRAS} Point Source Catalogue, to
determine which sources discovered in this field might be new, and hence
potentially cold regions at an early stage of star formation.
",Physics
"  The S=1/2 Heisenberg spin chain compound SrCuO2 doped with different amounts
of nickel (Ni), palladium (Pd), zinc (Zn) and cobalt (Co) has been studied by
means of Cu nuclear magnetic resonance (NMR). Replacing only a few of the S=1/2
Cu ions with Ni, Pd, Zn or Co has a major impact on the magnetic properties of
the spin chain system. In the case of Ni, Pd and Zn an unusual line broadening
in the low temperature NMR spectra reveals the existence of an impurity-induced
local alternating magnetization (LAM), while exponentially decaying
spin-lattice relaxation rates $T_1^{-1}$ towards low temperatures indicate the
opening of spin gaps. A distribution of gap magnitudes is proven by a stretched
spin-lattice relaxation and a variation of $T_1^{-1}$ within the broad
resonance lines. These observations depend strongly on the impurity
concentration and therefore can be understood using the model of finite
segments of the spin 1/2 antiferromagnetic Heisenberg chain, i.e. pure chain
segmentation due to S = 0 impurities. This is surprising for Ni as it was
previously assumed to be a magnetic impurity with S = 1 which is screened by
the neighboring copper spins. In order to confirm the S = 0 state of the Ni, we
performed x-ray absorption spectroscopy (XAS) and compared the measurements to
simulated XAS spectra based on multiplet ligand-field theory. Furthermore, Zn
doping leads to much smaller effects on both the NMR spectra and the
spin-lattice relaxation rates, indicating that Zn avoids occupying Cu sites.
For magnetic Co impurities, $T_1^{-1}$ does not obey the gap like decrease, and
the low-temperature spectra get very broad. This could be related to the
increase of the Neel temperature which was observed by recent muSR and
susceptibility measurements, and is most likely an effect of the impurity spin
$S\neq0$.
",Physics
"  Precise knowledge of the static density response function (SDRF) of the
uniform electron gas (UEG) serves as key input for numerous applications, most
importantly for density functional theory beyond generalized gradient
approximations. Here we extend the configuration path integral Monte Carlo
(CPIMC) formalism that was previously applied to the spatially uniform electron
gas to the case of an inhomogeneous electron gas by adding a spatially periodic
external potential. This procedure has recently been successfully used in
permutation blocking path integral Monte Carlo simulations (PB-PIMC) of the
warm dense electron gas [Dornheim \textit{et al.}, Phys. Rev. E in press,
arXiv:1706.00315], but this method is restricted to low and moderate densities.
Implementing this procedure into CPIMC allows us to obtain exact finite
temperature results for the SDRF of the electron gas at \textit{high to
moderate densities} closing the gap left open by the PB-PIMC data. In this
paper we demonstrate how the CPIMC formalism can be efficiently extended to the
spatially inhomogeneous electron gas and present the first data points.
Finally, we discuss finite size errors involved in the quantum Monte Carlo
results for the SDRF in detail and present a solution how to remove them that
is based on a generalization of ground state techniques.
",Physics
"  Electronic charge carriers in ionic materials can self-trap to form large
polarons. Interference between the ionic displacements associated with
oppositely charged large polarons increases as they approach one another.
Initially this interference produces an attractive potential that fosters their
merger. However, for small enough separations this interference generates a
repulsive interaction between oppositely charged large polarons. In suitable
circumstances this repulsion can overwhelm their direct Coulomb attraction.
Then the resulting net repulsion between oppositely charged large polarons
constitutes a potential barrier which impedes their recombination.
",Physics
"  Fractional quantum Hall-superconductor heterostructures may provide a
platform towards non-abelian topological modes beyond Majoranas. However their
quantitative theoretical study remains extremely challenging. We propose and
implement a numerical setup for studying edge states of fractional quantum Hall
droplets with a superconducting instability. The fully gapped edges carry a
topological degree of freedom that can encode quantum information protected
against local perturbations. We simulate such a system numerically using exact
diagonalization by restricting the calculation to the quasihole-subspace of a
(time-reversal symmetric) bilayer fractional quantum Hall system of Laughlin
$\nu=1/3$ states. We show that the edge ground states are permuted by
spin-dependent flux insertion and demonstrate their fractional $6\pi$ Josephson
effect, evidencing their topological nature and the Cooper pairing of
fractionalized quasiparticles.
",Physics
"  Living organisms process information to interact and adapt to their changing
environment with the goal of finding food, mates or averting hazards. The
structure of their niche has profound repercussions by both selecting their
internal architecture and also inducing adaptive responses to environmental
cues and stimuli. Adaptive, collective behaviour underpinned by specialized
optimization strategies is ubiquitously found in the natural world. This
exceptional success originates from the processes of fitness and selection.
Here we prove that a universal physical mechanism of a nonequilibrium
transition underlies the collective organization of information-processing
organisms. As cognitive agents build and update an internal, cognitive
representation of the causal structure of their environment, complex patterns
emerge in the system, where the onset of pattern formation relates to the
spatial overlap of cognitive maps. Studying the exchange of information among
the agents reveals a continuous, order-disorder transition. As a result of the
spontaneous breaking of translational symmetry, a Goldstone mode emerges, which
points at a collective mechanism of information transfer among cognitive
organisms. Taken together, the characteristics of this phase transition
consolidate different results in cognitive and biological sciences in a
universal manner. These finding are generally applicable to the design of
artificial intelligent swarm systems that do not rely on centralized control
schemes.
",Physics
"  Fragmentation of filaments into dense cores is thought to be an important
step in forming stars. The bar-mode instability of spherically collapsing cores
found in previous linear analysis invokes a possibility of re-fragmentation of
the cores due to their ellipsoidal (prolate or oblate) deformation. To
investigate this possibility, here we perform three-dimensional
self-gravitational hydrodynamics simulations that follow all the way from
filament fragmentation to subsequent core collapse. We assume the gas is
polytropic with index \gamma, which determines the stability of the bar-mode.
For the case that the fragmentation of isolated hydrostatic filaments is
triggered by the most unstable fragmentation mode, we find the bar mode grows
as collapse proceeds if \gamma < 1.1, in agreement with the linear analysis.
However, it takes more than ten orders-of-magnitude increase in the central
density for the distortion to become non-linear. In addition to this fiducial
case, we also study non-fiducial ones such as the fragmentation is triggered by
a fragmentation mode with a longer wavelength and it occurs during radial
collapse of filaments and find the distortion rapidly grows. In most of
astrophysical applications, the effective polytropic index of collapsing gas
exceeds 1.1 before ten orders-of-magnitude increase in the central density.
Thus, supposing the fiducial case of filament fragmentation, re-fragmentation
of dense cores would not be likely and their final mass would be determined
when the filaments fragment.
",Physics
"  We have performed magnetic susceptibility, heat capacity, muon spin
relaxation, and neutron scattering measurements on three members of the family
Ba3MRu2O9, where M = In, Y and Lu. These systems consist of mixed-valence Ru
dimers on a triangular lattice with antiferromagnetic interdimer exchange.
Although previous work has argued that charge order within the dimers or
intradimer double exchange plays an important role in determining the magnetic
properties, our results suggest that the dimers are better described as
molecular units due to significant orbital hybridization, resulting in one
spin-1/2 moment distributed equally over the two Ru sites. These molecular
building blocks form a frustrated, quasi-two-dimensional triangular lattice.
Our zero and longitudinal field muSR results indicate that the molecular
moments develop a collective, static magnetic ground state, with oscillations
of the zero field muon spin polarization indicative of long-range magnetic
order in the Lu sample. The static magnetism is much more disordered in the Y
and In samples, but they do not appear to be conventional spin glasses.
",Physics
"  Papers on the ANTARES multi-messenger program, prepared for the 35th
International Cosmic Ray Conference (ICRC 2017, Busan, South Korea) by the
ANTARES Collaboration
",Physics
"  The influence of superheat treatment on the microstructure and dynamic
mechanical properties of A357 alloys has been investigated. The study of
microstructure was performed by the optical microscope. Dynamic mechanical
properties (storage modulus, loss modulus, and damping capacity) were measured
by the dynamic mechanical analyzer (DMA). Microstructure showed coarser and
angular eutectic Si particles with larger {\alpha}-Al dendrites in the
non-superheated A357 alloy. In contrast, finer and rounded eutectic Si
particles together with smaller and preferred oriented {\alpha}-Al dendrites
have been observed in the superheated A357 alloy. Dynamic mechanical properties
showed an increasing trend of loss modulus and damping capacity meanwhile a
decreasing trend of storage modulus at elevated temperatures for superheated
and non-superheated A357 alloys. The high damping capacity of superheated A357
has been ascribed to the grain boundary damping at elevated temperatures.
",Physics
"  We present a three-dimensional cubic lattice spin model, anisotropic in the
$\hat{z}$ direction, that exhibits fracton topological order. The latter is a
novel type of topological order characterized by the presence of immobile
pointlike excitations, named fractons, residing at the corners of an operator
with two-dimensional support. As other recent fracton models, ours exhibits a
subextensive ground state degeneracy: On an $L_x\times L_y\times L_z$
three-torus, it has a $2^{2L_z}$ topological degeneracy, and an additional
non-topological degeneracy equal to $2^{L_xL_y-2}$. The fractons can be
combined into composite excitations that move either in a straight line along
the $\hat{z}$ direction, or freely in the $xy$ plane at a given height $z$.
While our model draws inspiration from the toric code, we demonstrate that it
cannot be adiabatically connected to a layered toric code construction.
Additionally, we investigate the effects of imposing open boundary conditions
on our system. We find zero energy modes on the surfaces perpendicular to
either the $\hat{x}$ or $\hat{y}$ directions, and their absence on the surfaces
normal to $\hat{z}$. This result can be explained using the properties of the
two kinds of composite two-fracton mobile excitations.
",Physics
"  We introduce the concept of saturated absorption competition (SAC) microscopy
as a means of providing sub-diffraction spatial resolution in fluorescence
imaging. Unlike the post-competition process between stimulated and spontaneous
emission that is used in stimulated emission depletion (STED) microscopy, SAC
microscopy breaks the diffraction limit by emphasizing a pre-competition
process that occurs in the fluorescence absorption stage in a manner that
shares similarities with ground-state depletion (GSD) microscopy. Moreover,
unlike both STED and GSD microscopy, SAC microscopy offers a reduction in
complexity and cost by utilizing only a single continuous-wave laser diode and
an illumination intensity that is ~ 20x smaller than that used in STED. Our
approach can be physically implemented in a confocal microscope by dividing the
input laser source into a time-modulated primary excitation beam and a
doughnut-shaped saturation beam, and subsequently employing a homodyne
detection scheme to select the modulated fluorescence signal. Herein, we
provide both a physico-chemical model of SAC and experimentally demonstrate by
way of a proof-of-concept experiment a transverse spatial resolution of
~lambda/6.
",Physics
"  In this work we exploit agglomeration based $h$-multigrid preconditioners to
speed-up the iterative solution of discontinuous Galerkin discretizations of
the Stokes and Navier-Stokes equations. As a distinctive feature $h$-coarsened
mesh sequences are generated by recursive agglomeration of a fine grid,
admitting arbitrarily unstructured grids of complex domains, and agglomeration
based discontinuous Galerkin discretizations are employed to deal with
agglomerated elements of coarse levels. Both the expense of building coarse
grid operators and the performance of the resulting multigrid iteration are
investigated. For the sake of efficiency coarse grid operators are inherited
through element-by-element $L^2$ projections, avoiding the cost of numerical
integration over agglomerated elements. Specific care is devoted to the
projection of viscous terms discretized by means of the BR2 dG method. We
demonstrate that enforcing the correct amount of stabilization on coarse grids
levels is mandatory for achieving uniform convergence with respect to the
number of levels. The numerical solution of steady and unsteady, linear and
non-linear problems is considered tackling challenging 2D test cases and 3D
real life computations on parallel architectures. Significant execution time
gains are documented.
",Physics
"  (abridged) In this paper we revisit the problem of inferring the innermost
structure of the Milky Way's nuclear star cluster via star counts, to clarify
whether it displays a core or a cusp around the central black hole. Through
image stacking and improved PSF fitting we push the completeness limit about
one magnitude deeper than in previous, comparable work. Contrary to previous
work, we analyse the stellar density in well-defined magnitude ranges in order
to be able to constrain stellar masses and ages. The RC and brighter giant
stars display a core-like surface density profile within a projected radius
R<0.3 pc of the central black hole, in agreement with previous studies, but
show a cusp-like surface density distribution at larger R. The surface density
of the fainter stars can be described well by a single power-law at R<2 pc. The
cusp-like profile of the faint stars persists even if we take into account the
possible contamination of stars in this brightness range by young pre-main
sequence stars. The data are inconsistent with a core-profile for the faint
stars.Finally, we show that a 3D Nuker law provides a very good description of
the cluster structure. We conclude that the observed stellar density at the
Galactic Centre, as it can be inferred with current instruments, is consistent
with the existence of a stellar cusp around the Milky Way's central black hole,
Sgr A*. This cusp is well developed inside the influence radius of about 3 pc
of Sgr A* and can be described by a single three-dimensional power-law with an
exponent gamma=1.23+-0.05. The apparent lack of RC stars and brighter giants at
projected distances of R < 0.3 pc (R<8"") of the massive black hole may indicate
that some mechanism has altered their distribution or intrinsic luminosity.
",Physics
"  WTe2 and its sister alloys have attracted tremendous attentions recent years
due to the large non-saturating magnetoresistance and topological non-trivial
properties. Herein, we briefly review the electrical property studies on this
new quantum material.
",Physics
"  Topological superfluid is an exotic state of quantum matter that possesses a
nodeless superfluid gap in the bulk and Andreev edge modes at the boundary of a
finite system. Here, we study a multi-orbital superfluid driven by attractive
s-wave interaction in a rotating optical lattice. Interestingly, we find that
the rotation induces the inter- orbital hybridization and drives the system
into topological orbital superfluid in accordance with intrinsically chiral
d-wave pairing characteristics. Thanks to the conservation of spin, the
topological orbital superfluid supports four rather than two chiral Andreev
edge modes at the boundary of the lattice. Moreover, we find that the intrinsic
harmonic confining potential forms a circular spatial barrier which accumulates
atoms and supports a mass current under injection of small angular momentum as
external driving force. This feature provides an experimentally detectable
phenomenon to verify the topological orbital superfluid with chiral d-wave
order in a rotating optical lattice.
",Physics
"  We have performed angle-resolved photoemission spectroscopy (ARPES) of LaSb
and CeSb, a candidate of topological insulator. Using soft-x-ray photons, we
have accurately determined the three-dimensional bulk band structure and
revealed that the band inversion at the Brillouin-zone corner - a prerequisite
for realizing topological-insulator phase - is absent in both LaSb and CeSb.
Moreover, unlike the ARPES data obtained with soft-x-ray photons, those with
vacuum ultraviolet (VUV) photons were found to suffer significant $k_z$
broadening. These results suggest that LaSb and CeSb are topologically trivial
semimetals, and unusual Dirac-cone-like states observed with VUV photons are
not of the topological origin.
",Physics
"  A number of image-processing problems can be formulated as optimization
problems. The objective function typically contains several terms specifically
designed for different purposes. Parameters in front of these terms are used to
control the relative weights among them. It is of critical importance to tune
these parameters, as quality of the solution depends on their values. Tuning
parameter is a relatively straightforward task for a human, as one can
intelligently determine the direction of parameter adjustment based on the
solution quality. Yet manual parameter tuning is not only tedious in many
cases, but becomes impractical when a number of parameters exist in a problem.
Aiming at solving this problem, this paper proposes an approach that employs
deep reinforcement learning to train a system that can automatically adjust
parameters in a human-like manner. We demonstrate our idea in an example
problem of optimization-based iterative CT reconstruction with a pixel-wise
total-variation regularization term. We set up a parameter tuning policy
network (PTPN), which maps an CT image patch to an output that specifies the
direction and amplitude by which the parameter at the patch center is adjusted.
We train the PTPN via an end-to-end reinforcement learning procedure. We
demonstrate that under the guidance of the trained PTPN for parameter tuning at
each pixel, reconstructed CT images attain quality similar or better than in
those reconstructed with manually tuned parameters.
",Physics
"  This study focuses on the social structure and interpersonal dynamics of an
afterschool math club for middle schoolers. Using social network analysis, two
networks were formed and analyzed: The network of friendship relationships and
the network of working relationships. The interconnections and correlations
between friendship relationships, working relationships, and student opinion
surveys are studied. A core working group of talented students emerged from the
network of working relations. This group acted a central go-between for other
members in the club. This core working group expanded into largest friendship
group in the friendship network. Although there were working isolates, they
were not found to be socially isolated. Students who were less popular tended
to report a greater favorable impact from club participation. Implications for
the study of the social structure of afterschool STEM clubs and classrooms are
discussed.
",Mathematics
"  In this paper, we consider the stochastic Langevin equation with additive
noises, which possesses both conformal symplectic geometric structure and
ergodicity. We propose a methodology of constructing high weak order conformal
symplectic schemes by converting the equation into an equivalent autonomous
stochastic Hamiltonian system and modifying the associated generating function.
To illustrate this approach, we construct a specific second order numerical
scheme, and prove that its symplectic form dissipates exponentially. Moreover,
for the linear case, the proposed scheme is also shown to inherit the
ergodicity of the original system, and the temporal average of the numerical
solution is a proper approximation of the ergodic limit over long time.
Numerical experiments are given to verify these theoretical results.
",Mathematics
"  Let $(M,g)$ be a smooth compact Riemannian manifold of dimension $n$ with
smooth boundary $\partial M$. Suppose that $(M,g)$ admits a scalar-flat
conformal metric. We prove that the supremum of the isoperimetric quotient over
the scalar-flat conformal class is strictly larger than the best constant of
the isoperimetric inequality in the Euclidean space, and consequently is
achieved, if either (i) $n\ge 12$ and $\partial M$ has a nonumbilic point; or
(ii) $n\ge 10$, $\partial M$ is umbilic and the Weyl tensor does not vanish at
some boundary point.
",Mathematics
"  Let $\Omega$ be a bounded open set of $\mathbb R^{n}$, $n\ge 2$. In this
paper we mainly study some properties of the second Dirichlet eigenvalue
$\lambda_{2}(p,\Omega)$ of the anisotropic $p$-Laplacian \[ -\mathcal
Q_{p}u:=-\textrm{div} \left(F^{p-1}(\nabla u)F_\xi (\nabla u)\right), \] where
$F$ is a suitable smooth norm of $\mathbb R^{n}$ and $p\in]1,+\infty[$. We
provide a lower bound of $\lambda_{2}(p,\Omega)$ among bounded open sets of
given measure, showing the validity of a Hong-Krahn-Szego type inequality.
Furthermore, we investigate the limit problem as $p\to+\infty$.
",Mathematics
"  Carmesin, Federici, and Georgakopoulos [arXiv:1603.06712] constructed a
transient hyperbolic graph that has no transient subtrees and that has the
Liouville property for harmonic functions. We modify their construction to get
a unimodular random graph with the same properties.
",Mathematics
"  Let $A$ be a free hyperplane arrangement. In 1989, Ziegler showed that the
restriction $A''$ of $A$ to any hyperplane endowed with the natural
multiplicity is then a free multiarrangement. We initiate a study of the
stronger freeness property of inductive freeness for these canonical free
multiarrangements and investigate them for the underlying class of reflection
arrangements.
More precisely, let $A = A(W)$ be the reflection arrangement of a complex
reflection group $W$. By work of Terao, each such reflection arrangement is
free. Thus so is Ziegler's canonical multiplicity on the restriction $A''$ of
$A$ to a hyperplane. We show that the latter is inductively free as a
multiarrangement if and only if $A''$ itself is inductively free.
",Mathematics
"  In this paper, we characterize all the irreducible Darboux polynomials and
polynomial first integrals of FitzHugh-Nagumo (F-N) system. The method of the
weight homogeneous polynomials and the characteristic curves is widely used to
give a complete classification of Darboux polynomials of a system. However,
this method does not work for F-N system. Here by considering the Darboux
polynomials of an assistant system associated to F-N system, we classified the
invariant algebraic surfaces of F-N system. Our results show that there is no
invariant algebraic surface of F-N system in the biological parameters region.
",Mathematics
"  In this paper we define the notion of pullback lifting of a lifting crossed
module over a crossed module morphism and interpret this notion in the category
of group-groupoid actions as pullback action. Moreover, we give a criterion for
the lifting of homotopic crossed module morphisms to be homotopic, which will
be called homotopy lifting property for crossed module morphisms. Finally, we
investigate some properties of derivations of lifting crossed modules according
to base crossed module derivations.
",Mathematics
"  We show that a self orbit equivalence of a transitive Anosov flow on a
$3$-manifold which is homotopic to identity has to either preserve every orbit
or the Anosov flow is $\mathbb{R}$-covered and the orbit equivalence has to be
of a specific type. This result shows that one can remove a relatively
unnatural assumption in a result of Farrell and Gogolev about the topological
rigidity of bundles supporting a fiberwise Anosov flow when the fiber is
$3$-dimensional.
",Mathematics
"  We investigate (2,1):1 structures, which consist of a countable set $A$
together with a function $f: A \to A$ such that for every element $x$ in $A$,
$f$ maps either exactly one element or exactly two elements of $A$ to $x$.
These structures extend the notions of injection structures, 2:1 structures,
and (2,0):1 structures studied by Cenzer, Harizanov, and Remmel, all of which
can be thought of as infinite directed graphs. We look at various
computability-theoretic properties of (2,1):1 structures, most notably that of
computable categoricity. We say that a structure $\mathcal{A}$ is computably
categorical if there exists a computable isomorphism between any two computable
copies of $\mathcal{A}$. We give a sufficient condition under which a (2,1):1
structure is computably categorical, and present some examples of (2,1):1
structures with different computability-theoretic properties.
",Mathematics
"  In this paper, we introduce the notion of an omni $n$-Lie algebra and show
that they are linearization of higher analogues of standard Courant algebroids.
We also introduce the notion of a nonabelian omni $n$-Lie algebra and show that
they are linearization of higher analogues of Courant algebroids associated to
Nambu-Poisson manifolds.
",Mathematics
"  Since the development of higher local class field theory, several explicit
reciprocity laws have been constructed. In particular, there are formulas
describing the higher-dimensional Hilbert symbol given, among others, by M.
Kurihara, A. Zinoviev and S. Vostokov. K. Kato also has explicit formulas for
the higher-dimensional Kummer pairing associated to certain (one-dimensional)
$p$-divisible groups.
In this paper we construct an explicit reciprocity law describing the Kummer
pairing associated to any (one-dimensional) formal group. The formulas are a
generalization to higher-dimensional local fields of Kolyvagin's reciprocity
laws. The formulas obtained describe the values of the pairing in terms of
multidimensional $p$-adic differentiation, the logarithm of the formal group,
the generalized trace and the norm on Milnor K-groups.
In the second part of this paper, we will apply the results obtained here to
give explicit formulas for the generalized Hilbert symbol and the Kummer
pairing associated to a Lubin-Tate formal group. The results obtained in the
second paper constitute a generalization to higher local fields, of the
formulas of Artin-Hasse, K. Iwasawa and A. Wiles.
",Mathematics
"  The object of this paper is to study $\eta$-Ricci solitons on
$(\varepsilon)$-almost paracontact metric manifolds. We investigate
$\eta$-Ricci solitons in the case when its potential vector field is exactly
the characteristic vector field $\xi$ of the $(\varepsilon)$-almost paracontact
metric manifold and when the potential vector field is torse-forming. We also
study Einstein-like and $(\varepsilon)$-para Sasakian manifolds admitting
$\eta$-Ricci solitons. Finally we obtain some results for $\eta$-Ricci solitons
on $(\varepsilon)$-almost paracontact metric manifolds with a special view
towards parallel symmetric (0,2)-tensor fields.
",Mathematics
"  The basin of attraction of a uniformly attracting sequence of holomorphic
automorphisms that agree to a certain order in the common fixed point, is
biholomorphic to $\mathbb{C}^n$. We also give sufficient estimates how large
this order has to be.
",Mathematics
"  Finite rank median spaces are a simultaneous generalisation of finite
dimensional CAT(0) cube complexes and real trees. If $\Gamma$ is an irreducible
lattice in a product of rank one simple Lie groups, we show that every action
of $\Gamma$ on a complete, finite rank median space has a global fixed point.
This is in sharp contrast with the behaviour of actions on infinite rank median
spaces.
The fixed point property is obtained as corollary to a superrigidity result;
the latter holds for irreducible lattices in arbitrary products of compactly
generated groups.
In previous work, we introduced ""Roller compactifications"" of median spaces;
these generalise a well-known construction in the case of cube complexes. We
provide a reduced $1$-cohomology class that detects group actions with a finite
orbit in the Roller compactification. Even for CAT(0) cube complexes, only
second bounded cohomology classes were known with this property, due to
Chatterji-Fernós-Iozzi. As a corollary, we observe that, in Gromov's density
model, random groups at low density do not have Shalom's property $H_{FD}$.
",Mathematics
"  A Leonard pair is a pair of diagonalizable linear transformations of a
finite-dimensional vector space, each of which acts in an irreducible
tridiagonal fashion on an eigenbasis for the other one. Let $\mathbb F$ denote
an algebraically closed field, and fix a nonzero $q \in \mathbb F$ that is not
a root of unity. The universal double affine Hecke algebra (DAHA) $\hat{H}_q$
of type $(C_1^\vee,C_1)$ is the associative $\mathbb F$-algebra defined by
generators $\lbrace t_i^{\pm 1}\rbrace_{i=0}^3$ and relations (i)
$t_it_i^{-1}=t_i^{-1}t_i=1$; (ii) $t_i+t_i^{-1}$ is central; (iii)
$t_0t_1t_2t_3 = q^{-1}$. We consider the elements $X=t_3t_0$ and $Y=t_0t_1$ of
$\hat{H}_q$. Let $\mathcal V$ denote a finite-dimensional irreducible
$\hat{H}_q$-module on which each of $X$, $Y$ is diagonalizable and $t_0$ has
two distinct eigenvalues. Then $\mathcal V$ is a direct sum of the two
eigenspaces of $t_0$. We show that the pair $X+X^{-1}$, $Y+Y^{-1}$ acts on each
eigenspace as a Leonard pair, and each of these Leonard pairs falls into a
class said to have $q$-Racah type. Thus from $\mathcal V$ we obtain a pair of
Leonard pairs of $q$-Racah type. It is known that a Leonard pair of $q$-Racah
type is determined up to isomorphism by a parameter sequence $(a,b,c,d)$ called
its Huang data. Given a pair of Leonard pairs of $q$-Racah type, we find
necessary and sufficient conditions on their Huang data for that pair to come
from the above construction.
",Mathematics
"  The Leah-Hamiltonian, $H(x,y)=y^2/2+3x^{4/3}/4$, is introduced as a
functional equation for $x(t)$ and $y(t)$. By means of a nonlinear
transformation to new independent variables, we show that this functional
equation has a special class of periodic solutions which we designate the Imani
functions. The explicit construction of these functions is done such that they
possess many of the general properties of the standard trigonometric cosine and
sine functions. We conclude by providing a listing of a number of currently
unresolved issues relating to the Imani functions.
",Mathematics
"  If M is a smooth compact connected Riemannian manifold, let P(M) denote the
Wasserstein space of probability measures on M. We describe a geometric
construction of parallel transport of some tangent cones along geodesics in
P(M). We show that when everything is smooth, the geometric parallel transport
agrees with earlier formal calculations.
",Mathematics
"  Two classifications of second order ODE's cubic with respect to the first
order derivative are compared in the case of general position, which is common
for both classifications. The correspondence of vectorial, pseudovectorial,
scalar, and pseudoscalar invariants is established.
",Mathematics
"  The regular icosahedron is connected to many exceptional objects in
mathematics. Here we describe two constructions of the $\mathrm{E}_8$ lattice
from the icosahedron. One uses a subring of the quaternions called the
""icosians"", while the other uses du Val's work on the resolution of Kleinian
singularities. Together they link the golden ratio, the quaternions, the
quintic equation, the 600-cell, and the Poincare homology 3-sphere. We leave it
as a challenge to the reader to find the connection between these two
constructions.
",Mathematics
"  By using Araki's relative entropy, Lieb's convexity and the theory of
singular integrals, we compute the mutual information associated with free
fermions, and we deduce many results about entropies for chiral CFT's which are
embedded into free fermions, and their extensions. Such relative entropies in
CFT are here computed explicitly for the first time in a mathematical rigorous
way. Our results agree with previous computations by physicists based on
heuristic arguments; in addition we uncover a surprising connection with the
theory of subfactors, in particular by showing that a certain duality, which is
argued to be true on physical grounds, is in fact violated if the global
dimension of the conformal net is greater than $1.$
",Mathematics
"  A famous result of Jurgen Moser states that a symplectic form on a compact
manifold cannot be deformed within its cohomology class to an inequivalent
symplectic form. It is well known that this does not hold in general for
noncompact symplectic manifolds. The notion of Eliashberg-Gromov convex ends
provides a natural restricted setting for the study of analogs of Moser's
symplectic stability result in the noncompact case, and this has been
significantly developed in work of Cieliebak-Eliashberg. Retaining the end
structure on the underlying smooth manifold, but dropping the convexity and
completeness assumptions on the symplectic forms at infinity we show that
symplectic stability holds under a natural growth condition on the path of
symplectic forms. The result can be straightforwardly applied as we show
through explicit examples.
",Mathematics
"  By considering a limiting case of a Kronecker-type identity, we obtain an
identity found by both Andrews and Crandall. We then use the Andrews-Crandall
identity to give a new proof of a formula of Gauss for the representations of a
number as a sum of three squares. From the Kronecker-type identity, we also
deduce Gauss's theorem that every positive integer is representable as a sum of
three triangular numbers.
",Mathematics
"  In this paper we have generalized the notion of $\lambda$-radial contraction
in complete Riemannian manifold and developed the concept of $p^\lambda$-convex
function. We have also given a counter example proving the fact that in general
$\lambda$-radial contraction of a geodesic is not necessarily a geodesic. We
have also deduced some relations between geodesic convex sets and
$p^\lambda$-convex sets and showed that under certain conditions they are
equivalent.
",Mathematics
"  For a Riemannian $G$-structure, we compute the divergence of the vector field
induced by the intrinsic torsion. Applying the Stokes theorem, we obtain the
integral formula on a closed oriented Riemannian manifold, which we interpret
in certain cases. We focus on almost harmitian and almost contact metric
structures.
",Mathematics
"  In this article we introduce a simple dynamical system called symplectic
billiards. As opposed to usual/Birkhoff billiards, where length is the
generating function, for symplectic billiards symplectic area is the generating
function. We explore basic properties and exhibit several similarities, but
also differences of symplectic billiards to Birkhoff billiards.
",Mathematics
"  We prove that any open subset $U$ of a semi-simple simply connected
quasi-split linear algebraic group $G$ with ${codim} (G\setminus U, G)\geq 2$
over a number field satisfies strong approximation by establishing a fibration
of $G$ over a toric variety. We also prove a similar result of strong
approximation with Brauer-Manin obstruction for a partial equivariant smooth
compactification of a homogeneous space where all invertible functions are
constant and the semi-simple part of the linear algebraic group is quasi-split.
Some semi-abelian varieties of any given dimension where the complements of a
rational point do not satisfy strong approximation with Brauer-Manin
obstruction are given.
",Mathematics
"  In this paper, we establish equivariant mirror symmetry for the weighted
projective line. This extends the results by B. Fang, C.C. Liu and Z. Zong,
where the projective line was considered [{\it Geometry \& Topology}
24:2049-2092, 2017]. More precisely, we prove the equivalence of the
$R$-matrices for A-model and B-model at large radius limit, and establish
isomorphism for $R$-matrices for general radius. We further demonstrate that
the graph sum of higher genus cases are the same for both models, hence
establish equivariant mirror symmetry for the weighted projective line.
",Mathematics
"  This paper presents a systematic approach for computing local solutions to
motion planning problems in non-convex environments using numerical optimal
control techniques. It extends the range of use of state-of-the-art numerical
optimal control tools to problem classes where these tools have previously not
been applicable. Today these problems are typically solved using motion
planners based on randomized or graph search. The general principle is to
define a homotopy that perturbs, or preferably relaxes, the original problem to
an easily solved problem. By combining a Sequential Quadratic Programming (SQP)
method with a homotopy approach that gradually transforms the problem from a
relaxed one to the original one, practically relevant locally optimal solutions
to the motion planning problem can be computed. The approach is demonstrated in
motion planning problems in challenging 2D and 3D environments, where the
presented method significantly outperforms a state-of-the-art open-source
optimizing sampled-based planner commonly used as benchmark.
",Mathematics
"  The main aim of this paper is to prove $R$-triviality for simple, simply
connected algebraic groups with Tits index $E_{8,2}^{78}$ or $E_{7,1}^{78}$,
defined over a field $k$ of arbitrary characteristic. Let $G$ be such a group.
We prove that there exists a quadratic extension $K$ of $k$ such that $G$ is
$R$-trivial over $K$, i.e., for any extension $F$ of $K$, $G(F)/R=\{1\}$, where
$G(F)/R$ denotes the group of $R$-equivalence classes in $G(F)$, in the sense
of Manin (see \cite{M}). As a consequence, it follows that the variety $G$ is
retract $K$-rational and that the Kneser-Tits conjecture holds for these groups
over $K$. Moreover, $G(L)$ is projectively simple as an abstract group for any
field extension $L$ of $K$. In their monograph (\cite{TW}) J. Tits and Richard
Weiss conjectured that for an Albert division algebra $A$ over a field $k$, its
structure group $Str(A)$ is generated by scalar homotheties and its
$U$-operators. This is known to be equivalent to the Kneser-Tits conjecture for
groups with Tits index $E_{8,2}^{78}$. We settle this conjecture for Albert
division algebras which are first constructions, in affirmative. These results
are obtained as corollaries to the main result, which shows that if $A$ is an
Albert division algebra which is a first construction and $\Gamma$ its
structure group, i.e., the algebraic group of the norm similarities of $A$,
then $\Gamma(F)/R=\{1\}$ for any field extension $F$ of $k$, i.e., $\Gamma$ is
$R$-trivial.
",Mathematics
"  In this paper, we continue the study in \cite{MiaoTX:DNLS:Stab}. We use the
perturbation argument, modulational analysis and the energy argument in
\cite{MartelMT:Stab:gKdV, MartelMT:Stab:NLS} to show the stability of the sum
of two solitary waves with weak interactions for the generalized derivative
Schrödinger equation (gDNLS) in the energy space. Here (gDNLS) hasn't the
Galilean transformation invariance, the pseudo-conformal invariance and the
gauge transformation invariance, and the case $\sigma>1$ we considered
corresponds to the $L^2$-supercritical case.
",Mathematics
"  In 1934, Reinhardt conjectured that the shape of the centrally symmetric
convex body in the plane whose densest lattice packing has the smallest density
is a smoothed octagon. This conjecture is still open. We formulate the
Reinhardt Conjecture as a problem in optimal control theory. The smoothed
octagon is a Pontryagin extremal trajectory with bang-bang control. More
generally, the smoothed regular $6k+2$-gon is a Pontryagin extremal with
bang-bang control. The smoothed octagon is a strict (micro) local minimum to
the optimal control problem. The optimal solution to the Reinhardt problem is a
trajectory without singular arcs. The extremal trajectories that do not meet
the singular locus have bang-bang controls with finitely many switching times.
Finally, we reduce the Reinhardt problem to an optimization problem on a
five-dimensional manifold. (Each point on the manifold is an initial condition
for a potential Pontryagin extremal lifted trajectory.) We suggest that the
Reinhardt conjecture might eventually be fully resolved through optimal control
theory. Some proofs are computer-assisted using a computer algebra system.
",Mathematics
"  We study the elliptic curve $E_a: (ax+1)y^2+(ax+1)(x-1)y+x^2-x=0$, which we
call the geometric normal form of an elliptic curve. We show that any elliptic
curve whose $j$-invariant is real is isomorphic to a curve $E_a$ in geometric
normal form, and show that for $a \notin \{0, -1, -9\}$, the points on $E_a$,
minus a set of $6$ points, can be characterized in terms of the cevian geometry
of a triangle.
",Mathematics
"  We show that $R^{cl}(\omega\cdot 2,3)^2$ is equal to $\omega^3\cdot 2$.
",Mathematics
"  In 2009, Corteel, Savelief and Vuletić generalized the concept of
overpartitions to a new object called plane overpartitions. In recent work, the
author considered a restricted form of plane overpartitions called $k$-rowed
plane overpartions and proved a method to obtain congruences for these and
other types of combinatorial generating functions. In this paper, we prove
several restricted and unrestricted plane overpartition congruences modulo $4$
and $8$ using other techniques.
",Mathematics
"  In this paper, we find explicit formulas for higher order derivatives of the
inverse tangent function. More precisely, we study polynomials which are
induced from the higher-order derivatives of arctan(x). Successively, we give
generating functions, recurrence relations and some particular properties for
these polynomials. Connections to Chebyshev, Fibonacci, Lucas and Matching
polynomials are established.
",Mathematics
"  We study the two-dimensional stochastic nonlinear wave equations (SNLW) with
an additive space-time white noise forcing. In particular, we introduce a
time-dependent renor- malization and prove that SNLW is pathwise locally
well-posed. As an application of the local well-posedness argument, we also
establish a weak universality result for the renormalized SNLW.
",Mathematics
"  We present natural families of coordinate algebras of noncommutative products
of Euclidean spaces. These coordinate algebras are quadratic ones associated
with an R-matrix which is involutive and satisfies the Yang-Baxter equations.
As a consequence they enjoy a list of nice properties, being regular of finite
global dimension. Notably, we have eight-dimensional noncommutative euclidean
spaces which are particularly well behaved and are deformations parametrised by
a two-dimensional sphere. Quotients include noncommutative seven-spheres as
well as noncommutative ""quaternionic tori"". There is invariance for an action
of $SU(2) \times SU(2)$ in parallel with the action of $U(1) \times U(1)$ on a
""complex"" noncommutative torus which allows one to construct quaternionic toric
noncommutative manifolds. Additional classes of solutions are disjoint from the
classical case.
",Mathematics
"  A characteristic feature of differential-algebraic equations is that one
needs to find derivatives of some of their equations with respect to time, as
part of so called index reduction or regularisation, to prepare them for
numerical solution. This is often done with the help of a computer algebra
system. We show in two significant cases that it can be done efficiently by
pure algorithmic differentiation. The first is the Dummy Derivatives method,
here we give a mainly theoretical description, with tutorial examples. The
second is the solution of a mechanical system directly from its Lagrangian
formulation. Here we outline the theory and show several non-trivial examples
of using the ""Lagrangian facility"" of the Nedialkov-Pryce initial-value solver
DAETS, namely: a spring-mass-multipendulum system, a prescribed-trajectory
control problem, and long-time integration of a model of the outer planets of
the solar system, taken from the DETEST testing package for ODE solvers.
",Mathematics
"  In this paper we investigate the properties of function spaces using the
selection principles.
",Mathematics
"  We define variable parameter analogues of the affine arclength measure on
curves and prove near-optimal $L^p$-improving estimates for associated
multilinear generalized Radon transforms. Some of our results are new even in
the convolution case.
",Mathematics
"  We show that the l-adic realization functor is conservative when restricted
to the Chow motives of abelian type over a finite field. A weak version of this
conservativity result extends to mixed motives of abelian type.
",Mathematics
"  The logarithmic strain measures $\lVert\log U\rVert^2$, where $\log U$ is the
principal matrix logarithm of the stretch tensor $U=\sqrt{F^TF}$ corresponding
to the deformation gradient $F$ and $\lVert\,.\,\rVert$ denotes the Frobenius
matrix norm, arises naturally via the geodesic distance of $F$ to the special
orthogonal group $\operatorname{SO}(n)$. This purely geometric characterization
of this strain measure suggests that a viable constitutive law of nonlinear
elasticity may be derived from an elastic energy potential which depends solely
on this intrinsic property of the deformation, i.e. that an energy function
$W\colon\operatorname{GL^+}(n)\to\mathbb{R}$ of the form \begin{equation}
W(F)=\Psi(\lVert\log U\rVert^2) \tag{1} \end{equation} with a suitable
function $\Psi\colon[0,\infty)\to\mathbb{R}$ should be used to describe finite
elastic deformations.
However, while such energy functions enjoy a number of favorable properties,
we show that it is not possible to find a strictly monotone function $\Psi$
such that $W$ of the form (1) is Legendre-Hadamard elliptic.
Similarly, we consider the related isochoric strain measure
$\lVert\operatorname{dev}_n\log U\rVert^2$, where $\operatorname{dev}_n \log U$
is the deviatoric part of $\log U$. Although a polyconvex energy function in
terms of this strain measure has recently been constructed in the planar case
$n=2$, we show that for $n\geq3$, no strictly monotone function
$\Psi\colon[0,\infty)\to\mathbb{R}$ exists such that $F\mapsto
\Psi(\lVert\operatorname{dev}_n\log U\rVert^2)$ is polyconvex or even rank-one
convex. Moreover, a volumetric-isochorically decoupled energy of the form
$F\mapsto \Psi(\lVert\operatorname{dev}_n\log U\rVert^2) +
W_{\mathrm{vol}}(\det F)$ cannot be rank-one convex for any function
$W_{\mathrm{vol}}\colon(0,\infty)\to\mathbb{R}$ if $\Psi$ is strictly monotone.
",Mathematics
"  This paper reproduces the text of a part of the Author's DPhil thesis. It
gives a proof of the classification of non-trivial, finite homogeneous
geometries of sufficiently high dimension which does not depend on the
classification of the finite simple groups.
",Mathematics
"  The Erd\H os unit distance conjecture in the plane says that the number of
pairs of points from a point set of size $n$ separated by a fixed (Euclidean)
distance is $\leq C_{\epsilon} n^{1+\epsilon}$ for any $\epsilon>0$. The best
known bound is $Cn^{\frac{4}{3}}$. We show that if the set under consideration
is well-distributed and the fixed distance is much smaller than the diameter of
the set, then the exponent $\frac{4}{3}$ is significantly improved.
Corresponding results are also established in higher dimensions. The results
are obtained by solving the corresponding continuous problem and using a
continuous-to-discrete conversion mechanism. The degree of sharpness of results
is tested using the known results on the distribution of lattice points dilates
of convex domains.
We also introduce the following variant of the Erd\H os unit distance
problem: how many pairs of points from a set of size $n$ are separated by an
integer distance? We obtain some results in this direction and formulate a
conjecture.
",Mathematics
"  We show that on any translation surface, if a regular point is contained in a
simple closed geodesic, then it is contained in infinitely many simple closed
geodesics, whose directions are dense in the unit circle. Moreover, the set of
points that are not contained in any simple closed geodesic is finite. We also
construct explicit examples showing that such points exist. For a surface in
any hyperelliptic component, we show that this finite exceptional set is
actually empty. The proofs of our results use Apisa's classifications of
periodic points and of $\GL(2,\R)$ orbit closures in hyperelliptic components,
as well as a recent result of Eskin-Filip-Wright.
",Mathematics
"  The \Delta-convolution of real probability measures, introduced by Bożejko,
generalizes both free and boolean convolutions. It is linearized by the
\Delta-cumulants, and Yoshida gave a combinatorial formula for moments in terms
of \Delta-cumulants, that implicitly defines the latter. It relies on the
definition of an appropriate weight on noncrossing partitions. We give here two
different expressions for the \Delta-cumulants: the first one is a simple
variant of Lagrange inversion formula, and the second one is a combinatorial
inversion of Yoshida's formula involving Schröder trees.
",Mathematics
"  In this paper we consider the class of K3 surfaces defined as hypersurfaces
in weighted projective space, and admitting a non-symplectic automorphism of
non-prime order, excluding the orders 4, 8, and 12. We show that on these
surfaces the Berglund-Hübsch-Krawitz mirror construction and mirror symmetry
for lattice polarized K3 surfaces constructed by Dolgachev agree; that is, both
versions of mirror symmetry define the same mirror K3 surface.
",Mathematics
"  We survey different classification results for surfaces with parallel mean
curvature immersed into some Riemannian homogeneous four-manifolds, including
real and complex space forms, and product spaces. We provide a common framework
for this problem, with special attention to the existence of holomorphic
quadratic differentials on such surfaces. The case of spheres with parallel
mean curvature is also explained in detail, as well as the state-of-the-art
advances in the general problem.
",Mathematics
"  In this paper we consider a nonlocal energy $I_\alpha$ whose kernel is
obtained by adding to the Coulomb potential an anisotropic term weighted by a
parameter $\alpha\in \R$. The case $\alpha=0$ corresponds to purely logarithmic
interactions, minimised by the celebrated circle law for a quadratic
confinement; $\alpha=1$ corresponds to the energy of interacting dislocations,
minimised by the semi-circle law. We show that for $\alpha\in (0,1)$ the
minimiser can be computed explicitly and is the normalised characteristic
function of the domain enclosed by an \emph{ellipse}. To prove our result we
borrow techniques from fluid dynamics, in particular those related to
Kirchhoff's celebrated result that domains enclosed by ellipses are rotating
vortex patches, called \emph{Kirchhoff ellipses}. Therefore we show a
surprising connection between vortices and dislocations.
",Mathematics
"  We present a sufficient condition for irreducibility of forcing algebras and
study the (non)-reducedness phenomenon. Furthermore, we prove a criterion for
normality for forcing algebras over a polynomial base ring with coefficients in
a perfect field. This gives a geometrical normality criterion for algebraic
(forcing) varieties over algebraically closed fields. Besides, we examine in
detail an specific (enlightening) example with several forcing equations.
Finally, we compute explicitly the normalization of a particular forcing
algebra by means of finding explicitly the generators of the ideal defining it
as an affine ring.
",Mathematics
"  Given a combinatorial design $\mathcal{D}$ with block set $\mathcal{B}$, the
block-intersection graph (BIG) of $\mathcal{D}$ is the graph that has
$\mathcal{B}$ as its vertex set, where two vertices $B_{1} \in \mathcal{B}$ and
$B_{2} \in \mathcal{B} $ are adjacent if and only if $|B_{1} \cap B_{2}| > 0$.
The $i$-block-intersection graph ($i$-BIG) of $\mathcal{D}$ is the graph that
has $\mathcal{B}$ as its vertex set, where two vertices $B_{1} \in \mathcal{B}$
and $B_{2} \in \mathcal{B}$ are adjacent if and only if $|B_{1} \cap B_{2}| =
i$. In this paper several constructions are obtained that start with twofold
triple systems (TTSs) with Hamiltonian $2$-BIGs and result in larger TTSs that
also have Hamiltonian $2$-BIGs. These constructions collectively enable us to
determine the complete spectrum of TTSs with Hamiltonian $2$-BIGs (equivalently
TTSs with cyclic $2$-intersecting Gray codes) as well as the complete spectrum
for TTSs with $2$-BIGs that have Hamilton paths (i.e., for TTSs with
$2$-intersecting Gray codes).
In order to prove these spectrum results, we sometimes require ingredient
TTSs that have large partial parallel classes; we prove lower bounds on the
sizes of partial parallel clasess in arbitrary TTSs, and then construct larger
TTSs with both cyclic $2$-intersecting Gray codes and parallel classes.
",Mathematics
"  Let $p\equiv 4,7\mod 9$ be a rational prime number such that $3\mod p$ is not
a cubic residue. In this paper we prove the 3-part of the product of the full
BSD conjectures for $E_p$ and $E_{3p^3}$ is true using an explicit Gross-Zagier
formula, where $E_p: x^3+y^3=p$ and $E_{3p^2}: x^3+y^3=3p^2$ are the elliptic
curves related to the Sylvester conjecture and cube sum problems.
",Mathematics
"  Batyrev constructed a family of Calabi-Yau hypersurfaces dual to the first
Chern class in toric Fano varieties. Using this construction, we introduce a
family of Calabi-Yau manifolds whose SU-bordism classes generate the special
unitary bordism ring
$\varOmega^{SU}\otimes\mathbb{Z}[\frac{1}{2}]\cong\mathbb{Z}[\frac{1}{2}][y_{i}\colon
i\ge 2]$. We also describe explicit Calabi-Yau representatives for
multiplicative generators of the SU-bordism ring in low dimensions.
",Mathematics
"  Let $R$ be a commutative Noetherian ring, $\mathfrak a$ and $\mathfrak b$
ideals of $R$. In this paper, we study the finiteness dimension $f_{\mathfrak
a}(M)$ of $M$ relative to $\mathfrak a$ and the $\mathfrak b$-minimum
$\mathfrak a$-adjusted depth $\lambda_{\mathfrak a}^{\mathfrak b}(M)$ of $M$,
where the underlying module $M$ is relative Cohen-Macaulay w.r.t $\mathfrak a$.
Some applications of such modules are given.
",Mathematics
"  In this paper, we proved an arithmetic Siegel-Weil formula and the modularity
of some arithmetic theta function on the modular curve $X_0(N)$ when $N$ is
square free. In the process, we also construct some generalized Delta function
for $\Gamma_0(N)$ and proved some explicit Kronecker limit formula for
Eisenstein series on $X_0(N)$.
",Mathematics
"  We show that the poset of $SL(n)$-orbit closures in the product of two
partial flag varieties is a lattice if the action of $SL(n)$ is spherical.
",Mathematics
"  In this paper, we investigate the integral of $x^n\log^m(\sin(x))$ for
natural numbers $m$ and $n$. In doing so, we recover some well-known results
and remark on some relations to the log-sine integral
$\operatorname{Ls}_{n+m+1}^{(n)}(\theta)$. Later, we use properties of Bell
polynomials to find a closed expression for the derivative of the central
binomial and shifted central binomial coefficients in terms of polygamma
functions and harmonic numbers.
",Mathematics
"  This paper is concerned with optimal control problems for systems governed by
mean-field stochastic differential equation, in which the control enters both
the drift and the diffusion coefficient. We prove that the relaxed state
process, associated with measure valued controls, is governed by an orthogonal
martingale measure rather that a Brownian motion. In particular, we show by a
counter example that replacing the drift and diffusion coefficient by their
relaxed counterparts does not define a true relaxed control problem. We
establish the existence of an optimal relaxed control, which can be
approximated by a sequence of strict controls. Moreover under some convexity
conditions, we show that the optimal control is realized by a strict control.
",Mathematics
"  A local existence and uniqueness theorem for ODEs in the special algebra of
generalized functions is established, as well as versions including parameters
and dependence on initial values in the generalized sense. Finally, a Frobenius
theorem is proved. In all these results, composition of generalized functions
is based on the notion of c-boundedness.
",Mathematics
"  We introduce a general scheme that permits to generate successive min-max
problems for producing critical points of higher and higher indices to
Palais-Smale Functionals in Banach manifolds equipped with Finsler structures.
We call the resulting tree of minmax problems a minmax hierarchy. Using the
viscosity approach to the minmax theory of minimal surfaces introduced by the
author in a series of recent works, we explain how this scheme can be deformed
for producing smooth minimal surfaces of strictly increasing area in arbitrary
codimension. We implement this scheme to the case of the $3-$dimensional
sphere. In particular we are giving a min-max characterization of the Clifford
Torus and conjecture what are the next minimal surfaces to come in the $S^3$
hierarchy. Among other results we prove here the lower semi continuity of the
Morse Index in the viscosity method below an area level.
",Mathematics
"  We combine aspects of the notions of finite decomposition complexity and
asymptotic property C into a notion that we call finite APC-decomposition
complexity. Any space with finite decomposition complexity has finite
APC-decomposition complexity and any space with asymptotic property C has
finite APC-decomposition complexity. Moreover, finite APC-decomposition
complexity implies property A for metric spaces. We also show that finite
APC-decomposition complexity is preserved by direct products of groups and
spaces, amalgamated products of groups, and group extensions, among other
constructions.
",Mathematics
"  In this paper we study the superalgebra $A_n$, introduced by the authors in
previous work on categorification of Verma modules for quantum
$\mathfrak{sl}_2$. The superalgebra $A_n$ is akin to the nilHecke algebra, and
shares similar properties. In particular, we prove a uniqueness result about
2-Verma modules on $\Bbbk$-linear 2-categories.
",Mathematics
"  In this paper we construct some regular sequences which arise naturally from
determinantal conditions.
",Mathematics
"  Let $E_n(f)_{\alpha,\beta,\gamma}$ denote the error of best approximation by
polynomials of degree at most $n$ in the space
$L^2(\varpi_{\alpha,\beta,\gamma})$ on the triangle $\{(x,y): x, y \ge 0, x+y
\le 1\}$, where $\varpi_{\alpha,\beta,\gamma}(x,y) := x^\alpha y ^\beta
(1-x-y)^\gamma$ for $\alpha,\beta,\gamma > -1$. Our main result gives a sharp
estimate of $E_n(f)_{\alpha,\beta,\gamma}$ in terms of the error of best
approximation for higher order derivatives of $f$ in appropriate Sobolev
spaces. The result also leads to a characterization of
$E_n(f)_{\alpha,\beta,\gamma}$ by a weighted $K$-functional.
",Mathematics
"  We study the problem of defining maps on link Floer homology induced by
unoriented link cobordisms. We provide a natural notion of link cobordism,
disoriented link cobordism, which tracks the motion of index zero and index
three critical points. Then we construct a map on unoriented link Floer
homology associated to a disoriented link cobordism. Furthermore, we give a
comparison with Oszváth-Stipsicz-Szabó's and Manolescu's constructions of
link cobordism maps for an unoriented band move.
",Mathematics
"  This paper addresses the problem of minimum cost resilient
actuation-sensing-communication co-design for regular descriptor systems while
ensuring selective strong structural system's properties. More specifically,
the problem consists of determining the minimum cost deployment of actuation
and sensing technology, as well as communication between the these, such that
decentralized control approaches are viable for an arbitrary realization of
regular descriptor systems satisfying a pre-specified selective structure,
i.e., some entries can be zero, nonzero, or either zero/nonzero. Towards this
goal, we rely on strong structural systems theory and extend it to cope with
the selective structure that casts resiliency/robustness properties and
uncertainty properties of system's model. Upon such framework, we introduce the
notion of selective strong structural fixed modes as a characterization of the
feasibility of decentralized control laws. Also, we provide necessary and
sufficient conditions for this property to hold, and show how these conditions
can be leveraged to determine the minimum cost resilient placement of
actuation-sensing-communication technology ensuring feasible solutions. In
particular, we study the minimum cost resilient actuation and sensing
placement, upon which we construct the solution to our problem. Finally, we
illustrate the applicability the main results of this paper on an electric
power grid example.
",Mathematics
"  The problem for two-dimensional steady water waves with vorticity is
considered. Using methods of spatial dynamics, we reduce the problem to a
finite dimensional Hamiltonian system. As an application, we prove the
existence of non-symmetric steady water waves when the number of roots of the
dispersion equation is greater than 1.
",Mathematics
"  We consider the inverse problems of determining the potential or the damping
coefficient appearing in the wave equation. We will prove the unique
determination of these coefficients from the one point measurement. Since our
problem is under-determined, so some extra assumption on the coefficients is
required to prove the uniqueness.
",Mathematics
"  We give a complete classification (up to isomorphism) of Lie conformal
algebras which are free of rank two as $\C[\partial]$-modules, and determine
their automorphism groups.
",Mathematics
"  An alternative proof is given of the existence of greatest lower bounds in
the imbalance order of binary maximal instantaneous codes of a given size.
These codes are viewed as maximal antichains of a given size in the infinite
binary tree of 0-1 words. The proof proposed makes use of a single balancing
operation instead of expansion and contraction as in the original proof of the
existence of glb.
",Mathematics
"  We analyze the space of differentiable functions on a quad-mesh $\cM$, which
are composed of 4-split spline macro-patch elements on each quadrangular face.
We describe explicit transition maps across shared edges, that satisfy
conditions which ensure that the space of differentiable functions is ample on
a quad-mesh of arbitrary topology. These transition maps define a finite
dimensional vector space of $G^{1}$ spline functions of bi-degree $\le (k,k)$
on each quadrangular face of $\cM$. We determine the dimension of this space of
$G^{1}$ spline functions for $k$ big enough and provide explicit constructions
of basis functions attached respectively to vertices, edges and faces. This
construction requires the analysis of the module of syzygies of univariate
b-spline functions with b-spline function coefficients. New results on their
generators and dimensions are provided. Examples of bases of $G^{1}$ splines of
small degree for simple topological surfaces are detailed and illustrated by
parametric surface constructions.
",Mathematics
"  We prove some basic results on the dimension theory of algebraic stacks, and
on the multiplicities of their irreducible components, for which we do not know
a reference.
",Mathematics
"  We fix a counting function of multiplicities of algebraic points in a
projective hypersurface over a number field, and take the sum over all
algebraic points of bounded height and fixed degree. An upper bound for the sum
with respect to this counting function will be given in terms of the degree of
the hypersurface, the dimension of the singular locus, the upper bounds of
height, and the degree of the field of definition.
",Mathematics
"  In this paper we show novel underlying connections between fractional powers
of the Laplacian on the unit sphere and functions from analytic number theory
and differential geometry, like the Hurwitz zeta function and the
Minakshisundaram zeta function. Inspired by Minakshisundaram's ideas, we find a
precise pointwise description of $(-\Delta_{\mathbb{S}^{n-1}})^s u(x)$ in terms
of fractional powers of the Dirichlet-to-Neumann map on the sphere. The Poisson
kernel for the unit ball will be essential for this part of the analysis. On
the other hand, by using the heat semigroup on the sphere, additional pointwise
integro-differential formulas are obtained. Finally, we prove a
characterization with a local extension problem and the interior Harnack
inequality.
",Mathematics
"  Homological index of a holomorphic 1-form on a complex analytic variety with
an isolated singular point is an analogue of the usual index of a 1-form on a
non-singular manifold. One can say that it corresponds to the top Chern number
of a manifold. We offer a definition of homological indices for collections of
1-forms on a (purely dimensional) complex analytic variety with an isolated
singular point corresponding to other Chern numbers. We also define new
invariants of germs of complex analytic varieties with isolated singular points
related to ""vanishing Chern numbers"" at them.
",Mathematics
"  In 1997 B. Weiss introduced the notion of measurably entire functions and
proved that they exist on every arbitrary free C- action defined on standard
probability space. In the same paper he asked about the minimal possible growth
of measurably entire functions. In this work we show that for every arbitrary
free C- action defined on a standard probability space there exists a
measurably entire function whose growth does not exceed exp (exp[log^p |z|])
for any p > 3. This complements a recent result by Buhovski, Glücksam,
Logunov, and Sodin (arXiv:1703.08101) who showed that such functions cannot
grow slower than exp (exp[log^p |z|]) for any p < 2.
",Mathematics
"  Extending the notion of maximal green sequences to an abelian category, we
characterize the stability functions, as defined by Rudakov, that induce a
maximal green sequence in an abelian length category. Furthermore, we use
$\tau$-tilting theory to give a description of the wall and chamber structure
of any finite dimensional algebra. Finally we introduce the notion of green
paths in the wall and chamber structure of an algebra and show that green paths
serve as geometrical generalization of maximal green sequences in this context.
",Mathematics
"  In this work we obtain a Liouville theorem for positive, bounded solutions of
the equation $$ (-\Delta)^s u= h(x_N)f(u) \quad \hbox{in }\mathbb{R}^{N} $$
where $(-\Delta)^s$ stands for the fractional Laplacian with $s\in (0,1)$, and
the functions $h$ and $f$ are nondecreasing. The main feature is that the
function $h$ changes sign in $\mathbb{R}$, therefore the problem is sometimes
termed as indefinite. As an application we obtain a priori bounds for positive
solutions of some boundary value problems, which give existence of such
solutions by means of bifurcation methods.
",Mathematics
"  In this paper we prove a global result for the Schrödinger map problem with
initial data with small Besov norm at critical regularity.
",Mathematics
"  Kenmotsu's formula describes surfaces in Euclidean 3-space by their mean
curvature functions and Gauss maps. In Lorentzian 3-space,
Akutagawa-Nishikawa's formula and Magid's formula are Kenmotsu-type formulas
for spacelike surfaces and for timelike surfaces, respectively. We apply them
to a few problems concerning rotational or helicoidal surfaces with constant
mean curvature. Before that, we show that the three formulas above can be
written in a unified single equation.
",Mathematics
"  Fixed point iterations play a central role in the design and the analysis of
a large number of optimization algorithms. We study a new iterative scheme in
which the update is obtained by applying a composition of quasinonexpansive
operators to a point in the affine hull of the orbit generated up to the
current iterate. This investigation unifies several algorithmic constructs,
including Mann's mean value method, inertial methods, and multi-layer
memoryless methods. It also provides a framework for the development of new
algorithms, such as those we propose for solving monotone inclusion and
minimization problems.
",Mathematics
"  We present and analyze a new space-time finite element method for the
solution of neural field equations with transmission delays. The numerical
treatment of these systems is rare in the literature and currently has several
restrictions on the spatial domain and the functions involved, such as
connectivity and delay functions. The use of a space-time discretization, with
basis functions that are discontinuous in time and continuous in space
(dGcG-FEM), is a natural way to deal with space-dependent delays, which is
important for many neural field applications. In this article we provide a
detailed description of a space-time dGcG-FEM algorithm for neural delay
equations, including an a-priori error analysis. We demonstrate the application
of the dGcG-FEM algorithm on several neural field models, including problems
with an inhomogeneous kernel.
",Mathematics
"  In the spirit of recent work of Lamm, Malchiodi and Micallef in the setting
of harmonic maps, we identify Yang-Mills connections obtained by approximations
with respect to the Yang-Mills {\alpha}-energy. More specifically, we show that
for the SU(2) Hopf fibration over the four sphere, for sufficiently small
{\alpha} values the SO(4) invariant ADHM instanton is the unique
{\alpha}-critical point which has Yang-Mills {\alpha}-energy lower than a
specific threshold.
",Mathematics
"  Suppose we have a elliptic curve over a number field whose mod $l$
representation has image isomorphic to $SL_2(\mathbb{F}_l)$. We present a
method to determine Frobenius elements of the associated Galois group which
incorporates the linear structure available. We are able to distinguish
$SL_n(\mathbb{F}_l)$-conjugacy from $GL_n(\mathbb{F}_l)$-conjugacy; this can be
thought of as being analogous to a result which distinguishes $A_n$-conjugacy
from $S_n$-conjugacy when the Galois group is considered as a permutation
group.
",Mathematics
"  In this article, we study the Kapustin-Witten equations on a closed,
simply-connected, four-manifold. We using a compactness theorem due to Taubes
to prove that if $(A,\phi)$ is a solution of Kapustin-Witten equations and the
connection $A$ is closed to a $generic$ ASD connection $A_{\infty}$, then
$(A,\phi)$ must be a trivial solution. We also prove that the moduli space of
the solutions of Kapustin-Witten equations is non-connected if the connections
on the compactification of moduli space of ASD connections are all $generic$.
As one application, we extend the ideas of Kapustin-Witten equations to other
equations on gauge theory-- Hitchin-Simpson equations and Vafa-Witten on
compact Kähler surface with a Kähler metric $g$.
",Mathematics
"  A Schottky structure on a handlebody $M$ of genus $g$ is provided by a
Schottky group of rank $g$. A symmetry (an orientation-reversing involution) of
$M$ is known to have at most $(g+1)$ connected components of fixed points. Each
of these components is either a point or a compact bordered surface (either
orientable or not) whose boundary is contained in the border of $M$. In this
paper, we derive sharp upper bounds for the total number of connected
components of the sets of fixed points of given two or three symmetries of $M$.
In order to obtain such an upper bound, we obtain a geometrical structure
description of those extended Kleinian groups $K$ containing a Schottky group
$\Gamma$ as finite index normal subgroup so that $K/\Gamma$ is a dihedral group
(called dihedral Schottky groups). Our upper bounds turn out to be different to
the corresponding ones at the level of closed Riemann surfaces. In contrast to
the case of Riemann surfaces, we observe that $M$ cannot have two different
maximal symmetries.
",Mathematics
"  Our goal is to find classes of convolution semigroups on Lie groups $G$ that
give rise to interesting processes in symmetric spaces $G/K$. The
$K$-bi-invariant convolution semigroups are a well-studied example. An
appealing direction for the next step is to generalise to right $K$-invariant
convolution semigroups, but recent work of Liao has shown that these are in
one-to-one correspondence with $K$-bi-invariant convolution semigroups. We
investigate a weaker notion of right $K$-invariance, but show that this is, in
fact, the same as the usual notion. Another possible approach is to use
generalised notions of negative definite functions, but this also leads to
nothing new. We finally find an interesting class of convolution semigroups
that are obtained by making use of the Cartan decomposition of a semisimple Lie
group, and the solution of certain stochastic differential equations. Examples
suggest that these are well-suited for generating random motion along geodesics
in symmetric spaces.
",Mathematics
"  Schmerl and Beklemishev's work on iterated reflection achieves two aims: It
introduces the important notion of $\Pi^0_1$-ordinal, characterizing the
$\Pi^0_1$-theorems of a theory in terms of transfinite iterations of
consistency; and it provides an innovative calculus to compute the
$\Pi^0_1$-ordinals for a range of theories. The present note demonstrates that
these achievements are independent: We read off $\Pi^0_1$-ordinals from a
Schütte-style ordinal analysis via infinite proofs, in a direct and
transparent way.
",Mathematics
"  Schubert polynomials are a basis for the polynomial ring that represent
Schubert classes for the flag manifold. In this paper, we introduce and develop
several new combinatorial models for Schubert polynomials that relate them to
other known bases including key polynomials and fundamental slide polynomials.
We unify these and existing models by giving simple bijections between the
combinatorial objects indexing each. In particular, we give a simple bijective
proof that the balanced tableaux of Edelman and Greene enumerate reduced
expressions and a direct combinatorial proof of Kohnert's algorithm for
computing Schubert polynomials. Further, we generalize the insertion algorithm
of Edelman and Greene to give a bijection between reduced expressions and pairs
of tableaux of the same key diagram shape and use this to give a simple
formula, directly in terms of reduced expressions, for the key polynomial
expansion of a Schubert polynomial.
",Mathematics
"  For characterizing the Brownian motion in a bounded domain: $\Omega$, it is
well-known that the boundary conditions of the classical diffusion equation
just rely on the given information of the solution along the boundary of a
domain; on the contrary, for the Lévy flights or tempered Lévy flights in a
bounded domain, it involves the information of a solution in the complementary
set of $\Omega$, i.e., $\mathbb{R}^n\backslash \Omega$, with the potential
reason that paths of the corresponding stochastic process are discontinuous.
Guided by probability intuitions and the stochastic perspectives of anomalous
diffusion, we show the reasonable ways, ensuring the clear physical meaning and
well-posedness of the partial differential equations (PDEs), of specifying
`boundary' conditions for space fractional PDEs modeling the anomalous
diffusion. Some properties of the operators are discussed, and the
well-posednesses of the PDEs with generalized boundary conditions are proved.
",Mathematics
"  Given any Koszul algebra of finite global dimension one can define a new
algebra, which we call a higher zigzag algebra, as a twisted trivial extension
of the Koszul dual of our original algebra. If our original algebra is the path
algebra of a quiver whose underlying graph is a tree, this construction
recovers the zigzag algebras of Huerfano and Khovanov. We study examples of
higher zigzag algebras coming from Iyama's iterative construction of type A
higher representation finite algebras. We give presentations of these algebras
by quivers and relations, and describe relations between spherical twists
acting on their derived categories. We then make a connection to the McKay
correspondence in higher dimensions: if G is a finite abelian subgroup of the
special linear group acting on affine space, then the skew group algebra which
controls the category of G-equivariant sheaves is Koszul dual to a higher
zigzag algebra. Using this, we show that our relations between spherical twists
appear naturally in examples from algebraic geometry.
",Mathematics
"  We introduce a reduction from the distinct distances problem in ${\mathbb
R}^d$ to an incidence problem with $(d-1)$-flats in ${\mathbb R}^{2d-1}$.
Deriving the conjectured bound for this incidence problem (the bound predicted
by the polynomial partitioning technique) would lead to a tight bound for the
distinct distances problem in ${\mathbb R}^d$. The reduction provides a large
amount of information about the $(d-1)$-flats, and a framework for deriving
more restrictions that these satisfy. Our reduction is based on introducing a
Lie group that is a double cover of the special Euclidean group. This group can
be seen as a variant of the Spin group, and a large part of our analysis
involves studying its properties.
",Mathematics
"  Let $G,H$ be groups, $\phi: G \rightarrow H$ a group morphism, and $A$ a
$G$-graded algebra. The morphism $\phi$ induces an $H$-grading on $A$, and on
any $G$-graded $A$-module, which thus becomes an $H$-graded $A$-module. Given
an injective $G$-graded $A$-module, we give bounds for its injective dimension
when seen as $H$-graded $A$-module. Following ideas by Van den Bergh, we give
an application of our results to the stability of dualizing complexes through
change of grading.
",Mathematics
"  In previous work, we defined and studied $\Sigma^*$-modules, a class of
Hilbert $C^*$-modules over $\Sigma^*$-algebras (the latter are $C^*$-algebras
that are sequentially closed in the weak operator topology). The present work
continues this study by developing the appropriate $\Sigma^*$-algebraic
analogue of the notion of strong Morita equivalence for $C^*$-algebras. We
define strong $\Sigma^*$-Morita equivalence, prove a few characterizations,
look at the relationship with equivalence of categories of a certain type of
Hilbert space representation, study $\Sigma^*$-versions of the interior and
exterior tensor products, and prove a $\Sigma^*$-version of the
Brown-Green-Rieffel stable isomorphism theorem.
",Mathematics
"  The article is about the representation theory of an inner form~$G$ of a
general linear group over a non-archimedean local field. We introduce
semisimple characters for~$G$ whose intertwining classes describe conjecturally
via Local Langlands correspondence the behavior on wild inertia. These
characters also play a potential role to understand the classification of
irreducible smooth representations of inner forms of classical groups. We prove
the intertwining formula for semisimple characters and an intertwining implies
conjugacy like theorem. Further we show that endo-parameters for~$G$, i.e.
invariants consisting of simple endo-classes and a numerical part, classify the
intertwining classes of semisimple characters for~$G$. They should be the
counter part for restrictions of Langlands-parameters to wild inertia under
Local Langlands correspondence.
",Mathematics
"  In this paper, a theory of quandle rings is proposed for quandles analogous
to the classical theory of group rings for groups, and interconnections between
quandles and associated quandle rings are explored.
",Mathematics
"  We study the indices of the geodesic central configurations on $\H^2$. We
then show that central configurations are bounded away from the singularity
set. With Morse's inequality, we get a lower bound for the number of central
configurations on $\H^2$.
",Mathematics
"  We provide an explicit presentation of an infinite hyperbolic Kazhdan group
with $4$ generators and $16$ relators of length at most $73$. That group acts
properly and cocompactly on a hyperbolic triangle building of type $(3,4,4)$.
We also point out a variation of the construction that yields examples of
lattices in $\tilde A_2$-buildings admitting non-Desarguesian residues of
arbitrary prime power order.
",Mathematics
"  We explore the existence of global weak solutions to the Hookean dumbbell
model, a system of nonlinear partial differential equations that arises from
the kinetic theory of dilute polymers, involving the unsteady incompressible
Navier--Stokes equations in a bounded domain in two or three space dimensions,
coupled to a Fokker--Planck-type parabolic equation. We prove the existence of
large-data global weak solutions in the case of two space dimensions.
Indirectly, our proof also rigorously demonstrates that, in two space
dimensions at least, the Oldroyd-B model is the macroscopic closure of the
Hookean dumbbell model. In three space dimensions, we prove the existence of
large-data global weak subsolutions to the model, which are weak solutions with
a defect measure, where the defect measure appearing in the Navier--Stokes
momentum equation is the divergence of a symmetric positive semidefinite
matrix-valued Radon measure.
",Mathematics
"  We explore all warped $AdS_4\times_w M^{D-4}$ backgrounds with the most
general allowed fluxes that preserve more than 16 supersymmetries in $D=10$-
and $11$-dimensional supergravities. After imposing the assumption that either
the internal space $M^{D-4}$ is compact without boundary or the isometry
algebra of the background decomposes into that of AdS$_4$ and that of
$M^{D-4}$, we find that there are no such backgrounds in IIB supergravity.
Similarly in IIA supergravity, there is a unique such background with 24
supersymmetries locally isometric to $AdS_4\times \mathbb{CP}^3$, and in $D=11$
supergravity all such backgrounds are locally isometric to the maximally
supersymmetric $AdS_4\times S^7$ solution.
",Mathematics
"  By assuming some widely-believed arithmetic conjectures, we show that the
task of accepting a number that is representable as a sum of $d\geq2$ squares
subjected to given congruence conditions is NP-complete. On the other hand, we
develop and implement a deterministic polynomial-time algorithm that represents
a number as a sum of 4 squares with some restricted congruence conditions, by
assuming a polynomial-time algorithm for factoring integers and
Conjecture~\ref{cc}. As an application, we develop and implement a
deterministic polynomial-time algorithm for navigating LPS Ramanujan graphs,
under the same assumptions.
",Mathematics
"  A scheme making use of an isolated feedback loop was recently proposed in
\cite{GP_} for creating an arbitrary bilinear Hamiltonian interaction between
two multi-mode Linear Quantum Stochastic Systems (LQSSs). In this work we
examine the presence of an isolated feedback loop in a general SLH network, and
derive the modified Hamiltonian of the network due to the presence of the loop.
In the case of a bipartite network with an isolated loop running through both
parts, this results in modified Hamiltonians for each subnetwork, as well as a
Hamiltonian interaction between them. As in the LQSS case, by engineering
appropriate ports in each subnetwork, we may create desired interactions
between them. Examples are provided that illustrate the general theory.
",Mathematics
"  We construct an analog of the intrinsic normal cone of Behrend-Fantechi in
the equivariant motivic stable homotopy category over a base-scheme B and
construct a fundament class in E-cohomology for any cohomology theory E in
SH(B). For affine B, a perfect obstruction theory gives rise to a virtual
fundamental class in a twisted Borel-Moore E-homology for arbitrary E. This
includes motivic cohomology (homotopy invariant) K-theory algebraic cobordism
and the oriented Chow groups of Barge-Morel and Fasel. In the case of motivic
cohomology, we recover the constructions of Behrend-Fantechi, with values in
the Chow group.
",Mathematics
"  We introduce and study ternary $f$-distributive structures, Ternary
$f$-quandles and more generally their higher $n$-ary analogues. A
classification of ternary $f$-quandles is provided in low dimensions. Moreover,
we study extension theory and introduce a cohomology theory for ternary, and
more generally $n$-ary, $f$-quandles. Furthermore, we give some computational
examples.
",Mathematics
"  In this paper, we give some counting results on integer polynomials of fixed
degree and bounded height whose distinct non-zero roots are multiplicatively
dependent. These include sharp lower bounds, upper bounds and asymptotic
formulas for various cases, although in general there is a logarithmic gap
between lower and upper bounds.
",Mathematics
"  In this paper, we deal with the null controllability of a population dynamics
model with an interior degenerate diffusion. To this end, we proved first a new
Carleman estimate for the full adjoint system and afterwards we deduce a
suitable observability inequality which will be needed to establish the
existence of a control acting on a subset of the space which lead the
population to extinction in a finite time.
",Mathematics
"  We give sufficient conditions of the nonnegative inverse eigenvalue problem
(NIEP) for normal centrosymmetric matrices. These sufficient conditions are
analogous to the sufficient conditions of the NIEP for normal matrices given by
Xu [16] and Julio, Manzaneda and Soto [2].
",Mathematics
"  Our purpose in this present paper is to investigate generalized integration
formulas containing the extended generalized hypergeometric function and
obtained results are expressed in terms of extended hypergeometric function.
Certain special cases of the main results presented here are also pointed out
for the extended Gauss' hypergeometric and confluent hypergeometric functions.
",Mathematics
"  We show that Zamolodchikov dynamics of a recurrent quiver has zero algebraic
entropy only if the quiver has a weakly subadditive labeling, and conjecture
the converse. By assigning a pair of generalized Cartan matrices of affine type
to each quiver with an additive labeling, we completely classify such quivers,
obtaining $40$ infinite families and $13$ exceptional quivers. This completes
the program of classifying Zamolodchikov periodic and integrable quivers.
",Mathematics
"  We develop a general polynomial chaos (gPC) based stochastic Galerkin (SG)
for hyperbolic equations with random and singular coefficients. Due to the
singu- lar nature of the solution, the standard gPC-SG methods may suffer from
a poor or even non convergence. Taking advantage of the fact that the discrete
solution, by the central type finite difference or finite volume approximations
in space and time for example, is smoother, we first discretize the equation by
a smooth finite difference or finite volume scheme, and then use the gPC-SG
approximation to the discrete system. The jump condition at the interface is
treated using the immersed upwind methods introduced in [8, 12]. This yields a
method that converges with the spectral accuracy for finite mesh size and time
step. We use a linear hyperbolic equation with discontinuous and random
coefficient, and the Liouville equation with discontinuous and random
potential, to illustrate our idea, with both one and second order spatial
discretizations. Spectral convergence is established for the first equation,
and numerical examples for both equations show the desired accu- racy of the
method.
",Mathematics
"  The inverse problem of antiplane elasticity on determination of the profiles
of $n$ uniformly stressed inclusions is studied. The inclusions are in ideal
contact with the surrounding matrix, the stress field inside the inclusions is
uniform, and at infinity the body is subjected to antiplane uniform shear. The
exterior of the inclusions, an $n$-connected domain, is treated as the image by
a conformal map of an $n$-connected slit domain with the slits lying in the
same line. The inverse problem is solved by quadratures by reducing it to two
Riemann-Hilbert problems on a Riemann surface of genus $n-1$. Samples of two
and three symmetric and non-symmetric uniformly stressed inclusions are
reported.
",Mathematics
"  We consider a certain quotient of a polynomial ring categorified by both the
isomorphic Green rings of the symmetric groups and Schur algebras generated by
the signed Young permutation modules and mixed powers respectively. They have
bases parametrised by pairs of partitions whose second partitions are multiples
of the odd prime $p$ the characteristic of the underlying field. We provide an
explicit formula rewriting a signed Young permutation module (respectively,
mixed power) in terms of signed Young permutation modules (respectively, mixed
powers) labelled by those pairs of partitions. As a result, for each partition
$\lambda$, we discovered the number of compositions $\delta$ such that $\delta$
can be rearranged to $\lambda$ and whose partial sums of $\delta$ are not
divisible by $p$.
",Mathematics
"  We consider the Schrödinger equation on a half space in any dimension with
a class of nonhomogeneous boundary conditions including Dirichlet, Neuman and
the so-called transparent boundary conditions. Building upon recent local in
time Strichartz estimates (for Dirichlet boundary conditions), we obtain global
Strichartz estimates for initial data in $H^s,\ 0\leq s\leq 2$ and boundary
data in a natural space $\mathcal{H}^s$. For $s\geq 1/2$, the issue of
compatibility conditions requires a thorough analysis of the $\mathcal{H}^s$
space. As an application we solve nonlinear Schrödinger equations and
construct global asymptotically linear solutions for small data. A discussion
is included on the appropriate notion of scattering in this framework, and the
optimality of the $\mathcal{H}^s$ space.
",Mathematics
"  We say that a finite metric space $X$ can be embedded almost isometrically
into a class of metric spaces $C$, if for every $\epsilon > 0$ there exists an
embedding of $X$ into one of the elements of $C$ with the bi-Lipschitz
distortion less then $1 + \epsilon$. We show that almost isometric
embeddability conditions are equal for following classes of spaces
(a) Quotients of Euclidean spaces by isometric actions of finite groups,
(b) $L_2$-Wasserstein spaces over Euclidean spaces,
(c) Compact flat manifolds,
(d) Compact flat orbifolds,
(e) Quotients of bi-invariant Lie groups by isometric actions of compact Lie
groups. (This one is the most surprising.)
We call spaces which satisfy this conditions finite flat spaces. The question
about synthetic definition naturally arises.
Since Markov type constants depend only on finite subsets we can conclude
that bi-invariant Lie groups and their quotients have Markov type $2$ with
constant $1$.
",Mathematics
"  A recent heuristic argument based on basic concepts in spectral analysis
showed that the twin prime conjecture and a few other related primes counting
problems are valid. A rigorous version of the spectral method, and a proof for
the existence of infinitely many quadratic twin primes $n^{2}+1$ and $n^{2}+3$,
$n \geq 1$, are proposed in this note.
",Mathematics
"  This paper presents a novel method that allows to generalise the use of the
Adam-Bashforth to Partial Differential Equations with local and non local
operator. The Method derives a two step Adam-Bashforth numerical scheme in
Laplace space and the solution is taken back into the real space via inverse
Laplace transform. The method yields a powerful numerical algorithm for
fractional order derivative where the usually very difficult to manage
summation in the numerical scheme disappears. Error Analysis of the method is
also presented. Applications of the method and numerical simulations are
presented on a wave-equation like, and on a fractional order diffusion
equation.
",Mathematics
"  Necessary and sufficient conditions for finite semihypergroups to be built
from groups of the same order are established
",Mathematics
"  We study the limit shape of successive coronas of a tiling, which models the
growth of crystals. We define basic terminologies and discuss the existence and
uniqueness of corona limits, and then prove that corona limits are completely
characterized by directional speeds. As an application, we give another proof
that the corona limit of a periodic tiling is a centrally symmetric convex
polyhedron (see [Zhuravlev 2001], [Maleev-Shutov 2011]).
",Mathematics
"  Inspired by Katok's examples of Finsler metrics with a small number of closed
geodesics, we present two results on Reeb flows with finitely many periodic
orbits. The first result is concerned with a contact-geometric description of
magnetic flows on the 2-sphere found recently by Benedetti. We give a simple
interpretation of that work in terms of a quaternionic symmetry. In the second
part, we use Hamiltonian circle actions on symplectic manifolds to produce
compact, connected contact manifolds in dimension at least five with
arbitrarily large numbers of periodic Reeb orbits. This contrasts sharply with
recent work by Cristofaro-Gardiner, Hutchings and Pomerleano on Reeb flows in
dimension three. With the help of Hamiltonian plugs and a surgery construction
due to Laudenbach we reprove a result of Cieliebak: one can produce Hamiltonian
flows in dimension at least five with any number of periodic orbits; in
dimension three, with any number greater than one.
",Mathematics
"  Any finite word $w$ of length $n$ contains at most $n+1$ distinct palindromic
factors. If the bound $n+1$ is reached, the word $w$ is called rich. The number
of rich words of length $n$ over an alphabet of cardinality $q$ is denoted
$R_n(q)$. For binary alphabet, Rubinchik and Shur deduced that ${R_n(2)}\leq c
1.605^n $ for some constant $c$. We prove that $\lim\limits_{n\rightarrow
\infty }\sqrt[n]{R_n(q)}=1$ for any $q$, i.e. $R_n(q)$ has a subexponential
growth on any alphabet.
",Mathematics
"  We derive a priori estimates for the incompressible free-boundary Euler
equations with surface tension in three spatial dimensions. Working in
Lagrangian coordinates, we provide a priori estimates for the local existence
when the initial velocity, which is rotational, belongs to $H^3$ and the trace
of initial velocity on the free boundary to $H^{3.5}$, thus lowering the
requirement on the regularity of initial data in the Lagrangian setting. Our
methods are direct and involve three key elements: estimates for the pressure,
the boundary regularity provided by the mean curvature, and the Cauchy
invariance.
",Mathematics
"  We prove that if $X---> X^+$ is a threefold terminal flip, then
$c_1(X).c_2(X)\leq c_1(X^+).c_2(X^+)$ where $c_1(X)$ and $c_2(X)$ denote the
Chern classes. This gives the affirmative answer to a Question by Xie
\cite{Xie2}. We obtain the similar but weaker result in the case of divisorial
contraction to curves.
",Mathematics
"  In this expository work we discuss the asymptotic behaviour of the solutions
of the classical heat equation posed in the whole Euclidean space.
After an introductory review of the main facts on the existence and
properties of solutions, we proceed with the proofs of convergence to the
Gaussian fundamental solution, a result that holds for all integrable
solutions, and represents in the PDE setting the Central Limit Theorem of
probability. We present several methods of proof: first, the scaling method.
Then several versions of the representation method. This is followed by the
functional analysis approach that leads to the famous related equations,
Fokker-Planck and Ornstein-Uhlenbeck. The analysis of this connection is also
given in rather complete form here. Finally, we present the Boltzmann entropy
method, coming from kinetic equations.
The different methods are interesting because of the possible extension to
prove the asymptotic behaviour or stabilization analysis for more general
equations, linear or nonlinear. It all depends a lot on the particular
features, and only one or some of the methods work in each case.Other settings
of the Heat Equation are briefly discussed in Section 9 and a longer mention of
results for different equations is done in Section 10.
",Mathematics
"  We classify finite $p$-groups, upto isoclinism, which have only two conjugacy
class sizes $1$ and $p^3$. It turns out that the nilpotency class of such
groups is $2$.
",Mathematics
"  We study the existence of homoclinic type solutions for second order
Lagrangian systems of the type $\ddot{q}(t)-q(t)+a(t)\nabla G(q(t))=f(t)$,
where $t\in\mathbb{R}$, $q\in\mathbb{R}^n$, $a\colon\mathbb{R}\to\mathbb{R}$ is
a continuous positive bounded function, $G\colon\mathbb{R}^n\to\mathbb{R}$ is a
$C^1$-smooth potential satisfying the Ambrosetti-Rabinowitz superquadratic
growth condition and $f\colon\mathbb{R}\to\mathbb{R}^n$ is a continuous bounded
square integrable forcing term. A homoclinic type solution is obtained as limit
of $2k$-periodic solutions of an approximative sequence of second order
differential equations.
",Mathematics
"  We associate to every central simple algebra with involution of orthogonal
type in characteristic two a totally singular quadratic form which reflects
certain anisotropy properties of the involution. It is shown that this
quadratic form can be used to classify totally decomposable algebras with
orthogonal involution. Also, using this form, a criterion is obtained for an
orthogonal involution on a split algebra to be conjugated to the transpose
involution.
",Mathematics
"  We apply the Min-Sum message-passing protocol to solve the consensus problem
in distributed optimization. We show that while the ordinary Min-Sum algorithm
does not converge, a modified version of it known as Splitting yields
convergence to the problem solution. We prove that a proper choice of the
tuning parameters allows Min-Sum Splitting to yield subdiffusive accelerated
convergence rates, matching the rates obtained by shift-register methods. The
acceleration scheme embodied by Min-Sum Splitting for the consensus problem
bears similarities with lifted Markov chains techniques and with multi-step
first order methods in convex optimization.
",Mathematics
"  We survey the dimension theory of self-affine sets for general mathematical
audience. The article is in Finnish.
",Mathematics
"  We consider a piecewise deterministic Markov decision process, where the
expected exponential utility of total (nonnegative) cost is to be minimized.
The cost rate, transition rate and post-jump distributions are under control.
The state space is Borel, and the transition and cost rates are locally
integrable along the drift. Under natural conditions, we establish the
optimality equation, justify the value iteration algorithm, and show the
existence of a deterministic stationary optimal policy. Applied to special
cases, the obtained results already significantly improve some existing results
in the literature on finite horizon and infinite horizon discounted
risk-sensitive continuous-time Markov decision processes.
",Mathematics
"  We prove that certain conditions on multigraded Betti numbers of a simplicial
complex $K$ imply existence of a higher Massey product in cohomology of a
moment-angle-complex $\mathcal Z_K$, which contains a unique element (a
strictly defined product). Using the simplicial multiwedge construction, we
find a family $\mathcal{F}$ of polyhedral products being smooth closed
manifolds such that for any $l,r\geq 2$ there exists an $l$-connected manifold
$M\in\mathcal F$ with a nontrivial strictly defined $r$-fold Massey product in
$H^{*}(M)$. As an application to homological algebra, we determine a wide class
of triangulated spheres $K$ such that a nontrivial higher Massey product of any
order may exist in Koszul homology of their Stanley--Reisner rings. As an
application to rational homotopy theory, we establish a combinatorial criterion
for a simple graph $\Gamma$ to provide a (rationally) formal generalized
moment-angle manifold $\mathcal Z_{P}^{J}=(D^{2j_{i}},S^{2j_{i}-1})^{\partial
P^*}$, $J=(j_{1},\ldots,j_m)$ over a graph-associahedron $P=P_{\Gamma}$ and
compute all the diffeomorphism types of formal moment-angle manifolds over
graph-associahedra.
",Mathematics
"  We consider the problem of grid-forming control of power converters in
low-inertia power systems. Starting from an average-switch three-phase inverter
model, we draw parallels to a synchronous machine (SM) model and propose a
novel grid-forming converter control strategy which dwells upon the main
characteristic of a SM: the presence of an internal rotating magnetic field. In
particular, we augment the converter system with a virtual oscillator whose
frequency is driven by the DC-side voltage measurement and which sets the
converter pulse-width-modulation signal, thereby achieving exact matching
between the converter in closed-loop and the SM dynamics. We then provide a
sufficient condition assuring existence, uniqueness, and global asymptotic
stability of equilibria in a coordinate frame attached to the virtual
oscillator angle. By actuating the DC-side input of the converter we are able
to enforce this sufficient condition. In the same setting, we highlight strict
incremental passivity, droop, and power-sharing properties of the proposed
framework, which are compatible with conventional requirements of power system
operation. We subsequently adopt disturbance decoupling techniques to design
additional control loops that regulate the DC-side voltage, as well as AC-side
frequency and amplitude, while in the end validating them with numerical
experiments.
",Mathematics
"  We interpret augmented racks as a certain kind of multiplicative graphs and
show that this point of view is natural for defining rack homology. We also
define the analogue of the group algebra for these objects; in particular, we
see how discrete racks give rise to Hopf algebras and Lie algebras in the
Loday-Pirashvili category $\mathcal{LM}$. Finally, we discuss the integration
of Lie algebras in $\mathcal{LM}$ in the context of multiplicative graphs and
augmented racks.
",Mathematics
"  We give a survey of a generalization of Quillen-Sullivan rational homotopy
theory which gives spectral algebra models of unstable v_n-periodic homotopy
types. In addition to describing and contextualizing our original approach, we
sketch two other recent approaches which are of a more conceptual nature, due
to Arone-Ching and Heuts. In the process, we also survey many relevant concepts
which arise in the study of spectral algebra over operads, including
topological André-Quillen cohomology, Koszul duality, and Goodwillie
calculus.
",Mathematics
"  This work builds on earlier results. We define universal elliptic Gau{\ss}
sums for Atkin primes in Schoof's algorithm for counting points on elliptic
curves. Subsequently, we show these quantities admit an efficiently computable
representation in terms of the $j$-invariant and two other modular functions.
We analyse the necessary computations in detail and derive an alternative
approach for determining the trace of the Frobenius homomorphism for Atkin
primes using these pre-computations. A rough run-time analysis shows, however,
that this new method is not competitive with existing ones.
",Mathematics
"  Differential calculus on Euclidean spaces has many generalisations. In
particular, on a set $X$, a diffeological structure is given by maps from open
subsets of Euclidean spaces to $X$, a differential structure is given by maps
from $X$ to $\mathbb{R}$, and a Frölicher structure is given by maps from
$\mathbb{R}$ to $X$ as well as maps from $X$ to $\mathbb{R}$. We illustrate the
relations between these structures through examples.
",Mathematics
"  In this work we mainly consider the dynamics and scattering of a narrow
soliton of NLS equation with a potential in $\mathbb{R}^3$, where the
asymptotic state of the system can be far from the initial state in parameter
space. Specifically, if we let a narrow soliton state with initial velocity
$\upsilon_{0}$ to interact with an extra potential $V(x)$, then the velocity
$\upsilon_{+}$ of outgoing solitary wave in infinite time will in general be
very different from $\upsilon_{0}$. In contrast to our present work, previous
works proved that the soliton is asymptotically stable under the assumption
that $\upsilon_{+}$ stays close to $\upsilon_{0}$ in a certain manner.
",Mathematics
"  We prove a general width duality theorem for combinatorial structures with
well-defined notions of cohesion and separation. These might be graphs and
matroids, but can be much more general or quite different. The theorem asserts
a duality between the existence of high cohesiveness somewhere local and a
global overall tree structure.
We describe cohesive substructures in a unified way in the format of tangles:
as orientations of low-order separations satisfying certain consistency axioms.
These axioms can be expressed without reference to the underlying structure,
such as a graph or matroid, but just in terms of the poset of the separations
themselves. This makes it possible to identify tangles, and apply our
tangle-tree duality theorem, in very diverse settings.
Our result implies all the classical duality theorems for width parameters in
graph minor theory, such as path-width, tree-width, branch-width or rank-width.
It yields new, tangle-type, duality theorems for tree-width and path-width. It
implies the existence of width parameters dual to cohesive substructures such
as $k$-blocks, edge-tangles, or given subsets of tangles, for which no width
duality theorems were previously known.
Abstract separation systems can be found also in structures quite unlike
graphs and matroids. For example, our theorem can be applied to image analysis
by capturing the regions of an image as tangles of separations defined as
natural partitions of its set of pixels. It can be applied in big data contexts
by capturing clusters as tangles. It can be applied in the social sciences,
e.g. by capturing as tangles the few typical mindsets of individuals found by a
survey. It could also be applied in pure mathematics, e.g. to separations of
compact manifolds.
",Mathematics
"  We study a variational Ginzburg-Landau type model depending on a small
parameter $\epsilon>0$ for (tangent) vector fields on a $2$-dimensional
Riemannian surface. As $\epsilon\to 0$, the vector fields tend to be of unit
length and will have singular points of a (non-zero) index, called vortices.
Our main result determines the interaction energy between these vortices as a
$\Gamma$-limit (at the second order) as $\epsilon\to 0$.
",Mathematics
"  We establish effective mean-value estimates for a wide class of
multiplicative arithmetic functions, thereby providing (essentially optimal)
quantitative versions of Wirsing's classical estimates and extending those of
Halász. Several applications are derived, including: estimates for the
difference of mean-values of so-called pretentious functions, local laws for
the distribution of prime factors in an arbitrary set, and weighted
distribution of additive functions.
",Mathematics
"  We prove versions of Khintchine's Theorem (1924) for approximations by
rational numbers whose numerators lie in randomly chosen sets of integers, and
we explore the extent to which the monotonicity assumption can be removed.
Roughly speaking, we show that if the number of available fractions for each
denominator grows too fast, then the monotonicity assumption cannot be removed.
There are questions in this random setting which may be seen as cognates of the
Duffin-Schaeffer Conjecture (1941), and are likely to be more accessible. We
point out that the direct random analogue of the Duffin-Schaeffer Conjecture,
like the Duffin-Schaeffer Conjecture itself, implies Catlin's Conjecture
(1976). It is not obvious whether the Duffin-Schaeffer Conjecture and its
random version imply one another, and it is not known whether Catlin's
Conjecture implies either of them. The question of whether Catlin implies
Duffin-Schaeffer has been unsettled for decades.
",Mathematics
"  In bounded smooth domains $\Omega\subset\mathbb{R}^N$, $N\in\{2,3\}$,
considering the chemotaxis--fluid system
\[ \begin{cases} \begin{split} & n_t + u\cdot \nabla n &= \Delta n - \chi
\nabla \cdot(\frac{n}{c}\nabla c) &\\ & c_t + u\cdot \nabla c &= \Delta c - c +
n &\\ & u_t + \kappa (u\cdot \nabla) u &= \Delta u + \nabla P + n\nabla \Phi &
\end{split}\end{cases} \] with singular sensitivity, we prove global existence
of classical solutions for given $\Phi\in C^2(\bar{\Omega})$, for $\kappa=0$
(Stokes-fluid) if $N=3$ and $\kappa\in\{0,1\}$ (Stokes- or Navier--Stokes
fluid) if $N=2$ and under the condition that \[
0<\chi<\sqrt{\frac{2}{N}}. \]
",Mathematics
"  For a second order operator on a compact manifold satisfying the strong
Hörmander condition, we give a bound for the spectral gap analogous to the
Lichnerowicz estimate for the Laplacian of a Riemannian manifold. We consider a
wide class of such operators which includes horizontal lifts of the Laplacian
on Riemannian submersions with minimal leaves.
",Mathematics
"  We consider some properties of integrals considered by Hardy and Koshliakov,
and which have also been further extended recently by Dixit. We establish a new
general integral formula from some observations about the digamma function. We
also obtain lower and upper bounds for Hardy's integral through properties of
the digamma function.
",Mathematics
"  We will say that an Abelian group $\Gamma$ of order $n$ has the
$m$-\emph{zero-sum-partition property} ($m$-\textit{ZSP-property}) if $m$
divides $n$, $m\geq 2$ and there is a partition of $\Gamma$ into pairwise
disjoint subsets $A_1, A_2,\ldots , A_t$, such that $|A_i| = m$ and $\sum_{a\in
A_i}a = g_0$ for $1 \leq i \leq t$, where $g_0$ is the identity element of
$\Gamma$.
In this paper we study the $m$-ZSP property of $\Gamma$. We show that
$\Gamma$ has $m$-ZSP if and only if $|\Gamma|$ is odd or $m\geq 3$ and $\Gamma$
has more than one involution. We will apply the results to the study of group
distance magic graphs as well as to generalized Kotzig arrays.
",Mathematics
"  We consider continuous-time Markov chains which display a family of wells at
the same depth. We provide sufficient conditions which entail the convergence
of the finite-dimensional distributions of the order parameter to the ones of a
finite state Markov chain. We also show that the state of the process can be
represented as a time-dependent convex combination of metastable states, each
of which is supported on one well.
",Mathematics
"  Consider a quadratic vector field on $\mathbb{C}^2$ having an invariant line
at infinity and isolated singularities only. We define the extended spectra of
singularities to be the collection of the spectra of the linearization matrices
of each of the singular points over the affine part, together with all the
characteristic numbers (i.e. Camacho-Sad indices) at infinity. This collection
consists of 11 complex numbers, and is invariant under affine equivalence of
vector fields.
In this paper we describe all polynomial relations among these numbers. There
are 5 independent polynomial relations; four of them follow from the
Euler-Jacobi, the Baum-Bott and the Camacho-Sad index theorems, and are well
known. The fifth relation was, until now, completely unknown. We provide an
explicit formula for the missing 5th relation, discuss it's meaning and prove
that it cannot be formulated as an index theorem.
",Mathematics
"  A space $G(M, \varPhi)$ of infinitely differentiable functions in ${\mathbb
R}^n$ constructed with a help of a family
$\varPhi=\{\varphi_m\}_{m=1}^{\infty}$ of real-valued functions $\varphi_m
\in~C({\mathbb R}^n)$ and a logarithmically convex sequence $M$ of positive
numbers is considered in the article. In view of conditions on $M$ each
function of $G(M, \varPhi)$ can be extended to an entire function in ${\mathbb
C}^n$. Imposed conditions on $M$ and $\varPhi$ allow to describe the space of
such extensions.
",Mathematics
"  In this paper, we study general $(\alpha,\beta)$-metrics which $\alpha$ is a
Riemannian metric and $\beta$ is an one-form. We have proven that every weak
Landsberg general $(\alpha,\beta)$-metric is a Berwald metric, where $\beta$ is
a closed and conformal one-form. This show that there exist no generalized
unicorn metric in this class of general $(\alpha,\beta)$-metric. Further, We
show that $F$ is a Landsberg general $(\alpha,\beta)$-metric if and only if it
is weak Landsberg general $(\alpha,\beta)$-metric, where $\beta$ is a closed
and conformal one-form.
",Mathematics
"  New upper bounds on the pointwise behaviour of Christoffel function on convex
domains in ${\mathbb{R}}^d$ are obtained. These estimates are established by
explicitly constructing the corresponding ""needle""-like algebraic polynomials
having small integral norm on the domain, and are stated in terms of few
easy-to-measure geometric characteristics of the location of the point of
interest in the domain. Sharpness of the results is shown and examples of
applications are given.
",Mathematics
"  While Wigner functions forming phase space representation of quantum states
is a well-known fact, their construction for noncommutative quantum mechanics
(NCQM) remains relatively lesser known, in particular with respect to gauge
dependencies. This paper deals with the construction of Wigner functions of
NCQM for a system of 2-degrees of freedom using 2-parameter families of gauge
equivalence classes of unitary irreducible representations (UIRs) of the Lie
group $\g$ which has been identified as the kinematical symmetry group of NCQM
in an earlier paper. This general construction of Wigner functions for NCQM, in
turn, yields the special cases of Landau and symmetric gauges of NCQM.
",Mathematics
"  We study Shimura curves of PEL type in $\mathsf{A}_g$ generically contained
in the Prym locus. We study both the unramified Prym locus, obtained using
étale double covers, and the ramified Prym locus, corresponding to double
covers ramified at two points. In both cases we consider the family of all
double covers compatible with a fixed group action on the base curve. We
restrict to the case where the family is 1-dimensional and the quotient of the
base curve by the group is $\mathbb{P}^1$. We give a simple criterion for the
image of these families under the Prym map to be a Shimura curve. Using
computer algebra we check all the examples gotten in this way up to genus 28.
We obtain 43 Shimura curves generically contained in the unramified Prym locus
and 9 families generically contained in the ramified Prym locus. Most of these
curves are not generically contained in the Jacobian locus.
",Mathematics
"  We exhibit a Hamel basis for the concrete $*$-algebra $\mathfrak{M}_o$
associated to monotone commutation relations realised on the monotone Fock
space, mainly composed by Wick ordered words of annihilators and creators. We
apply such a result to investigate spreadability and exchangeability of the
stochastic processes arising from such commutation relations. In particular, we
show that spreadability comes from a monoidal action implementing a dissipative
dynamics on the norm closure $C^*$-algebra $\mathfrak{M} =
\overline{\mathfrak{M}_o}$. Moreover, we determine the structure of spreadable
and exchangeable monotone stochastic processes using their correspondence with
sp\-reading invariant and symmetric monotone states, respectively.
",Mathematics
"  The $E_8$ root lattice can be constructed from the modular curve $X(13)$ by
the invariant theory for the simple group $\text{PSL}(2, 13)$. This gives a
different construction of the $E_8$ root lattice. It also gives an explicit
construction of the modular curve $X(13)$.
",Mathematics
"  We study definably compact definably connected groups definable in a
sufficiently saturated real closed field $R$. We introduce the notion of
group-generic point for $\bigvee$-definable groups and show the existence of
group-generic points for definably compact groups definable in a sufficiently
saturated o-minimal expansion of a real closed field. We use this notion along
with some properties of generic sets to prove that for every definably compact
definably connected group $G$ definable in $R$ there are a connected
$R$-algebraic group $H$, a definable injective map $\phi$ from a generic
definable neighborhood of the identity of $G$ into the group $H\left(R\right)$
of $R$-points of $H$ such that $\phi$ acts as a group homomorphism inside its
domain. This result is used in [2] to prove that the o-minimal universal
covering group of an abelian connected definably compact group definable in a
sufficiently saturated real closed field $R$ is, up to locally definable
isomorphisms, an open connected locally definable subgroup of the o-minimal
universal covering group of the $R$-points of some $R$-algebraic group.
",Mathematics
"  The theoretical existence of non-classical Schottky groups is due to Marden.
Explicit examples of such kind of groups are only known in rank two, the first
one by by Yamamoto in 1991 and later by Williams in 2009. In 2006, Maskit and
the author provided a theoretical method to obtain examples of non-classical
Schottky groups in any rank. The method assumes the knowledge of some algebraic
limits of Schottky groups, called sufficiently complicated noded Schottky
groups, whose existence was stated. In this paper we provide an explicit
construction of a sufficiently complicated noded Schottky group of rank three
and it is explained how to construct explicit non-classical Schottky groups of
rank three.
",Mathematics
"  The stochastic Gross-Pitaevskii equation is used as a model to describe
Bose-Einstein condensation at positive temperature. The equation is a complex
Ginzburg Landau equation with a trapping potential and an additive space-time
white noise. Two important questions for this system are the global existence
of solutions in the support of the Gibbs measure, and the convergence of those
solutions to the equilibrium for large time. In this paper, we give a proof of
these two results in one space dimension. In order to prove the convergence to
equilibrium, we use the associated purely dissipative equation as an auxiliary
equation, for which the convergence may be obtained using standard techniques.
Global existence is obtained for all initial data, and not almost surely with
respect to the invariant measure.
",Mathematics
"  There are a number of examples of variations of Hodge structure of maximum
dimension. However, to our knowledge, those that are global on the level of the
period domain are totally geodesic subspaces that arise from an orbit of a
subgroup of the group of the period domain. That is, they are defined by Lie
theory rather than by algebraic geometry. In this note, we give an example of a
variation of maximum dimension which is nowhere tangent to a geodesic
variation. The period domain in question, which classifies weight two Hodge
structures with $h^{2,0} = 2$ and $h^{1,1} = 28$, is of dimension $57$. The
horizontal tangent bundle has codimension one, thus it is an example of a
holomorphic contact structure, with local integral manifolds of dimension 28.
The group of the period domain is $SO(4,28)$, and one can produce global
integral manifolds as orbits of the action of subgroups isomorphic to
$SU(2,14)$. Our example is given by the variation of Hodge structure on the
second cohomology of weighted projective hypersurfaces of degree $10$ in a
weighted projective three-space with weights $1, 1, 2, 5$
",Mathematics
"  Let $R$ be a two-sided noetherian ring and $M$ be a nilpotent $R$-bimodule,
which is finitely generated on both sides. We study Gorenstein homological
properties of the tensor ring $T_R(M)$. Under certain conditions, the ring $R$
is Gorenstein if and only if so is $T_R(M)$. We characterize Gorenstein
projective $T_R(M)$-modules in terms of $R$-modules.
",Mathematics
"  We give a new formulation and proof of a theorem of Halmos and Wallen on the
structure of power partial isometries on Hilbert space. We then use this
theorem to give a structure theorem for a finite set of partial isometries
which star-commute: each operator commutes with the others and with their
adjoints.
",Mathematics
"  The goal of the paper is to investigate the dynamics of the eigenvalues of
the Sturm-Liouville operator with summable PT-symmetric potential on the finite
interval. It turns out that the case of a complex Airy operator presents an
exactly solvable model which allows us to trace the dynamics of the movement of
the eigenvalues in all details and to find explicitly the critical parameter
values, in particular, to specify precisely the number $\varepsilon_1$ such
that for $0<\varepsilon<\varepsilon_1$ the operator has a real spectrum and is
similar to a self-adjoint operator.
",Mathematics
"  Excitation of waves in a three-layer acoustic wavegide is studied. The wave
field is presented as a sum of integrals. The summation is held over all
waveguide modes. The integration is performed over the temporal frequency axis.
The dispersion diagram of the waveguide is analytically continued, and the
integral is transformed by deformation of the integration contour into the
domain of complex frequencies. As the result, the expression for the fast
components of the signal (i.e. for the transient fields) is simplified.
The structure of the Riemann surface of the dispersion diagram of the
waveguide is studied. For this, a family of auxiliary problems indexed by the
parameters describing the links between layers is introduced. The family
depends on the linking parameters analytically, and the limiting case of weak
links can be solved analytically.
",Mathematics
"  Let $\theta, \theta'$ be irrational numbers and $A, B$ be matrices in
$SL_2(\mathbb{Z})$ of infinite order. We compute the $K$-theory of the crossed
product $\mathcal{A}_{\theta}\rtimes_A \mathbb{Z}$ and show that
$\mathcal{A}_{\theta} \rtimes_A\mathbb{Z}$ and $\mathcal{A}_{\theta'} \rtimes_B
\mathbb{Z}$ are $*$-isomorphic if and only if $\theta = \pm\theta'
\pmod{\mathbb{Z}}$ and $I-A^{-1}$ is matrix equivalent to $I-B^{-1}$. Combining
this result and an explicit construction of equivariant bimodules, we show that
$\mathcal{A}_{\theta} \rtimes_A\mathbb{Z}$ and $\mathcal{A}_{\theta'} \rtimes_B
\mathbb{Z}$ are Morita equivalent if and only if $\theta$ and $\theta'$ are in
the same $GL_2(\mathbb{Z})$ orbit and $I-A^{-1}$ is matrix equivalent to
$I-B^{-1}$. Finally, we determine the Morita equivalence class of
$\mathcal{A}_{\theta} \rtimes F$ for any finite subgroup $F$ of
$SL_2(\mathbb{Z})$.
",Mathematics
"  We prove new pinching estimate for the inverse curvature flow of strictly
convex hypersurfaces in the space form $N$ of constant sectional curvature
$K_N$ with speed given by $F^{-\alpha}$, where $\alpha\in (0,1]$ for $K_N=0,-1$
and $\alpha=1$ for $K_N=1$, $F$ is a smooth, symmetric homogeneous of degree
one function which is inverse concave and has dual $F_*$ approaching zero on
the boundary of the positive cone $\Gamma_+$. We show that the ratio of the
largest principal curvature to the smallest principal curvature of the flow
hypersurface is controlled by its initial value. This can be used to prove the
smooth convergence of the flow.
",Mathematics
"  We present an amelioration of current known algorithms for optimal spectral
partitioning problems. The idea is to use the advantage of a representation
using density functions while decreasing the computational time. This is done
by restricting the computation to neighbourhoods of regions where the
associated densities are above a certain threshold. The algorithm extends and
improves known methods in the plane and on surfaces in dimension 3. It also
makes possible to make some of the first computations of volumic 3D spectral
partitions on sufficiently large discretizations.
",Mathematics
"  The irreducible representations of full support in the rational Cherednik
category $\mathcal{O}_c(W)$ attached to a Coxeter group $W$ are in bijection
with the irreducible representations of an associated Iwahori-Hecke algebra.
Recent work has shown that the irreducible representations in
$\mathcal{O}_c(W)$ of arbitrary given support are similarly governed by certain
generalized Hecke algebras. In this paper we compute the parameters for these
generalized Hecke algebras in the remaining previously unknown cases,
corresponding to the parabolic subgroup $B_n \times S_k$ in $B_{n+k}$ for $k
\geq 2$ and $n \geq 0$.
",Mathematics
"  We propose a dimensional reduction procedure in the Stolz--Teichner framework
of supersymmetric Euclidean field theories (EFTs) that is well-suited in the
presence of a finite gauge group or, more generally, for field theories over an
orbifold. As an illustration, we give a geometric interpretation of the Chern
character for manifolds with an action by a finite group.
",Mathematics
"  We study effective versions of unlikely intersections of images of torsion
points of elliptic curves on the projective line.
",Mathematics
"  A vector bundle E on a projective variety X is called finite if it satisfies
a nontrivial polynomial equation with integral coefficients. A theorem of Nori
implies that E is finite if and only if the pullback of E to some finite etale
Galois covering of X is trivial. We prove the same statement when X is a
compact complex manifold admitting a Gauduchon astheno-Kahler metric.
",Mathematics
"  Assume $\mathsf{M}_n$ is the $n$-dimensional permutation module for the
symmetric group $\mathsf{S}_n$, and let $\mathsf{M}_n^{\otimes k}$ be its
$k$-fold tensor power. The partition algebra $\mathsf{P}_k(n)$ maps
surjectively onto the centralizer algebra
$\mathsf{End}_{\mathsf{S}_n}(\mathsf{M}_n^{\otimes k})$ for all $k, n \in
\mathbb{Z}_{\ge 1}$ and isomorphically when $n \ge 2k$. We describe the image
of the surjection $\Phi_{k,n}:\mathsf{P}_k(n) \to
\mathsf{End}_{\mathsf{S}_n}(\mathsf{M}_n^{\otimes k})$ explicitly in terms of
the orbit basis of $\mathsf{P}_k(n)$ and show that when $2k > n$ the kernel of
$\Phi_{k,n}$ is generated by a single essential idempotent $\mathsf{e}_{k,n}$,
which is an orbit basis element. We obtain a presentation for
$\mathsf{End}_{\mathsf{S}_n}(\mathsf{M}_n^{\otimes k})$ by imposing one
additional relation, $\mathsf{e}_{k,n} = 0$, to the standard presentation of
the partition algebra $\mathsf{P}_k(n)$ when $2k > n$. As a consequence, we
obtain the fundamental theorems of invariant theory for the symmetric group
$\mathsf{S}_n$. We show under the natural embedding of the partition algebra
$\mathsf{P}_n(n)$ into $\mathsf{P}_k(n)$ for $k \ge n$ that the essential
idempotent $\mathsf{e}_{n,n}$ generates the kernel of $\Phi_{k,n}$. Therefore,
the relation $\mathsf{e}_{n,n} = 0$ can replace $\mathsf{e}_{k,n} = 0$ when $k
\ge n$.
",Mathematics
"  Using the representation theory of Cherednik algebras at $t=0$ and a Galois
covering of the Calogero-Moser space, we define the notions of left, right and
two-sided Calogero-Moser cells for any finite complex reflection group. To each
Caloger-Moser two-sided cell is associated a Calogero-Moser family, while to
each Calogero-Moser left cell is associated a Calogero-Moser cellular
representation. We study properties of these objects and we conjecture that,
whenever the reflection group is real (i.e. is a Coxeter group), these notions
coincide with the one of Kazhdan-Lusztig left, right and two-sided cells,
Kazhdan-Lusztig families and Kazhdan-Lusztig cellular representations.
",Mathematics
"  In the 1950's Hopf gave examples of non-round convex 2-spheres in Euclidean
3-space with rotational symmetry that satisfy a linear relationship between
their principal curvatures. In this paper we investigate conditions under which
evolving a smooth rotationally symmetric sphere by a linear combination of its
radii of curvature yields a Hopf sphere. When the coefficients of the flow have
certain integer values, the fate of an initial sphere is entirely determined by
the local geometry of its isolated umbilic points. A surprising variety of
behaviours is uncovered: convergence to round spheres and non-round Hopf
spheres, as well as divergence to infinity.
The critical quantity is the rate of vanishing of the astigmatism - the
difference of the radii of curvature - at the isolated umbilic points. It is
proven that the size of this quantity versus the coefficient in the flow
function determines the fate of the evolution.
The geometric setting for the equation is Radius of Curvature space, viewed
as a pair of hyperbolic/AdS half-planes joined along their boundary, the
umbilic horizon. A rotationally symmetric sphere determines a parameterized
curve in this plane with end-points on the umbilic horizon. The slope of the
curve at the umbilic horizon is linked by the Codazzi-Mainardi equations to the
rate of vanishing of astigmatism, and for generic initial conditions can be
used to determine the outcome of the flow.
The slope can jump during the flow, and a number of examples are given:
instant jumps of the initial slope, as well as umbilic circles that contract to
points in finite time and 'pop' the slope. Finally, we present soliton-like
solutions: curves that evolve under linear flows by mutual hyperbolic/AdS
isometries (dilation and translation) of Radius of Curvature space. A
forthcoming paper will apply these geometric ideas to non-linear curvature
flows.
",Mathematics
"  The goal of the present paper is to introduce a smaller, but equivalent
version of the Deligne-Hinich-Getzler $\infty$-groupoid associated to a
homotopy Lie algebra. In the case of differential graded Lie algebras, we
represent it by a universal cosimplicial object.
",Mathematics
"  We define a symmetric monoidal (4,3)-category with duals whose objects are
certain enriched multi-fusion categories. For every modular tensor category
$\mathcal{C}$, there is a self enriched multi-fusion category $\mathfrak{C}$
giving rise to an object of this symmetric monoidal (4,3)-category. We
conjecture that the extended 3D TQFT given by the fully dualizable object
$\mathfrak{C}$ extends the 1-2-3-dimensional Reshetikhin-Turaev TQFT associated
to the modular tensor category $\mathcal{C}$ down to dimension zero.
",Mathematics
"  The branch of provability logic investigates the provability-based behavior
of the mathematical theories. In a more precise way, it studies the relation
between a mathematical theory $T$ and a modal logic $L$ via the provability
interpretation which interprets the modality as the provability predicate of
$T$. In this paper we will extend this relation to investigate the
provability-based behavior of a hierarchy of theories. More precisely, using
the modal language with infinitely many modalities,
$\{\Box_n\}_{n=0}^{\infty}$, we will define the hierarchical counterparts of
some of the classical modal theories such as $\mathbf{K4}$, $\mathbf{KD4}$,
$\mathbf{GL}$ and $\mathbf{S4}$. Then we will define their canonical
provability interpretations and their corresponding soundness-completeness
theorems.
",Mathematics
"  The purpose of the present paper is to investigate a fusion rule algebra
arising from irreducible characters of a compact group $G$ and a closed
subgroup $G_0$ of $G$ with finite index. The convolution of this fusion rule
algebra is introduced by inducing irreducible representations of $G_0$ to $G$
and by restricting irreducible representations of $G$ to $G_0$.
",Mathematics
"  We prove upper bounds for the mean square of the remainder in the prime
geodesic theorem, for every cofinite Fuchsian group, which improve on average
on the best known pointwise bounds. The proof relies on the Selberg trace
formula. For the modular group we prove a refined upper bound by using the
Kuznetsov trace formula.
",Mathematics
"  For a contraction $C_0$-semigroup on a separable Hilbert space, the decay
rate is estimated by using the weak Poincaré inequalities for the symmetric
and anti-symmetric part of the generator. As applications, non-exponential
convergence rate is characterized for a class of degenerate diffusion
processes, so that the study of hypocoercivity is extended. Concrete examples
are presented.
",Mathematics
"  In this paper, we consider the nonlinear inhomogeneous compressible elastic
waves in three spatial dimensions when the density is a small disturbance
around a constant state. In homogeneous case, the almost global existence was
established by Klainerman-Sideris [1996_CPAM], and global existence was built
by Agemi [2000_Invent. Math.] and Sideris [1996_Invent. Math., 2000_Ann. Math.]
independently. Here we establish the corresponding almost global and global
existence theory in the inhomogeneous case.
",Mathematics
"  This paper is a sequel to [He11] and [GH17]. In [He11] a notion of marking of
isolated hypersurface singularities was defined, and a moduli space
$M_\mu^{mar}$ for marked singularities in one $\mu$-homotopy class of isolated
hypersurface singularities was established. It is an analogue of a
Teichmüller space. It comes together with a $\mu$-constant monodromy group
$G^{mar}\subset G_{\mathbb{Z}}$. Here $G_{\mathbb{Z}}$ is the group of
automorphisms of a Milnor lattice which respect the Seifert form. It was
conjectured that $M_\mu^{mar}$ is connected. This is equivalent to $G^{mar}=
G_{\mathbb{Z}}$. Also Torelli type conjectures were formulated. In [He11] and
[GH17] $M_\mu^{mar}, G_{\mathbb{Z}}$ and $G^{mar}$ were determined and all
conjectures were proved for the simple, the unimodal and the exceptional
bimodal singularities. In this paper the quadrangle singularities and the
bimodal series are treated. The Torelli type conjectures are true. But the
conjecture $G^{mar}= G_{\mathbb{Z}}$ and $M_\mu^{mar}$ connected does not hold
for certain subseries of the bimodal series.
",Mathematics
"  Given a suitable ordering of the positive root system associated with a
semisimple Lie algebra, there exists a natural correspondence between Verma
modules and related polynomial algebras. With this, the Lie algebra action on a
Verma module can be interpreted as a differential operator action on
polynomials, and thus on the corresponding truncated formal power series. We
prove that the space of truncated formal power series is a
differential-operator representation of the Weyl group $W$. We also introduce a
system of partial differential equations to investigate singular vectors in the
Verma module. It is shown that the solution space of the system in the space of
truncated formal power series is the span of $\{w(1)\ |\ w\in W\}$. Those
$w(1)$ that are polynomials correspond to singular vectors in the Verma module.
This elementary approach by partial differential equations also gives a new
proof of the well-known BGG-Verma Theorem.
",Mathematics
"  We introduce an up-down coloring of a virtual-link diagram. The
colorabilities give a lower bound of the minimum number of Reidemeister moves
of type II which are needed between two 2-component virtual-link diagrams. By
using the notion of a quandle cocycle invariant, we determine the necessity of
Reidemeister moves of type II for a pair of diagrams of the trivial
virtual-knot. This implies that for any virtual-knot diagram $D$, there exists
a diagram $D'$ representing the same virtual-knot such that any sequence of
generalized Reidemeister moves between them includes at least one Reidemeister
move of type II.
",Mathematics
"  The main purpose of this paper is to study multi-parameter singular integral
operators which commute with Zygmund dilations. We introduce a class of
singular integral operators associated with Zygmund dilations and show the
boundedness for these operators on $L^p, 1<p<\infty$, which covers those
studied by Ricci--Stein \cite{RS} and Nagel--Wainger \cite{NW}
",Mathematics
"  The Hamming graph $H(d,n)$ is the Cartesian product of $d$ complete graphs on
$n$ vertices. Let $m=d(n-1)$ be the degree and $V = n^d$ be the number of
vertices of $H(d,n)$. Let $p_c^{(d)}$ be the critical point for bond
percolation on $H(d,n)$. We show that, for $d \in \mathbb N$ fixed and $n \to
\infty$,
\begin{equation*}
p_c^{(d)}= \dfrac{1}{m} + \dfrac{2d^2-1}{2(d-1)^2}\dfrac{1}{m^2}
+ O(m^{-3}) + O(m^{-1}V^{-1/3}),
\end{equation*} which extends the asymptotics found in
\cite{BorChaHofSlaSpe05b} by one order. The term $O(m^{-1}V^{-1/3})$ is the
width of the critical window. For $d=4,5,6$ we have $m^{-3} =
O(m^{-1}V^{-1/3})$, and so the above formula represents the full asymptotic
expansion of $p_c^{(d)}$. In \cite{FedHofHolHul16a} \st{we show that} this
formula is a crucial ingredient in the study of critical bond percolation on
$H(d,n)$ for $d=2,3,4$. The proof uses a lace expansion for the upper bound and
a novel comparison with a branching random walk for the lower bound. The proof
of the lower bound also yields a refined asymptotics for the susceptibility of
a subcritical Erdős-Rényi random graph.
",Mathematics
"  We consider fiberwise singly generated Fell-bundles over etale groupoids.
Given a continuous real-valued 1-cocycle on the groupoid, there is a natural
dynamics on the cross-sectional algebra of the Fell bundle. We study the
Kubo-Martin-Schwinger equilibrium states for this dynamics. Following work of
Neshveyev on equilibrium states on groupoid C*-algebras, we describe the
equilibrium states of the cross-sectional algebra in terms of measurable fields
of traces on the C*-algebras of the restrictions of the Fell bundle to the
isotropy subgroups of the groupoid. As a special case, we obtain a description
of the trace space of the cross-sectional algebra. We apply our result to
generalise Neshveyev's main theorem to twisted groupoid C*-algebras, and then
apply this to twisted C*-algebras of strongly connected finite k-graphs.
",Mathematics
"  Let $G^{(r)}$ denote the metaplectic covering group of the linear algebraic
group $G$. In this paper we study conditions on unramified representations of
the group $G^{(r)}$ not to have a nonzero Whittaker function. We state a
general Conjecture about the possible unramified characters $\chi$ such that
the unramified sub-representation of
$Ind_{B^{(r)}}^{G^{(r)}}\chi\delta_B^{1/2}$ will have no nonzero Whittaker
function. We prove this Conjecture for the groups $GL_n^{(r)}$ with $r\ge n-1$,
and for the exceptional groups $G_2^{(r)}$ when $r\ne 2$.
",Mathematics
"  We define a class of surfaces and surface pairs corresponding to the ADE root
lattices and construct compactifications of their moduli spaces, generalizing
Losev-Manin spaces of curves.
",Mathematics
"  We describe the structure of Hausdorff locally compact semitopological
$0$-bisimple inverse $\omega$-semigroups with compact maximal subgroups. In
particular, we show that a Hausdorff locally compact semitopological
$0$-bisimple inverse $\omega$-semigroup with a compact maximal subgroup is
either compact or topologically isomorphic to the topological sum of its
$\mathscr{H}$-classes. We describe the structure of Hausdorff locally compact
semitopological $0$-bisimple inverse $\omega$-semigroups with a monothetic
maximal subgroups. In particular we prove the dichotomy for $T_1$ locally
compact semitopological Reilly semigroup
$\left(\textbf{B}(\mathbb{Z}_{+},\theta)^0,\tau\right)$ with adjoined zero and
with a non-annihilating homomorphism $\theta\colon \mathbb{Z}_{+}\to
\mathbb{Z}_{+}$: $\left(\textbf{B}(\mathbb{Z}_{+},\theta)^0,\tau\right)$ is
either compact or discrete. At the end we discuss on the remainder under the
closure of the discrete Reilly semigroup $\textbf{B}(\mathbb{Z}_{+},\theta)^0$
in a semitopological semigroup.
",Mathematics
"  The main purpose of this article is to fix several aspects aspects of the
proof of the Whittaker Plancherel Theorem in Real Reductive Groups II that are
affected by recently observed errors or gaps . In the process of completing the
proof of the theorem the paper also gives an exposition of its structure, and
adds some clarifying new results. It also outlines the steps in the proof of
the Harish-Chandra Plancherel theorem as they are needed in our proof of the
Whittaker version.
",Mathematics
"  In this short note we explain the proof that proper surjective and faithfully
flat maps are morphisms of effective descent for overconvergent isocrystals. We
then show how to deduce the folklore theorem that for an arbitrary variety over
a perfect field of characteristic $p$, the Frobenius pull-back functor is an
equivalence on the overconvergent category.
",Mathematics
"  In this paper, we consider pure infiniteness of generalized Cuntz-Krieger
algebras associated to labeled spaces $(E,\mathcal{L},\mathcal{E})$. It is
shown that a $C^*$-algebra $C^*(E,\mathcal{L},\mathcal{E})$ is purely infinite
in the sense that every nonzero hereditary subalgebra contains an infinite
projection (we call this property (IH)) if $(E, \mathcal{L},\mathcal{E})$ is
disagreeable and every vertex connects to a loop. We also prove that under the
condition analogous to (K) for usual graphs,
$C^*(E,\mathcal{L},\mathcal{E})=C^*(p_A, s_a)$ is purely infinite in the sense
of Kirchberg and R{\o}rdam if and only if every generating projection $p_A$,
$A\in \mathcal{E}$, is properly infinite, and also if and only if every
quotient of $C^*(E,\mathcal{L},\mathcal{E})$ has the property (IH).
",Mathematics
"  We introduce a class of theories called metastable, including the theory of
algebraically closed valued fields (ACVF) as a motivating example. The key
local notion is that of definable types dominated by their stable part. A
theory is metastable (over a sort $\Gamma$) if every type over a sufficiently
rich base structure can be viewed as part of a $\Gamma$-parametrized family of
stably dominated types. We initiate a study of definable groups in metastable
theories of finite rank. Groups with a stably dominated generic type are shown
to have a canonical stable quotient. Abelian groups are shown to be
decomposable into a part coming from $\Gamma$, and a definable direct limit
system of groups with stably dominated generic. In the case of ACVF, among
definable subgroups of affine algebraic groups, we characterize the groups with
stably dominated generics in terms of group schemes over the valuation ring.
Finally, we classify all fields definable in ACVF.
",Mathematics
"  By applying the classic telescoping summation formula and its variants to
identities involving inverse hyperbolic tangent functions having inverse powers
of the golden ratio as arguments and employing subtle properties of the
Fibonacci and Lucas numbers, we derive interesting general infinite product
identities involving these numbers.
",Mathematics
"  Let K be a field and denote by K[t], the polynomial ring with coefficients in
K. Set A = K[f1,. .. , fs], with f1,. .. , fs $\in$ K[t]. We give a procedure
to calculate the monoid of degrees of the K algebra M = F1A + $\times$ $\times$
$\times$ + FrA with F1,. .. , Fr $\in$ K[t]. We show some applications to the
problem of the classification of plane polynomial curves (that is, plane
algebraic curves parametrized by polynomials) with respect to some oh their
invariants, using the module of K{ä}hler differentials.
",Mathematics
"  We give characterizations of a finite group $G$ acting symplectically on a
rational surface ($\mathbb{C}P^2$ blown up at two or more points). In
particular, we obtain a symplectic version of the dichotomy of $G$-conic
bundles versus $G$-del Pezzo surfaces for the corresponding $G$-rational
surfaces, analogous to a classical result in algebraic geometry. Besides the
characterizations of the group $G$ (which is completely determined for the case
of $\mathbb{C}P^2\# N\overline{\mathbb{C}P^2}$, $N=2,3,4$), we also investigate
the equivariant symplectic minimality and equivariant symplectic cone of a
given $G$-rational surface.
",Mathematics
"  Manifolds with infinite cylindrical ends have continuous spectrum of
increasing multiplicity as energy grows, and in general embedded resonances and
eigenvalues can accumulate at infinity. However, we prove that if geodesic
trapping is sufficiently mild, then such an accumulation is ruled out, and
moreover the cutoff resolvent is uniformly bounded at high energies. We obtain
as a corollary the existence of resonance free regions near the continuous
spectrum.
We also obtain improved estimates when the resolvent is cut off away from
part of the trapping, and along the way we prove some resolvent estimates for
repulsive potentials on the half line which may be of independent interest.
",Mathematics
"  We initiate the study of the completely bounded multipliers of the Haagerup
tensor product $A(G)\otimes_{\rm h} A(G)$ of two copies of the Fourier algebra
$A(G)$ of a locally compact group $G$. If $E$ is a closed subset of $G$ we let
$E^{\sharp} = \{(s,t) : st\in E\}$ and show that if $E^{\sharp}$ is a set of
spectral synthesis for $A(G)\otimes_{\rm h} A(G)$ then $E$ is a set of local
spectral synthesis for $A(G)$. Conversely, we prove that if $E$ is a set of
spectral synthesis for $A(G)$ and $G$ is a Moore group then $E^{\sharp}$ is a
set of spectral synthesis for $A(G)\otimes_{\rm h} A(G)$. Using the natural
identification of the space of all completely bounded weak* continuous
$VN(G)'$-bimodule maps with the dual of $A(G)\otimes_{\rm h} A(G)$, we show
that, in the case $G$ is weakly amenable, such a map leaves the multiplication
algebra of $L^{\infty}(G)$ invariant if and only if its support is contained in
the antidiagonal of $G$.
",Mathematics
"  A simplified trisection is a trisection map on a 4-manifold such that, in its
critical value set, there is no double point and cusps only appear in triples
on innermost fold circles. We give a necessary and sufficient condition for a
3-tuple of systems of simple closed curves in a surface to be a diagram of a
simplified trisection in terms of mapping class groups. As an application of
this criterion, we show that trisections of spun 4-manifolds due to Meier are
diffeomorphic (as trisections) to simplified ones. Baykur and Saeki recently
gave an algorithmic construction of a simplified trisection from a directed
broken Lefschetz fibration. We also give an algorithm to obtain a diagram of a
simplified trisection derived from their construction.
",Mathematics
"  We introduce Nevanlinna classes of holomorphic functions associated to a
closed set on the boundary of the unit disc in the complex plane and we get
Blaschke type theorems relative to these classes by use of several complex
variables methods. This gives alternative proofs of some results of Favorov \&
Golinskii, useful, in particular, for the study of eigenvalues of non self
adjoint Schr{ö}dinger operators.
",Mathematics
"  Recently Tewari and van Willigenburg constructed modules of the 0-Hecke
algebra that are mapped to the quasisymmetric Schur functions by the
quasisymmetric characteristic and decomposed them into a direct sum of certain
submodules. We show that these submodules are indecomposable by determining
their endomorphism rings.
",Mathematics
"  We present a strengthening of the lemma on the lower bound of the slice rank
by Tao (2016) motivated by the Croot-Lev-Pach-Ellenberg-Gijswijt bound on cap
sets (2017, 2017). The Croot-Lev-Pach-Ellenberg-Gijswijt method and the lemma
of Tao are based on the fact that the rank of a diagonal matrix is equal to the
number of non-zero diagonal entries. Our lemma is based on the rank of
upper-triangular matrices. This stronger lemma allows us to prove the following
extension of the Ellenberg-Gijswijt result (2017). A tricolored ordered
sum-free set in $\mathbb F_p^n$ is a collection
$\{(a_i,b_i,c_i):i=1,2,\ldots,m\}$ of ordered triples in $(\mathbb F_p^n )^3$
such that $a_i+b_i+c_i=0$ and if $a_i+b_j+c_k=0$, then $i\le j\le k$. By using
the new lemma, we present an upper bound on the size of a tricolored ordered
sum-free set in $\mathbb F_p^n$.
",Mathematics
"  While reduced-order models (ROMs) have been popular for efficiently solving
large systems of differential equations, the stability of reduced models over
long-time integration is of present challenges. We present a greedy approach
for ROM generation of parametric Hamiltonian systems that captures the
symplectic structure of Hamiltonian systems to ensure stability of the reduced
model. Through the greedy selection of basis vectors, two new vectors are added
at each iteration to the linear vector space to increase the accuracy of the
reduced basis. We use the error in the Hamiltonian due to model reduction as an
error indicator to search the parameter space and identify the next best basis
vectors. Under natural assumptions on the set of all solutions of the
Hamiltonian system under variation of the parameters, we show that the greedy
algorithm converges with exponential rate. Moreover, we demonstrate that
combining the greedy basis with the discrete empirical interpolation method
also preserves the symplectic structure. This enables the reduction of the
computational cost for nonlinear Hamiltonian systems. The efficiency, accuracy,
and stability of this model reduction technique is illustrated through
simulations of the parametric wave equation and the parametric Schrodinger
equation.
",Mathematics
"  We study front propagation phenomena for a large class of nonlocal KPP-type
reaction-diffusion equations in oscillatory environments, which model various
forms of population growth with periodic dependence. The nonlocal diffusion is
an anisotropic integro-differential operator of order $\alpha \in (0,2)$.
",Mathematics
"  We study XXZ spin systems on general graphs. In particular, we describe the
formation of droplet states near the bottom of the spectrum in the Ising phase
of the model, where the Z-term dominates the XX-term. As key tools we use
particle number conservation of XXZ systems and symmetric products of graphs
with their associated adjacency matrices and Laplacians. Of particular interest
to us are strips and multi-dimensional Euclidean lattices, for which we discuss
the existence of spectral gaps above the droplet regime. We also prove a
Combes-Thomas bound which shows that the eigenstates in the droplet regime are
exponentially small perturbations of strict (classical) droplets.
",Mathematics
"  We study threefolds fibred by K3 surfaces admitting a lattice polarization by
a certain class of rank 19 lattices. We begin by showing that any family of
such K3 surfaces is completely determined by a map from the base of the family
to the appropriate K3 moduli space, which we call the generalized functional
invariant. Then we show that if the threefold total space is a smooth
Calabi-Yau, there are only finitely many possibilities for the polarizing
lattice and the form of the generalized functional invariant. Finally, we
construct explicit examples of Calabi-Yau threefolds realizing each case and
compute their Hodge numbers.
",Mathematics
"  We study the $m$-th Gauss map in the sense of F.~L.~Zak of a projective
variety $X \subset \mathbb{P}^N$ over an algebraically closed field in any
characteristic. For all integer $m$ with $n:=\dim(X) \leq m < N$, we show that
the contact locus on $X$ of a general tangent $m$-plane is a linear variety if
the $m$-th Gauss map is separable. We also show that for smooth $X$ with $n <
N-2$, the $(n+1)$-th Gauss map is birational if it is separable, unless $X$ is
the Segre embedding $\mathbb{P}^1 \times \mathbb{P}^n \subset
\mathbb{P}^{2n-1}$. This is related to L. Ein's classification of varieties
with small dual varieties in characteristic zero.
",Mathematics
"  In this paper, we prove formulas that represent two-pointed Gromov-Witten
invariant <O_{h^a}O_{h^b}>_{0,d} of projective hypersurfaces with d=1,2 in
terms of Chow ring of Mbar_{0,2}(P^{N-1},d), the moduli spaces of stable maps
from genus 0 stable curves to projective space P^{N-1}. Our formulas are based
on representation of the intersection number w(O_{h^a}O_{h^b})_{0,d}, which was
introduced by Jinzenji, in terms of Chow ring of Mp_{0,2}(N,d), the moduli
space of quasi maps from P^1 to P^{N-1} with two marked points. In order to
prove our formulas, we use the results on Chow ring of Mbar_{0,2}(P^{N-1},d),
that were derived by A. Mustata and M. Mustata. We also present explicit toric
data of Mp_{0,2}(N,d) and prove relations of Chow ring of Mp_{0,2}(N,d).
",Mathematics
"  In this paper we introduce an easily verifiable sufficient condition to
determine whether an algebra is quasi-hereditary. In the case of monomial
algebras, we give conditions that are both necessary and sufficient to show
whether an algebra is quasi-hereditary.
",Mathematics
"  We construct embedded minimal surfaces which are $n$-periodic in
$\mathbb{R}^n$. They are new for codimension $n-2\ge 2$. We start with a Jordan
curve of edges of the $n$-dimensional cube. It bounds a Plateau minimal disk
which Schwarz reflection extends to a complete minimal surface. Studying the
group of Schwarz reflections, we can characterize those Jordan curves for which
the complete surface is embedded. For example, for $n=4$ exactly five such
Jordan curves generate embedded surfaces. Our results apply to surface classes
other than minimal as well, for instance polygonal surfaces.
",Mathematics
"  We construct a special class of Lorentz surfaces in the pseudo-Euclidean
4-space with neutral metric which are one-parameter systems of meridians of
rotational hypersurfaces with lightlike axis and call them meridian surfaces.
We give the complete classification of the meridian surfaces with constant
Gauss curvature and prove that there are no meridian surfaces with parallel
mean curvature vector field other than CMC surfaces lying in a hyperplane. We
also classify the meridian surfaces with parallel normalized mean curvature
vector field. We show that in the family of the meridian surfaces there exist
Lorentz surfaces which have parallel normalized mean curvature vector field but
not parallel mean curvature vector.
",Mathematics
"  In this paper we consider a $d$-dimensional ($d=1,2$) parabolic-elliptic
Keller-Segel equation with a logistic forcing and a fractional diffusion of
order $\alpha \in (0,2)$. We prove uniform in time boundedness of its solution
in the supercritical range $\alpha>d\left(1-c\right)$, where $c$ is an explicit
constant depending on parameters of our problem. Furthermore, we establish
sufficient conditions for $\|u(t)-u_\infty\|_{L^\infty}\rightarrow0$, where
$u_\infty\equiv 1$ is the only nontrivial homogeneous solution. Finally, we
provide a uniqueness result.
",Mathematics
"  We prove an abstract theorem giving a $\langle t\rangle^\epsilon$ bound
($\forall \epsilon>0$) on the growth of the Sobolev norms in linear
Schrödinger equations of the form $i \dot \psi = H_0 \psi + V(t) \psi $ when
the time $t \to \infty$. The abstract theorem is applied to several cases,
including the cases where (i) $H_0$ is the Laplace operator on a Zoll manifold
and $V(t)$ a pseudodifferential operator of order smaller then 2; (ii) $H_0$ is
the (resonant or nonresonant) Harmonic oscillator in $R^d$ and $V(t)$ a
pseudodifferential operator of order smaller then $H_0$ depending in a
quasiperiodic way on time. The proof is obtained by first conjugating the
system to some normal form in which the perturbation is a smoothing operator
and then applying the results of \cite{MaRo}.
",Mathematics
"  Let $\mathbb Q^{n+1}_c$ be the complete simply-connected $(n+1)$-dimensional
space form of curvature $c$. In this paper we obtain a new characterization of
geodesic spheres in $\mathbb Q^{n+1}_c$ in terms of the higher order mean
curvatures. In particular, we prove that the geodesic sphere is the only
complete bounded immersed hypersurface in $\mathbb Q^{n+1}_c,\;c\leq 0,$ with
constant mean curvature and constant scalar curvature. The proof relies on the
well known Omori-Yau maximum principle, a formula of Walter for the Laplacian
of the $r$-th mean curvature of a hypersurface in a space form, and a classical
inequality of G\aa rding for hyperbolic polynomials.
",Mathematics
"  Let $G$ be a finite, simple, connected graph. An arithmetical structure on
$G$ is a pair of positive integer vectors $\mathbf{d},\mathbf{r}$ such that
$(\mathrm{diag}(\mathbf{d})-A)\mathbf{r}=0$, where $A$ is the adjacency matrix
of $G$. We investigate the combinatorics of arithmetical structures on path and
cycle graphs, as well as the associated critical groups (the cokernels of the
matrices $(\mathrm{diag}(\mathbf{d})-A)$). For paths, we prove that
arithmetical structures are enumerated by the Catalan numbers, and we obtain
refined enumeration results related to ballot sequences. For cycles, we prove
that arithmetical structures are enumerated by the binomial coefficients
$\binom{2n-1}{n-1}$, and we obtain refined enumeration results related to
multisets. In addition, we determine the critical groups for all arithmetical
structures on paths and cycles.
",Mathematics
"  We define a Koszul sign map encoding the Koszul sign convention. A
cohomological interpretation is given.
",Mathematics
"  We define web categories describing intertwiners for the orthogonal and
symplectic Lie algebras, and, in the quantized setup, for certain orthogonal
and symplectic coideal subalgebras. They generalize the Brauer category, and
allow us to prove quantum versions of some classical type
$\mathbf{B}\mathbf{C}\mathbf{D}$ Howe dualities.
",Mathematics
"  We provide a pair of dual results, each stating the coincidence of highness
properties from computability theory. We provide an analogous pair of dual
results on the coincidence of cardinal characteristics within ZFC.
A mass problem is a set of functions on $\omega$. For mass problems $\mathcal
C, \mathcal D$, one says that $\mathcal C$ is Muchnik reducible to $\mathcal D$
if each function in $\mathcal D$ computes a function in $\mathcal C$. In this
paper we view highness properties as mass problems, and compare them with
respect to Muchnik reducibility and its uniform strengthening, Medvedev
reducibility.
Let $\mathcal D(p)$ be the mass problem of infinite bit sequences $y$ (i.e.,
0,1 valued functions) such that for each computable bit sequence $x$, the
asymptotic lower density $\underline \rho$ of the agreement bit sequence $x
\leftrightarrow y$ is at most $p$ (this sequence takes the value 1 at a bit
position iff $x$ and $y$ agree).
We show that all members of this family of mass problems parameterized by a
real $p$ with $0 < p<1/2 $ have the same complexity in the sense of Muchnik
reducibility. This also yields a new version of Monin's affirmative answer to
the ""Gamma question"", whether $\Gamma(A)< 1/2$ implies $\Gamma(A)=0$ for each
Turing oracle $A$.
We also show, together with Joseph Miller, that for any order function~$g$
there exists a faster growing order function $h $ such that $\mathrm{IOE}(g) $
is strictly Muchnik below $\mathrm{IOE}(h)$.
We study cardinal characteristics analogous to the highness properties above.
For instance, $\mathfrak d (p)$ is the least size of a set $G$ of bit sequences
so that for each bit sequence $x$ there is a bit sequence $y$ in $G$ so that
$\underline \rho (x \leftrightarrow y) >p$. We prove within ZFC all the
coincidences of cardinal characteristics that are the analogs of the results
above.
",Mathematics
"  Let $\mathcal{A}$ be a finite-dimensional subspace of
$C(\mathcal{X};\mathbb{R})$, where $\mathcal{X}$ is a locally compact Hausdorff
space, and $\mathsf{A}=\{f_1,\dots,f_m\}$ a basis of $\mathcal{A}$. A sequence
$s=(s_j)_{j=1}^m$ is called a moment sequence if $s_j=\int f_j(x) \, d\mu(x)$,
$j=1,\dots,m$, for some positive Radon measure $\mu$ on $\mathcal{X}$. Each
moment sequence $s$ has a finitely atomic representing measure $\mu$. The
smallest possible number of atoms is called the Carathéodory number
$\mathcal{C}_{\mathsf{A}}(s)$. The largest number $\mathcal{C}_{\mathsf{A}}(s)$
among all moment sequences $s$ is the Carathéodory number
$\mathcal{C}_{\mathsf{A}}$. In this paper the Carathéodory numbers
$\mathcal{C}_{\mathsf{A}}(s)$ and $\mathcal{C}_{\mathsf{A}}$ are studied. In
the case of differentiable functions methods from differential geometry are
used. The main emphasis is on real polynomials. For a large class of spaces of
polynomials in one variable the number $\mathcal{C}_{\mathsf{A}}$ is
determined. In the multivariate case we obtain some lower bounds and we use
results on zeros of positive polynomials to derive upper bounds for the
Carathéodory numbers.
",Mathematics
"  We study the Liouville heat kernel (in the $L^2$ phase) associated with a
class of logarithmically correlated Gaussian fields on the two dimensional
torus. We show that for each $\varepsilon>0$ there exists such a field, whose
covariance is a bounded perturbation of that of the two dimensional Gaussian
free field, and such that the associated Liouville heat kernel satisfies the
short time estimates, $$ \exp \left( - t^{ - \frac 1 { 1 + \frac 1 2 \gamma^2 }
- \varepsilon } \right) \le p_t^\gamma (x, y) \le \exp \left( - t^{- \frac 1 {
1 + \frac 1 2 \gamma^2 } + \varepsilon } \right) , $$ for $\gamma<1/2$. In
particular, these are different from predictions, due to Watabiki, concerning
the Liouville heat kernel for the two dimensional Gaussian free field.
",Mathematics
"  The purpose of this paper is to study stable representations of partially
ordered sets (posets) and compare it to the well known theory for quivers. In
particular, we prove that every indecomposable representation of a poset of
finite type is stable with respect to some weight and construct that weight
explicitly in terms of the dimension vector. We show that if a poset is
primitive then Coxeter transformations preserve stable representations. When
the base field is the field of complex numbers we establish the connection
between the polystable representations and the unitary $\chi$-representations
of posets. This connection explains the similarity of the results obtained in
the series of papers.
",Mathematics
"  We present an introductory survey to first order logic for metric structures
and its applications to C*-algebras.
",Mathematics
"  Defining the $m$-th stratum of a closed subset of an $n$ dimensional
Euclidean space to consist of those points, where it can be touched by a ball
from at least $n-m$ linearly independent directions, we establish that the
$m$-th stratum is second-order rectifiable of dimension $m$ and a Borel set.
This was known for convex sets, but is new even for sets of positive reach. The
result is based on a new criterion for second-order rectifiability.
",Mathematics
"  We obtain results on mixing for a large class of (not necessarily Markov)
infinite measure semiflows and flows. Erickson proved, amongst other things, a
strong renewal theorem in the corresponding i.i.d. setting. Using operator
renewal theory, we extend Erickson's methods to the deterministic (i.e.
non-i.i.d.) continuous time setting and obtain results on mixing as a
consequence.
Our results apply to intermittent semiflows and flows of Pomeau-Manneville
type (both Markov and nonMarkov), and to semiflows and flows over
Collet-Eckmann maps with nonintegrable roof function.
",Mathematics
"  In this paper, we prove that there exists a dimensional constant $\delta > 0$
such that given any background Kähler metric $\omega$, the Calabi flow with
initial data $u_0$ satisfying \begin{equation*} \partial \bar \partial u_0 \in
L^\infty (M) \text{ and } (1- \delta )\omega < \omega_{u_0} < (1+\delta
)\omega, \end{equation*} admits a unique short time solution and it becomes
smooth immediately, where $\omega_{u_0} : = \omega +\sqrt{-1}\partial
\bar\partial u_0$. The existence time depends on initial data $u_0$ and the
metric $\omega$. As a corollary, we get that Calabi flow has short time
existence for any initial data satisfying \begin{equation*} \partial \bar
\partial u_0 \in C^0(M) \text{ and } \omega_{u_0} > 0, \end{equation*} which
should be interpreted as a ""continuous Kähler metric"". A main technical
ingredient is Schauder-type estimates for biharmonic heat equation on
Riemannian manifolds with time weighted Hölder norms.
",Mathematics
"  This paper studies the large time behavior of solution for a class of
nonlinear massless Dirac equations in $R^{1+1}$. It is shown that the solution
will tend to travelling wave solution when time tends to infinity.
",Mathematics
"  Let $\Pi_q$ be an arbitrary finite projective plane of order $q$. A subset
$S$ of its points is called saturating if any point outside $S$ is collinear
with a pair of points from $S$. Applying probabilistic tools we improve the
upper bound on the smallest possible size of the saturating set to
$\lceil\sqrt{3q\ln{q}}\rceil+ \lceil(\sqrt{q}+1)/2\rceil$. The same result is
presented using an algorithmic approach as well, which points out the
connection with the transversal number of uniform multiple intersecting
hypergraphs.
",Mathematics
"  If $E$ is an elliptic curve with a point of order two, then work of Klagsbrun
and Lemke Oliver shows that the distribution of
$\dim_{\mathbb{F}_2}\mathrm{Sel}_\phi(E^d/\mathbb{Q}) - \dim_{\mathbb{F}_2}
\mathrm{Sel}_{\hat\phi}(E^{\prime d}/\mathbb{Q})$ within the quadratic twist
family tends to the discrete normal distribution $\mathcal{N}(0,\frac{1}{2}
\log \log X)$ as $X \rightarrow \infty$.
We consider the distribution of $\mathrm{dim}_{\mathbb{F}_2}
\mathrm{Sel}_\phi(E^d/\mathbb{Q})$ within such a quadratic twist family when
$\dim_{\mathbb{F}_2} \mathrm{Sel}_\phi(E^d/\mathbb{Q}) - \dim_{\mathbb{F}_2}
\mathrm{Sel}_{\hat\phi}(E^{\prime d}/\mathbb{Q})$ has a fixed value $u$.
Specifically, we show that for every $r$, the limiting probability that
$\dim_{\mathbb{F}_2} \mathrm{Sel}_\phi(E^d/\mathbb{Q}) = r$ is given by an
explicit constant $\alpha_{r,u}$. The constants $\alpha_{r,u}$ are closely
related to the $u$-probabilities introduced in Cohen and Lenstra's work on the
distribution of class groups, and thus provide a connection between the
distribution of Selmer groups of elliptic curves and random abelian groups.
Our analysis of this problem has two steps. The first step uses algebraic and
combinatorial methods to directly relate the ranks of the Selmer groups in
question to the dimensions of the kernels of random $\mathbb{F}_2$-matrices.
This proves that the density of twists with a given $\phi$-Selmer rank $r$ is
given by $\alpha_{r,u}$ for an unusual notion of density. The second step of
the analysis utilizes techniques from analytic number theory to show that this
result implies the correct asymptotics in terms of the natural notion of
density.
",Mathematics
"  In this paper, we study the generalized polynomial chaos (gPC) based
stochastic Galerkin method for the linear semiconductor Boltzmann equation
under diffusive scaling and with random inputs from an anisotropic collision
kernel and the random initial condition. While the numerical scheme and the
proof of uniform-in-Knudsen-number regularity of the distribution function in
the random space has been introduced in [Jin-Liu-16'], the main goal of this
paper is to first obtain a sharper estimate on the regularity of the
solution-an exponential decay towards its local equilibrium, which then lead to
the uniform spectral convergence of the stochastic Galerkin method for the
problem under study.
",Mathematics
"  Anderson's paving conjecture, now known to hold due to the resolution of the
Kadison-Singer problem asserts that every zero diagonal Hermitian matrix admits
non-trivial pavings with dimension independent bounds. In this paper, we
develop a technique extending the arguments of Marcus, Spielman and Srivastava
in their solution of the Kadison-Singer problem to show the existence of
non-trivial pavings for collections of matrices. We show that given zero
diagonal Hermitian contractions $A^{(1)}, \cdots, A^{(k)} \in M_n(\mathbb{C})$
and $\epsilon > 0$, one may find a paving $X_1 \amalg \cdots \amalg X_r = [n]$
where $r \leq 18k\epsilon^{-2}$ such that, \[\lambda_{max} (P_{X_i} A^{(j)}
P_{X_i}) < \epsilon, \quad i \in [r], \, j \in [k].\] As a consequence, we get
the correct asymptotic estimates for paving general zero diagonal matrices;
zero diagonal contractions can be $(O(\epsilon^{-2}),\epsilon)$ paved. As an
application, we give a simplified proof wth slightly better estimates of a
theorem of Johnson, Ozawa and Schechtman concerning commutator representations
of zero trace matrices.
",Mathematics
"  We prove that the moduli space of complete Riemannian metrics of bounded
geometry and uniformly positive scalar curvature on an orientable 3-manifold is
path-connected. This generalizes the main result of the fourth author [Mar12]
in the compact case. The proof uses Ricci flow with surgery as well as
arguments involving performing infinite connected sums with control on the
geometry.
",Mathematics
"  It is well known that the normaized characters of integrable highest weight
modules of given level over an affine Lie algebra $\hat{\frak{g}}$ span an
$SL_2(\mathbf{Z})$-invariant space. This result extends to admissible
$\hat{\frak{g}}$-modules, where $\frak{g}$ is a simple Lie algebra or
$osp_{1|n}$. Applying the quantum Hamiltonian reduction (QHR) to admissible
$\hat{\frak{g}}$-modules when $\frak{g} =sl_2$ (resp. $=osp_{1|2}$) one obtains
minimal series modules over the Virasoro (resp. $N=1$ superconformal algebras),
which form modular invariant families.
Another instance of modular invariance occurs for boundary level admissible
modules, including when $\frak{g}$ is a basic Lie superalgebra. For example, if
$\frak{g}=sl_{2|1}$ (resp. $=osp_{3|2}$), we thus obtain modular invariant
families of $\hat{\frak{g}}$-modules, whose QHR produces the minimal series
modules for the $N=2$ superconformal algebras (resp. a modular invariant family
of $N=3$ superconformal algebra modules).
However, in the case when $\frak{g}$ is a basic Lie superalgebra different
from a simple Lie algebra or $osp_{1|n}$, modular invariance of normalized
supercharacters of admissible $\hat{\frak{g}}$-modules holds outside of
boundary levels only after their modification in the spirit of Zwegers'
modification of mock theta functions. Applying the QHR, we obtain families of
representations of $N=2,3,4$ and big $N=4$ superconformal algebras, whose
modified (super)characters span an $SL_2(\mathbf{Z})$-invariant space.
",Mathematics
"  In their work on a sharp compactness theorem for the Yamabe problem, Khuri,
Marques and Schoen apply a refined blow-up analysis (what we call `second order
blow-up argument' in this article) to obtain highly accurate approximate
solutions for the Yamabe equation. As for the conformal scalar curvature
equation on S^n with n > 3, we examine the second order blow-up argument and
obtain refined estimate for a blow-up sequence near a simple blow-up point. The
estimate involves local effect from the Taylor expansion of the scalar
curvature function, global effect from other blow-up points, and the balance
formula as expressed in the Pohozaev identity in an essential way.
",Mathematics
"  To a complex projective structure $\Sigma$ on a surface, Thurston associates
a locally convex pleated surface. We derive bounds on the geometry of both in
terms of the norms $\|\phi_\Sigma\|_\infty$ and $\|\phi_\Sigma\|_2$ of the
quadratic differential $\phi_\Sigma$ of $\Sigma$ given by the Schwarzian
derivative of the associated locally univalent map. We show that these give a
unifying approach that generalizes a number of important, well known results
for convex cocompact hyperbolic structures on 3-manifolds, including bounds on
the Lipschitz constant for the nearest-point retraction and the length of the
bending lamination. We then use these bounds to begin a study of the
Weil-Petersson gradient flow of renormalized volume on the space $CC(N)$ of
convex cocompact hyperbolic structures on a compact manifold $N$ with
incompressible boundary, leading to a proof of the conjecture that the
renormalized volume has infimum given by one-half the simplicial volume of
$DN$, the double of $N$.
",Mathematics
"  In work of Higson-Roe the fundamental role of the signature as a homotopy and
bordism invariant for oriented manifolds is made manifest in how it and related
secondary invariants define a natural transformation between the
(Browder-Novikov-Sullivan-Wall) surgery exact sequence and a long exact
sequence of C*-algebra K-theory groups.
In recent years the (higher) signature invariants have been extended from
closed oriented manifolds to a class of stratified spaces known as L-spaces or
Cheeger spaces. In this paper we show that secondary invariants, such as the
rho-class, also extend from closed manifolds to Cheeger spaces. We revisit a
surgery exact sequence for stratified spaces originally introduced by
Browder-Quinn and obtain a natural transformation analogous to that of
Higson-Roe. We also discuss geometric applications.
",Mathematics
"  We study the asymptotic behaviour of the twisted first moment of central
$L$-values associated to cusp forms in weight aspect on average. Our estimate
of the error term allows extending the logarithmic length of mollifier $\Delta$
up to 2. The best previously known result, due to Iwaniec and Sarnak, was
$\Delta<1$. The proof is based on a representation formula for the error in
terms of Legendre polynomials.
",Mathematics
"  Zeta functions for linear codes were defined by Iwan Duursma in 1999. They
were generalized to the case of some invariant polynomials by the preset
author. One of the most important problems is whether extremal weight
enumerators satisfy the Riemann hypothesis. In this article, we show there
exist extremal polynomials of the weight enumerator type which are invariant
under the MacWilliams transform and do not satisfy the Riemann hypothesis.
",Mathematics
"  We derive a lower bound on the location of global extrema of eigenfunctions
for a large class of non-local Schrödinger operators in convex domains under
Dirichlet exterior conditions, featuring the symbol of the kinetic term, the
strength of the potential, and the corresponding eigenvalue, and involving a
new universal constant. We show a number of probabilistic and spectral
geometric implications, and derive a Faber-Krahn type inequality for non-local
operators. Our study also extends to potentials with compact support, and we
establish bounds on the location of extrema relative to the boundary edge of
the support or level sets around minima of the potential.
",Mathematics
"  These are lecture notes for the course ""MATS4300 Analysis and X-ray
tomography"" given at the University of Jyväskylä in Fall 2017. The course
is a broad overview of various tools in analysis that can be used to study
X-ray tomography. The focus is on tools and ideas, not so much on technical
details and minimal assumptions. Only very basic functional analysis is assumed
as background. Exercise problems are included.
",Mathematics
"  Let $M$ be a compact connected smooth Riemannian $n$-manifold with boundary.
We combine Gromov's amenable localization technique with the Poincaré
duality to study the traversally generic geodesic flows on $SM$, the space of
the spherical tangent bundle. Such flows generate stratifications of $SM$,
governed by rich universal combinatorics. The stratification reflects the ways
in which the geodesic flow trajectories interact with the boundary $\d(SM)$.
Specifically, we get lower estimates of the numbers of connected components of
these flow-generated strata of any given codimension $k$. These universal
bounds are expressed in terms of the normed homology $H_k(M; \R)$ and $H_k(DM;
\R)$, where $DM = M\cup_{\d M} M$ denotes the double of $M$. The norms here are
the Gromov simplicial semi-norms in homology. The more complex the metric on
$M$ is, the more numerous the strata of $SM$ and $S(DM)$ are. So one may regard
our estimates as analogues of the Morse inequalities for the geodesics on
manifolds with boundary.
It turns out that some close relatives of the normed homology spaces form
obstructions to the existence of globally $k$-convex traversally generic
metrics on $M$.
",Mathematics
"  We exhibit an equivalence between the model-theoretic framework of universal
classes and the category-theoretic framework of locally multipresentable
categories. We similarly give an equivalence between abstract elementary
classes (AECs) admitting intersections and locally polypresentable categories.
We use these results to shed light on Shelah's presentation theorem for AECs.
",Mathematics
"  We define triangulated factorization systems on triangulated categories, and
prove that a suitable subclass thereof (the normal triangulated torsion
theories) corresponds bijectively to $t$-structures on the same category. This
result is then placed in the framework of derivators regarding a triangulated
category as the base of a stable derivator. More generally, we define derivator
factorization systems in the 2-category $\mathrm{PDer}$, describing them as
algebras for a suitable strict 2-monad (this result is of independent
interest), and prove that a similar characterization still holds true: for a
stable derivator $\mathbb D$, a suitable class of derivator factorization
systems (the normal derivator torsion theories) correspond bijectively with
$t$-structures on the base $\mathbb{D}(\mathbb{1})$ of the derivator. These two
result can be regarded as the triangulated- and derivator- analogues,
respectively, of the theorem that says that `$t$-structures are normal torsion
theories' in the setting of stable $\infty$-categories, showing how the result
remains true whatever the chosen model for stable homotopy theory is.
",Mathematics
"  Let G be the group of rational points of a reductive connected group over a
finite field (resp. nonarchimedean local field of characteristic p) and R a
commutative ring. The unipotent (resp. pro-p Iwahori) invariant functor takes a
smooth representation of G to a module over the unipotent (resp. pro-p Iwahori)
Hecke R-algebra H of G. We prove that these functors for G and for a Levi
subgroup of G commute with the parabolic induction functors, as well as with
the right adjoints of the parabolic induction functors. However, they do not
commute with the left adjoints of the parabolic induction functors in general;
they do if p is invertible in R.
When R is an algebraically closed field of characteristic p, we show in the
local case that an irreducible admissible R-representation V of G is
supercuspidal (or equivalently supersingular) if and only if the H-module V^I
of its invariants by the pro-p Iwahori I admits a supersingular subquotient, if
and only if V^I is supersingular.
",Mathematics
"  In this paper we study the integral of type
\[_{\delta,a}\Gamma_{\rho,b}(x)
=\Gamma(\delta,a;\rho,b)(x)=\int_{0}^{\infty}t^{x-1}e^{-\frac{t^{\delta}}{a}-\frac{t^{-\rho}}{b}}dt.\]
Different authors called this integral by different names like ultra gamma
function, generalized gamma function, Kratzel integral, inverse Gaussian
integral, reaction-rate probability integral, Bessel integral etc. We prove
several identities and recurrence relation of above said integral, we called
this integral as Four Parameter Gamma Function. Also we evaluate relation
between Four Parameter Gamma Function, p-k Gamma Function and Classical Gamma
Function. With some conditions we can evaluate Four Parameter Gamma Function in
term of Hypergeometric function.
",Mathematics
"  We introduce dual matroids of 2-dimensional simplicial complexes. Under
certain necessary conditions, duals matroids are used to characterise
embeddability in 3-space in a way analogous to Whitney's planarity criterion.
We further use dual matroids to extend a 3-dimensional analogue of
Kuratowski's theorem to the class of 2-dimensional simplicial complexes
obtained from simply connected ones by identifying vertices or edges.
",Mathematics
"  The truncated Fourier operator $\mathscr{F}_{\mathbb{R^{+}}}$, $$
(\mathscr{F}_{\mathbb{R^{+}}}x)(t)=\frac{1}{\sqrt{2\pi}}
\int\limits_{\mathbb{R^{+}}}x(\xi)e^{it\xi}\,d\xi\,,\ \ \
t\in{}{\mathbb{R^{+}}}, $$ is studied. The operator
$\mathscr{F}_{\mathbb{R^{+}}}$ is considered as an operator acting in the space
$L^2(\mathbb{R^{+}})$. The functional model for the operator
$\mathscr{F}_{\mathbb{R^{+}}}$ is constructed. This functional model is the
multiplication operator on the appropriate $2\times2$ matrix function acting in
the space $L^2(\mathbb{R^{+}})\oplus{}L^2(\mathbb{R^{+}})$. Using this
functional model, the spectrum of the operator $\mathscr{F}_{\mathbb{R^{+}}}$
is found. The resolvent of the operator $\mathscr{F}_{\mathbb{R^{+}}}$ is
estimated near its spectrum.
",Mathematics
"  We give a generalization of a theorem of Silverman and Stephens regarding the
signs in an elliptic divisibility sequence to the case of an elliptic net. We
also describe applications of this theorem in the study of the distribution of
the signs in elliptic nets and generating elliptic nets using the denominators
of the linear combination of points on elliptic curves.
",Mathematics
"  In this work, we prove an existence result for an optimal partition problem
of the form $$\min \{F_s(A_1,\dots,A_m)\colon A_i \in \mathcal{A}_s, \, A_i\cap
A_j =\emptyset \mbox{ for } i\neq j\},$$ where $F_s$ is a cost functional with
suitable assumptions of monotonicity and lowersemicontinuity, $\mathcal{A}_s$
is the class of admissible domains and the condition $A_i\cap A_j =\emptyset$
is understood in the sense of the Gagliardo $s$-capacity, where $0<s<1$.
Examples of this type of problem are related to the fractional eigenvalues. In
addition, we prove some type of convergence of the $s$-minimizers to the
minimizer of the problem with $s=1$, studied in \cite{Bucur-Buttazzo-Henrot}.
",Mathematics
"  In this paper we prove the uniqueness and radial symmetry of minimizers for
variational problems that model several phenomena. The uniqueness is a
consequence of the convexity of the functional. The main technique is Fourier
transform of tempered distributions.
",Mathematics
"  Given the subjective preferences of n roommates in an n-bedroom apartment,
one can use Sperner's lemma to find a division of the rent such that each
roommate is content with a distinct room. At the given price distribution, no
roommate has a strictly stronger preference for a different room. We give a new
elementary proof that the subjective preferences of only n-1 of the roommates
actually suffice to achieve this envy-free rent division. Our proof, in
particular, yields an algorithm to find such a fair division of rent. The
techniques also give generalizations of Sperner's lemma including a new proof
of a conjecture of the third author.
",Mathematics
"  This article describes a sequence of rational functions which converges
locally uniformly to the zeta function. The numerators (and denominators) of
these rational functions can be expressed as characteristic polynomials of
matrices that are on the face of it very simple. As a consequence, the Riemann
hypothesis can be restated as what looks like a rather conventional spectral
problem but which is related to the one found by Connes in his analysis of the
zeta function. However the point here is that the rational approximations look
to be susceptible of quantitative estimation.
",Mathematics
"  Let $K$ be a field, $G$ a finite group. Let $G$ act on the function field $L
= K(x_{\sigma} : \sigma \in G)$ by $\tau \cdot x_{\sigma} = x_{\tau\sigma}$ for
any $\sigma, \tau \in G$. Denote the fixed field of the action by $K(G) = L^{G}
= \left\{ \frac{f}{g} \in L : \sigma(\frac{f}{g}) = \frac{f}{g}, \forall \sigma
\in G \right\}$. Noether's problem asks whether $K(G)$ is rational (purely
transcendental) over $K$. It is known that if $G = C_m \rtimes C_n$ is a
semidirect product of cyclic groups $C_m$ and $C_n$ with $\mathbb{Z}[\zeta_n]$
a unique factorization domain, and $K$ contains an $e$th primitive root of
unity, where $e$ is the exponent of $G$, then $K(G)$ is rational over $K$. In
this paper, we give another criteria to determine whether $K(C_m \rtimes C_n)$
is rational over $K$. In particular, if $p, q$ are prime numbers and there
exists $x \in \mathbb{Z}[\zeta_q]$ such that the norm
$N_{\mathbb{Q}(\zeta_q)/\mathbb{Q}}(x) = p$, then $\mathbb{C}(C_{p} \rtimes
C_{q})$ is rational over $\mathbb{C}$.
",Mathematics
"  We use nonabelian Poincaré duality to recover the stable splitting of
compactly supported mapping spaces, $\rm{Map_c}$$(M,\Sigma^nX)$, where $M$ is a
parallelizable $n$-manifold. Our method for deriving this splitting is new, and
naturally extends to give a more general stable splitting of the space of
compactly supported sections of a certain bundle on $M$ with fibers
$\Sigma^nX$, twisted by the tangent bundle of $M$. This generalization
incorporates possible $O(n)$-actions on $X$ as well as accommodating
non-parallelizable manifolds.
",Mathematics
"  In this paper we study moment sequences of matrix-valued measures on compact
intervals. A complete parametrization of such sequences is obtained via a
symmetric version of matricial canonical moments. Furthermore, distinguished
extensions of finite moment sequences are characterized in this framework. The
results are applied to the underlying matrix-valued measures, generalizing some
results from the scalar theory of canonical moments.
",Mathematics
"  We give a description of complex geodesics and we study the structure of
stationary discs in some non-convex domains for which complex geodesics are not
unique.
",Mathematics
"  A proper ideal $I$ in a commutative ring with unity is called a
$z^\circ$-ideal if for each $a$ in $I$, the intersection of all minimal prime
ideals in $R$ which contain $a$ is contained in $I$. For any totally ordered
field $F$ and a completely $F$-regular topological space $X$, let $C(X,F)$ be
the ring of all $F$-valued continuous functions on $X$ and $B(X,F)$ the
aggregate of all those functions which are bounded over $X$. An explicit
formula for all the $z^\circ$-ideals in $A(X,F)$ in terms of ideals of closed
sets in $X$ is given. It turns out that an intermediate ring $A(X,F)\neq
C(X,F)$ is never regular in the sense of Von-Neumann. This property further
characterizes $C(X,F)$ amongst the intermediate rings within the class of
$P_F$-spaces $X$. It is also realized that $X$ is an almost $P_F$-space if and
only if each maximal ideal in $C(X,F)$ is $z^\circ$-ideal. Incidentally this
property also characterizes $C(X,F)$ amongst the intermediate rings within the
family of almost $P_F$-spaces.
",Mathematics
"  We develop refined Strichartz estimates at $L^2$ regularity for a class of
time-dependent Schrödinger operators. Such refinements begin to
characterize the near-optimizers of the Strichartz estimate, and play a pivotal
part in the global theory of mass-critical NLS. On one hand, the harmonic
analysis is quite subtle in the $L^2$-critical setting due to an enormous group
of symmetries, while on the other hand, the spacetime Fourier analysis employed
by the existing approaches to the constant-coefficient equation are not adapted
to nontranslation-invariant situations, especially with potentials as large as
those considered in this article.
Using phase space techniques, we reduce to proving certain analogues of
(adjoint) bilinear Fourier restriction estimates. Then we extend Tao's bilinear
restriction estimate for paraboloids to more general Schrödinger operators.
As a particular application, the resulting inverse Strichartz theorem and
profile decompositions constitute a key harmonic analysis input for studying
large data solutions to the $L^2$-critical NLS with a harmonic oscillator
potential in dimensions $\ge 2$. This article builds on recent work of Killip,
Visan, and the author in one space dimension.
",Mathematics
"  Random code-trees with necks were introduced recently to generalise the
notion of $V$-variable and random homogeneous sets. While it is known that the
Hausdorff and packing dimensions coincide irrespective of overlaps, their exact
Hausdorff and packing measure has so far been largely ignored. In this article
we consider the general question of an appropriate gauge function for positive
and finite Hausdorff and packing measure. We first survey the current state of
knowledge and establish some bounds on these gauge functions. We then show that
self-similar code-trees do not admit a gauge functions that simultaneously give
positive and finite Hausdorff measure almost surely. This surprising result is
in stark contrast to the random recursive model and sheds some light on the
question of whether $V$-variable sets interpolate between random homogeneous
and random recursive sets. We conclude by discussing implications of our
results.
",Mathematics
"  In this paper, we prove a functorial aspect of the formal geometric
quantization procedure of non-compact spin-c manifolds.
",Mathematics
"  The concept of a C-class of differential equations goes back to E. Cartan
with the upshot that generic equations in a C-class can be solved without
integration. While Cartan's definition was in terms of differential invariants
being first integrals, all results exhibiting C-classes that we are aware of
are based on the fact that a canonical Cartan geometry associated to the
equations in the class descends to the space of solutions. For sufficiently low
orders, these geometries belong to the class of parabolic geometries and the
results follow from the general characterization of geometries descending to a
twistor space.
In this article we answer the question of whether a canonical Cartan geometry
descends to the space of solutions in the case of scalar ODEs of order at least
four and of systems of ODEs of order at least three. As in the lower order
cases, this is characterized by the vanishing of the generalized Wilczynski
invariants, which are defined via the linearization at a solution. The
canonical Cartan geometries (which are not parabolic geometries) are a slight
variation of those available in the literature based on a recent general
construction. All the verifications needed to apply this construction for the
classes of ODEs we study are carried out in the article, which thus also
provides a complete alternative proof for the existence of canonical Cartan
connections associated to higher order (systems of) ODEs.
",Mathematics
"  Let $X$ be a normal algebraic variety over a finitely generated field $k$ of
characteristic zero, and let $\ell$ be a prime. Say that a continuous
$\ell$-adic representation $\rho$ of $\pi_1^{\text{ét}}(X_{\bar k})$ is
arithmetic if there exists a representation $\tilde \rho$ of a finite index
subgroup of $\pi_1^{\text{ét}}(X)$, with $\rho$ a subquotient of
$\tilde\rho|_{\pi_1(X_{\bar k})}$. We show that there exists an integer $N=N(X,
\ell)$ such that every nontrivial, semisimple arithmetic representation of
$\pi_1^{\text{ét}}(X_{\bar k})$ is nontrivial mod $\ell^N$. As a corollary,
we prove that any nontrivial semisimple representation of
$\pi_1^{\text{ét}}(X_{\bar k})$, which arises from geometry, is nontrivial
mod $\ell^N$.
",Mathematics
"  Motivated by the study of Nishinou-Nohara-Ueda on the Floer thoery of
Gelfand-Cetlin systems over complex partial flag manifolds, we provide a
complete description of the topology of Gelfand-Cetlin fibers. We prove that
all fibers are \emph{smooth} isotropic submanifolds and give a complete
description of the fiber to be Lagrangian in terms of combinatorics of
Gelfand-Cetlin polytope. Then we study (non-)displaceability of Lagrangian
fibers. After a few combinatorial and numercal tests for the displaceability,
using the bulk-deformation of Floer cohomology by Schubert cycles, we prove
that every full flag manifold $\mathcal{F}(n)$ ($n \geq 3$) with a monotone
Kirillov-Kostant-Souriau symplectic form carries a continuum of
non-displaceable Lagrangian tori which degenerates to a non-torus fiber in the
Hausdorff limit. In particular, the Lagrangian $S^3$-fiber in $\mathcal{F}(3)$
is non-displaceable the question of which was raised by Nohara-Ueda who
computed its Floer cohomology to be vanishing.
",Mathematics
"  We show that a sufficient condition for the weak limit of a sequence of
$W^1_q$-homeomorphisms with finite distortion to be almost everywhere injective
for $q \geq n-1$, can be stated by means of composition operators. Applying
this result, we study nonlinear elasticity problems with respect to these new
classes of mappings. Furthermore, we impose loose growth conditions on the
stored-energy function for the class of $W^1_n$-homeomorphisms with finite
distortion and integrable inner as well as outer distortion coefficients.
",Mathematics
"  We study the spatially homogeneous time dependent solutions and their
bifurcations of the Gray-Scott model. We find the global map of bifurcations by
a combination of rigorous verification of the existence of Takens Bogdanov and
a Bautin bifurcations, in the space of two parameters k and F. With the aid of
numerical continuation of local bifurcation curves we give a global description
of all the possible bifurcations
",Mathematics
"  Let $Di\langle X\rangle$ be the free dialgebra over a field generated by a
set $X$. Let $S$ be a monic subset of $Di\langle X\rangle$. A
Composition-Diamond lemma for dialgebras is firstly established by Bokut, Chen
and Liu in 2010 \cite{Di} which claims that if (i) $S$ is a
Gröbner-Shirshov basis in $Di\langle X\rangle$, then (ii) the set of
$S$-irreducible words is a linear basis of the quotient dialgebra $Di\langle X
\mid S \rangle$, but not conversely. Such a lemma based on a fixed ordering on
normal diwords of $Di\langle X\rangle$ and special definition of composition
trivial modulo $S$. In this paper, by introducing an arbitrary monomial-center
ordering and the usual definition of composition trivial modulo $S$, we give a
new Composition-Diamond lemma for dialgebras which makes the conditions (i) and
(ii) equivalent. We show that every ideal of $Di\langle X\rangle$ has a unique
reduced Gröbner-Shirshov basis. The new lemma is more useful and convenient
than the one in \cite{Di}. As applications, we give a method to find normal
forms of elements of an arbitrary disemigroup, in particular, A.V. Zhuchok's
(2010) and Y.V. Zhuchok's (2015) normal forms of the free commutative
disemigroups and the free abelian disemigroups, and normal forms of the free
left (right) commutative disemigroups.
",Mathematics
"  This paper addresses distributed average tracking of physical second-order
agents with heterogeneous nonlinear dynamics, where there is no constraint on
input signals. The nonlinear terms in agents' dynamics are heterogeneous,
satisfying a Lipschitz-like condition that will be defined later and is more
general than the Lipschitz condition. In the proposed algorithm, a control
input and a filter are designed for each agent. Each agent's filter has two
outputs and the idea is that the first output estimates the average of the
input signals and the second output estimates the average of the input
velocities asymptotically. In parallel, each agent's position and velocity are
driven to track, respectively, the first and the second outputs. Having
heterogeneous nonlinear terms in agents' dynamics necessitates designing the
filters for agents. Since the nonlinear terms in agents' dynamics can be
unbounded and the input signals are arbitrary, novel state-dependent
time-varying gains are employed in agents' filters and control inputs to
overcome these unboundedness effects. Finally the results are improved to
achieve the distributed average tracking for a group of double-integrator
agents, where there is no constraint on input signals and the filter is not
required anymore. Numerical simulations are also presented to illustrate the
theoretical results.
",Mathematics
"  We develop a general framework for $c$-vectors of 2-Calabi--Yau categories,
which deals with cluster tilting subcategories that are not reachable from each
other and contain infinitely many indecomposable objects. It does not rely on
iterative sequences of mutations.
We prove a categorical (infinite-rank) generalization of the
Nakanishi--Zelevinsky duality for $c$-vectors and establish two formulae for
the effective computation of $c$-vectors -- one in terms of indices and the
other in terms of dimension vectors for cluster tilted algebras.
In this framework, we construct a correspondence between the $c$-vectors of
the cluster categories ${\mathscr{C}}(A_{\infty})$ of type $A_{\infty}$ due to
Igusa--Todorov and the roots of the Borel subalgebras of
${\mathfrak{sl}}_{\infty}$. Contrary to the finite dimensional case, the Borel
subalgebras of ${\mathfrak{sl}}_{\infty}$ are not conjugate to each other. On
the categorical side, the cluster tilting subcategories of
${\mathscr{C}}(A_{\infty})$ exhibit different homological properties. The
correspondence builds a bridge between the two classes of objects.
",Mathematics
"  A complete proof is given of relative interpretability of Adjunctive Set
Theory with Extensionality in an elementary concatenation theory.
",Mathematics
"  For each $n$, we construct a separable metric space $\mathbb{U}_n$ that is
universal in the coarse category of separable metric spaces with asymptotic
dimension ($\mathop{asdim}$) at most $n$ and universal in the uniform category
of separable metric spaces with uniform dimension ($\mathop{udim}$) at most
$n$. Thus, $\mathbb{U}_n$ serves as a universal space for dimension $n$ in both
the large-scale and infinitesimal topology. More precisely, we prove:
\[
\mathop{asdim} \mathbb{U}_n = \mathop{udim} \mathbb{U}_n = n
\] and such that for each separable metric space $X$,
a) if $\mathop{asdim} X \leq n$, then $X$ is coarsely equivalent to a subset
of $\mathbb{U}_n$;
b) if $\mathop{udim} X \leq n$, then $X$ is uniformly homeomorphic to a
subset of $\mathbb{U}_n$.
",Mathematics
"  In this paper, the existence, the uniqueness and estimates of solution to the
integral Cauchy problem for linear and nonlinear abstract wave equations are
proved. The equation includes a linear operator A defined in a Banach space E,
in which by choosing E and A we can obtain numerous classis of nonlocal initial
value problems for wave equations which occur in a wide variety of physical
systems.
",Mathematics
"  Under the usual condition that the volume of a geodesic ball is close to the
Euclidean one or the injectivity radii is bounded from below, we prove a lower
bound of the $C^{\alpha} W^{1, q}$ harmonic radius for manifolds with bounded
Bakry-Émery Ricci curvature when the gradient of the potential is bounded.
Under these conditions, the regularity that can be imposed on the metrics under
harmonic coordinates is only $C^\alpha W^{1,q}$, where $q>2n$ and $n$ is the
dimension of the manifolds. This is almost 1 order lower than that in the
classical $C^{1,\alpha} W^{2, p}$ harmonic coordinates under bounded Ricci
curvature condition [And]. The loss of regularity induces some difference in
the method of proof, which can also be used to address the detail of $W^{2, p}$
convergence in the classical case.
Based on this lower bound and the techniques in [ChNa2] and [WZ], we extend
Cheeger-Naber's Codimension 4 Theorem in [ChNa2] to the case where the
manifolds have bounded Bakry-Émery Ricci curvature when the gradient of the
potential is bounded. This result covers Ricci solitons when the gradient of
the potential is bounded.
During the proof, we will use a Green's function argument and adopt a linear
algebra argument in [Bam]. A new ingradient is to show that the diagonal
entries of the matrices in the Transformation Theorem are bounded away from 0.
Together these seem to simplify the proof of the Codimension 4 Theorem, even in
the case where Ricci curvature is bounded.
",Mathematics
"  In this paper, we enumerate Newton polygons asymptotically. The number of
Newton polygons is computable by a simple recurrence equation, but unexpectedly
the asymptotic formula of its logarithm contains growing oscillatory terms. As
the terms come from non-trivial zeros of the Riemann zeta function, an
estimation of the amplitude of the oscillating part is equivalent to the
Riemann hypothesis.
",Mathematics
"  In this paper, we give a correspondence between the Berezin-Toeplitz and the
complex Weyl quantizations of the torus $ \mathbb{T}^2$. To achieve this, we
use the correspondence between the Berezin-Toeplitz and the complex Weyl
quantizations of the complex plane and a relation between the Berezin-Toeplitz
quantization of a periodic symbol on the real phase space $\mathbb{R}^2$ and
the Berezin-Toeplitz quantization of a symbol on the torus $ \mathbb{T}^2 $.
",Mathematics
"  We consider in this paper the regularity problem for time-optimal
trajectories of a single-input control-affine system on a n-dimensional
manifold. We prove that, under generic conditions on the drift and the
controlled vector field, any control u associated with an optimal trajectory is
smooth out of a countable set of times. More precisely, there exists an integer
K, only depending on the dimension n, such that the non-smoothness set of u is
made of isolated points, accumulations of isolated points, and so on up to K-th
order iterated accumulations.
",Mathematics
"  We prove that certain coinduced actions for an inclusion of finitely
generated commensurated subgroups with relative one end are continuous cocycle
superrigid actions. We also show the necessity for the relative end assumption.
",Mathematics
"  We consider the four structures $(\mathbb{Z}; \mathrm{Sqf}^\mathbb{Z})$,
$(\mathbb{Z}; <, \mathrm{Sqf}^\mathbb{Z})$, $(\mathbb{Q};
\mathrm{Sqf}^\mathbb{Q})$, and $(\mathbb{Q}; <, \mathrm{Sqf}^\mathbb{Q})$ where
$\mathbb{Z}$ is the additive group of integers, $\mathrm{Sqf}^\mathbb{Z}$ is
the set of $a \in \mathbb{Z}$ such that $v_{p}(a) < 2$ for every prime $p$ and
corresponding $p$-adic valuation $v_{p}$, $\mathbb{Q}$ and
$\mathrm{Sqf}^\mathbb{Q}$ are defined likewise for rational numbers, and $<$
denotes the natural ordering on each of these domains. We prove that the second
structure is model-theoretically wild while the other three structures are
model-theoretically tame. Moreover, all these results can be seen as examples
where number-theoretic randomness yields model-theoretic consequences.
",Mathematics
"  Generalized Bäcklund-Darboux transformations (GBDTs) of discrete
skew-selfadjoint Dirac systems have been successfully used for explicit solving
of direct and inverse problems of Weyl-Titchmarsh theory. During explicit
solving of the direct and inverse problems, we considered GBDTs of the trivial
initial systems. However, GBDTs of arbitrary discrete skew-selfadjoint Dirac
systems are important as well and we introduce these transformations in the
present paper. The obtained results are applied to the construction of explicit
solutions of the interesting related non-stationary systems.
",Mathematics
"  Let $G$ be a finite group and let $p_1,\dots,p_n$ be distinct primes. If $G$
contains an element of order $p_1\cdots p_n,$ then there is an element in $G$
which is not contained in the Frattini subgroup of $G$ and whose order is
divisible by $p_1\cdots p_n.$
",Mathematics
"  For a smooth manifold $M$, possibly with boundary and corners, and a Lie
group $G$, we consider a suitable description of gauge fields in terms of
parallel transport, as groupoid homomorphisms from a certain path groupoid in
$M$ to $G$. Using a cotriangulation $\mathscr{C}$ of $M$, and collections of
finite-dimensional families of paths relative to $\mathscr{C}$, we define a
homotopical equivalence relation of parallel transport maps, leading to the
concept of an extended lattice gauge (ELG) field. A lattice gauge field, as
used in Lattice Gauge Theory, is part of the data contained in an ELG field,
but the latter contains further local topological information sufficient to
reconstruct a principal $G$-bundle on $M$ up to equivalence. The space of ELG
fields of a given pair $(M,\mathscr{C})$ is a covering for the space of fields
in Lattice Gauge Theory, whose connected components parametrize equivalence
classes of principal $G$-bundles on $M$. We give a criterion to determine when
ELG fields over different cotriangulations define equivalent bundles.
",Mathematics
"  We discuss channel surfaces in the context of Lie sphere geometry and
characterise them as certain $\Omega_{0}$-surfaces. Since $\Omega_{0}$-surfaces
possess a rich transformation theory, we study the behaviour of channel
surfaces under these transformations. Furthermore, by using certain Dupin
cyclide congruences, we characterise Ribaucour pairs of channel surfaces.
",Mathematics
"  We prove that if a solution of the time-dependent Schr{ö}dinger equation on
an homogeneous tree with bounded potential decays fast at two distinct times
then the solution is trivial. For the free Schr{ö}dinger operator, we use the
spectral theory of the Laplacian and complex analysis and obtain a
characterization of the initial conditions that lead to a sharp decay at any
time. We then use the recent spectral decomposition of the Schr{ö}dinger
operator with compactly supported potential due to Colin de Verdi{è}rre and
Turc to extend our results in the presence of such potentials. Finally, we use
real variable methods first introduced by Escauriaza, Kenig, Ponce and Vega to
establish a general sharp result in the case of bounded potentials.
",Mathematics
"  In this paper, we strengthen the splitting theorem proved in [14, 15] and
provide a different approach using ideas from the weak KAM theory.
",Mathematics
"  Counting formulae for general primary fields in free four dimensional
conformal field theories of scalars, vectors and matrices are derived. These
are specialised to count primaries which obey extremality conditions defined in
terms of the dimensions and left or right spins (i.e. in terms of relations
between the charges under the Cartan subgroup of $SO(4,2)$). The construction
of primary fields for scalar field theory is mapped to a problem of determining
multi-variable polynomials subject to a system of symmetry and differential
constraints. For the extremal primaries, we give a construction in terms of
holomorphic polynomial functions on permutation orbifolds, which are shown to
be Calabi-Yau spaces.
",Mathematics
"  The first goal of this note is to study the Almansi property on an
m-dimensional model in the sense of Greene and Wu and, more generally, in a
Riemannian geometric setting. In particular, we shall prove that the only model
on which the Almansi property is verified is the Euclidean space R^m. In the
second part of the paper we shall study Almansi's property and biharmonicity
for functions which depend on the distance from a given submanifold. Finally,
in the last section we provide an extension to the semi-Euclidean case R^{p,q}
which includes the proof of the classical Almansi property in R^m as a special
instance.
",Mathematics
"  We show that the knowledge of Dirichlet to Neumann map for rough $A$ and $q$
in $(-\Delta)^m +A\cdot D +q$ for $m \geq 2$ for a bounded domain in
$\mathbb{R}^n$, $n \geq 3$ determines $A$ and $q$ uniquely. The unique
identifiability is proved using property of products of functions in Sobolev
spaces and constructing complex geometrical optics solutions with sufficient
decay of remainder terms.
",Mathematics
"  In this paper, we prove $L^q$-estimates for gradients of solutions to
singular quasilinear elliptic equations with measure data
$$-\operatorname{div}(A(x,\nabla u))=\mu,$$ in a bounded domain
$\Omega\subset\mathbb{R}^{N}$, where $A(x,\nabla u)\nabla u \asymp |\nabla
u|^p$, $p\in (1,2-\frac{1}{n}]$ and $\mu$ is a Radon measure in $\Omega$
",Mathematics
"  Let $A$ be a commutative Noetherian ring containing a field $K$ of
characteristic zero and let $R= A[X_1, \ldots, X_m]$. Consider $R$ as standard
graded with $°A=0$ and $°X_i=1$ for all $i$. We present a few results
about the behavior of the graded components of local cohomology modules
$H_I^i(R)$ where $I$ is an arbitrary homogeneous ideal in $R$. We mostly
restrict our attention to the Vanishing, Tameness and Rigidity problems.
",Mathematics
"  Slater's condition -- existence of a ""strictly feasible solution"" -- is a
common assumption in conic optimization. Without strict feasibility,
first-order optimality conditions may be meaningless, the dual problem may
yield little information about the primal, and small changes in the data may
render the problem infeasible. Hence, failure of strict feasibility can
negatively impact off-the-shelf numerical methods, such as primal-dual interior
point methods, in particular. New optimization modelling techniques and convex
relaxations for hard nonconvex problems have shown that the loss of strict
feasibility is a more pronounced phenomenon than has previously been realized.
In this text, we describe various reasons for the loss of strict feasibility,
whether due to poor modelling choices or (more interestingly) rich underlying
structure, and discuss ways to cope with it and, in many pronounced cases, how
to use it as an advantage. In large part, we emphasize the facial reduction
preprocessing technique due to its mathematical elegance, geometric
transparency, and computational potential.
",Mathematics
"  This paper is concerned with two-person dynamic zero-sum games. Let games for
some family have common dynamics, running costs and capabilities of players,
and let these games differ in densities only. We show that the Dynamic
Programming Principle directly leads to the General Tauberian Theorem---that
the existence of a uniform limit of the value functions for uniform
distribution or for exponential distribution implies that the value functions
uniformly converge to the same limit for arbitrary distribution from large
class. No assumptions on strategies are necessary. Applications to differential
games and stochastic statement are considered.
",Mathematics
"  The problem of construction a quantum mechanical evolution for the
Schrodinger equation with a degenerate Hamiltonian which is a symmetric
operator that does not have self-adjoint extensions is considered. Self-adjoint
regularization of the Hamiltonian does not lead to a preserving probability
limiting evolution for vectors from the Hilbert space but it is used to
construct a limiting evolution of states on a C*-algebra of compact operators
and on an abelian subalgebra of operators in the Hilbert space. The limiting
evolution of the states on the abelian algebra can be presented by the Kraus
decomposition with two terms. Both of this terms are corresponded to the
unitary and shift components of Wold's decomposition of isometric semigroup
generated by the degenerate Hamiltonian. Properties of the limiting evolution
of the states on the C*-algebras are investigated and it is shown that pure
states could evolve into mixed states.
",Mathematics
"  Our start point is a 3D piecewise smooth vector field defined in two zones
and presenting a shared fold curve for the two smooth vector fields considered.
Moreover, these smooth vector fields are symmetric relative to the fold curve,
giving raise to a continuum of nested topological cylinders such that each
orthogonal section of these cylinders is filled by centers. First we prove that
the normal form considered represents a whole class of piecewise smooth vector
fields. After we perturb the initial model in order to obtain exactly
$\mathcal{L}$ invariant planes containing centers. A second perturbation of the
initial model also is considered in order to obtain exactly $k$ isolated
cylinders filled by periodic orbits. Finally, joining the two previous
bifurcations we are able to exhibit a model, preserving the symmetry relative
to the fold curve, and having exactly $k.\mathcal{L}$ limit cycles.
",Mathematics
"  In this paper, we consider the final state problem for the nonlinear
Schrödinger equation with a homogeneous nonlinearity of the critical order
which is not necessarily a polynomial. In [10], the first and the second
authors consider one- and two-dimensional cases and gave a sufficient condition
on the nonlinearity for that the corresponding equation admits a solution that
behaves like a free solution with or without a logarithmic phase correction.
The present paper is devoted to the study of the three-dimensional case, in
which it is required that a solution converges to a given asymptotic profile in
a faster rate than in the lower dimensional cases. To obtain the necessary
convergence rate, we employ the end-point Strichartz estimate and modify a
time-dependent regularizing operator, introduced in [10]. Moreover, we present
a candidate of the second asymptotic profile to the solution.
",Mathematics
"  We relate the old and new cohomology monoids of an arbitrary monoid $M$ with
coefficients in semimodules over $M$, introduced in the author's previous
papers, to monoid and group extensions. More precisely, the old and new second
cohomology monoids describe Schreier extensions of semimodules by monoids, and
the new third cohomology monoid is related to a certain group extension
problem.
",Mathematics
"  In this paper, we consider the cubic fourth-order nonlinear Schrödinger
equation (4NLS) under the periodic boundary condition. We prove two results.
One is the local well-posedness in $H^s$ with $-1/3 \le s < 0$ for the Cauchy
problem of the Wick ordered 4NLS. The other one is the non-squeezing property
for the flow map of 4NLS in the symplectic phase space $L^2(\mathbb{T})$. To
prove the former we used the ideas introduced in [Takaoka and Tsutsumi 2004]
and [Nakanish et al 2010], and to prove the latter we used the ideas in
[Colliander et al 2005].
",Mathematics
"  This paper can be viewed as a sequel to the author's long survey on the
Zimmer program \cite{F11} published in 2011. The sequel focuses on recent rapid
progress on certain aspects of the program particularly concerning rigidity of
Anosov actions and Zimmer's conjecture that there are no actions in low
dimensions. Some emphasis is put on the surprising connections between these
two different sets of developments and also on the key connections and ideas
for future research that arise from these works taken together.
",Mathematics
"  We study a set of uniquely determined tilting and cotilting modules for an
algebra with positive dominant dimension, with the property that they are
generated or cogenerated (and usually both) by projective-injectives. These
modules have various interesting properties, for example that their
endomorphism algebras always have global dimension at most that of the original
algebra. We characterise d-Auslander-Gorenstein algebras and d-Auslander
algebras via the property that the relevant tilting and cotilting modules
coincide. By the Morita-Tachikawa correspondence, any algebra of dominant
dimension at least 2 may be expressed (essentially uniquely) as the
endomorphism algebra of a generator-cogenerator for another algebra, and we
also study our special tilting and cotilting modules from this point of view,
via the theory of recollements and intermediate extension functors.
",Mathematics
"  We consider a generalized Dirac operator on a compact stratified space with
an iterated cone-edge metric. Assuming a spectral Witt condition, we prove its
essential self-adjointness and identify its domain and the domain of its square
with weighted edge Sobolev spaces. This sharpens previous results where the
minimal domain is shown only to be a subset of an intersection of weighted edge
Sobolev spaces. Our argument does not rely on microlocal techniques and is very
explicit. The novelty of our approach is the use of an abstract functional
analytic notion of interpolation scales. Our results hold for the Gauss-Bonnet
and spin Dirac operators satisfying a spectral Witt condition.
",Mathematics
"  The object of study in the present dissertation are some topics in
differential geometry of smooth manifolds with additional tensor structures and
metrics of Norden type. There are considered four cases depending on the
dimension of the manifold: 2n, 2n + 1, 4n and 4n + 3. The studied tensor
structures, which are counterparts in the different related dimensions, are the
almost complex/contact/hypercomplex structure and the almost contact
3-structure. The considered metric on the 2n-dimensional case is the Norden
metric, and the metrics in the other three cases are generated by it. The
purpose of the dissertation is to carry out the following: 1. Further
investigations of almost complex manifolds with Norden metric including
studying of natural connections with conditions for their torsion and invariant
tensors under the twin interchange of Norden metrics. 2. Further investigations
of almost contact manifolds with B-metric including studying of natural
connections with conditions for their torsion and associated Schouten-van
Kampen connections as well as a classification of affine connections. 3.
Introducing and studying of Sasaki-like almost contact complex Riemannian
manifolds. 4. Further investigations of almost hypercomplex manifolds with
Hermitian-Norden metrics including studying of integrable structures of the
considered type on 4-dimensional Lie algebra and tangent bundles with the
complete lift of the base metric; introducing of associated Nijenhuis tensors
in relation with natural connections having totally skew-symmetric torsion as
well as quaternionic Kähler manifolds with Hermitian-Norden metrics. 5.
Introducing and studying of manifolds with almost contact 3-structures and
metrics of Hermitian-Norden type and, in particular, associated Nijenhuis
tensors and their relationship with natural connections having totally
skew-symmetric torsion.
",Mathematics
"  This article studies a confluence of a pair of regular singular points to an
irregular one in a generic family of time-dependent Hamiltonian systems in
dimension 2. This is a general setting for the understanding of the
degeneration of the sixth Painleve equation to the fifth one. The main result
is a theorem of sectoral normalization of the family to an integrable formal
normal form, through which is explained the relation between the local
monodromy operators at the two regular singularities and the non-linear Stokes
phenomenon at the irregular singularity of the limit system. The problem of
analytic classification is also addressed.
Key words: Non-autonomous Hamiltonian systems; irregular singularity;
non-linear Stokes phenomenon; wild monodromy; confluence; local analytic
classification; Painleve equations.
",Mathematics
"  According to the Wiener-Hopf factorization, the characteristic function
$\varphi$ of any probability distribution $\mu$ on $\mathbb{R}$ can be
decomposed in a unique way as
\[1-s\varphi(t)=[1-\chi_-(s,it)][1-\chi_+(s,it)]\,,\;\;\;|s|\le1,\,t\in\mathbb{R}\,,\]
where $\chi_-(e^{iu},it)$ and $\chi_+(e^{iu},it)$ are the characteristic
functions of possibly defective distributions in
$\mathbb{Z}_+\times(-\infty,0)$ and $\mathbb{Z}_+\times[0,\infty)$,
respectively.
We prove that $\mu$ can be characterized by the sole data of the upward
factor $\chi_+(s,it)$, $s\in[0,1)$, $t\in\mathbb{R}$ in many cases including
the cases where:
1) $\mu$ has some exponential moments;
2) the function $t\mapsto\mu(t,\infty)$ is completely monotone on
$(0,\infty)$;
3) the density of $\mu$ on $[0,\infty)$ admits an analytic continuation on
$\mathbb{R}$.
We conjecture that any probability distribution is actually characterized by
its upward factor. This conjecture is equivalent to the following: {\it Any
probability measure $\mu$ on $\mathbb{R}$ whose support is not included in
$(-\infty,0)$ is determined by its convolution powers $\mu^{*n}$, $n\ge1$
restricted to $[0,\infty)$}. We show that in many instances, the sole knowledge
of $\mu$ and $\mu^{*2}$ restricted to $[0,\infty)$ is actually sufficient to
determine $\mu$. Then we investigate the analogous problem in the framework of
infinitely divisible distributions.
",Mathematics
"  For a field $k$, we prove that the $i$th homology of the groups $GL_n(k)$,
$SL_n(k)$, $Sp_{2n}(k)$, $SO_{n,n}(k)$, and $SO_{n,n+1}(k)$ with coefficients
in their Steinberg representations vanish for $n \geq 2i+2$.
",Mathematics
"  A trace $\tau$ on a separable C*-algebra $A$ is called matricial field (MF)
if there is a trace-preserving morphism from $A$ to $Q_\omega$, where
$Q_\omega$ denotes the norm ultrapower of the universal UHF-algebra $Q$. In
general, the trace $\tau$ induces a state on the Cuntz semigroup $Cu(A)$. We
show there is always a state-preserving morphism from $Cu(A)$ to
$Cu(Q_\omega)$.
As an application, if $A$ is an AI-algebra and $F$ is a free group acting on
$A$, then every trace on the reduced crossed product $A \rtimes F$ is MF. This
further implies the same result when $A$ is an AH-algebra with the ideal
property such that $K_1(A)$ is a torsion group. We also use this to
characterize when $A \rtimes F$ is MF (i.e. admits an isometric morphism into
$Q_\omega$) for many simple, nuclear C*-algebras $A$.
",Mathematics
"  A high order wavelet integral collocation method (WICM) is developed for
general nonlinear boundary value problems in physics. This method is
established based on Coiflet approximation of multiple integrals of interval
bounded functions combined with an accurate and adjustable boundary extension
technique. The convergence order of this approximation has been proven to be N
as long as the Coiflet with N-1 vanishing moment is adopted, which can be any
positive even integers. Before the conventional collocation method is applied
to the general problems, the original differential equation is changed into its
equivalent form by denoting derivatives of the unknown function as new
functions and constructing relations between the low and high order
derivatives. For the linear cases, error analysis has proven that the proposed
WICM is order N, and condition numbers of relevant matrices are almost
independent of the number of collocation points. Numerical examples of a wide
range of nonlinear differential equations in physics demonstrate that accuracy
of the proposed WICM is even greater than N, and most interestingly, such
accuracy is independent of the order of the differential equation to be solved.
Comparison to existing numerical methods further justifies the accuracy and
efficiency of the proposed method.
",Mathematics
"  We construct an absolutely normal number whose continued fraction expansion
is normal in the sense that it contains all finite patterns of partial
quotients with the expected asymptotic frequency as given by the Gauss-Kuzmin
measure. The construction is based on ideas of Sierpinski and uses a large
deviations theorem for sums of mixing random variables.
",Mathematics
"  We study the fragmentation-coagulation (or merging and splitting)
evolutionary control model as introduced recently by one of the authors, where
$N$ small players can form coalitions to resist to the pressure exerted by the
principal. It is a Markov chain in continuous time and the players have a
common reward to optimize. We study the behavior as $N$ grows and show that the
problem converges to a (one player) deterministic optimization problem in
continuous time, in the infinite dimensional state space.
",Mathematics
"  Let $\mu$ be a borelian probability measure on
$\mathbf{G}:=\mathrm{SL}_d(\mathbb{Z}) \ltimes \mathbb{T}^d$. Define, for $x\in
\mathbb{T}^d$, a random walk starting at $x$ denoting for $n\in \mathbb{N}$, \[
\left\{\begin{array}{rcl} X_0 &=&x\\ X_{n+1} &=& a_{n+1} X_n + b_{n+1}
\end{array}\right. \] where $((a_n,b_n))\in \mathbf{G}^\mathbb{N}$ is an iid
sequence of law $\mu$.
Then, we denote by $\mathbb{P}_x$ the measure on $(\mathbb{T}^d)^\mathbb{N}$
that is the image of $\mu^{\otimes \mathbb{N}}$ by the map $\left((g_n) \mapsto
(x,g_1 x, g_2 g_1 x, \dots , g_n \dots g_1 x, \dots)\right)$ and for any
$\varphi \in \mathrm{L}^1((\mathbb{T}^d)^\mathbb{N}, \mathbb{P}_x)$, we set
$\mathbb{E}_x \varphi((X_n)) = \int \varphi((X_n))
\mathrm{d}\mathbb{P}_x((X_n))$.
Bourgain, Furmann, Lindenstrauss and Mozes studied this random walk when
$\mu$ is concentrated on $\mathrm{SL}_d(\mathbb{Z}) \ltimes\{0\}$ and this
allowed us to study, for any hölder-continuous function $f$ on the torus, the
sequence $(f(X_n))$ when $x$ is not too well approximable by rational points.
In this article, we are interested in the case where $\mu$ is not
concentrated on $\mathrm{SL}_d(\mathbb{Z}) \ltimes \mathbb{Q}^d/\mathbb{Z}^d$
and we prove that, under assumptions on the group spanned by the support of
$\mu$, the Lebesgue's measure $\nu$ on the torus is the only stationary
probability measure and that for any hölder-continuous function $f$ on the
torus, $\mathbb{E}_x f(X_n)$ converges exponentially fast to $\int
f\mathrm{d}\nu$.
Then, we use this to prove the law of large numbers, a non-concentration
inequality, the functional central limit theorem and it's almost-sure version
for the sequence $(f(X_n))$.
In the appendix, we state a non-concentration inequality for products of
random matrices without any irreducibility assumption.
",Mathematics
"  Let H(q,p) = p^2/2 + V(q) be a 1-degree of freedom mechanical Hamiltonian
with a C^n periodic potential V where n>4. The Nosé-thermostated system
associated to H is shown to have invariant tori near the infinite temperature
limit. This is shown to be true for all thermostats similar to Nosé's. These
results complement the result of Legoll, Luskin and Moeckel who proved the
existence of such tori near the decoupling limit.
",Mathematics
"  Permutation polynomials over finite fields have wide applications in many
areas of science and engineering. In this paper, we present six new classes of
permutation trinomials over $\mathbb{F}_{2^n}$ which have explicit forms by
determining the solutions of some equations.
",Mathematics
"  In this work we consider open quantum random walks on the non-negative
integers. By considering orthogonal matrix polynomials we are able to describe
transition probability expressions for classes of walks via a matrix version of
the Karlin-McGregor formula. We focus on absorbing boundary conditions and, for
simpler classes of examples, we consider path counting and the corresponding
combinatorial tools. A non-commutative version of the gambler's ruin is studied
by obtaining the probability of reaching a certain fortune and the mean time to
reach a fortune or ruin in terms of generating functions. In the case of the
Hadamard coin, a counting technique for boundary restricted paths in a lattice
is also presented. We discuss an open quantum version of Foster's Theorem for
the expected return time together with applications.
",Mathematics
"  Hecke-Hopf algebras were defined by A. Berenstein and D. Kazhdan. We give an
explicit presentation of an Hecke-Hopf algebra when the parameter $m_{ij},$
associated to any two distinct vertices $i$ and $j$ in the presentation of a
Coxeter group, equals $4,$ $5$ or $6$. As an application, we give a proof of a
conjecture of Berenstein and Kazhdan when the Coxeter group is crystallographic
and non-simply-laced. As another application, we show that another conjecture
of Berenstein and Kazhdan holds when $m_{ij},$ associated to any two distinct
vertices $i$ and $j,$ equals $4$ and that the conjecture does not hold when
some $m_{ij}$ equals $6$ by giving a counterexample to it.
",Mathematics
"  Learning approaches have recently become very popular in the field of inverse
problems. A large variety of methods has been established in recent years,
ranging from bi-level learning to high-dimensional machine learning techniques.
Most learning approaches, however, only aim at fitting parametrised models to
favourable training data whilst ignoring misfit training data completely. In
this paper, we follow up on the idea of learning parametrised regularisation
functions by quotient minimisation as established in [3]. We extend the model
therein to include higher-dimensional filter functions to be learned and allow
for fit- and misfit-training data consisting of multiple functions. We first
present results resembling behaviour of well-established derivative-based
sparse regularisers like total variation or higher-order total variation in
one-dimension. Our second and main contribution is the introduction of novel
families of non-derivative-based regularisers. This is accomplished by learning
favourable scales and geometric properties while at the same time avoiding
unfavourable ones.
",Mathematics
"  We prove that for a free noncyclic group $F$, $H_2(\hat F_\mathbb Q, \mathbb
Q)$ is an uncountable $\mathbb Q$-vector space. Here $\hat F_\mathbb Q$ is the
$\mathbb Q$-completion of $F$. This answers a problem of A.K. Bousfield for the
case of rational coefficients. As a direct consequence of this result it
follows that, a wedge of circles is $\mathbb Q$-bad in the sense of
Bousfield-Kan. The same methods as used in the proof of the above results allow
to show that, the homology $H_2(\hat F_\mathbb Z,\mathbb Z)$ is not divisible
group, where $\hat F_\mathbb Z$ is the integral pronilpotent completion of $F$.
",Mathematics
"  A generalization of the coordinated transaction scheduling (CTS)---the
state-of-the-art interchange scheduling---is proposed. Referred to as
generalized coordinated transaction scheduling (GCTS), the proposed approach
addresses major seams issues of CTS: the ad hoc use of proxy buses, the
presence of loop flow as a result of proxy bus approximation, and difficulties
in dealing with multiple interfaces. By allowing market participants to submit
bids across market boundaries, GCTS also generalizes the joint economic
dispatch that achieves seamless interchange without market participants. It is
shown that GCTS asymptotically achieves seamless interface under certain
conditions. GCTS is also shown to be revenue adequate in that each regional
market has a non-negative net revenue that is equal to its congestion rent.
Numerical examples are presented to illustrate the quantitative improvement of
the proposed approach.
",Mathematics
"  Let $K$ be a simply connected compact Lie group and $T^{\ast}(K)$ its
cotangent bundle. We consider the problem of ""quantization commutes with
reduction"" for the adjoint action of $K$ on $T^{\ast}(K).$ We quantize both
$T^{\ast}(K)$ and the reduced phase space using geometric quantization with
half-forms. We then construct a geometrically natural map from the space of
invariant elements in the quantization of $T^{\ast}(K)$ to the quantization of
the reduced phase space. We show that this map is a constant multiple of a
unitary map.
",Mathematics
"  In this paper we present and expand upon procedures for obtaining large d
digit prime number to an arbitrary probability. We use a layered approach. The
first step is to limit the pool of random number to exclude numbers that are
obviously composite. We first remove any number ending in 1,3,7 or 9. We then
exclude numbers whose digital root is not 3, 6, or 9. This sharply reduces the
probability of the random number being composite. We then use the Prime Number
Theorem to find the probability that the selected number n is prime and use
primality tests to increase the probability to an arbitrarily high degree that
n is prime. We apply primality tests including Euler's test based on Fermat
Little theorem and the Miller-Rabin test. We computed these conditional
probabilities and implemented it using the GNU GMP library.
",Mathematics
"  The modified Gram-Schmidt (MGS) orthogonalization is one of the most
well-used algorithms for computing the thin QR factorization. MGS can be
straightforwardly extended to a non-standard inner product with respect to a
symmetric positive definite matrix $A$. For the thin QR factorization of an $m
\times n$ matrix with the non-standard inner product, a naive implementation of
MGS requires $2n$ matrix-vector multiplications (MV) with respect to $A$. In
this paper, we propose $n$-MV implementations: a high accuracy (HA) type and a
high performance (HP) type, of MGS. We also provide error bounds of the HA-type
implementation. Numerical experiments and analysis indicate that the proposed
implementations have competitive advantages over the naive implementation in
terms of both computational cost and accuracy.
",Mathematics
"  We give a classification and complete algebraic description of groups
allowing only finitely many (left multiplication invariant) circular orders. In
particular, they are all solvable groups with a specific semi-direct product
decomposition. This allows us to also show that the space of circular orders of
any group is either finite or uncountable. As a special case and first step, we
show that the space of circular orderings of an infinite Abelian group has no
isolated points, hence is homeomorphic to a cantor set.
",Mathematics
"  We establish four supercongruences between truncated ${}_3F_2$ hypergeometric
series involving $p$-adic Gamma functions, which extend some of the
Rodriguez-Villegas supercongruences.
",Mathematics
"  The present contribution investigates the dynamics generated by the
two-dimensional Vlasov-Poisson-Fokker-Planck equation for charged particles in
a steady inhomogeneous background of opposite charges. We provide global in
time estimates that are uniform with respect to initial data taken in a bounded
set of a weighted $L^2$ space, and where dependencies on the mean-free path
$\tau$ and the Debye length $\delta$ are made explicit. In our analysis the
mean free path covers the full range of possible values: from the regime of
evanescent collisions $\tau\to\infty$ to the strongly collisional regime
$\tau\to0$. As a counterpart, the largeness of the Debye length, that enforces
a weakly nonlinear regime, is used to close our nonlinear estimates.
Accordingly we pay a special attention to relax as much as possible the
$\tau$-dependent constraint on $\delta$ ensuring exponential decay with
explicit $\tau$-dependent rates towards the stationary solution. In the
strongly collisional limit $\tau\to0$, we also examine all possible asymptotic
regimes selected by a choice of observation time scale. Here also, our emphasis
is on strong convergence, uniformity with respect to time and to initial data
in bounded sets of a $L^2$ space. Our proofs rely on a detailed study of the
nonlinear elliptic equation defining stationary solutions and a careful
tracking and optimization of parameter dependencies of
hypocoercive/hypoelliptic estimates.
",Mathematics
"  This paper deals with existence and regularity of positive solutions of
singular elliptic problems on a smooth bounded domain with Dirichlet boundary
conditions involving the $\Phi$-Laplacian operator. The proof of existence is
based on a variant of the generalized Galerkin method that we developed
inspired on ideas by Browder and a comparison principle. By using a kind of
Moser iteration scheme we show $L^{\infty}(\Omega)$-regularity for positive
solutions
",Mathematics
"  In this sequel to earlier papers by three of the authors, we obtain a new
bound on the complexity of a closed 3--manifold, as well as a characterisation
of manifolds realising our complexity bounds. As an application, we obtain the
first infinite families of minimal triangulations of Seifert fibred spaces
modelled on Thurston's geometry $\widetilde{\text{SL}_2(\mathbb{R})}.$
",Mathematics
"  In a recent work, the degenerate Stirling polynomials of the second kind were
studied by T. Kim. In this paper, we investigate the extended degenerate
Stirling numbers of the second kind and the extended degenerate Bell
polynomials associated with them. As results, we give some expressions,
identities and properties about the extended degener- ate Stirling numbers of
the second kind and the extended degenerate Bell polynomials.
",Mathematics
"  We observe that derived equivalent K3 surfaces have isomorphic Chow motives.
",Mathematics
"  Let $X$ be a del Pezzo surface of degree $5$ defined over a field $F$. A
theorem of Yu. I. Manin and P. Swinnerton-Dyer asserts that every Del Pezzo
surface of degree $5$ is rational. In this paper we generalize this result as
follows. Recall that del Pezzo surfaces of degree $5$ over a field $F$ are
precisely the twisted $F$-forms of the moduli space $\overline{M_{0, 5}}$ of
stable curves of genus $0$ with $5$ marked points. Suppose $n \geq 5$ is an
integer, and $F$ is an infinite field of characteristic $\neq 2$. It is easy to
see that every twisted $F$-form of $\overline{M_{0, n}}$ is unirational over
$F$. We show that
(a) if $n$ is odd, then every twisted $F$-form of $\overline{M_{0, n}}$ is
rational over $F$.
(b) If $n$ is even, there exists a field extension $F/k$ and a twisted
$F$-form $X$ of $\overline{M_{0, n}}$ such that $X$ is not retract rational
over $F$.
",Mathematics
"  We prove (and improve) the Muir-Suffridge conjecture for holomorphic convex
maps. Namely, let $F:\mathbb B^n\to \mathbb C^n$ be a univalent map from the
unit ball whose image $D$ is convex. Let $\mathcal S\subset \partial \mathbb
B^n$ be the set of points $\xi$ such that $\lim_{z\to \xi}\|F(z)\|=\infty$.
Then we prove that $\mathcal S$ is either empty, or contains one or two points
and $F$ extends as a homeomorphism $\tilde{F}:\overline{\mathbb B^n}\setminus
\mathcal S\to \overline{D}$. Moreover, $\mathcal S=\emptyset$ if $D$ is
bounded, $\mathcal S$ has one point if $D$ has one connected component at
$\infty$ and $\mathcal S$ has two points if $D$ has two connected components at
$\infty$ and, up to composition with an affine map, $F$ is an extension of the
strip map in the plane to higher dimension.
",Mathematics
"  In this paper, we construct the Green function for the classical
Orr-Sommerfeld equations, which are the linearized Navier-Stokes equations
around a boundary layer profile. As an immediate application, we derive uniform
sharp bounds on the semigroup of the linearized Navier-Stokes problem around
unstable profiles in the vanishing viscosity limit.
",Mathematics
"  This is a continuation and completion of the program (initiated in
\cite{GrN1,GrN2}) to derive pointwise estimates on the Green function and sharp
bounds on the semigroup of linearized Navier-Stokes around a generic stationary
boundary layer profile. This is done via a spectral analysis approach and a
careful study of the Orr-Sommerfeld equations, or equivalently the
Navier-Stokes resolvent operator $(\lambda - L)^{-1}$. The earlier work
(\cite{GrN1,GrN2}) treats the Orr-Sommerfeld equations away from critical
layers: this is the case when the phase velocity is away from the range of the
background profile or when $\lambda$ is away from the Euler continuous
spectrum. In this paper, we study the critical case: the Orr-Sommerfeld
equations near critical layers, providing pointwise estimates on the Green
function as well as carefully studying the Dunford's contour integral near the
critical layers.
As an application, we obtain pointwise estimates on the Green function and
sharp bounds on the semigroup of the linearized Navier-Stokes problem near
monotonic boundary layers that are spectrally stable to the Euler equations,
complementing \cite{GrN1,GrN2} where unstable profiles are considered.
",Mathematics
"  We calculate model theoretic ranks of Painlevé equations in this article,
showing in particular, that any equation in any of the Painlevé families has
Morley rank one, extending results of Nagloo and Pillay (2011). We show that
the type of the generic solution of any equation in the second Painlevé
family is geometrically trivial, extending a result of Nagloo (2015).
We also establish the orthogonality of various pairs of equations in the
Painlevé families, showing at least generically, that all instances of
nonorthogonality between equations in the same Painlevé family come from
classically studied B{ä}cklund transformations. For instance, we show that if
at least one of $\alpha, \beta$ is transcendental, then $P_{II} (\alpha)$ is
nonorthogonal to $P_{II} ( \beta )$ if and only if $\alpha+ \beta \in \mathbb
Z$ or $\alpha - \beta \in \mathbb Z$. Our results have concrete interpretations
in terms of characterizing the algebraic relations between solutions of
Painlevé equations. We give similar results for orthogonality relations
between equations in different Painlevé families, and formulate some general
questions which extend conjectures of Nagloo and Pillay (2011) on transcendence
and algebraic independence of solutions to Painlevé equations. We also apply
our analysis of ranks to establish some orthogonality results for pairs of
Painlevé equations from different families. For instance, we answer several
open questions of Nagloo (2016), and in the process answer a question of Boalch
(2012).
",Mathematics
"  We study the structure of the $(\mathfrak{g},K)$-modules of the principal
series representations of $SL(3,\mathbb{R})$ and $Sp(2,\mathbb{R})$ induced
from minimal parabolic subgroups, in the case when the infinitesimal character
is nonsingular. The composition factors of these modules are known by
Kazhdan-Lusztig-Vogan conjecture. In this paper, we give complete descriptions
of the socle filtrations of these modules.
",Mathematics
"  Given a 0-dimensional scheme $\mathbb{X}$ in a projective space
$\mathbb{P}^n_K$ over a field $K$, we characterize the Cayley-Bacharach
property of $\mathbb{X}$ in terms of the algebraic structure of the Dedekind
different of its homogeneous coordinate ring. Moreover, we characterize
Cayley-Bacharach schemes by Dedekind's formula for the conductor and the
complementary module, we study schemes with minimal Dedekind different using
the trace of the complementary module, and we prove various results about
almost Gorenstein and nearly Gorenstein schemes.
",Mathematics
"  In this paper we study right $S$-Noetherian rings and modules, extending of
notions introduced by Anderson and Dumitrescu in commutative algebra to
noncommutative rings. Two characterizations of right $S$-Noetherian rings are
given in terms of completely prime right ideals and point annihilator sets. We
also prove an existence result for completely prime point annihilators of
certain $S$-Noetherian modules with the following consequence in commutative
algebra: If a module $M$ over a commutative ring is $S$-Noetherian with respect
to a multiplicative set $S$ that contains no zero-divisors for $M$, then $M$
has an associated prime.
",Mathematics
"  Let $\,\Xi\,$ be the crown domain associated with a non-compact irreducible
hermitian symmetric space $\,G/K$. We give an explicit description of the
unique $\,G$-invariant adapted hyper-Kähler structure on $\,\Xi$,$\
$i.$\,$e.$\ $compatible with the adapted complex structure $\,J_{ad}\,$ and
with the $\,G$-invariant Kähler structure of $\,G/K$. We also compute
invariant potentials of the involved Kähler metrics and the associated moment
maps.
",Mathematics
"  We construct Knörrer type equivalences outside of the hypersurface case,
namely, between singularity categories of cyclic quotient surface singularities
and certain finite dimensional local algebras. This generalises Knörrer's
equivalence for singularities of Dynkin type A (between Krull dimensions $2$
and $0$) and yields many new equivalences between singularity categories of
finite dimensional algebras.
Our construction uses noncommutative resolutions of singularities, relative
singularity categories, and an idea of Hille & Ploog yielding strongly
quasi-hereditary algebras which we describe explicitly by building on Wemyss's
work on reconstruction algebras. Moreover, K-theory gives obstructions to
generalisations of our main result.
",Mathematics
"  The curvature estimates of quotient curvature equation do not always exist
even for convex setting \cite{GRW}. Thus it is natural question to find other
type of elliptic equations possessing curvature estimates. In this paper, we
discuss the existence of curvature estimate for fully nonlinear elliptic
equations defined by symmetric polynomials, mainlly, the linear combination of
elementary symmetric polynomials.
",Mathematics
"  We introduce the concept of multiplicatively closed subsets of a commutative
ring $R$ which split an $R$-module $M$ and study factorization properties of
elements of $M$ with respect to such a set. Also we demonstrate how one can
utilize this concept to investigate factorization properties of $R$ and deduce
some Nagata type theorems relating factorization properties of $R$ to those of
its localizations, when $R$ is an integral domain.
",Mathematics
"  We study two colored operads of configurations of little $n$-disks in a unit
$n$-disk, with the centers of the small disks of one color restricted to an
$m$-plane, $m<n$. We compute the rational homotopy type of these \emph{extended
Swiss Cheese operads} and show how they are connected to the rational homotopy
types of the inclusion maps from the little $m$-disks to the little $n$-disks
operad.
",Mathematics
"  We show that relative Property (T) for the abelianization of a nilpotent
normal subgroup implies relative Property (T) for the subgroup itself. This and
other results are a consequence of a theorem of independent interest, which
states that if $H$ is a closed subgroup of a locally compact group $G$, and $A$
is a closed subgroup of the center of $H$, such that $A$ is normal in $G$, and
$(G/A, H/A)$ has relative Property (T), then $(G, H^{(1)})$ has relative
Property (T), where $H^{(1)}$ is the closure of the commutator subgroup of $H$.
In fact, the assumption that $A$ is in the center of $H$ can be replaced with
the weaker assumption that $A$ is abelian and every $H$-invariant finite
measure on the unitary dual of $A$ is supported on the set of fixed points.
",Mathematics
"  We aim to introduce the generalized multiindex Bessel function $J_{\left(
\beta _{j}\right) _{m},\kappa ,b}^{\left( \alpha _{j}\right)_{m},\gamma
,c}\left[ z\right] $ and to present some formulas of the Riemann-Liouville
fractional integration and differentiation operators. Further, we also derive
certain integral formulas involving the newly defined generalized multiindex
Bessel function $J_{\left( \beta _{j}\right) _{m},\kappa ,b}^{\left( \alpha
_{j}\right)_{m},\gamma ,c}\left[ z\right] $. We prove that such integrals are
expressed in terms of the Fox-Wright function $_{p}\Psi_{q}(z)$. The results
presented here are of general in nature and easily reducible to new and known
results.
",Mathematics
"  For a reductive group G defined over an algebraically closed field of
positive characteristic, we show that the Frobenius contraction functor of
G-modules is right adjoint to the Frobenius twist of the modules tensored with
the Steinberg module twice. It follows that the Frobenius contraction functor
preserves injectivity, good filtrations, but not semisiplicity.
",Mathematics
"  First the Hardy and Rellich inequalities are defined for the submarkovian
operator associated with a local Dirichlet form. Secondly, two general
conditions are derived which are sufficient to deduce the Rellich inequality
from the Hardy inequality. In addition the Rellich constant is calculated from
the Hardy constant. Thirdly, we establish that the criteria for the Rellich
inequality are verified for a large class of weighted second-order operators on
a domain $\Omega\subseteq \Ri^d$. The weighting near the boundary $\partial
\Omega$ can be different from the weighting at infinity. Finally these results
are applied to weighted second-order operators on $\Ri^d\backslash\{0\}$ and to
a general class of operators of Grushin type.
",Mathematics
"  In this paper we generalize the main result of [4] for manifolds that are not
necessarily Einstein. In fact, we obtain an upper bound for the volume of a
locally volume-minimizing closed hypersurface $\Sigma$ of a Riemannian
5-manifold $M$ with scalar curvature bounded from below by a positive constant
in terms of the total traceless Ricci curvature of $\Sigma$. Furthermore, if
$\Sigma$ saturates the respective upper bound and $M$ has nonnegative Ricci
curvature, then $\Sigma$ is isometric to $\mathbb{S}^4$ up to scaling and $M$
splits in a neighborhood of $\Sigma$. Also, we obtain a rigidity result for the
Riemannian cover of $M$ when $\Sigma$ minimizes the volume in its homotopy
class and saturates the upper bound.
",Mathematics
"  We answer Mark Kac's famous question, ""can one hear the shape of a drum?"" in
the positive for orbifolds that are 3-dimensional and 4-dimensional lens
spaces; we thus complete the answer to this question for orbifold lens spaces
in all dimensions. We also show that the coefficients of the asymptotic
expansion of the trace of the heat kernel are not sufficient to determine the
above results.
",Mathematics
"  In this paper, we are interested in the decomposition of the tensor product
of two representations of a symmetrizable Kac-Moody Lie algebra $\mathfrak g$.
Let $P\_+$ be the set of dominant integral weights. For $\lambda\in P\_+$ ,
$L(\lambda)$ denotes the irreducible, integrable, highest weight representation
of g with highest weight $\lambda$. Let $P\_{+,\mathbb Q}$ be the rational
convex cone generated by $P\_+$. Consider the tensor cone $\Gamma(\mathfrak g)
:= \{(\lambda\_1 ,\lambda\_2, \mu) $\in$ P\_{+,\mathbb Q}^3\,| \exists N
\textgreater{} 1 L(N\mu) \subset L(N \lambda\_1)\otimes L(N \lambda\_2)\}$. If
$\mathfrak g$ is finite dimensional, $\Gamma(\mathfrak g)$ is a polyhedral
convex cone described in 2006 by Belkale-Kumar by an explicit finite list of
inequalities. In general, $\Gamma(\mathfrak g)$ is nor polyhedral, nor closed.
In this article we describe the closure of $\Gamma(\mathfrak g)$ by an explicit
countable family of linear inequalities, when $\mathfrak g$ is untwisted
affine. This solves a Brown-Kumar's conjecture in this case. We also obtain
explicit saturation factors for the semigroup of triples $(\lambda\_1,
\lambda\_2 , \mu) $\in$ P\_+^3$ such that $L(\mu) $\subset$ L(\lambda\_1)
\otimes L(\lambda\_2)$. Note that even the existence of such saturation factors
is not obvious since the semigroup is not finitely generated. For example, in
type $A , we prove that any integer $d\geq 2$ is a saturation factor,
generalizing the case ${\tilde A}\_1$ shown by Brown-Kumar.
",Mathematics
"  We introduce a new method for building models of CH, together with $\Pi_2$
statements over $H(\omega_2)$, by forcing over a model of CH. Unlike similar
constructions in the literature, our construction adds new reals, but only
$\aleph_1$-many of them. Using this approach, we prove that a very strong form
of the negation of Club Guessing at $\omega_1$ known as Measuring is consistent
together with CH, thereby answering a well-known question of Moore. The
construction works over any model of ZFC + CH and can be described as a finite
support forcing construction with finite systems of countable models with
markers as side conditions and with strong symmetry constraints on both side
conditions and working parts.
",Mathematics
"  We propose an extended variant of the reformulation and decomposition
algorithm for solving a special class of mixed-integer bilevel linear programs
(MIBLPs) where continuous and integer variables are involved in both upper- and
lower-level problems. In particular, we consider MIBLPs with upper-level
constraints that involve lower-level variables. We assume that the inducible
region is nonempty and all variables are bounded. By using the reformulation
and decomposition scheme, an MIBLP is first converted into its equivalent
single-level formulation, then computed by a column-and-constraint generation
based decomposition algorithm. The solution procedure is enhanced by a
projection strategy that does not require the relatively complete response
property. To ensure its performance, we prove that our new method converges to
the global optimal solution in a finite number of iterations. A large-scale
computational study on random instances and instances of hierarchical supply
chain planning are presented to demonstrate the effectiveness of the algorithm.
",Mathematics
"  The convolution properties are discussed for the complex-valued harmonic
functions in the unit disk $\mathbb{D}$ constructed from the harmonic shearing
of the analytic function $\phi(z):=\int_0^z
(1/(1-2\xi\textit{e}^{\textit{i}\mu}\cos\nu+\xi^2\textit{e}^{2\textit{i}\mu}))\textit{d}\xi$,
where $\mu$ and $\nu$ are real numbers. For any real number $\alpha$ and
harmonic function $f=h+\overline{g}$, define an analytic function
$f_{\alpha}:=h+\textit{e}^{-2\textit{i}\alpha}g$. Let $\mu_1$ and $\mu_2$
$(\mu_1+\mu_2=\mu)$ be real numbers, and $f=h+\overline{g}$ and
$F=H+\overline{G}$ be locally-univalent and sense-preserving harmonic functions
such that $f_{\mu_1}*F_{\mu_2}=\phi$. It is shown that the convolution $f*F$ is
univalent and convex in the direction of $-\mu$, provided it is locally
univalent and sense-preserving. Also, local-univalence of the above convolution
$f*F$ is shown for some specific analytic dilatations of $f$ and $F$.
Furthermore, if $g\equiv0$ and both the analytic functions $f_{\mu_1}$ and
$F_{\mu_2}$ are convex, then the convolution $f*F$ is shown to be convex. These
results extends the work done by Dorff \textit{et al.} to a larger class of
functions.
",Mathematics
"  The distinguishing index of a simple graph $G$, denoted by $D'(G)$, is the
least number of labels in an edge labeling of $G$ not preserved by any
non-trivial automorphism. It was conjectured by Pilśniak (2015) that for any
2-connected graph $D'(G) \leq \lceil \sqrt{\Delta (G)}\rceil +1$. We prove a
more general result for the distinguishing index of graphs with minimum degree
at least two from which the conjecture follows. Also we present graphs $G$ for
which $D'(G)\leq \lceil \sqrt{\Delta }\rceil$.
",Mathematics
"  Li and Wei (2009) studied the density of zeros of Gaussian harmonic
polynomials with independent Gaussian coefficients. They derived a formula for
the expected number of zeros of random harmonic polynomials as well as
asymptotics for the case that the polynomials are drawn from the Kostlan
ensemble. In this paper we extend their work to cover the case that the
polynomials are drawn from the Weyl ensemble by deriving asymptotics for this
class of harmonic polynomials.
",Mathematics
"  In this paper, we obtain new results related to Minkowski fractional integral
inequality using generalized k-fractional integral operator which is in terms
of the Gauss hypergeometric function.
",Mathematics
"  A one-to-one correspondence between the infinitesimal motions of bar-joint
frameworks in $\mathbb{R}^d$ and those in $\mathbb{S}^d$ is a classical
observation by Pogorelov, and further connections among different rigidity
models in various different spaces have been extensively studied. In this
paper, we shall extend this line of research to include the infinitesimal
rigidity of frameworks consisting of points and hyperplanes. This enables us to
understand correspondences between point-hyperplane rigidity, classical
bar-joint rigidity, and scene analysis.
Among other results, we derive a combinatorial characterization of graphs
that can be realized as infinitesimally rigid frameworks in the plane with a
given set of points collinear. This extends a result by Jackson and Jordán,
which deals with the case when three points are collinear.
",Mathematics
"  We study an optimal boundary control problem for the two-dimensional
stationary micropolar fluids system with variable density. We control the
system by considering boundary controls, for the velocity vector and angular
velocity of rotation of particles, on parts of the boundary of the flow domain.
On the remaining part of the boundary, we consider mixed boundary conditions
for the vector velocity (Dirichlet and Navier conditions) and Dirichlet
boundary conditions for the angular velocity. We analyze the existence of a
weak solution obtaining the fluid density as a scalar function of the stream
function. We prove the existence of an optimal solution and, by using the
Lagrange multipliers theorem, we state first-order optimality conditions. We
also derive, through a penalty method, some optimality conditions satisfied by
the optimal controls.
",Mathematics
"  Let $A$ be the inductive limit of a sequence $$A_1\, \xrightarrow{\phi_{1,2}}
\,A_2\,\xrightarrow{\phi_{2,3}} \,A_3\rightarrow\cdots$$ with
$A_n=\oplus_{i=1}^{n_i}A_{[n,i]}$, where all the $A_{[n,i]}$ are
Elliott-Thomsen algebras and $\phi_{n,n+1}$ are homomorphisms, in this paper,
we will prove that $A$ can be written as another inductive limit
$$B_1\,\xrightarrow{\psi_{1,2}} \,B_2\,\xrightarrow{\psi_{2,3}}
\,B_3\rightarrow\cdots$$ with $B_n=\oplus_{i=1}^{n_i}B_{[n,i]}$, where all the
$B_{[n,i]}$ are Elliott-Thomsen building blocks and with the extra condition
that all the $\phi_{n,n+1}$ are injective.
",Mathematics
"  We develop the general theory for the construction of Extended Topological
Quantum Field Theories (ETQFTs) associated with the Costantino-Geer-Patureau
quantum invariants of closed 3-manifolds. In order to do so, we introduce
relative modular categories, a class of ribbon categories which are modeled on
representations of unrolled quantum groups, and which can be thought of as a
non-semisimple analogue to modular categories. Our approach exploits a
2-categorical version of the universal construction introduced by Blanchet,
Habegger, Masbaum, and Vogel. The 1+1+1-EQFTs thus obtained are realized by
symmetric monoidal 2-functors which are defined over non-rigid 2-categories of
admissible cobordisms decorated with colored ribbon graphs and cohomology
classes, and which take values in 2-categories of complete graded linear
categories. In particular, our construction extends the family of graded
2+1-TQFTs defined for the unrolled version of quantum $\mathfrak{sl}_2$ by
Blanchet, Costantino, Geer, and Patureau to a new family of graded ETQFTs. The
non-semisimplicity of the theory is witnessed by the presence of non-semisimple
graded linear categories associated with critical 1-manifolds.
",Mathematics
"  We consider partial torsion fields (fields generated by a root of a division
polynomial) for elliptic curves. By analysing the reduction properties of
elliptic curves, and applying the Montes Algorithm, we obtain information about
the ring of integers. In particular, for the partial $3$-torsion fields for a
certain one-parameter family of non-CM elliptic curves, we describe a power
basis. As a result, we show that the one-parameter family of quartic $S_4$
fields given by $T^4 - 6T^2 - \alpha T - 3$ for $\alpha \in \mathbb{Z}$ such
that $\alpha \pm 8$ are squarefree, are monogenic.
",Mathematics
"  Given a property of representations satisfying a basic stability condition,
Ramakrishna developed a variant of Mazur's Galois deformation theory for
representations with that property. We introduce an axiomatic definition of
pseudorepresentations with such a property. Among other things, we show that
pseudorepresentations with a property enjoy a good deformation theory,
generalizing Ramakrishna's theory to pseudorepresentations.
",Mathematics
"  Using the Kato-Rosenblum theorem, we describe the absolutely continuous
spectrum of a class of weighted integral Hankel operators in $L^2(\mathbb
R_+)$. These self-adjoint operators generalise the explicitly diagonalisable
operator with the integral kernel $s^\alpha t^\alpha(s+t)^{-1-2\alpha}$, where
$\alpha>-1/2$. Our analysis can be considered as an extension of J.Howland's
1992 paper which dealt with the unweighted case, corresponding to $\alpha=0$.
",Mathematics
"  This survey contains the main results in rational homotopy, from the
beginning to the most recent ones. It makes the status of the art, gives a
short presentation of some areas where rational homotopy has been used, and
contains a lot of important open problems
",Mathematics
"  A system of $N$ particles in a chemical medium in $\mathbb{R}^{d}$ is studied
in a discrete time setting. Underlying interacting particle system in
continuous time can be expressed as \begin{eqnarray} dX_{i}(t)
&=&[-(I-A)X_{i}(t) + \bigtriangledown h(t,X_{i}(t))]dt + dW_{i}(t), \,\,
X_{i}(0)=x_{i}\in \mathbb{R}^{d}\,\,\forall i=1,\ldots,N\nonumber\\
\frac{\partial}{\partial t} h(t,x)&=&-\alpha h(t,x) + D\bigtriangleup h(t,x)
+\frac{\beta}{n} \sum_{i=1}^{N} g(X_{i}(t),x),\quad h(0,\cdot) =
h(\cdot).\label{main} \end{eqnarray} where $X_{i}(t)$ is the location of the
$i$th particle at time $t$ and $h(t,x)$ is the function measuring the
concentration of the medium at location $x$ with $h(0,x) = h(x)$. In this
article we describe a general discrete time non-linear formulation of the
aforementioned model and a strongly coupled particle system approximating it.
Similar models have been studied before (Budhiraja et al.(2011)) under a
restrictive compactness assumption on the domain of particles. In current work
the particles take values in $\R^{d}$ and consequently the stability analysis
is particularly challenging. We provide sufficient conditions for the existence
of a unique fixed point for the dynamical system governing the large $N$
asymptotics of the particle empirical measure. We also provide uniform in time
convergence rates for the particle empirical measure to the corresponding limit
measure under suitable conditions on the model.
",Mathematics
"  In this article we us the mean curvature flow with surgery to derive
regularity estimates going past Brakke regularity for the level set flow. We
also show a stability result for the plane under the level set flow.
",Mathematics
"  We prove that any cyclic quadrilateral can be inscribed in any closed convex
$C^1$-curve. The smoothness condition is not required if the quadrilateral is a
rectangle.
",Mathematics
"  When participating in electricity markets, owners of battery energy storage
systems must bid in such a way that their revenues will at least cover their
true cost of operation. Since cycle aging of battery cells represents a
substantial part of this operating cost, the cost of battery degradation must
be factored in these bids. However, existing models of battery degradation
either do not fit market clearing software or do not reflect the actual battery
aging mechanism. In this paper we model battery cycle aging using a piecewise
linear cost function, an approach that provides a close approximation of the
cycle aging mechanism of electrochemical batteries and can be incorporated
easily into existing market dispatch programs. By defining the marginal aging
cost of each battery cycle, we can assess the actual operating profitability of
batteries. A case study demonstrates the effectiveness of the proposed model in
maximizing the operating profit of a battery energy storage system taking part
in the ISO New England energy and reserve markets.
",Mathematics
"  In this paper we construct two groupoids from morphisms of groupoids, with
one from a categorical viewpoint and the other from a geometric viewpoint. We
show that for each pair of groupoids, the two kinds of groupoids of morphisms
are equivalent. Then we study the automorphism groupoid of a groupoid.
",Mathematics
"  In 1902, P. Stäckel proved the existence of a transcendental function
$f(z)$, analytic in a neighbourhood of the origin, and with the property that
both $f(z)$ and its inverse function assume, in this neighbourhood, algebraic
values at all algebraic points. Based on this result, in 1976, K. Mahler raised
the question of the existence of such functions which are analytic in
$\mathbb{C}$. Recently, the authors answered positively this question. In this
paper, we prove a much stronger version of this result by considering other
subsets of $\mathbb{C}$.
",Mathematics
"  We fix a monic polynomial $f(x) \in \mathbb F_q[x]$ over a finite field of
characteristic $p$ of degree relatively prime to $p$. Let $a\mapsto \omega(a)$
be the Teichmüller lift of $\mathbb F_q$, and let $\chi:\mathbb{Z}\to \mathbb
C_p^\times$ be a finite character of $\mathbb Z_p$. The $L$-function associated
to the polynomial $f$ and the so-called twisted character $\omega^u\times \chi$
is denoted by $L_f(\omega^u,\chi,s)$. We prove that, when the conductor of the
character is large enough, the $p$-adic Newton slopes of this $L$-function form
arithmetic progressions.
",Mathematics
"  In the junction $\Omega$ of several semi-infinite cylindrical waveguides we
consider the Dirichlet Laplacian whose continuous spectrum is the ray
$[\lambda_\dagger, +\infty)$ with a positive cut-off value $\lambda_\dagger$.
We give two different criteria for the threshold resonance generated by
nontrivial bounded solutions to the Dirichlet problem for the Helmholtz
equation $-\Delta u=\lambda_\dagger u$ in $\Omega$. The first criterion is
quite simple and is convenient to disprove the existence of bounded solutions.
The second criterion is rather involved but can help to detect concrete shapes
supporting the resonance. Moreover, the latter distinguishes in a natural way
between stabilizing, i.e., bounded but non-descending solutions and trapped
modes with exponential decay at infinity.
",Mathematics
"  In this note we investigate the $p$-degree function of elliptic curves over
the field $\mathbb{Q}_p$ of $p$-adic numbers. The $p$-degree measures the least
complexity of a non-zero $p$-torsion point on an elliptic curve. We prove some
properties of this function and compute it explicitly in some special cases.
",Mathematics
"  We study the decomposition of a multivariate Hankel matrix H\_$\sigma$ as a
sum of Hankel matrices of small rank in correlation with the decomposition of
its symbol $\sigma$ as a sum of polynomial-exponential series. We present a new
algorithm to compute the low rank decomposition of the Hankel operator and the
decomposition of its symbol exploiting the properties of the associated
Artinian Gorenstein quotient algebra A\_$\sigma$. A basis of A\_$\sigma$ is
computed from the Singular Value Decomposition of a sub-matrix of the Hankel
matrix H\_$\sigma$. The frequencies and the weights are deduced from the
generalized eigenvectors of pencils of shifted sub-matrices of H $\sigma$.
Explicit formula for the weights in terms of the eigenvectors avoid us to solve
a Vandermonde system. This new method is a multivariate generalization of the
so-called Pencil method for solving Prony-type decomposition problems. We
analyse its numerical behaviour in the presence of noisy input moments, and
describe a rescaling technique which improves the numerical quality of the
reconstruction for frequencies of high amplitudes. We also present a new Newton
iteration, which converges locally to the closest multivariate Hankel matrix of
low rank and show its impact for correcting errors on input moments.
",Mathematics
"  This paper studies a recently proposed continuous-time distributed
self-appraisal model with time-varying interactions among a network of $n$
individuals which are characterized by a sequence of time-varying relative
interaction matrices. The model describes the evolution of the
social-confidence levels of the individuals via a reflected appraisal mechanism
in real time. We first show by example that when the relative interaction
matrices are stochastic (not doubly stochastic), the social-confidence levels
of the individuals may not converge to a steady state. We then show that when
the relative interaction matrices are doubly stochastic, the $n$ individuals'
self-confidence levels will all converge to $1/n$, which indicates a democratic
state, exponentially fast under appropriate assumptions, and provide an
explicit expression of the convergence rate.
",Mathematics
"  The paper surveys topological problems relevant to the motion planning
problem of robotics and includes some new results and constructions. First we
analyse the notion of topological complexity of configuration spaces which is
responsible for discontinuities in algorithms for robot navigation. Then we
present explicit motion planning algorithms for coordinated collision free
control of many particles moving in Euclidean spaces or on graphs. These
algorithms are optimal in the sense that they have minimal number of regions of
continuity. Moreover, we describe in full detail the topology of configuration
spaces of two particles on a tree and use it to construct some top-dimensional
cohomology classes in configuration spaces of n particles on a tree.
",Mathematics
"  The free loops space $\Lambda X$ of a space $X$ has become an important
object of study particularly in the case when $X$ is a manifold.The study of
free loop spaces is motivated in particular by two main examples. The first is
their relation to geometrically distinct periodic geodesics on a manifold,
originally studied by Gromoll and Meyer in $1969$. More recently the study of
string topology and in particular the Chas-Sullivan loop product has been an
active area of research.
A complete flag manifold is the quotient of a Lie group by its maximal torus
and is one of the nicer examples of a homogeneous space. Both the cohomology
and Chas-Sullivan product structure are understood for spaces $S^n$,
$\mathbb{C}P^n$ and most simple Lie groups. Hence studying the topology of the
free loops space on homogeneous space is a natural next step.
In the thesis we compute the differentials in the integral Leray-Serre
spectral sequence associated to the free loops space fibrations in the cases of
$SU(n+1)/T^n$ and $Sp(n)/T^n$. Study in detail the structure of the third page
of the spectral sequence in the case of $SU(n)$ and give the module structure
of $H^*(\Lambda(SU(3)/T^2);\mathbb{Z})$ and
$H^*(\Lambda(Sp(2)/T^2);\mathbb{Z})$.
",Mathematics
"  In earlier work, Katz exhibited some very simple one parameter families of
exponential sums which gave rigid local systems on the affine line in
characteristic p whose geometric (and usually, arithmetic) monodromy groups
were SL(2,q), and he exhibited other such very simple families giving SU(3,q).
[Here q is a power of the characteristic p with p odd]. In this paper, we
exhibit equally simple families whose geometric monodromy groups are the
alternating groups Alt(2q). $. We also determine their arithmetic monodromy
groups. By Raynaud's solution of the Abhyankar Conjecture, any finite simple
group whose order is divisible by p will occur as the geometric monodromy group
of some local system on the affine line in characteristic p; the interest here
is that it occurs in our particularly simple local systems.
In the earlier work of Katz, he used a theorem to Kubert to know that the
monodromy groups in question were finite, then work of Gross to determine which
finite groups they were. Here we do not have, at present, any direct way of
showing this finiteness. Rather, the situation is more complicated and more
interesting. Using some basic information about these local systems, a
fundamental dichotomy is proved:
The geometric monodromy group is either Alt(2q) or it is the special
orthogonal group SO(2q-1). An elementary polynomial identity is used to show
that the third moment is 1. This rules out the SO(2q-1) case. This roundabout
method establishes the theorem. It would be interesting to find a ""direct""
proof that these local systems have integer (rather than rational) traces; this
integrality is in fact equivalent to their monodromy groups being finite, Even
if one had such a direct proof, it would still require serious group theory to
show that their geometric monodromy groups are the alternating groups.
",Mathematics
"  The class of quasi-median graphs is a generalisation of median graphs, or
equivalently of CAT(0) cube complexes. The purpose of this thesis is to
introduce these graphs in geometric group theory. In the first part of our
work, we extend the definition of hyperplanes from CAT(0) cube complexes, and
we show that the geometry of a quasi-median graph essentially reduces to the
combinatorics of its hyperplanes. In the second part, we exploit the specific
structure of the hyperplanes to state combination results. The main idea is
that if a group acts in a suitable way on a quasi-median graph so that
clique-stabilisers satisfy some non-positively curved property $\mathcal{P}$,
then the whole group must satisfy $\mathcal{P}$ as well. The properties we are
interested in are mainly (relative) hyperbolicity, (equivariant)
$\ell^p$-compressions, CAT(0)-ness and cubicality. In the third part, we apply
our general criteria to several classes of groups, including graph products,
Guba and Sapir's diagram products, some wreath products, and some graphs of
groups. Graph products are our most natural examples, where the link between
the group and its quasi-median graph is particularly strong and explicit; in
particular, we are able to determine precisely when a graph product is
relatively hyperbolic.
",Mathematics
"  It is well-known that the Harish-Chandra transform, $f\mapsto\mathcal{H}f,$
is a topological isomorphism of the spherical (Schwartz) convolution algebra
$\mathcal{C}^{p}(G//K)$ (where $K$ is a maximal compact subgroup of any
arbitrarily chosen group $G$ in the Harish-Chandra class and $0<p\leq2$) onto
the (Schwartz) multiplication algebra
$\bar{\mathcal{Z}}({\mathfrak{F}}^{\epsilon})$ (of $\mathfrak{w}-$invariant
members of $\mathcal{Z}({\mathfrak{F}}^{\epsilon}),$ with $\epsilon=(2/p)-1$).
The same cannot however be said of the full Schwartz convolution algebra
$\mathcal{C}^{p}(G),$ except for few specific examples of groups (notably
$G=SL(2,\mathbb{R})$) and for some notable values of $p$ (with restrictions on
$G$ and/or on $\mathcal{C}^{p}(G)$). Nevertheless the full Harish-Chandra
Plancherel formula on $G$ is known for all of
$\mathcal{C}^{2}(G)=:\mathcal{C}(G).$ In order to then understand the structure
of Harish-Chandra transform more clearly and to compute the image of
$\mathcal{C}^{p}(G)$ under it (without any restriction) we derive an absolutely
convergent series expansion (in terms of known functions) for the
Harish-Chandra transform by an application of the full Plancherel formula on
$G.$ This leads to a computation of the image of $\mathcal{C}(G)$ under the
Harish-Chandra transform which may be seen as a concrete realization of
Arthur's result and be easily extended to all of $\mathcal{C}^{p}(G)$ in much
the same way as it is known in the work of Trombi and Varadarajan.
",Mathematics
"  Under the generalized Lindelöf hypothesis, the exponent in the error term
of the prime geodesic theorem for the modular surface is reduced to
$\frac{5}{8}+\varepsilon $ outside a set of finite logarithmic measure.
",Mathematics
"  In this paper we consider the phase retrieval problem for Herglotz functions,
that is, solutions of the Helmholtz equation $\Delta u+\lambda^2u=0$ on domains
$\Omega\subset\mathbb{R}^d$, $d\geq2$. In dimension $d=2$, if $u,v$ are two
such solutions then $|u|=|v|$ implies that either $u=cv$ or $u=c\bar v$ for
some $c\in\mathbb{C}$ with $|c|=1$. In dimension $d\geq3$, the same conclusion
holds under some restriction on $u$ and $v$: either they are real valued or
zonal functions or have non vanishing mean.
",Mathematics
"  We provide a physical definition of new homological invariants $\mathcal{H}_a
(M_3)$ of 3-manifolds (possibly, with knots) labeled by abelian flat
connections. The physical system in question involves a 6d fivebrane theory on
$M_3$ times a 2-disk, $D^2$, whose Hilbert space of BPS states plays the role
of a basic building block in categorification of various partition functions of
3d $\mathcal{N}=2$ theory $T[M_3]$: $D^2\times S^1$ half-index, $S^2\times S^1$
superconformal index, and $S^2\times S^1$ topologically twisted index. The
first partition function is labeled by a choice of boundary condition and
provides a refinement of Chern-Simons (WRT) invariant. A linear combination of
them in the unrefined limit gives the analytically continued WRT invariant of
$M_3$. The last two can be factorized into the product of half-indices. We show
how this works explicitly for many examples, including Lens spaces, circle
fibrations over Riemann surfaces, and plumbed 3-manifolds.
",Mathematics
"  The vortex method is a common numerical and theoretical approach used to
implement the motion of an ideal flow, in which the vorticity is approximated
by a sum of point vortices, so that the Euler equations read as a system of
ordinary differential equations. Such a method is well justified in the full
plane, thanks to the explicit representation formulas of Biot and Savart. In an
exterior domain, we also replace the impermeable boundary by a collection of
point vortices generating the circulation around the obstacle. The density of
these point vortices is chosen in order that the flow remains tangent at
midpoints between adjacent vortices. In this work, we provide a rigorous
justification for this method in exterior domains. One of the main mathematical
difficulties being that the Biot-Savart kernel defines a singular integral
operator when restricted to a curve. For simplicity and clarity, we only treat
the case of the unit disk in the plane approximated by a uniformly distributed
mesh of point vortices. The complete and general version of our work is
available in [arXiv:1707.01458].
",Mathematics
"  We explore lattice structures on integer binary relations (i.e. binary
relations on the set $\{1, 2, \dots, n\}$ for a fixed integer $n$) and on
integer posets (i.e. partial orders on the set $\{1, 2, \dots, n\}$ for a fixed
integer $n$). We first observe that the weak order on the symmetric group
naturally extends to a lattice structure on all integer binary relations. We
then show that the subposet of this weak order induced by integer posets
defines as well a lattice. We finally study the subposets of this weak order
induced by specific families of integer posets corresponding to the elements,
the intervals, and the faces of the permutahedron, the associahedron, and some
recent generalizations of those.
",Mathematics
"  We prove Szegő-Widom asymptotics for the Chebyshev polynomials of a
compact subset of $\mathbb{R}$ which is regular for potential theory and obeys
the Parreau-Widom and DCT conditions.
",Mathematics
"  An elementary proof of the two-sidedness of the matrix-inverse is given using
only linear independence and the reduced row-echelon form of a matrix. In
addition, it is shown that a matrix is invertible if and only if it is
row-equivalent to the identity matrix without appealing to elementary matrices.
This proof underscores the importance of a basis and provides a proof of the
invertible matrix theorem.
",Mathematics
"  Chern-Schwartz-MacPherson (CSM) classes generalize to singular and/or
noncompact varieties the classical total homology Chern class of the tangent
bundle of a smooth compact complex manifold. The theory of CSM classes has been
extended to the equivariant setting by Ohmoto. We prove that for an arbitrary
complex projective manifold $X$, the homogenized, torus equivariant CSM class
of a constructible function $\varphi$ is the restriction of the characteristic
cycle of $\varphi$ via the zero section of the cotangent bundle of $X$. This
extends to the equivariant setting results of Ginzburg and Sabbah. We
specialize $X$ to be a (generalized) flag manifold $G/B$. In this case CSM
classes are determined by a Demazure-Lusztig (DL) operator. We prove a `Hecke
orthogonality' of CSM classes, determined by the DL operator and its
Poincar{é} adjoint. We further use the theory of holonomic
$\mathcal{D}_X$-modules to show that the characteristic cycle of a Verma
module, restricted to the zero section, gives the CSM class of the
corresponding Schubert cell. Since the Verma characteristic cycles naturally
identify with the Maulik and Okounkov's stable envelopes, we establish an
equivalence between CSM classes and stable envelopes; this reproves results of
Rim{á}nyi and Varchenko. As an application, we obtain a Segre type formula
for CSM classes. In the non-equivariant case this formula is manifestly
positive, showing that the expansion in the Schubert basis of the CSM class of
a Schubert cell is effective. This proves a previous conjecture by Aluffi and
Mihalcea, and it extends previous positivity results by J. Huh in the Grassmann
manifold case. Finally, we generalize all of this to partial flag manifolds
$G/P$.
",Mathematics
"  Let $(\mathbf{B}, \|\cdot\|)$ be a real separable Banach space. Let
$\varphi(\cdot)$ and $\psi(\cdot)$ be two continuous and increasing functions
defined on $[0, \infty)$ such that $\varphi(0) = \psi(0) = 0$, $\lim_{t
\rightarrow \infty} \varphi(t) = \infty$, and
$\frac{\psi(\cdot)}{\varphi(\cdot)}$ is a nondecreasing function on $[0,
\infty)$. Let $\{V_{n};~n \geq 1 \}$ be a sequence of independent and symmetric
{\bf B}-valued random variables. In this note, we establish a probability
inequality for sums of independent {\bf B}-valued random variables by showing
that for every $n \geq 1$ and all $t \geq 0$, \[
\mathbb{P}\left(\left\|\sum_{i=1}^{n} V_{i} \right\| > t b_{n} \right) \leq 4
\mathbb{P} \left(\left\|\sum_{i=1}^{n} \varphi\left(\psi^{-1}(\|V_{i}\|)\right)
\frac{V_{i}}{\|V_{i}\|} \right\| > t a_{n} \right) +
\sum_{i=1}^{n}\mathbb{P}\left(\|V_{i}\| > b_{n} \right), \] where $a_{n} =
\varphi(n)$ and $b_{n} = \psi(n)$, $n \geq 1$. As an application of this
inequality, we establish what we call a comparison theorem for the weak law of
large numbers for independent and identically distributed ${\bf B}$-valued
random variables.
",Mathematics
"  In this note we prove that the Borel class of representations of 3-manifold
groups to PGL(n,C) is preserved under Cartan involution up to sign. For
representations to PGL(3,C) this is implied by a more general result of E.
Falbel and Q. Wang, however our proof appears to be much shorter for that
special case.
",Mathematics
"  In this paper, we study the Gauss map of a free boundary minimal surface. The
main theorem asserts that if components of the Gauss map are eigenfunctions of
the Jacobi-Steklov operator, then the surface must be rotationally symmetric.
",Mathematics
"  For a given smooth compact manifold $M$, we introduce an open class $\mathcal
G(M)$ of Riemannian metrics, which we call \emph{metrics of the gradient type}.
For such metrics $g$, the geodesic flow $v^g$ on the spherical tangent bundle
$SM \to M$ admits a Lyapunov function (so the $v^g$-flow is traversing). It
turns out, that metrics of the gradient type are exactly the non-trapping
metrics.
For every $g \in \mathcal G(M)$, the geodesic scattering along the boundary
$\partial M$ can be expressed in terms of the \emph{scattering map} $C_{v^g}:
\partial_1^+(SM) \to \partial_1^-(SM)$. It acts from a domain
$\partial_1^+(SM)$ in the boundary $\partial(SM)$ to the complementary domain
$\partial_1^-(SM)$, both domains being diffeomorphic. We prove that, for a
\emph{boundary generic} metric $g \in \mathcal G(M)$ the map $C_{v^g}$ allows
for a reconstruction of $SM$ and of the geodesic foliation $\mathcal F(v^g)$ on
it, up to a homeomorphism (often a diffeomorphism).
Also, for such $g$, the knowledge of the scattering map $C_{v^g}$ makes it
possible to recover the homology of $M$, the Gromov simplicial semi-norm on it,
and the fundamental group of $M$. Additionally, $C_{v^g}$ allows to reconstruct
the naturally stratified topological type of the space of geodesics on $M$.
",Mathematics
"  In 1993, Bismut and Zhang establish a mod Z embedding formula of
Atiyah-Patodi-Singer reduced eta invariants. In this paper, we explain the
hidden mod Z term as a spectral flow and extend this embedding formula to the
equivariant family case. In this case, the spectral flow is generalized to the
equivariant chern character of some equivariant Dai-Zhang higher spectral flow.
",Mathematics
"  We generalise the notion of a separating intersection of links (SIL) to give
necessary and sufficient criteria on the defining graph $\Gamma$ of a
right-angled Coxeter group $W_\Gamma$ so that its outer automorphism group is
large: that is, it contains a finite index subgroup that admits the free group
$F_2$ as a quotient. When $Out(W_\Gamma)$ is not large, we show it is virtually
abelian. We also show that the same dichotomy holds for the outer automorphism
groups of graph products of finite abelian groups. As a consequence, these
groups have property (T) if and only if they are finite, or equivalently
$\Gamma$ contains no SIL.
",Mathematics
"  Let $G$ be a simple and finite graph without isolated vertices. In this paper
we study forcing sets (zero forcing sets) which induce a subgraph of $G$
without isolated vertices. Such a set is called a total forcing set, introduced
and first studied by Davila \cite{Davila}. The minimum cardinality of a total
forcing set in $G$ is the total forcing number of $G$, denoted $F_t(G)$. We
study basic properties of $F_t(G)$, relate $F_t(G)$ to various domination
parameters, and establish $NP$-completeness of the associated decision problem
for $F_t(G)$. We also prove that if $G$ is a connected graph of order $n \ge 3$
and maximum degree $\Delta$, then $F_t(G) \le ( \frac{\Delta}{\Delta +1} ) n$,
with equality if and only if $G$ is a complete graph $K_{\Delta + 1}$.
",Mathematics
"  Scattering for the mass-critical fractional Schrödinger equation with a
cubic Hartree-type nonlinearity for initial data in a small ball in the
scale-invariant space of three-dimensional radial and square-integrable initial
data is established. For this, we prove a bilinear estimate for free solutions
and extend it to perturbations of bounded quadratic variation. This result is
shown to be sharp by proving the unboundedness of a third order derivative of
the flow map in the super-critical range.
",Mathematics
"  We describe the dimensions of low Hochschild cohomology spaces of exceptional
periodic representation-infinite algebras of polynomial growth. As an
application we obtain that an indecomposable non-standard periodic
representation-infinite algebra of polynomial growth is not derived equivalent
to a standard self-injective algebra.
",Mathematics
"  Skorobogatov constructed a bielliptic surface which is a counterexample to
the Hasse principle not explained by the Brauer-Manin obstruction. We show that
this surface has a $0$-cycle of degree 1, as predicted by a conjecture of
Colliot-Thélène.
",Mathematics
"  This paper considers mean field games in a multi-agent Markov decision
process (MDP) framework. Each player has a continuum state and binary action.
By active control, a player can bring its state to a resetting point. All
players are coupled through their cost functions. The structural property of
the individual strategies is characterized in terms of threshold policies when
the mean field game admits a solution. We further introduce a stationary
equation system of the mean field game and analyze uniqueness of its solution
under positive externalities.
",Mathematics
"  We formulate notions of subadditivity and additivity of the Yang-Mills action
functional in noncommutative geometry. We identify a suitable hypothesis on
spectral triples which proves that the Yang-Mills functional is always
subadditive, as per expectation. The additivity property is much stronger in
the sense that it implies the subadditivity property. Under this hypothesis we
obtain a necessary and sufficient condition for the additivity of the
Yang-Mills functional. An instance of additivity is shown for the case of
noncommutative $n$-tori. We also investigate the behaviour of critical points
of the Yang-Mills functional under additivity. At the end we discuss few
examples involving compact spin manifolds, matrix algebras, noncommutative
$n$-torus and the quantum Heisenberg manifolds which validate our hypothesis.
",Mathematics
"  The aim of this paper is to study relations between regular reductive PVs
with one-dimensional scalar multiplication and the structure of graded Lie
algebras. We will show that the regularity of such PVs is described by an
$\mathfrak{sl}_2$-triplet of a graded Lie algebra.
",Mathematics
"  We present a general framework for studying regularized estimators; i.e.,
estimation problems wherein ""plug-in"" type estimators are either ill-defined or
ill-behaved. We derive primitive conditions that imply consistency and
asymptotic linear representation for regularized estimators, allowing for
slower than $\sqrt{n}$ estimators as well as infinite dimensional parameters.
We also provide data-driven methods for choosing tuning parameters that, under
some conditions, achieve the aforementioned results. We illustrate the scope of
our approach by studying a wide range of applications, revisiting known results
and deriving new ones.
",Mathematics
"  In this paper, we consider distributed optimization design for resource
allocation problems over weight-balanced graphs. With the help of singular
perturbation analysis, we propose a simple sub-optimal continuous-time
optimization algorithm. Moreover, we prove the existence and uniqueness of the
algorithm equilibrium, and then show the convergence with an exponential rate.
Finally, we verify the sub-optimality of the algorithm, which can approach the
optimal solution as an adjustable parameter tends to zero.
",Mathematics
"  The stochastic Allen-Cahn equation with multiplicative noise involves the
nonlinear drift operator ${\mathscr A}(x) = \Delta x - \bigl(\vert x\vert^2
-1\bigr)x$. We use the fact that ${\mathscr A}(x) = -{\mathcal J}^{\prime}(x)$
satisfies a weak monotonicity property to deduce uniform bounds in strong norms
for solutions of the temporal, as well as of the spatio-temporal discretization
of the problem. This weak monotonicity property then allows for the estimate $
\underset{1 \leq j \leq J}\sup {\mathbb E}\bigl[ \Vert X_{t_j} -
Y^j\Vert_{{\mathbb L}^2}^2\bigr] \leq C_{\delta}(k^{1-\delta} + h^2)$ for all
small $\delta>0$, where $X$ is the strong variational solution of the
stochastic Allen-Cahn equation, while $\big\{Y^j:0\le j\le J\big\}$ solves a
structure preserving finite element based space-time discretization of the
problem on a temporal mesh $\{ t_j;\, 1 \leq j \leq J\}$ of size $k>0$ which
covers $[0,T]$.
",Mathematics
"  In [Mas82] and [Vee78] it was proved independently that almost every interval
exchange transformation is uniquely ergodic. The Birkhoff ergodic theorem
implies that these maps mainly have uniformly distributed orbits. This raises
the question under which conditions the orbits yield low-discrepancy sequences.
The case of $n=2$ intervals corresponds to circle rotation, where conditions
for low-discrepancy are well-known. In this paper, we give corresponding
conditions in the case $n=3$. Furthermore, we construct infinitely many
interval exchange transformations with low-discrepancy orbits for $n \geq 4$.
We also show that these examples do not coincide with $LS$-sequences if $S \geq
2$.
",Mathematics
"  We consider a class of kinetic models for polymeric fluids motivated by the
Peterlin dumbbell theories for dilute polymer solutions with a nonlinear spring
law for an infinitely extensible spring. The polymer molecules are suspended in
an incompressible viscous Newtonian fluid confined to a bounded domain in two
or three space dimensions. The unsteady motion of the solvent is described by
the incompressible Navier-Stokes equations with the elastic extra stress tensor
appearing as a forcing term in the momentum equation. The elastic stress tensor
is defined by the Kramers expression through the probability density function
that satisfies the corresponding Fokker-Planck equation. In this case, a
coefficient depending on the average length of polymer molecules appears in the
latter equation. Following the recent work of Barrett and Süli we prove the
existence of global-in-time weak solutions to the kinetic Peterlin model in two
space dimensions.
",Mathematics
"  In this paper, we are concerned with the existence of least energy solutions
for the following biharmonic equations: $$\Delta^2 u+(\lambda
V(x)-\delta)u=|u|^{p-2}u \quad in\quad \mathbb{R}^N$$ where $N\geq 5,
2<p\leq\frac{2N}{N-4}, \lambda>0$ is a parameter, $V(x)$ is a nonnegative
potential function with nonempty zero sets $\mbox{int} V^{-1}(0)$,
$0<\delta<\mu_0$ and $\mu_0$ is the principle eigenvalue of $\Delta^2$ in the
zero sets $\mbox{int} V^{-1}(0)$ of $V(x)$. Here $\mbox{int} V^{-1}(0)$ denotes
the interior part of the set $V^{-1}(0):=\{x\in \mathbb{R}^N: V(x)=0\}$. We
prove that the above equation admits a least energy solution which is trapped
near the zero sets $\mbox{int} V^{-1}(0)$ for $\lambda>0$ large.
",Mathematics
"  For two complex vector bundles admitting a homomorphism, whose singularity
locates in the disjoint union of some odd--dimensional spheres, we give a
formula to compute the relative Chern characteristic number of these two
complex vector bundles. In particular, for a spin manifold admitting some
sphere bundle structure, we give a formula to express the index of a special
twisted Dirac operator.
",Mathematics
"  We briefly recall the history of the Nijenhuis torsion of (1,1)-tensors on
manifolds and of the lesser-known Haantjes torsion. We then show how the
Haantjes manifolds of Magri and the symplectic-Haantjes structures of Tempesta
and Tondo generalize the classical approach to integrable systems in the
bi-hamiltonian and symplectic-Nijenhuis formalisms, the sequence of powers of
the recursion operator being replaced by a family of commuting Haantjes
operators.
",Mathematics
"  For a prime $p$, let $\hat F_p$ be a finitely generated free pro-$p$-group of
rank $\geq 2$. We show that the second discrete homology group $H_2(\hat
F_p,\mathbb Z/p)$ is an uncountable $\mathbb Z/p$-vector space. This answers a
problem of A.K. Bousfield.
",Mathematics
"  This paper studies the approximate and null controllability for impulse
controlled systems of heat equations coupled by a pair (A,B) of constant
matrices. We present a necessary and sufficient condition for the approximate
controllability, which is exactly Kalman's controllability rank condition of
(A,B). We prove that when such a system is approximately controllable, the
approximate controllability over an interval [0,T] can be realized by adding
controls at arbitrary n different control instants
0<\tau_1<\tau_2<\cdots<\tau_n<T, provided that \tau_n-\tau_1<d_A, where
d_A=\min\{\pi/|Im \lambda| : \lambda\in \sigma(A)\}. We also show that in
general, such systems are not null controllable.
",Mathematics
"  In this paper, we introduce a Weyl functional calculus $a \mapsto a(Q,P)$ for
the position and momentum operators $Q$ and $P$ associated with the
Ornstein-Uhlenbeck operator $ L = -\Delta + x\cdot \nabla$, and give a simple
criterion for restricted $L^p$-$L^q$ boundedness of operators in this
functional calculus. The analysis of this non-commutative functional calculus
is simpler than the analysis of the functional calculus of $L$. It allows us to
recover, unify, and extend, old and new results concerning the boundedness of
$\exp(-zL)$ as an operator from $L^p(\mathbb{R}^d,\gamma_{\alpha})$ to
$L^q(\mathbb{R}^d,\gamma_{\beta})$ for suitable values of $z\in \mathbb{C}$
with $\Re z>0$, $p,q\in [1,\infty)$, and $\alpha,\beta>0$. Here, $\gamma_\tau$
denotes the centred Gaussian measure on $\mathbb{R}^d$ with density
$(2\pi\tau)^{-d/2}\exp(-|x|^2/2\tau)$.
",Mathematics
"  I show that propositional intuitionistic logic is complete with respect to an
adaptation of Dummett's pragmatist justification procedure. In particular,
given a pragmatist justification of an argument, I show how to obtain a natural
deduction derivation of the conclusion of the argument from, at most, the same
assumptions.
",Mathematics
"  We consider submanifolds into Riemannian manifold with metallic structures.
We obtain some new results for hypersurfaces in these spaces and we express the
fundamental theorem of submanifolds into products spaces in terms of metallic
structures. Moreover, we define new structures called complex metallic
structures. We show that these structures are linked with complex structures.
Then, we consider submanifolds into Riemannian manifold with such structures
with a focus on invariant submanifolds and hypersurfaces. We also express in
particular the fundamental theorem of submanifolds of complex space form in
terms of complex metallic structures.
",Mathematics
"  There is often a significant trade-off between formulation strength and size
in mixed integer programming (MIP). When modeling convex disjunctive
constraints (e.g. unions of convex sets), adding auxiliary continuous variables
can sometimes help resolve this trade-off. However, standard formulations that
use such auxiliary continuous variables can have a worse-than-expected
computational effectiveness, which is often attributed precisely to these
auxiliary continuous variables. For this reason, there has been considerable
interest in constructing strong formulations that do not use continuous
auxiliary variables. We introduce a technique to construct formulations without
these detrimental continuous auxiliary variables. To develop this technique we
introduce a natural non-polyhedral generalization of the Cayley embedding of a
family of polytopes and show it inherits many geometric properties of the
original embedding. We then show how the associated formulation technique can
be used to construct small and strong formulation for a wide range of
disjunctive constraints. In particular, we show it can recover and generalize
all known strong formulations without continuous auxiliary variables.
",Mathematics
"  A theorem of Gekeler compares the number of non-isomorphic automorphic
representations associated with the space of cusp forms of weight $k$ on
$\Gamma_0(N)$ to a simpler function of $k$ and $N$, showing that the two are
equal whenever $N$ is squarefree. We prove the converse of this theorem (with
one small exception), thus providing a characterization of squarefree integers.
We also establish a similar characterization of prime numbers in terms of the
number of Hecke newforms of weight $k$ on $\Gamma_0(N)$.
It follows that a hypothetical fast algorithm for computing the number of
such automorphic representations for even a single weight $k$ would yield a
fast test for whether $N$ is squarefree. We also show how to obtain bounds on
the possible square divisors of a number $N$ that has been found to not be
squarefree via this test, and we show how to probabilistically obtain the
complete factorization of the squarefull part of $N$ from the number of such
automorphic representations for two different weights. If in addition we have
the number of such Hecke newforms for even a single weight $k$, then we show
how to probabilistically factor $N$ entirely. All of these computations could
be performed quickly in practice, given the number(s) of automorphic
representations and modular forms as input.
",Mathematics
"  We establish the Gröbner-Shirshov bases theory for differential Lie
$\Omega$-algebras. As an application, we give a linear basis of a free
differential Lie Rota-Baxter algebra on a set.
",Mathematics
"  We prove the Banach strong Novikov conjecture for groups having polynomially
bounded higher-order combinatorial functions. This includes all automatic
groups.
",Mathematics
"  This paper deals with the initial value problem for the multi-term fractional
differential equation. The fractional derivative is defined in the Caputo
sense. Firstly the initial value problem is transformed into a equivalent
Volterra-type integral equation under appropriate assumptions. Then new
existence results for smooth solutions are established by using the Schauder
fixed point theorem.
",Mathematics
"  It came to my attention after posting this paper that Yu Ding has proved the
same result before. I would like to apologize to Yu Ding for the appearance of
this paper.
",Mathematics
"  In this paper, we consider a concentration of measure problem on Riemannian
manifolds with boundary. We study concentration phenomena of non-negative
$1$-Lipschitz functions with Dirichlet boundary condition around zero, which is
called boundary concentration phenomena. We first examine relation between
boundary concentration phenomena and large spectral gap phenomena of Dirichlet
eigenvalues of Laplacian. We will obtain analogue of the Gromov-V. D. Milman
theorem and the Funano-Shioya theorem for closed manifolds. Furthermore, to
capture boundary concentration phenomena, we introduce a new invariant called
the observable inscribed radius. We will formulate comparison theorems for such
invariant under a lower Ricci curvature bound, and a lower mean curvature bound
for the boundary. Based on such comparison theorems, we investigate various
boundary concentration phenomena of sequences of manifolds with boundary.
",Mathematics
"  The involution Stanley symmetric functions $\hat{F}_y$ are the stable limits
of the analogues of Schubert polynomials for the orbits of the orthogonal group
in the flag variety. These symmetric functions are also generating functions
for involution words, and are indexed by the involutions in the symmetric
group. By construction each $\hat{F}_y$ is a sum of Stanley symmetric functions
and therefore Schur positive. We prove the stronger fact that these power
series are Schur $P$-positive. We give an algorithm to efficiently compute the
decomposition of $\hat{F}_y$ into Schur $P$-summands, and prove that this
decomposition is triangular with respect to the dominance order on partitions.
As an application, we derive pattern avoidance conditions which characterize
the involution Stanley symmetric functions which are equal to Schur
$P$-functions. We deduce as a corollary that the involution Stanley symmetric
function of the reverse permutation is a Schur $P$-function indexed by a
shifted staircase shape. These results lead to alternate proofs of theorems of
Ardila-Serrano and DeWitt on skew Schur functions which are Schur
$P$-functions. We also prove new Pfaffian formulas for certain related
involution Schubert polynomials.
",Mathematics
"  We deal with kernel theorems for modulation spaces. We completely
characterize the continuity of a linear operator on the modulation spaces $M^p$
for every $1\leq p\leq\infty$, by the membership of its kernel to (mixed)
modulation spaces. Whereas Feichtinger's kernel theorem (which we recapture as
a special case) is the modulation space counterpart of Schwartz' kernel theorem
for temperate distributions, our results do not have a couterpart in
distribution theory. This reveals the superiority, in some respects, of the
modulation space formalism upon distribution theory, as already emphasized in
Feichtinger's manifesto for a post-modern harmonic analysis, tailored to the
needs of mathematical signal processing. The proof uses in an essential way a
discretization of the problem by means of Gabor frames. We also show the
equivalence of the operator norm and the modulation space norm of the
corresponding kernel. For operators acting on $M^{p,q}$ a similar
characterization is not expected, but sufficient conditions for boundedness can
be sated in the same spirit.
",Mathematics
"  We give lower bounds for the degree of multiplicative combinations of
iterates of rational functions (with certain exceptions) over a general field,
establishing the multiplicative independence of said iterates. This leads to a
generalisation of Gao's method for constructing elements in the finite field
$\mathbb{F}_{q^n}$ whose orders are larger than any polynomial in $n$ when $n$
becomes large. Additionally, we discuss the finiteness of polynomials which
translate a given finite set of polynomials to become multiplicatively
dependent.
",Mathematics
"  We study the topological dynamics of the horocycle flow $h_\mathbb{R}$ on a
geometrically infinite hyperbolic surface S. Let u be a non-periodic vector for
$h_\mathbb{R}$ in T^1 S. Suppose that the half-geodesic $u(\mathbb{R}^+)$ is
almost minimizing and that the injectivity radius along $u(\mathbb{R}^+)$ has a
finite inferior limit $Inj(u(\mathbb{R}^+))$. We prove that the closure of
$h_\mathbb{R} u$ meets the geodesic orbit along un unbounded sequence of points
$g_{t_n} u$. Moreover, if $Inj(u(\mathbb{R}^+)) = 0$, the whole half-orbit
$g_{\mathbb{R}^+} u$ is contained in $h_\mathbb{R} u$. When
$Inj(u(\mathbb{R}^+)) > 0$, it is known that in general $g_{\mathbb{R}^+} u
\subset h_\mathbb{R} u$. Yet, we give a construction where
$Inj(u(\mathbb{R}^+)) > 0$ and $g_{\mathbb{R}^+} u \subset h_\mathbb{R} u$,
which also constitutes a counterexample to Proposition 3 of [Led97].
",Mathematics
"  The set of all possible configurations of the Ehrenfest wind-tree model
endowed with the Hausdorff topology is a compact metric space. For a typical
configuration we show that the wind-tree dynamics has infinite ergodic index in
almost every direction. In particular some ergodic theorems can be applied to
show that if we start with a large number of initially parallel particles their
directions decorrelate as the dynamics evolve answering the question posed by
the Ehrenfests.
",Mathematics
"  The dual motivic Steenrod algebra with mod $\ell$ coefficients was computed
by Voevodsky over a base field of characteristic zero, and by Hoyois, Kelly,
and {\O}stv{\ae}r over a base field of characteristic $p \neq \ell$. In the
case $p = \ell$, we show that the conjectured answer is a retract of the actual
answer. We also describe the slices of the algebraic cobordism spectrum $MGL$:
we show that the conjectured form of $s_n MGL$ is a retract of the actual
answer.
",Mathematics
"  We study the motion of isentropic gas in nozzles. This is a major subject in
fluid dynamics. In fact, the nozzle is utilized to increase the thrust of
rocket engines. Moreover, the nozzle flow is closely related to astrophysics.
These phenomena are governed by the compressible Euler equation, which is one
of crucial equations in inhomogeneous conservation laws.
In this paper, we consider its unsteady flow and devote to proving the global
existence and stability of solutions to the Cauchy problem for the general
nozzle. The theorem has been proved in (Tsuge in Arch. Ration. Mech. Anal.
209:365-400 (2013)). However, this result is limited to small data. Our aim in
the present paper is to remove this restriction, that is, we consider large
data. Although the subject is important in Mathematics, Physics and
engineering, it remained open for a long time. The problem seems to lie in a
bounded estimate of approximate solutions, because we have only method to
investigate the behavior with respect to the time variable. To solve this, we
first introduce a generalized invariant region. Compared with the existing
ones, its upper and lower bounds are extended constants to functions of the
space variable. However, we cannot apply the new invariant region to the
traditional difference method. Therefore, we invent the modified Godunov
scheme. The approximate solutions consist of some functions corresponding to
the upper and lower bounds of the invariant regions. These methods enable us to
investigate the behavior of approximate solutions with respect to the space
variable. The ideas are also applicable to other nonlinear problems involving
similar difficulties.
",Mathematics
"  The Kite graph $Kite_{p}^{q}$ is obtained by appending the complete graph
$K_{p}$ to a pendant vertex of the path $P_{q}$. In this paper, the kite graph
is proved to be determined by the spectrum of its adjacency matrix.
",Mathematics
"  We study the instability of standing wave solutions for nonlinear
Schrödinger equations with a one-dimensional harmonic potential in
dimension $N\ge 2$. We prove that if the nonlinearity is $L^2$-critical or
supercritical in dimension $N-1$, then any ground states are strongly unstable
by blowup.
",Mathematics
"  Let us be given two graphs $\Gamma_1$, $\Gamma_2$ of $n$ vertices. Are they
isomorphic? If they are, the set of isomorphisms from $\Gamma_1$ to $\Gamma_2$
can be identified with a coset $H\cdot\pi$ inside the symmetric group on $n$
elements. How do we find $\pi$ and a set of generators of $H$?
The challenge of giving an always efficient algorithm answering these
questions remained open for a long time. Babai has recently shown how to solve
these problems -- and others linked to them -- in quasi-polynomial time, i.e.
in time $\exp\left(O(\log n)^{O(1)}\right)$. His strategy is based in part on
the algorithm by Luks (1980/82), who solved the case of graphs of bounded
degree.
",Mathematics
"  We prove the nonvanishing of the twisted central critical values of a class
of automorphic L-functions for twists by all but finitely many unitary
characters in particular infinite families. The methods build on a
non-archimedean approach introduced by Greenberg in the context of the Birch
and Swinnerton-Dyer Conjecture. While this paper focuses on L-functions
associated to certain automorphic representations of unitary groups, it
illustrates how decades-old methods from Iwasawa theory can be combined with
the output of new machinery to achieve broader nonvanishing results.
",Mathematics
"  The aim of this paper is to give a short overview on error bounds and to
provide the first bricks of a unified theory. Inspired by the works of [8, 15,
13, 16, 10], we show indeed the centrality of the Lojasiewicz gradient
inequality. For this, we review some necessary and sufficient conditions for
global/local error bounds, both in the convex and nonconvex case. We also
recall some results on quantitative error bounds which play a major role in
convergence rate analysis and complexity theory of many optimization methods.
",Mathematics
"  In this note we present an $\infty$-categorical framework for descent along
adjunctions and a general formula for counting conjugates up to equivalence
which unifies several known formulae from different fields.
",Mathematics
"  An infinite convergent sum of independent and identically distributed random
variables discounted by a multiplicative random walk is called perpetuity,
because of a possible actuarial application. We give three disjoint groups of
sufficient conditions which ensure that the distribution right tail of a
perpetuity $\mathbb{P}\{X>x\}$ is asymptotic to $ax^ce^{-bx}$ as $x\to\infty$
for some $a,b>0$ and $c\in\mathbb{R}$. Our results complement those of Denisov
and Zwart [J. Appl. Probab. 44 (2007), 1031--1046]. As an auxiliary tool we
provide criteria for the finiteness of the one-sided exponential moments of
perpetuities. Several examples are given in which the distributions of
perpetuities are explicitly identified.
",Mathematics
"  Lorenzen's ""Algebraische und logistische Untersuchungen über freie
Verbände"" appeared in 1951 in The journal of symbolic logic. These
""Investigations"" have immediately been recognised as a landmark in the history
of infinitary proof theory, but their approach and method of proof have not
been incorporated into the corpus of proof theory. More precisely, Lorenzen
proves the admissibility of cut by double induction, on the cut formula and on
the complexity of the derivations, without using any ordinal assignment,
contrary to the presentation of cut elimination in most standard texts on proof
theory. This translation has the intent of giving a new impetus to their
reception.
The ""Investigations"" are best known for providing a constructive proof of
consistency for ramified type theory without axiom of reducibility. They do so
by showing that it is a part of a trivially consistent ""inductive calculus""
that describes our knowledge of arithmetic without detour. The proof resorts
only to the inductive definition of formulas and theorems.
They propose furthermore a definition of a semilattice, of a distributive
lattice, of a pseudocomplemented semilattice, and of a countably complete
boolean lattice as deductive calculuses, and show how to present them for
constructing the respective free object over a given preordered set.
This translation is published with the kind permission of Lorenzen's
daughter, Jutta Reinhardt.
",Mathematics
"  Let $M$ be a compact constant mean curvature surface either in $\mathbb{S}^3$
or $\mathbb{R}^3$. In this paper we prove that the stability index of $M$ is
bounded below by a linear function of the genus. As a by product we obtain a
comparison theorem between the spectrum of the Jacobi operator of $M$ and those
of Hodge Laplacian of $1$-forms on $M$.
",Mathematics
"  We study the Kepler metrics on Kepler manifolds from the point of view of
Sasakian geometry and Hessian geometry. This establishes a link between the
problem of classical gravity and the modern geometric methods in the study of
AdS/CFT correspondence in string theory.
",Mathematics
"  There are two natural simplicial complexes associated to the noncrossing
partition lattice: the order complex of the full lattice and the order complex
of the lattice with its bounding elements removed. The latter is a complex that
we call the noncrossing partition link because it is the link of an edge in the
former. The first author and his coauthors conjectured that various collections
of simplices of the noncrossing partition link (determined by the undesired
parking spaces in the corresponding parking functions) form contractible
subcomplexes. In this article we prove their conjecture by combining the fact
that the star of a simplex in a flag complex is contractible with the second
author's theory of noncrossing hypertrees.
",Mathematics
"  The generators of the classical Specht module satisfy intricate relations. We
introduce the Specht matroid, which keeps track of these relations, and the
Specht polytope, which also keeps track of convexity relations. We establish
basic facts about the Specht polytope, for example, that the symmetric group
acts transitively on its vertices and irreducibly on its ambient real vector
space. A similar construction builds a matroid and polytope for a tensor
product of Specht modules, giving ""Kronecker matroids"" and ""Kronecker
polytopes"" instead of the usual Kronecker coefficients. We dub this process of
upgrading numbers to matroids and polytopes ""matroidification,"" giving two more
examples. In the course of describing these objects, we also give an elementary
account of the construction of Specht modules different from the standard one.
Finally, we provide code to compute with Specht matroids and their Chow rings.
",Mathematics
"  The ADR algebra $R_A$ of a finite-dimensional algebra $A$ is a
quasihereditary algebra. In this paper we study the Ringel dual
$\mathcal{R}(R_A)$ of $R_A$. We prove that $\mathcal{R}(R_A)$ can be identified
with $(R_{A^{op}})^{op}$, under certain 'minimal' regularity conditions for
$A$. We also give necessary and sufficient conditions for the ADR algebra to be
Ringel selfdual.
",Mathematics
"  We offer the proofs that complete our article introducing the propositional
calculus called semi-intuitionistic logic with strong negation.
",Mathematics
"  We study the Vladimirov fractional differentiation operator $D^\alpha_N$,
$\alpha >0, N\in \mathbb Z$, on a $p$-adic ball $B_N=\{ x\in \mathbb Q_p:\
|x|_p\le p^N\}$. To its known interpretations via restriction from a similar
operator on $\mathbb Q_p$ and via a certain stochastic process on $B_N$, we add
an interpretation as a pseudo-differential operator in terms of the Pontryagin
duality on the additive group of $B_N$. We investigate the Green function of
$D^\alpha_N$ and a nonlinear equation on $B_N$, an analog the classical porous
medium equation.
",Mathematics
"  We show that whenever $\delta>0$, $\eta$ is real and constants $\lambda_i$
satisfy some necessary conditions, there are infinitely many prime triples
$p_1,\, p_2,\, p_3$ satisfying the inequality $|\lambda_1p_1 + \lambda_2p_2 +
\lambda_3p_3+\eta|<(\max p_j)^{-1/12+\delta}$ and such that, for each
$i\in\{1,2,3\}$, $p_i+2$ has at most $28$ prime factors.
",Mathematics
"  Stochastic integration \textit{wrt} Gaussian processes has raised strong
interest in recent years, motivated in particular by its applications in
Internet traffic modeling, biomedicine and finance. The aim of this work is to
define and develop a White Noise Theory-based anticipative stochastic calculus
with respect to all Gaussian processes that have an integral representation
over a real (maybe infinite) interval. Very rich, this class of Gaussian
processes contains, among many others, Volterra processes (and thus fractional
Brownian motion) as well as processes the regularity of which varies along the
time (such as multifractional Brownian motion).A systematic comparison of the
stochastic calculus (including It{ô} formula) we provide here, to the ones
given by Malliavin calculus in
\cite{nualart,MV05,NuTa06,KRT07,KrRu10,LN12,SoVi14,LN12}, and by It{ô}
stochastic calculus is also made. Not only our stochastic calculus fully
generalizes and extends the ones originally proposed in \cite{MV05} and in
\cite{NuTa06} for Gaussian processes, but also the ones proposed in
\cite{ell,bosw,ben1} for fractional Brownian motion (\textit{resp.} in
\cite{JLJLV1,JL13,LLVH} for multifractional Brownian motion).
",Mathematics
"  We study the adjoint of the double layer potential associated with the
Laplacian (the adjoint of the Neumann-Poincaré operator), as a map on the
boundary surface $\Gamma$ of a domain in $\mathbb{R}^3$ with conical points.
The spectrum of this operator directly reflects the well-posedness of related
transmission problems across $\Gamma$. In particular, if the domain is
understood as an inclusion with complex permittivity $\epsilon$, embedded in a
background medium with unit permittivity, then the polarizability tensor of the
domain is well-defined when $(\epsilon+1)/(\epsilon-1)$ belongs to the
resolvent set in energy norm. We study surfaces $\Gamma$ that have a finite
number of conical points featuring rotational symmetry. On the energy space, we
show that the essential spectrum consists of an interval. On $L^2(\Gamma)$,
i.e. for square-integrable boundary data, we show that the essential spectrum
consists of a countable union of curves, outside of which the Fredholm index
can be computed as a winding number with respect to the essential spectrum. We
provide explicit formulas, depending on the opening angles of the conical
points. We reinforce our study with very precise numerical experiments,
computing the energy space spectrum and the spectral measures of the
polarizability tensor in two different examples. Our results indicate that the
densities of the spectral measures may approach zero extremely rapidly in the
continuous part of the energy space spectrum.
",Mathematics
"  A version of Liouville's theorem is proved for solutions of some degenerate
elliptic equations defined in $\mathbb{R}^n\backslash K$, where $K$ is a
compact set, provided the structure of this equation and the dimension $n$ are
related. This result is a correction of a previous one established by Serrin,
since some additional hypotheses are necessary. Theoretical and numerical
examples are given. Furthermore, a comparison result and the uniqueness of
solution are obtained for such equations in exterior domains.
",Mathematics
"  A system modeling bacteriophage treatments with coinfections in a noisy
context is analyzed. We prove that in a small noise regime, the system
converges in the long term to a bacteria free equilibrium. Moreover, we compare
the treatment with coinfection with the treatment without coinfection, showing
how the coinfection affects the dose of bacteriophages that is needed to
eliminate the bacteria and the velocity of convergence to the free bacteria
equilibrium.
",Mathematics
"  For a finite field of odd cardinality $q$, we show that the sequence of
iterates of $aX^2+c$, starting at $0$, always recurs after $O(q/\log\log q)$
steps. For $X^2+1$ the same is true for any starting value. We suggest that the
traditional ""Birthday Paradox"" model is inappropriate for iterates of $X^3+c$,
when $q$ is 2 mod 3.
",Mathematics
"  Let $\Omega$ be a $C^2$-smooth bounded pseudoconvex domain in $\mathbb{C}^n$
for $n\geq 2$ and let $\varphi$ be a holomorphic function on $\Omega$ that is
$C^2$-smooth on the closure of $\Omega$. We prove that if
$H_{\overline{\varphi}}$ is in Schatten $p$-class for $p\leq 2n$ then $\varphi$
is a constant function. As a corollary, we show that the
$\overline{\partial}$-Neumann operator on $\Omega$ is not Hilbert-Schmidt.
",Mathematics
"  Consider the parabolic equation with measure data \begin{equation*} \left\{
\begin{aligned} &u_t-{\rm div} \mathbf{a}(D u,x,t)=\mu&\text{in}& \quad
\Omega_T, &u=0 \quad &\text{on}& \quad \partial_p\Omega_T, \end{aligned}\right.
\end{equation*} where $\Omega$ is a bounded domain in $\mathbb{R}^n$,
$\Omega_T=\Omega\times (0,T)$, $\partial_p\Omega_T=(\partial\Omega\times
(0,T))\cup (\Omega\times\{0\})$, and $\mu$ is a signed Borel measure with
finite total mass. Assume that the nonlinearity ${\bf a}$ satisfies a small
BMO-seminorm condition, and $\Omega$ is a Reifenberg flat domain. This paper
proves a global Marcinkiewicz estimate for the SOLA (Solution Obtained as
Limits of Approximation) to the parabolic equation.
",Mathematics
"  Using the natural action of $S_\infty$ we show that a countable hereditary
class $\cC$ of finitely generated structures has the joint embedding property
(JEP) and the weak amalgamation property (WAP) if and only if there is a
structure $M$ whose isomorphism type is comeager in the space of all countable,
infinitely generated structures with age in $\cC$. In this case, $M$ is the
weak Fraïssé limit of $\cC$.
This applies in particular to countable structures with generic automorphisms
and recovers a result by Kechris and Rosendal [\textit{Proc.\ Lond.\ Math.\
Soc.,\ 2007}].
",Mathematics
"  I describe a relation (mostly conjectural) between the Seiberg-Witten
monopoles, Fueter sections, and G2 instantons. In the last part of this article
I gathered some open questions connected with this relation.
",Mathematics
"  Recently, wind Riemannian structures (WRS) have been introduced as a
generalization of Randers and Kropina metrics. They are constructed from the
natural data for Zermelo navigation problem, namely, a Riemannian metric $g_R$
and a vector field $W$ (the wind), where, now, the restriction of mild wind
$g_R(W,W)<1$ is dropped.
Here, the models of WRS spaceforms of constant flag curvature are determined.
Indeed, the celebrated classification of Randers metrics of constant flag
curvature by Bao, Robles and Shen, extended to the Kropina case in the works by
Yoshikawa, Okubo and Sabau, can be used to obtain the local classification. For
the global one, a suitable result on completeness for WRS yields the complete
simply connected models. In particular, any of the local models in the Randers
classification does admit an extension to a unique model of wind Riemannian
structure, even if it cannot be extended as a complete Finslerian manifold.
Thus, WRS's emerge as the natural framework for the analysis of Randers
spaceforms and, prospectively, wind Finslerian structures would become
important for other global problems too. For the sake of completeness, a brief
overview about WRS (including a useful link with the conformal geometry of a
class of relativistic spacetimes) is also provided.
",Mathematics
"  We consider an optimal stopping problem where a constraint is placed on the
distribution of the stopping time. Reformulating the problem in terms of
so-called measure-valued martingales allows us to transform the marginal
constraint into an initial condition and view the problem as a stochastic
control problem; we establish the corresponding dynamic programming principle.
",Mathematics
"  The two dimensional incompressible Navier-Stokes equation on $D_\delta := [0,
2\pi\delta] \times [0, 2\pi]$ with $\delta \approx 1$, periodic boundary
conditions, and viscosity $0 < \nu \ll 1$ is considered. Bars and dipoles, two
explicitly given quasi-stationary states of the system, evolve on the time
scale $\mathcal{O}(e^{-\nu t})$ and have been shown to play a key role in its
long-time evolution. Of particular interest is the role that $\delta$ plays in
selecting which of these two states is observed. Recent numerical studies
suggest that, after a transient period of rapid decay of the high Fourier
modes, the bar state will be selected if $\delta \neq 1$, while the dipole will
be selected if $\delta = 1$. Our results support this claim and seek to
mathematically formalize it. We consider the system in Fourier space, project
it onto a center manifold consisting of the lowest eight Fourier modes, and use
this as a model to study the selection of bars and dipoles. It is shown for
this ODE model that the value of $\delta$ controls the behavior of the
asymptotic ratio of the low modes, thus determining the likelihood of observing
a bar state or dipole after an initial transient period. Moreover, in our
model, for all $\delta \approx 1$, there is an initial time period in which the
high modes decay at the rapid rate $\mathcal{O}(e^{-t/\nu})$, while the low
modes evolve at the slower $\mathcal{O}(e^{-\nu t})$ rate. The results for the
ODE model are proven using energy estimates and invariant manifolds and further
supported by formal asymptotic expansions and numerics.
",Mathematics
"  We study closed $n$-dimensional manifolds of which the metrics are critical
for quadratic curvature functionals involving the Ricci curvature, the scalar
curvature and the Riemannian curvature tensor on the space of Riemannian
metrics with unit volume. Under some additional integral conditions, we
classify such manifolds. Moreover, under some curvature conditions, the result
that a critical metric must be Einstein is proved.
",Mathematics
"  Alternative expressions for calculating the oblate spheroidal radial
functions of both kinds R1ml and R2ml are shown to provide accurate values over
very large parameter ranges using 64 bit arithmetic, even where the traditional
expressions fail. First is the expansion of the product of a radial function
and the angular function of the first kind in a series of products of the
corresponding spherical functions, with the angular coordinate being a free
parameter. Setting the angular coordinate equal to zero leads to accurate
values for R2ml when the radial coordinate xi is larger than 0.01 and l is
somewhat larger than m. Allowing it to vary with increasing l leads to highly
accurate values for R1ml over all parameter ranges. Next is the calculation of
R2ml as an integral of the product of S1ml and a spherical Neumann function
kernel. This is useful for smaller values of xi. Also used is the near equality
of pairs of low order eigenvalues when the size parameter c is large that leads
to accurate values for R2ml using neighboring accurate values for R1ml. A
modified method is described that provides accurate values for the necessary
expansion coefficients when c is large and l is near m and traditional methods
fail. A resulting Fortran computer program Oblfcn almost always provides radial
function values with at least 8 accurate decimal digits using 64 bit arithmetic
for m up to at least 1000 with c up to at least 2000 when xi is greater than
0.000001 and c up to at least 5000 when xi is greater than 0.01. Use of 128 bit
arithmetic extends the accuracy to 15 or more digits and extends xi to all
values other than zero. Oblfcn is freely available.
",Mathematics
"  This paper develops a Carleman type estimate for immersed surface in
Euclidean space at infinity. With this estimate, we obtain an unique
continuation property for harmonic functions on immersed surfaces vanishing at
infinity, which leads to rigidity results in geometry.
",Mathematics
"  Knot Floer homology is an invariant for knots discovered by the authors and,
independently, Jacob Rasmussen. The discovery of this invariant grew naturally
out of studying how a certain three-manifold invariant, Heegaard Floer
homology, changes as the three-manifold undergoes Dehn surgery along a knot.
Since its original definition, thanks to the contributions of many researchers,
knot Floer homology has emerged as a useful tool for studying knots in its own
right. We give here a few selected highlights of this theory, and then move on
to some new algebraic developments in the computation of knot Floer homology.
",Mathematics
"  We are concerned with multidimensional nonlinear stochastic transport
equation driven by Brownian motions. For irregular fluxes, by using stochastic
BGK approximations and commutator estimates, we gain the existence and
uniqueness of stochastic entropy solutions. Besides, for $BV$ initial data, the
$BV$ and Hölder regularities are also derived for the unique stochastic
entropy solution. Particularly, for the transport equation, we gain a
regularization result, i.e. while the existence fails for the transport
equation, we prove that a multiplicative stochastic perturbation of Brownian
type is enough to render the equation well-posed. This seems to be another
explicit example (the first example is given in [22]) of a PDE of fluid
dynamics that becomes well-posed under the influence of a multiplicative
Brownian type noise.
",Mathematics
"  We study the Bratteli diagram of 2-Sylow subgroups of symmetric groups. We
show that it is simple, has a recursive structure, and self-similarities at all
scales. We contrast its subgraph of one-dimensional representations with the
Macdonald tree.
",Mathematics
"  We prove an equivalence between the infinitesimal Torelli theorem for top
forms on a hypersurface contained inside a Grassmannian $\mathbb G$ and the
theory of adjoint volume forms presented in L. Rizzi, F. Zucconi, ""Generalized
adjoint forms on algebraic varieties"", Ann. Mat. Pura e Applicata, in press.
More precisely, via this theory and a suitable generalization of Macaulay's
theorem we show that the differential of the period map vanishes on an
infinitesimal deformation if and only if certain explicitly given twisted
volume forms go in the generalized Jacobi ideal of $X$ via the cup product
homomorphism.
",Mathematics
"  Many classical results in relativity theory concerning spherically symmetric
space-times have easy generalizations to warped product space-times, with a
two-dimensional Lorentzian base and arbitrary dimensional Riemannian fibers. We
first give a systematic presentation of the main geometric constructions, with
emphasis on the Kodama vector field and the Hawking energy; the construction is
signature independent. This leads to proofs of general Birkhoff-type theorems
for warped product manifolds; our theorems in particular apply to situations
where the warped product manifold is not necessarily Einstein, and thus can be
applied to solutions with matter content in general relativity. Next we
specialize to the Lorentzian case and study the propagation of null expansions
under the assumption of the dominant energy condition. We prove several
non-existence results relating to the Yamabe class of the fibers, in the spirit
of the black-hole topology theorem of Hawking-Galloway-Schoen. Finally we
discuss the effect of the warped product ansatz on matter models. In particular
we construct several cosmological solutions to the Einstein-Euler equations
whose spatial geometry is generally not isotropic.
",Mathematics
"  Given two infinite sequences with known binomial transforms, we compute the
binomial transform of the product sequence. Various identities are obtained and
numerous examples are given involving sequences of special numbers: Harmonic
numbers, Bernoulli numbers, Fibonacci numbers, and also Laguerre polynomials.
",Mathematics
"  We continue the first and second authors' study of $q$-commutative power
series rings $R=k_q[[x_1,\ldots,x_n]]$ and Laurent series rings $L=k_q[[x^{\pm
1}_1,\ldots,x^{\pm 1}_n]]$, specializing to the case in which the commutation
parameters $q_{ij}$ are all roots of unity. In this setting, $R$ is a PI
algebra, and we can apply results of De Concini, Kac, and Procesi to show that
$L$ is an Azumaya algebra whose degree can be inferred from the $q_{ij}$. Our
main result establishes an exact criterion (dependent on the $q_{ij}$) for
determining when the centers of $L$ and $R$ are commutative Laurent series and
commutative power series rings, respectively. In the event this criterion is
satisfied, it follows that $L$ is a unique factorization ring in the sense of
Chatters and Jordan, and it further follows, by results of Dumas, Launois,
Lenagan, and Rigal, that $R$ is a unique factorization ring. We thus produce
new examples of complete, local, noetherian, noncommutative, unique
factorization rings (that are PI domains).
",Mathematics
"  We prove Riemann hypothesis, Generalized Riemann hypothesis, and Ramanujan
$\tau$-Dirichlet series hypothesis. Method is to show the convexity of function
which has zeros critical strip the same as zeta function.
",Mathematics
"  The liar paradox is widely seen as not a serious problem. I try to explain
why this view is mistaken.
",Mathematics
"  The fundamental group $\pi$ of a Kodaira fibration is, by definition, the
extension of a surface group $\Pi_b$ by another surface group $\Pi_g$, i.e. \[
1 \rightarrow \Pi_g \rightarrow \pi \rightarrow \Pi_b \rightarrow 1. \]
Conversely, we can inquire about what conditions need to be satisfied by a
group of that sort in order to be the fundamental group of a Kodaira fibration.
In this short note we collect some restriction on the image of the classifying
map $m \colon \Pi_b \to \Gamma_g$ in terms of the coinvariant homology of
$\Pi_g$. In particular, we observe that if $\pi$ is the fundamental group of a
Kodaira fibration with relative irregularity $g-s$, then $g \leq 1+ 6s$, and we
show that this effectively constrains the possible choices for $\pi$, namely
that there are group extensions as above that fail to satisfy this bound, hence
cannot be the fundamental group of a Kodaira fibration. In particular this
provides examples of symplectic $4$--manifolds that fail to admit a Kähler
structure for reasons that eschew the usual obstructions.
",Mathematics
"  In statistics cumulants are defined to be functions that measure the linear
independence of random variables. In the non-communicative case the Boolean
cumulants can be described as functions that measure deviation of a map between
algebras from being an algebra morphism. In Algebraic topology maps that are
homotopic to being algebra morphisms are studied using the theory of $A_\infty$
algebras. In this paper we will explore the link between these two points of
views on maps between algebras that are not algebra maps.
",Mathematics
"  The Baran metric $\delta_E$ is a Finsler metric on the interior of $E\subset
\R^n$ arising from Pluripotential Theory. We consider the few instances, namely
$E$ being the ball, the simplex, or the sphere, where $\delta_E$ is known to be
Riemaniann and we prove that the eigenfunctions of the associated Laplace
Beltrami operator (with no boundary conditions) are the orthogonal polynomials
with respect to the pluripotential equilibrium measure $\mu_E$ of $E.$ We
conjecture that this may hold in a wider generality.
The considered differential operators have been already introduced in the
framework of orthogonal polynomials and studied in connection with certain
symmetry groups. In this work instead we highlight the relationships between
orthogonal polynomials with respect to $\mu_E$ and the Riemaniann structure
naturally arising from Pluripotential Theory
",Mathematics
"  An interesting attempt for solving infrared divergence problems via the
theory of generalized wave operators was made by P. Kulish and L. Faddeev. Our
method of using the ideas from the theory of generalized wave operators is
essentially different. We assume that the unperturbed operator $A_0$ is known
and that the scattering operator $S$ and the unperturbed operator $A_0$ are
permutable. (In the Kulish-Faddeev theory this basic property is not
fulfilled.) The permutability of $S$ and $A_0$ gives us an important
information about the structure of the scattering operator. We show that the
divergences appeared because the deviations of the initial and final waves from
the free waves were not taken into account. The approach is demonstrated on
important examples.
",Mathematics
"  We study upper bounds on Weierstrass primary factors and discuss their
application in spectral theory. One of the main aims of this note is to draw
attention to works of Blumenthal and Denjoy from 1910, but we also provide some
new results and some numerical computations of our own.
",Mathematics
"  In this short communication we study a fluid queue with a finite buffer. The
performance measure we are interested in is the occupation time over a finite
time period, i.e., the fraction of time the workload process is below some
fixed target level. We construct an alternating sequence of sojourn times
$D_1,U_1,...$ where the pairs $(D_i,U_i)_{i\in\mathbb{N}}$ are i.i.d. random
vectors. We use this sequence to determine the distribution function of the
occupation time in terms of its double transform.
",Mathematics
"  The Jordan decomposition theorem states that every function $f \colon [0,1]
\to \mathbb{R}$ of bounded variation can be written as the difference of two
non-decreasing functions. Combining this fact with a result of Lebesgue, every
function of bounded variation is differentiable almost everywhere in the sense
of Lebesgue measure. We analyze the strength of these theorems in the setting
of reverse mathematics. Over $\mathsf{RCA}_0$, a stronger version of Jordan's
result where all functions are continuous is equivalent to $\mathsf{ACA}_0$,
while the version stated is equivalent to $\mathsf{WKL}_0$. The result that
every function on $[0,1]$ of bounded variation is almost everywhere
differentiable is equivalent to $\mathsf{WWKL}_0$. To state this equivalence in
a meaningful way, we develop a theory of Martin-Löf randomness over
$\mathsf{RCA}_0$.
",Mathematics
"  The Hasse-Witt matrix of a hypersurface in ${\mathbb P}^n$ over a finite
field of characteristic $p$ gives essentially complete mod $p$ information
about the zeta function of the hypersurface. But if the degree $d$ of the
hypersurface is $\leq n$, the zeta function is trivial mod $p$ and the
Hasse-Witt matrix is zero-by-zero. We generalize a classical formula for the
Hasse-Witt matrix to obtain a matrix that gives a nontrivial congruence for the
zeta function for all $d$. We also describe the differential equations
satisfied by this matrix and prove that it is generically invertible.
",Mathematics
"  In this article we introduce Variable exponent Fock spaces and study some of
their basic properties such as the boundedness of evaluation functionals,
density of polynomials, boundedness of a Bergman-type projection and duality.
",Mathematics
"  Duke, Imamoglu, and Toth constructed a polyharmonic Maass form of level 4
whose Fourier coefficients encode real quadratic class numbers. A more general
construction of such forms was subsequently given by Bruinier, Funke, and
Imamoglu. Here we give a direct construction of such a form for the full
modular group and study the properties of its coefficients. We give
interpretations of the coefficients of the holomorphic parts of each of these
polyharmonic Maass forms as inner products of certain weakly holomorphic
modular forms and harmonic Maass forms. The coefficients of square index are
particularly intractable; in order to address these, we develop various
extensions of the usual normalized Peterson inner product using a strategy of
Bringmann, Ehlen and Diamantis.
",Mathematics
"  We are concerned with unbounded sets of $\mathbb{R}^N$ whose boundary has
constant nonlocal (or fractional) mean curvature, which we call CNMC sets. This
is the equation associated to critical points of the fractional perimeter
functional under a volume constraint. We construct CNMC sets which are the
countable union of a certain bounded domain and all its translations through a
periodic integer lattice of dimension $M\leq N$. Our CNMC sets form a $C^2$
branch emanating from the unit ball alone and where the parameter in the branch
is essentially the distance to the closest lattice point. Thus, the new
translated near-balls (or near-spheres) appear from infinity. We find their
exact asymptotic shape as the parameter tends to infinity.
",Mathematics
"  This paper studies the eigenvalue problem on $\mathbb{R}^d$ for a class of
second order, elliptic operators of the form $\mathscr{L} =
a^{ij}\partial_{x_i}\partial_{x_j} + b^{i}\partial_{x_i} + f$, associated with
non-degenerate diffusions. We show that strict monotonicity of the principal
eigenvalue of the operator with respect to the potential function $f$ fully
characterizes the ergodic properties of the associated ground state diffusion,
and the unicity of the ground state, and we present a comprehensive study of
the eigenvalue problem from this point of view. This allows us to extend or
strengthen various results in the literature for a class of viscous
Hamilton-Jacobi equations of ergodic type with smooth coefficients to equations
with measurable drift and potential. In addition, we establish the strong
duality for the equivalent infinite dimensional linear programming formulation
of these ergodic control problems. We also apply these results to the study of
the infinite horizon risk-sensitive control problem for diffusions, and
establish existence of optimal Markov controls, verification of optimality
results, and the continuity of the controlled principal eigenvalue with respect
to stationary Markov controls.
",Mathematics
"  We prove an identity relating the product of two opposite Schubert varieties
in the (equivariant) quantum K-theory ring of a cominuscule flag variety to the
minimal degree of a rational curve connecting the Schubert varieties. We deduce
that the sum of the structure constants associated to any product of Schubert
classes is equal to one. Equivalently, the sheaf Euler characteristic map
extends to a ring homomorphism defined on the quantum K-theory ring.
",Mathematics
"  We provide a particle picture representation for the non-symmetric Rosenblatt
process and for Hermite processes of any order, extending the result of
Bojdecki, Gorostiza and Talarczyk in~\cite{FILT}. We show that these processes
can be obtained as limits in the sense of finite-dimensional distributions of
certain functionals of a system of particles evolving according to symmetric
stable Lévy motions. In the case of $k$-Hermite processes the corresponding
functional involves $k$-intersection local time of symmetric stable Lévy
processes
",Mathematics
"  We develop a quantitative theory of stochastic homogenization for linear,
uniformly parabolic equations with coefficients depending on space and time.
Inspired by recent works in the elliptic setting, our analysis is focused on
certain subadditive quantities derived from a variational interpretation of
parabolic equations. These subadditive quantities are intimately connected to
spatial averages of the fluxes and gradients of solutions. We implement a
renormalization-type scheme to obtain an algebraic rate for their convergence,
which is essentially a quantification of the weak convergence of the gradients
and fluxes of solutions to their homogenized limits. As a consequence, we
obtain estimates of the homogenization error for the Cauchy-Dirichlet problem
which are optimal in stochastic integrability. We also develop a higher
regularity theory for solutions of the heterogeneous equation, including a
uniform $C^{0,1}$-type estimate and a Liouville theorem of every finite order.
",Mathematics
"  In this paper we construct an analogue of Lurie's ""unstraightening""
construction that we refer to as the ""comprehension construction"". Its input is
a cocartesian fibration $p \colon E \to B$ between $\infty$-categories together
with a third $\infty$-category $A$. The comprehension construction then defines
a map from the quasi-category of functors from $A$ to $B$ to the large
quasi-category of cocartesian fibrations over $A$ that acts on $f \colon A \to
B$ by forming the pullback of $p$ along $f$. To illustrate the versatility of
this construction, we define the covariant and contravariant Yoneda embeddings
as special cases of the comprehension functor. We then prove that the hom-wise
action of the comprehension functor coincides with an ""external action"" of the
hom-spaces of $B$ on the fibres of $p$ and use this to prove that the Yoneda
embedding is fully faithful, providing an explicit equivalence between a
quasi-category and the homotopy coherent nerve of a Kan-complex enriched
category.
",Mathematics
"  We present an elementary proof of a conjecture proposed by I. Rasa in 2017
which is an inequality involving Bernstein basis polynomials and convex
functions. It was affirmed in positive by A. Komisarski and T. Rajba very
recently by the use of stochastic convex orderings.
",Mathematics
"  Let $K(B_{\ell_p^n},B_{\ell_q^n}) $ be the $n$-dimensional $(p,q)$-Bohr
radius for holomorphic functions on $\mathbb C^n$. That is,
$K(B_{\ell_p^n},B_{\ell_q^n}) $ denotes the greatest constant $r\geq 0$ such
that for every entire function $f(z)=\sum_{\alpha} c_{\alpha} z^{\alpha}$ in
$n$-complex variables, we have the following (mixed) Bohr-type inequality
$$\sup_{z \in r \cdot B_{\ell_q^n}} \sum_{\alpha} | c_{\alpha} z^{\alpha} |
\leq \sup_{z \in B_{\ell_p^n}} | f(z) |,$$ where $B_{\ell_r^n}$ denotes the
closed unit ball of the $n$-dimensional sequence space $\ell_r^n$.
For every $1 \leq p, q \leq \infty$, we exhibit the exact asymptotic growth
of the $(p,q)$-Bohr radius as $n$ (the number of variables) goes to infinity.
",Mathematics
"  This is a survey article, based on the author's lectures in the 2015 AMS
Summer Research Institute in Algebraic Geometry, and to appear in the
Proceedings.
",Mathematics
"  A generalization of classical determinant inequalities like Hadamard's
inequality and Fischer's inequality is studied. For a version of the
inequalities originally proved by Arveson for positive operators in von Neumann
algebras with a tracial state, we give a different proof. We also improve and
generalize to the setting of finite von Neumann algebras, some `Fischer-type'
inequalities by Matic for determinants of perturbed positive-definite matrices.
In the process, a conceptual framework is established for viewing these
inequalities as manifestations of Jensen's inequality in conjunction with the
theory of operator monotone and operator convex functions on $[0,\infty)$. We
place emphasis on documenting necessary and sufficient conditions for equality
to hold.
",Mathematics
"  We provide a non-trivial measure of irrationality for a class of Mahler
numbers defined with infinite products which cover the Thue-Morse constant.
",Mathematics
"  In the previous article we derived a detailed asymptotic expansion of the
heat trace for the Laplace-Beltrami operator on functions on manifolds with
conic singularities. In this article we investigate how the terms in the
expansion reflect the geometry of the manifold. Since the general expansion
contains a logarithmic term, its vanishing is a necessary condition for
smoothness of the manifold. In the two-dimensional case this implies that the
constant term of the expansion contains a non-local term that determines the
length of the (circular) cross section and vanishes precisely if this length
equals $2\pi$, that is, in the smooth case. We proceed to the study of higher
dimensions. In the four-dimensional case, the logarithmic term in the expansion
vanishes precisely when the cross section is a spherical space form, and we
expect that the vanishing of a further singular term will imply again
smoothness, but this is not yet clear beyond the case of cyclic space forms. In
higher dimensions the situation is naturally more difficult. We illustrate this
in the case of cross sections with constant curvature. Then the logarithmic
term becomes a polynomial in the curvature with roots that are different from
1, which necessitates more vanishing of other terms, not isolated so far.
",Mathematics
"  We propose and analyze an efficient spectral-Galerkin approximation for the
Maxwell transmission eigenvalue problem in spherical geometry. Using a vector
spherical harmonic expansion, we reduce the problem to a sequence of equivalent
one-dimensional TE and TM modes that can be solved individually in parallel.
For the TE mode, we derive associated generalized eigenvalue problems and
corresponding pole conditions. Then we introduce weighted Sobolev spaces based
on the pole condition and prove error estimates for the generalized eigenvalue
problem. The TM mode is a coupled system with four unknown functions, which is
challenging for numerical calculation. To handle it, we design an effective
algorithm using Legendre-type vector basis functions. Finally, we provide some
numerical experiments to validate our theoretical results and demonstrate the
efficiency of the algorithms.
",Mathematics
"  The study of knots and links from a probabilistic viewpoint provides insight
into the behavior of ""typical"" knots, and opens avenues for new constructions
of knots and other topological objects with interesting properties. The
knotting of random curves arises also in applications to the natural sciences,
such as in the context of the structure of polymers. We present here several
known and new randomized models of knots and links. We review the main known
results on the knot distribution in each model. We discuss the nature of these
models and the properties of the knots they produce. Of particular interest to
us are finite type invariants of random knots, and the recently studied
Petaluma model. We report on rigorous results and numerical experiments
concerning the asymptotic distribution of such knot invariants. Our approach
raises questions of universality and classification of the various random knot
models.
",Mathematics
"  Not necessarily self-adjoint quantum graphs -- differential operators on
metric graphs -- are considered. Assume in addition that the underlying metric
graph possesses an automorphism (symmetry) $ \mathcal P $. If the differential
operator is $ \mathcal P \mathcal T$-symmetric, then its spectrum has
reflection symmetry with respect to the real line. Our goal is to understand
whether the opposite statement holds, namely whether the reflection symmetry of
the spectrum of a quantum graph implies that the underlying metric graph
possesses a non-trivial automorphism and the differential operator is $
\mathcal P \mathcal T$-symmetric. We give partial answer to this question by
considering equilateral star-graphs. The corresponding Laplace operator with
Robin vertex conditions possesses reflection-symmetric spectrum if and only if
the operator is $ \mathcal P \mathcal T$-symmetric with $ \mathcal P $ being an
automorphism of the metric graph.
",Mathematics
"  In this paper, we first discuss the relation between VB-Courant algebroids
and E-Courant algebroids and construct some examples of E-Courant algebroids.
Then we introduce the notion of a generalized complex structure on an E-Courant
algebroid, unifying the usual generalized complex structures on
even-dimensional manifolds and generalized contact structures on
odd-dimensional manifolds. Moreover, we study generalized complex structures on
an omni-Lie algebroid in detail. In particular, we show that generalized
complex structures on an omni-Lie algebra $\gl(V)\oplus V$ correspond to
complex Lie algebra structures on V.
",Mathematics
"  We prove generalized weighted Ostrowski and Ostrowski--Grüss type
inequalities on time scales via a parameter function. In particular, our result
extends a result of Dragomir and Barnett. Furthermore, we apply our results to
the continuous, discrete, and quantum cases, to obtain some interesting new
inequalities.
",Mathematics
"  We construct energy-dependent potentials for which the Schroedinger equations
admit solu- tions in terms of exceptional orthogonal polynomials. Our method of
construction is based on certain point transformations, applied to the
equations of exceptional Hermite, Jacobi and Laguerre polynomials. We present
several examples of boundary-value problems with energy-dependent potentials
that admit a discrete spectrum and the corresponding normalizable solutions in
closed form.
",Mathematics
"  In this paper we present a family of conjectural relations in the
tautological ring of the moduli spaces of stable curves which implies the
strong double ramification/Dubrovin-Zhang equivalence conjecture. Our
tautological relations have the form of an equality between two different
families of tautological classes, only one of which involves the double
ramification cycle. We prove that both families behave the same way upon
pullback and pushforward with respect to forgetting a marked point. We also
prove that our conjectural relations are true in genus $0$ and $1$ and also
when first pushed forward from $\overline{\mathcal{M}}_{g,n+m}$ to
$\overline{\mathcal{M}}_{g,n}$ and then restricted to $\mathcal{M}_{g,n}$, for
any $g,n,m\geq 0$. Finally we show that, for semisimple CohFTs, the DR/DZ
equivalence only depends on a subset of our relations, finite in each genus,
which we prove for $g\leq 2$. As an application we find a new formula for the
class $\lambda_g$ as a linear combination of dual trees intersected with kappa
and psi classes, and we check it for $g \leq 3$.
",Mathematics
"  If several independent algorithms for a computer-calculated quantity exist,
then one can expect their results (which differ because of numerical errors) to
follow approximately Gaussian distribution. The mean of this distribution,
interpreted as the value of the quantity of interest, can be determined with
better precision than what is the precision provided by a single algorithm.
Often, with lack of enough independent algorithms, one can proceed differently:
many practical algorithms introduce a bias using a parameter, e.g. a small but
finite number to compute a limit or a large but finite number (cutoff) to
approximate infinity. One may vary such parameter of a single algorithm and
interpret the resulting numbers as generated by several algorithms. A numerical
evidence for the validity of this approach is shown for differentiation.
",Mathematics
"  In this article, we study orbifold constructions associated with the Leech
lattice vertex operator algebra. As an application, we prove that the structure
of a strongly regular holomorphic vertex operator algebra of central charge
$24$ is uniquely determined by its weight one Lie algebra if the Lie algebra
has the type $A_{3,4}^3A_{1,2}$, $A_{4,5}^2$, $D_{4,12}A_{2,6}$, $A_{6,7}$,
$A_{7,4}A_{1,1}^3$, $D_{5,8}A_{1,2}$ or $D_{6,5}A_{1,1}^2$ by using the reverse
orbifold construction. Our result also provides alternative constructions of
these vertex operator algebras (except for the case $A_{6,7}$) from the Leech
lattice vertex operator algebra.
",Mathematics
"  We give a bordered extension of involutive HF-hat and use it to give an
algorithm to compute involutive HF-hat for general 3-manifolds. We also explain
how the mapping class group action on HF-hat can be computed using bordered
Floer homology. As applications, we prove that involutive HF-hat satisfies a
surgery exact triangle and compute HFI-hat of the branched double covers of all
10-crossing knots.
",Mathematics
"  We construct examples of flat fiber bundles over the Hopf surface such that
the total spaces have no pseudoconvex neighborhood basis, admit a complete
Kähler metric, or are hyperconvex but have no nonconstant holomorphic
functions. For any compact Riemannian surface of positive genus, we construct a
flat $\mathbb P^1$ bundle over it and a Stein domain with real analytic bundary
in it whose closure does not have pseudoconvex neighborhood basis. For a
compact complex manifold with positive first Betti number, we construct a flat
disc bundle over it such that the total space is hyperconvex but admits no
nonconstant holomorphic functions.
",Mathematics
"  We examine collective properties of closure operators on posets that are at
least dcpos. The first theorem sets the tone of the paper: it tells how a set
of preclosure maps on a dcpo determines the least closure operator above them,
and pronounces the related induction principle, and its companion, the obverse
induction principle. Using this theorem we prove that the poset of closure
operators on a dcpo is a complete lattice, and then provide a constructive
proof of the Tarski's theorem for dcpos. We go on to construct the joins in the
complete lattice of Scott-continuous closure operators on a dcpo, and to prove
that the complete lattice of nuclei on a preframe is a frame, giving some
constructions in the special case of the frame of all nuclei on a frame. In the
rather drawn-out proof if the Hofmann-Mislove-Johnstone theorem we show off the
utility of the obverse induction, applying it in the proof of the crucial
lemma. After that we shift a viewpoint and prove some results, analogous to
results about dcpos, for posets in which certain special subsets have enough
maximal elements; these results actually specialize to dcpos, but at the price
of using the axiom of choice. We conclude by pointing out two convex geometries
associated with closure operators on a dcpo.
",Mathematics
"  We prove the existence of an optimal feedback controller for a stochastic
optimization problem constituted by a variation of the Heston model, where a
stochastic input process is added in order to minimize a given performance
criterion. The stochastic feedback controller is searched by solving a
nonlinear backward parabolic equation for which one proves the existence of a
martingale solution.
",Mathematics
"  Let G be an abelian group. For a subset A of G, Cyc(A) denotes the set of all
elements x of G such that the cyclic subgroup generated by x is contained in A,
and G is said to have the small subgroup generating property (abbreviated to
SSGP) if the smallest subgroup of G generated by Cyc(U) is dense in G for every
neighbourhood U of zero of G. SSGP groups form a proper subclass of the class
of minimally almost periodic groups. Comfort and Gould asked for a
characterization of abelian groups G which admit an SSGP group topology, and
they solved this problem for bounded torsion groups (which have divisible rank
zero). Dikranjan and the first author proved that an abelian group of infinite
divisible rank admits an SSGP group topology. In the remaining case of positive
finite divisible rank, the same authors found a necessary condition on G in
order to admit an SSGP group topology and asked if this condition is also
sufficient. We answer this question positively, thereby completing the
characterization of abelian groups which admit an SSGP group topology.
",Mathematics
"  We investigate spatial evolutionary games with death-birth updating in large
finite populations. Within growing spatial structures subject to appropriate
conditions, the density processes of a fixed type are proven to converge to the
Wright-Fisher diffusions with drift. In addition, convergence in the
Wasserstein distance of the laws of their occupation measures holds. The proofs
of these results develop along an equivalence between the laws of the
evolutionary games and certain voter models and rely on the analogous results
of voter models on large finite sets by convergences of the Radon-Nikodym
derivative processes. As another application of this equivalence of laws, we
show that in a general, large population of size $N$, for which the stationary
probabilities of the corresponding voting kernel are comparable to uniform
probabilities, a first-derivative test among the major methods for these
evolutionary games is applicable at least up to weak selection strengths in the
usual biological sense (that is, selection strengths of the order $\mathcal
O(1/N)$).
",Mathematics
"  Riemannian geometry is a particular case of Hamiltonian mechanics: the orbits
of the hamiltonian $H=\frac{1}{2}g^{ij}p_{i}p_{j}$ are the geodesics. Given a
symplectic manifold (\Gamma,\omega), a hamiltonian $H:\Gamma\to\mathbb{R}$ and
a Lagrangian sub-manifold $M\subset\Gamma$ we find a generalization of the
notion of curvature. The particular case
$H=\frac{1}{2}g^{ij}\left[p_{i}-A_{i}\right]\left[p_{j}-A_{j}\right]+\phi $ of
a particle moving in a gravitational, electromagnetic and scalar fields is
studied in more detail. The integral of the generalized Ricci tensor w.r.t. the
Boltzmann weight reduces to the action principle
$\int\left[R+\frac{1}{4}F_{ik}F_{jl}g^{kl}g^{ij}-g^{ij}\partial_{i}\phi\partial_{j}\phi\right]e^{-\phi}\sqrt{g}d^{n}q$
for the scalar, vector and tensor fields.
",Mathematics
"  We consider a control-constrained parabolic optimal control problem without
Tikhonov term in the tracking functional. For the numerical treatment, we use
variational discretization of its Tikhonov regularization: For the state and
the adjoint equation, we apply Petrov-Galerkin schemes from [Daniels et al
2015] in time and usual conforming finite elements in space. We prove a-priori
estimates for the error between the discretized regularized problem and the
limit problem. Since these estimates are not robust if the regularization
parameter tends to zero, we establish robust estimates, which --- depending on
the problem's regularity --- enhance the previous ones. In the special case of
bang-bang solutions, these estimates are further improved. A numerical example
confirms our analytical findings.
",Mathematics
"  In this note, we provide a conceptual explanation of a well-known polynomial
identity used in algebraic number theory.
",Mathematics
"  This article describes the motivation, design, and progress of the Journal of
Open Source Software (JOSS). JOSS is a free and open-access journal that
publishes articles describing research software. It has the dual goals of
improving the quality of the software submitted and providing a mechanism for
research software developers to receive credit. While designed to work within
the current merit system of science, JOSS addresses the dearth of rewards for
key contributions to science made in the form of software. JOSS publishes
articles that encapsulate scholarship contained in the software itself, and its
rigorous peer review targets the software components: functionality,
documentation, tests, continuous integration, and the license. A JOSS article
contains an abstract describing the purpose and functionality of the software,
references, and a link to the software archive. The article is the entry point
of a JOSS submission, which encompasses the full set of software artifacts.
Submission and review proceed in the open, on GitHub. Editors, reviewers, and
authors work collaboratively and openly. Unlike other journals, JOSS does not
reject articles requiring major revision; while not yet accepted, articles
remain visible and under review until the authors make adequate changes (or
withdraw, if unable to meet requirements). Once an article is accepted, JOSS
gives it a DOI, deposits its metadata in Crossref, and the article can begin
collecting citations on indexers like Google Scholar and other services.
Authors retain copyright of their JOSS article, releasing it under a Creative
Commons Attribution 4.0 International License. In its first year, starting in
May 2016, JOSS published 111 articles, with more than 40 additional articles
under review. JOSS is a sponsored project of the nonprofit organization
NumFOCUS and is an affiliate of the Open Source Initiative.
",Cybersecurity
"  The paper addresses the problem of passivation of a class of nonlinear
systems where the dynamics are unknown. For this purpose, we use the highly
flexible, data-driven Gaussian process regression for the identification of the
unknown dynamics for feed-forward compensation. The closed loop system of the
nonlinear system, the Gaussian process model and a feedback control law is
guaranteed to be semi-passive with a specific probability. The predicted
variance of the Gaussian process regression is used to bound the model error
which additionally allows to specify the state space region where the
closed-loop system behaves passive. Finally, the theoretical results are
illustrated by a simulation.
",Cybersecurity
"  Walking quadruped robots face challenges in positioning their feet and
lifting their legs during gait cycles over uneven terrain. The robot Laika is
under development as a quadruped with a flexible, actuated spine designed to
assist with foot movement and balance during these gaits. This paper presents
the first set of hardware designs for the spine of Laika, a physical prototype
of those designs, and tests in both hardware and simulations that show the
prototype's capabilities. Laika's spine is a tensegrity structure, used for its
advantages with weight and force distribution, and represents the first working
prototype of a tensegrity spine for a quadruped robot. The spine bends by
adjusting the lengths of the cables that separate its vertebrae, and twists
using an actuated rotating vertebra at its center. The current prototype of
Laika has stiff legs attached to the spine, and is used as a test setup for
evaluation of the spine itself. This work shows the advantages of Laika's spine
by demonstrating the spine lifting each of the robot's four feet, both as a
form of balancing and as a precursor for a walking gait. These foot motions,
using specific combinations of bending and rotation movements of the spine, are
measured in both simulation and hardware experiments. Hardware data are used to
calibrate the simulations, such that the simulations can be used for control of
balancing or gait cycles in the future. Future work will attach actuated legs
to Laika's spine, and examine balancing and gait cycles when combined with leg
movements.
",Cybersecurity
"  Network analysis techniques remain rarely used for understanding
international management strategies. Our paper highlights their value as
research tool in this field of social science using a large set of micro-data
(20,000) to investigate the presence of networks of subsidiaries overseas. The
research question is the following: to what extent did/do global Japanese
business networks mirror organizational models existing in Japan? In
particular, we would like to assess how much the links building such business
networks are shaped by the structure of big-size industrial conglomerates of
firms headquartered in Japan, also described as HK. The major part of the
academic community in the fields of management and industrial organization
considers that formal links can be identified among firms belonging to HK. Miwa
and Ramseyer (Miwa and Ramseyer 2002; Ramseyer 2006) challenge this claim and
argue that the evidence supporting the existence of HK is weak. So far,
quantitative empirical investigation has been conducted exclusively using data
for firms incorporated in Japan. Our study tests the Miwa-Ramseyer hypothesis
(MRH) at the global level using information on the network of Japanese
subsidiaries overseas. The results obtained lead us to reject the MRH for the
global dataset, as well as for subsets restricted to the two main
regions/countries of destination of Japanese foreign investment. The results
are robust to the weighting of the links, with different specifications, and
are observed in most industrial sectors. The global Japanese network became
increasingly complex during the late 20th century as a consequence of increase
in the number of Japanese subsidiaries overseas but the key features of the
structure remained rather stable. We draw implications of these findings for
academic research in international business and for professionals involved in
corporate strategy.
",Cybersecurity
"  Fine-tuning of a deep convolutional neural network (CNN) is often desired.
This paper provides an overview of our publicly available py-faster-rcnn-ft
software library that can be used to fine-tune the VGG_CNN_M_1024 model on
custom subsets of the Microsoft Common Objects in Context (MS COCO) dataset.
For example, we improved the procedure so that the user does not have to look
for suitable image files in the dataset by hand which can then be used in the
demo program. Our implementation randomly selects images that contain at least
one object of the categories on which the model is fine-tuned.
",Cybersecurity
"  Publishing reproducible analyses is a long-standing and widespread challenge
for the scientific community, funding bodies and publishers. Although a
definitive solution is still elusive, the problem is recognized to affect all
disciplines and lead to a critical system inefficiency. Here, we propose a
blockchain-based approach to enhance scientific reproducibility, with a focus
on life science studies and precision medicine. While the interest of encoding
permanently into an immutable ledger all the study key information-including
endpoints, data and metadata, protocols, analytical methods and all
findings-has been already highlighted, here we apply the blockchain approach to
solve the issue of rewarding time and expertise of scientists that commit to
verify reproducibility. Our mechanism builds a trustless ecosystem of
researchers, funding bodies and publishers cooperating to guarantee digital and
permanent access to information and reproducible results. As a natural
byproduct, a procedure to quantify scientists' and institutions' reputation for
ranking purposes is obtained.
",Cybersecurity
"  We describe some progress towards a new common framework for model driven
engineering, based on behavioral programming. The tool we have developed
unifies almost all of the work done in behavioral programming so far, under a
common set of interfaces. Its architecture supports pluggable event selection
strategies, which can make models more intuitive and compact. Program state
space can be traversed using various algorithms, such as DFS and A*.
Furthermore, program state is represented in a way that enables scanning a
state space using parallel and distributed algorithms. Executable models
created with this tool can be directly embedded in Java applications, enabling
a model-first approach to system engineering, where initially a model is
created and verified, and then a working application is gradually built around
the model. The model itself consists of a collection of small scripts written
in JavaScript (hence ""BPjs""). Using a variety of case-studies, this paper shows
how the combination of a lenient programming language with formal model
analysis tools creates an efficient way of developing robust complex systems.
Additionally, as we learned from an experimental course we ran, the usage of
JavaScript make practitioners more amenable to using this system and, thus,
model checking and model driven engineering. In addition to providing
infrastructure for development and case-studies in behavioral programming, the
tool is designed to serve as a common platform for research and innovation in
behavioral programming and in model driven engineering in general.
",Cybersecurity
"  EPG graphs, introduced by Golumbic et al. in 2009, are edge-intersection
graphs of paths on an orthogonal grid. The class $B_k$-EPG is the subclass of
EPG graphs where the path on the grid associated to each vertex has at most $k$
bends. Epstein et al. showed in 2013 that computing a maximum clique in
$B_1$-EPG graphs is polynomial. As remarked in [Heldt et al., 2014], when the
number of bends is at least $4$, the class contains $2$-interval graphs for
which computing a maximum clique is an NP-hard problem. The complexity status
of the Maximum Clique problem remains open for $B_2$ and $B_3$-EPG graphs. In
this paper, we show that we can compute a maximum clique in polynomial time in
$B_2$-EPG graphs given a representation of the graph.
Moreover, we show that a simple counting argument provides a
${2(k+1)}$-approximation for the coloring problem on $B_k$-EPG graphs without
knowing the representation of the graph. It generalizes a result of [Epstein et
al, 2013] on $B_1$-EPG graphs (where the representation was needed).
",Cybersecurity
"  We give an elementary combinatorial proof of Bass's determinant formula for
the zeta function of a finite regular graph. This is done by expressing the
number of non-backtracking cycles of a given length in terms of Chebychev
polynomials in the eigenvalues of the adjacency operator of the graph.
",Cybersecurity
"  In the classical binary search in a path the aim is to detect an unknown
target by asking as few queries as possible, where each query reveals the
direction to the target. This binary search algorithm has been recently
extended by [Emamjomeh-Zadeh et al., STOC, 2016] to the problem of detecting a
target in an arbitrary graph. Similarly to the classical case in the path, the
algorithm of Emamjomeh-Zadeh et al. maintains a candidates' set for the target,
while each query asks an appropriately chosen vertex-- the ""median""--which
minimises a potential $\Phi$ among the vertices of the candidates' set. In this
paper we address three open questions posed by Emamjomeh-Zadeh et al., namely
(a) detecting a target when the query response is a direction to an
approximately shortest path to the target, (b) detecting a target when querying
a vertex that is an approximate median of the current candidates' set (instead
of an exact one), and (c) detecting multiple targets, for which to the best of
our knowledge no progress has been made so far. We resolve questions (a) and
(b) by providing appropriate upper and lower bounds, as well as a new potential
$\Gamma$ that guarantees efficient target detection even by querying an
approximate median each time. With respect to (c), we initiate a systematic
study for detecting two targets in graphs and we identify sufficient conditions
on the queries that allow for strong (linear) lower bounds and strong
(polylogarithmic) upper bounds for the number of queries. All of our positive
results can be derived using our new potential $\Gamma$ that allows querying
approximate medians.
",Cybersecurity
"  Security exploits can include cyber threats such as computer programs that
can disturb the normal behavior of computer systems (viruses), unsolicited
e-mail (spam), malicious software (malware), monitoring software (spyware),
attempting to make computer resources unavailable to their intended users
(Distributed Denial-of-Service or DDoS attack), the social engineering, and
online identity theft (phishing). One such cyber threat, which is particularly
dangerous to computer users is phishing. Phishing is well known as online
identity theft, which targets to steal victims' sensitive information such as
username, password and online banking details. This paper focuses on designing
an innovative and gamified approach to educate individuals about phishing
attacks. The study asks how one can integrate self-efficacy, which has a
co-relation with the user's knowledge, into an anti-phishing educational game
to thwart phishing attacks? One of the main reasons would appear to be a lack
of user knowledge to prevent from phishing attacks. Therefore, this research
investigates the elements that influence (in this case, either conceptual or
procedural knowledge or their interaction effect) and then integrate them into
an anti-phishing educational game to enhance people's phishing prevention
behaviour through their motivation.
",Cybersecurity
"  Vaccine hesitancy has been recognized as a major global health threat. Having
access to any type of information in social media has been suggested as a
potential powerful influence factor to hesitancy. Recent studies in other
fields than vaccination show that access to a wide amount of content through
the Internet without intermediaries resolved into major segregation of the
users in polarized groups. Users select the information adhering to theirs
system of beliefs and tend to ignore dissenting information. In this paper we
assess whether there is polarization in Social Media use in the field of
vaccination. We perform a thorough quantitative analysis on Facebook analyzing
2.6M users interacting with 298.018 posts over a time span of seven years and 5
months. We used community detection algorithms to automatically detect the
emergent communities from the users activity and to quantify the cohesiveness
over time of the communities. Our findings show that content consumption about
vaccines is dominated by the echo-chamber effect and that polarization
increased over years. Communities emerge from the users consumption habits,
i.e. the majority of users only consumes information in favor or against
vaccines, not both. The existence of echo-chambers may explain why social-media
campaigns providing accurate information may have limited reach, may be
effective only in sub-groups and might even foment further polarization of
opinions. The introduction of dissenting information into a sub-group is
disregarded and can have a backfire effect, further reinforcing the existing
opinions within the sub-group.
",Cybersecurity
"  Unlike the Web where each web page has a global URL to reach, a specific
""content page"" inside a mobile app cannot be opened unless the user explores
the app with several operations from the landing page. Recently, deep links
have been advocated by major companies to enable targeting and opening a
specific page of an app externally with an accessible uniform resource
identifier (URI). To empirically investigate the state of the practice on
adopting deep links, in this article, we present the largest empirical study of
deep links over 20,000 Android apps, and find that deep links do not get wide
adoption among current Android apps, and non-trivial manual efforts are
required for app developers to support deep links. To address such an issue, we
propose the Aladdin approach and supporting tool to release deep links to
access arbitrary location of existing apps. Aladdin instantiates our novel
cooperative framework to synergically combine static analysis and dynamic
analysis while minimally engaging developers to provide inputs to the framework
for automation, without requiring any coding efforts or additional deployment
efforts. We evaluate Aladdin with popular apps and demonstrate its
effectiveness and performance.
",Cybersecurity
"  In recent years, research has been done on applying Recurrent Neural Networks
(RNNs) as recommender systems. Results have been promising, especially in the
session-based setting where RNNs have been shown to outperform state-of-the-art
models. In many of these experiments, the RNN could potentially improve the
recommendations by utilizing information about the user's past sessions, in
addition to its own interactions in the current session. A problem for
session-based recommendation, is how to produce accurate recommendations at the
start of a session, before the system has learned much about the user's current
interests. We propose a novel approach that extends a RNN recommender to be
able to process the user's recent sessions, in order to improve
recommendations. This is done by using a second RNN to learn from recent
sessions, and predict the user's interest in the current session. By feeding
this information to the original RNN, it is able to improve its
recommendations. Our experiments on two different datasets show that the
proposed approach can significantly improve recommendations throughout the
sessions, compared to a single RNN working only on the current session. The
proposed model especially improves recommendations at the start of sessions,
and is therefore able to deal with the cold start problem within sessions.
",Cybersecurity
"  Data analytics and data science play a significant role in nowadays society.
In the context of Smart Grids (SG), the collection of vast amounts of data has
seen the emergence of a plethora of data analysis approaches. In this paper, we
conduct a Systematic Mapping Study (SMS) aimed at getting insights about
different facets of SG data analysis: application sub-domains (e.g., power load
control), aspects covered (e.g., forecasting), used techniques (e.g.,
clustering), tool-support, research methods (e.g., experiments/simulations),
replicability/reproducibility of research. The final goal is to provide a view
of the current status of research. Overall, we found that each sub-domain has
its peculiarities in terms of techniques, approaches and research methodologies
applied. Simulations and experiments play a crucial role in many areas. The
replicability of studies is limited concerning the provided implemented
algorithms, and to a lower extent due to the usage of private datasets.
",Cybersecurity
"  In this work, we conducted a survey on different registration algorithms and
investigated their suitability for hyperspectral historical image registration
applications. After the evaluation of different algorithms, we choose an
intensity based registration algorithm with a curved transformation model. For
the transformation model, we select cubic B-splines since they should be
capable to cope with all non-rigid deformations in our hyperspectral images.
From a number of similarity measures, we found that residual complexity and
localized mutual information are well suited for the task at hand. In our
evaluation, both measures show an acceptable performance in handling all
difficulties, e.g., capture range, non-stationary and spatially varying
intensity distortions or multi-modality that occur in our application.
",Cybersecurity
"  The inability to interpret the model prediction in semantically and visually
meaningful ways is a well-known shortcoming of most existing computer-aided
diagnosis methods. In this paper, we propose MDNet to establish a direct
multimodal mapping between medical images and diagnostic reports that can read
images, generate diagnostic reports, retrieve images by symptom descriptions,
and visualize attention, to provide justifications of the network diagnosis
process. MDNet includes an image model and a language model. The image model is
proposed to enhance multi-scale feature ensembles and utilization efficiency.
The language model, integrated with our improved attention mechanism, aims to
read and explore discriminative image feature descriptions from reports to
learn a direct mapping from sentence words to image pixels. The overall network
is trained end-to-end by using our developed optimization strategy. Based on a
pathology bladder cancer images and its diagnostic reports (BCIDR) dataset, we
conduct sufficient experiments to demonstrate that MDNet outperforms
comparative baselines. The proposed image model obtains state-of-the-art
performance on two CIFAR datasets as well.
",Cybersecurity
"  For every $q\in \mathbb N$ let $\textrm{FO}_q$ denote the class of sentences
of first-order logic FO of quantifier rank at most $q$. If a graph property can
be defined in $\textrm{FO}_q$, then it can be decided in time $O(n^q)$. Thus,
minimizing $q$ has favorable algorithmic consequences. Many graph properties
amount to the existence of a certain set of vertices of size $k$. Usually this
can only be expressed by a sentence of quantifier rank at least $k$. We use the
color-coding method to demonstrate that some (hyper)graph problems can be
defined in $\textrm{FO}_q$ where $q$ is independent of $k$. This property of a
graph problem is equivalent to the question of whether the corresponding
parameterized problem is in the class $\textrm{para-AC}^0$.
It is crucial for our results that the FO-sentences have access to built-in
addition and multiplication. It is known that then FO corresponds to the
circuit complexity class uniform $\textrm{AC}^0$. We explore the connection
between the quantifier rank of FO-sentences and the depth of
$\textrm{AC}^0$-circuits, and prove that $\textrm{FO}_q \subsetneq
\textrm{FO}_{q+1}$ for structures with built-in addition and multiplication.
",Cybersecurity
"  This paper proposes a new method which builds a simplex based approximation
of a $d-1$-dimensional manifold $M$ separating a $d$-dimensional compact set
into two parts, and an efficient algorithm classifying points according to this
approximation. In a first variant, the approximation is made of simplices that
are defined in the cubes of a regular grid covering the compact set, from
boundary points that approximate the intersection between $M$ and the edges of
the cubes. All the simplices defined in a cube share the barycentre of the
boundary points located in the cube and include simplices similarly defined in
cube facets, and so on recursively. In a second variant, the Kuhn triangulation
is used to break the cubes into simplices and the approximation is defined in
these simplices from the boundary points computed on their edges, with the same
principle. Both the approximation in cubes and in simplices define a separating
surface on the whole grid and classifying a point on one side or the other of
this surface requires only a small number (at most $d$) of simple tests. Under
some conditions on the definition of the boundary points and on the reach of
$M$, for both variants the Hausdorff distance between $M$ and its approximation
decreases like $\mathcal{O}(d n_G^{-2})$, where $n_G$ is the number of points
on each axis of the grid. The approximation in cubes requires computing less
boundary points than the approximation in simplices but the latter is always a
manifold and is more accurate for a given value of $n_G$. The paper reports
tests of the method when varying $n_G$ and the dimensionality of the space (up
to 9).
",Cybersecurity
"  In 2009, Joselli et al introduced the Neighborhood Grid data structure for
fast computation of neighborhood estimates in point clouds. Even though the
data structure has been used in several applications and shown to be
practically relevant, it is theoretically not yet well understood. The purpose
of this paper is to present a polynomial-time algorithm to build the data
structure. Furthermore, it is investigated whether the presented algorithm is
optimal. This investigations leads to several combinatorial questions for which
partial results are given.
",Cybersecurity
"  We present PS-DBSCAN, a communication efficient parallel DBSCAN algorithm
that combines the disjoint-set data structure and Parameter Server framework in
Platform of AI (PAI). Since data points within the same cluster may be
distributed over different workers which result in several disjoint-sets,
merging them incurs large communication costs. In our algorithm, we employ a
fast global union approach to union the disjoint-sets to alleviate the
communication burden. Experiments over the datasets of different scales
demonstrate that PS-DBSCAN outperforms the PDSDBSCAN with 2-10 times speedup on
communication efficiency.
We have released our PS-DBSCAN in an algorithm platform called Platform of AI
(PAI - this https URL) in Alibaba Cloud. We have also
demonstrated how to use the method in PAI.
",Cybersecurity
"  Recent progress in deep learning for audio synthesis opens the way to models
that directly produce the waveform, shifting away from the traditional paradigm
of relying on vocoders or MIDI synthesizers for speech or music generation.
Despite their successes, current state-of-the-art neural audio synthesizers
such as WaveNet and SampleRNN suffer from prohibitive training and inference
times because they are based on autoregressive models that generate audio
samples one at a time at a rate of 16kHz. In this work, we study the more
computationally efficient alternative of generating the waveform frame-by-frame
with large strides. We present SING, a lightweight neural audio synthesizer for
the original task of generating musical notes given desired instrument, pitch
and velocity. Our model is trained end-to-end to generate notes from nearly
1000 instruments with a single decoder, thanks to a new loss function that
minimizes the distances between the log spectrograms of the generated and
target waveforms. On the generalization task of synthesizing notes for pairs of
pitch and instrument not seen during training, SING produces audio with
significantly improved perceptual quality compared to a state-of-the-art
autoencoder based on WaveNet as measured by a Mean Opinion Score (MOS), and is
about 32 times faster for training and 2, 500 times faster for inference.
",Cybersecurity
"  In this paper, we consider the problems for covering multiple intervals on a
line. Given a set $B$ of $m$ line segments (called ""barriers"") on a horizontal
line $L$ and another set $S$ of $n$ horizontal line segments of the same length
in the plane, we want to move all segments of $S$ to $L$ so that their union
covers all barriers and the maximum movement of all segments of $S$ is
minimized. Previously, an $O(n^3\log n)$-time algorithm was given for the case
$m=1$. In this paper, we propose an $O(n^2\log n\log \log n+nm\log m)$-time
algorithm for a more general setting with any $m\geq 1$, which also improves
the previous work when $m=1$. We then consider a line-constrained version of
the problem in which the segments of $S$ are all initially on the line $L$.
Previously, an $O(n\log n)$-time algorithm was known for the case $m=1$. We
present an algorithm of $O(m\log m+n\log m \log n)$ time for any $m\geq 1$.
These problems may have applications in mobile sensor barrier coverage in
wireless sensor networks.
",Cybersecurity
"  Geospatial semantics is a broad field that involves a variety of research
areas. The term semantics refers to the meaning of things, and is in contrast
with the term syntactics. Accordingly, studies on geospatial semantics usually
focus on understanding the meaning of geographic entities as well as their
counterparts in the cognitive and digital world, such as cognitive geographic
concepts and digital gazetteers. Geospatial semantics can also facilitate the
design of geographic information systems (GIS) by enhancing the
interoperability of distributed systems and developing more intelligent
interfaces for user interactions. During the past years, a lot of research has
been conducted, approaching geospatial semantics from different perspectives,
using a variety of methods, and targeting different problems. Meanwhile, the
arrival of big geo data, especially the large amount of unstructured text data
on the Web, and the fast development of natural language processing methods
enable new research directions in geospatial semantics. This chapter,
therefore, provides a systematic review on the existing geospatial semantic
research. Six major research areas are identified and discussed, including
semantic interoperability, digital gazetteers, geographic information
retrieval, geospatial Semantic Web, place semantics, and cognitive geographic
concepts.
",Cybersecurity
"  We develop an assume-guarantee contract framework for the design of
cyber-physical systems, modeled as closed-loop control systems, under
probabilistic requirements. We use a variant of signal temporal logic, namely,
Stochastic Signal Temporal Logic (StSTL) to specify system behaviors as well as
contract assumptions and guarantees, thus enabling automatic reasoning about
requirements of stochastic systems. Given a stochastic linear system
representation and a set of requirements captured by bounded StSTL contracts,
we propose algorithms that can check contract compatibility, consistency, and
refinement, and generate a controller to guarantee that a contract is
satisfied, following a stochastic model predictive control approach. Our
algorithms leverage encodings of the verification and control synthesis tasks
into mixed integer optimization problems, and conservative approximations of
probabilistic constraints that produce both sound and tractable problem
formulations. We illustrate the effectiveness of our approach on a few
examples, including the design of embedded controllers for aircraft power
distribution networks.
",Cybersecurity
"  This work describes the development of a high-resolution tactile-sensing
finger for robot grasping. This finger, inspired by previous GelSight sensing
techniques, features an integration that is slimmer, more robust, and with more
homogeneous output than previous vision-based tactile sensors. To achieve a
compact integration, we redesign the optical path from illumination source to
camera by combining light guides and an arrangement of mirror reflections. We
parameterize the optical path with geometric design variables and describe the
tradeoffs between the finger thickness, the depth of field of the camera, and
the size of the tactile sensing area. The sensor sustains the wear from
continuous use -- and abuse -- in grasping tasks by combining tougher materials
for the compliant soft gel, a textured fabric skin, a structurally rigid body,
and a calibration process that maintains homogeneous illumination and contrast
of the tactile images during use. Finally, we evaluate the sensor's durability
along four metrics that track the signal quality during more than 3000 grasping
experiments.
",Cybersecurity
"  Based on 13 agile transformation cases over 15 years, this article identifies
nine challenges associated with implementing SAFe, Scrum-at-Scale, Spotify,
LeSS, Nexus, and other mixed or customised large-scale agile frameworks. These
challenges should be considered by organizations aspiring to pursue a
large-scale agile strategy. This article also provides recommendations for
practitioners and agile researchers.
",Cybersecurity
"  Targeted attacks against network infrastructure are notoriously difficult to
guard against. In the case of communication networks, such attacks can leave
users vulnerable to censorship and surveillance, even when cryptography is
used. Much of the existing work on network fault-tolerance focuses on random
faults and does not apply to adversarial faults (attacks). Centralized networks
have single points of failure by definition, leading to a growing popularity in
decentralized architectures and protocols for greater fault-tolerance. However,
centralized network structure can arise even when protocols are decentralized.
Despite their decentralized protocols, the Internet and World-Wide Web have
been shown both theoretically and historically to be highly susceptible to
attack, in part due to emergent structural centralization. When single points
of failure exist, they are potentially vulnerable to non-technological (i.e.,
coercive) attacks, suggesting the importance of a structural approach to
attack-tolerance. We show how the assumption of partial trust transitivity,
while more realistic than the assumption underlying webs of trust, can be used
to quantify the effective redundancy of a network as a function of trust
transitivity. We also prove that the effective redundancy of the wrap-around
butterfly topology increases exponentially with trust transitivity and describe
a novel concurrent multipath routing algorithm for constructing paths to
utilize that redundancy. When portions of network structure can be dictated our
results can be used to create scalable, attack-tolerant infrastructures. More
generally, our results provide a theoretical formalism for evaluating the
effects of network structure on adversarial fault-tolerance.
",Cybersecurity
"  Exploratory testing is neither black nor white, but rather a continuum of
exploration exists. In this research we propose an approach for decision
support helping practitioners to distribute time between different degrees of
exploratory testing on that continuum. To make the continuum manageable, five
levels have been defined: freestyle testing, high, medium and low degrees of
exploration, and scripted testing. The decision support approach is based on
the repertory grid technique. The approach has been used in one company. The
method for data collection was focus groups. The results showed that the
proposed approach aids practitioners in the reflection of what exploratory
testing levels to use, and aligns their understanding for priorities of
decision criteria and the performance of exploratory testing levels in their
contexts. The findings also showed that the participating company, which is
currently conducting mostly scripted testing, should spend more time on testing
using higher degrees of exploration in comparison to scripted testing.
",Cybersecurity
"  Self-admitted technical debt refers to situations where a software developer
knows that their current implementation is not optimal and indicates this using
a source code comment. In this work, we hypothesize that it is possible to
develop automated techniques to understand a subset of these comments in more
detail, and to propose tool support that can help developers manage
self-admitted technical debt more effectively. Based on a qualitative study of
335 comments indicating self-admitted technical debt, we first identify one
particular class of debt amenable to automated management: ""on-hold""
self-admitted technical debt, i.e., debt which contains a condition to indicate
that a developer is waiting for a certain event or an updated functionality
having been implemented elsewhere. We then design and evaluate an automated
classifier which can automatically identify these ""on-hold"" instances with a
precision of 0.81 as well as detect the specific conditions that developers are
waiting for. Our work presents a first step towards automated tool support that
is able to indicate when certain instances of self-admitted technical debt are
ready to be addressed.
",Cybersecurity
"  The ever-increasing architectural complexity in contemporary ASIC projects
turns Design Verification (DV) into a highly advanced endeavor. Pressing needs
for short time-to-market has made automation a key solution in DV. However,
recurring execution of large regression suites inevitably leads to challenging
amounts of test results. Following the design science paradigm, we present an
action research study to introduce visual analytics in a commercial ASIC
project. We develop a cityscape visualization tool using the game engine Unity.
Initial evaluations are promising, suggesting that the tool offers a novel
approach to identify error-prone parts of the design, as well as coverage
holes.
",Cybersecurity
"  Security is a critical and vital task in wireless sensor networks, therefore
different key management systems have been proposed, many of which are based on
symmetric cryptography. Such systems are very energy efficient, but they lack
some other desirable characteristics. On the other hand, systems based on
public key cryptography have those desirable characteristics, but they consume
more energy. Recently based on authenticated messages from base station a new
PKC based key agreement protocol was proposed. We show this method is
susceptible to a form of denial of service attack where resources of the
network can be exhausted with bogus messages. Then, we propose two different
improvements to solve this vulnerability. Simulation results show that these
new protocols retain desirable characteristics of the basic method and solve
its deficiencies.
",Cybersecurity
"  We present simple deterministic algorithms for subgraph finding and
enumeration in the broadcast CONGEST model of distributed computation:
-- For any constant $k$, detecting $k$-paths and trees on $k$ nodes can be
done in $O(1)$ rounds.
-- For any constant $k$, detecting $k$-cycles and pseudotrees on $k$ nodes
can be done in $O(n)$ rounds.
-- On $d$-degenerate graphs, cliques and $4$-cycles can be enumerated in $O(d
+ \log n)$ rounds, and $5$-cycles in $O(d^2 + \log n)$ rounds.
In many cases, these bounds are tight up to logarithmic factors. Moreover, we
show that the algorithms for $d$-degenerate graphs can be improved to optimal
complexity $O(d/\log n)$ and $O(d^2/\log n)$, respectively, in the supported
CONGEST model, which can be seen as an intermediate model between CONGEST and
the congested clique.
",Cybersecurity
"  We consider the problem of detecting data races in program traces that have
been compressed using straight line programs (SLP), which are special
context-free grammars that generate exactly one string, namely the trace that
they represent. We consider two classical approaches to race detection ---
using the happens-before relation and the lockset discipline. We present
algorithms for both these methods that run in time that is linear in the size
of the compressed, SLP representation. Typical program executions almost always
exhibit patterns that lead to significant compression. Thus, our algorithms are
expected to result in large speedups when compared with analyzing the
uncompressed trace. Our experimental evaluation of these new algorithms on
standard benchmarks confirms this observation.
",Cybersecurity
"  This paper represents a systematic way for generation of Aaria, a simulated
model for serial manipulators for the purpose of kinematic or dynamic analysis
with a vast variety of structures based on Simulink SimMechanics. The proposed
model can receive configuration parameters, for instance in accordance with
modified Denavit-Hartenberg convention, or trajectories for its base or joints
for structures with 1 to 6 degrees of freedom (DOF). The manipulator is
equipped with artificial joint sensors as well as simulated Inertial
Measurement Units (IMUs) on each link. The simulation output can be positions,
velocities, torques, in the joint space or IMU outputs; angular velocity,
linear acceleration, tool coordinates with respect to the inertial frame. This
simulation model is a source of a dataset for virtual multimodal sensory data
for automation of robot modeling and control designed for machine learning and
deep learning approaches based on big data.
",Cybersecurity
"  We propose NOPOL, an approach to automatic repair of buggy conditional
statements (i.e., if-then-else statements). This approach takes a buggy program
as well as a test suite as input and generates a patch with a conditional
expression as output. The test suite is required to contain passing test cases
to model the expected behavior of the program and at least one failing test
case that reveals the bug to be repaired. The process of NOPOL consists of
three major phases. First, NOPOL employs angelic fix localization to identify
expected values of a condition during the test execution. Second, runtime trace
collection is used to collect variables and their actual values, including
primitive data types and objected-oriented features (e.g., nullness checks), to
serve as building blocks for patch generation. Third, NOPOL encodes these
collected data into an instance of a Satisfiability Modulo Theory (SMT)
problem, then a feasible solution to the SMT instance is translated back into a
code patch. We evaluate NOPOL on 22 real-world bugs (16 bugs with buggy IF
conditions and 6 bugs with missing preconditions) on two large open-source
projects, namely Apache Commons Math and Apache Commons Lang. Empirical
analysis on these bugs shows that our approach can effectively fix bugs with
buggy IF conditions and missing preconditions. We illustrate the capabilities
and limitations of NOPOL using case studies of real bug fixes.
",Cybersecurity
"  With the availability of more powerful computers, iterative reconstruction
algorithms are the subject of an ongoing work in the design of more efficient
reconstruction algorithms for X-ray computed tomography. In this work, we show
how two analytical reconstruction algorithms can be improved by correcting the
corresponding reconstructions using a randomized iterative reconstruction
algorithm. The combined analytical reconstruction followed by randomized
iterative reconstruction can also be viewed as a reconstruction algorithm
which, in the experiments we have conducted, uses up to $35\%$ less projection
angles as compared to the analytical reconstruction algorithms and produces the
same results in terms of quality of reconstruction, without increasing the
execution time significantly.
",Cybersecurity
"  Transfer learning has the potential to reduce the burden of data collection
and to decrease the unavoidable risks of the training phase. In this letter, we
introduce a multirobot, multitask transfer learning framework that allows a
system to complete a task by learning from a few demonstrations of another task
executed on another system. We focus on the trajectory tracking problem where
each trajectory represents a different task, since many robotic tasks can be
described as a trajectory tracking problem. The proposed multirobot transfer
learning framework is based on a combined $\mathcal{L}_1$ adaptive control and
an iterative learning control approach. The key idea is that the adaptive
controller forces dynamically different systems to behave as a specified
reference model. The proposed multitask transfer learning framework uses
theoretical control results (e.g., the concept of vector relative degree) to
learn a map from desired trajectories to the inputs that make the system track
these trajectories with high accuracy. This map is used to calculate the inputs
for a new, unseen trajectory. Experimental results using two different
quadrotor platforms and six different trajectories show that, on average, the
proposed framework reduces the first-iteration tracking error by 74% when
information from tracking a different single trajectory on a different
quadrotor is utilized.
",Cybersecurity
"  In this paper, we address the problem of spatio-temporal person retrieval
from multiple videos using a natural language query, in which we output a tube
(i.e., a sequence of bounding boxes) which encloses the person described by the
query. For this problem, we introduce a novel dataset consisting of videos
containing people annotated with bounding boxes for each second and with five
natural language descriptions. To retrieve the tube of the person described by
a given natural language query, we design a model that combines methods for
spatio-temporal human detection and multimodal retrieval. We conduct
comprehensive experiments to compare a variety of tube and text representations
and multimodal retrieval methods, and present a strong baseline in this task as
well as demonstrate the efficacy of our tube representation and multimodal
feature embedding technique. Finally, we demonstrate the versatility of our
model by applying it to two other important tasks.
",Cybersecurity
"  Robots have the potential to assist people in bed, such as in healthcare
settings, yet bedding materials like sheets and blankets can make observation
of the human body difficult for robots. A pressure-sensing mat on a bed can
provide pressure images that are relatively insensitive to bedding materials.
However, prior work on estimating human pose from pressure images has been
restricted to 2D pose estimates and flat beds. In this work, we present two
convolutional neural networks to estimate the 3D joint positions of a person in
a configurable bed from a single pressure image. The first network directly
outputs 3D joint positions, while the second outputs a kinematic model that
includes estimated joint angles and limb lengths. We evaluated our networks on
data from 17 human participants with two bed configurations: supine and seated.
Our networks achieved a mean joint position error of 77 mm when tested with
data from people outside the training set, outperforming several baselines. We
also present a simple mechanical model that provides insight into ambiguity
associated with limbs raised off of the pressure mat, and demonstrate that
Monte Carlo dropout can be used to estimate pose confidence in these
situations. Finally, we provide a demonstration in which a mobile manipulator
uses our network's estimated kinematic model to reach a location on a person's
body in spite of the person being seated in a bed and covered by a blanket.
",Cybersecurity
"  We present three new semi-Lagrangian methods based on radial basis function
(RBF) interpolation for numerically simulating transport on a sphere. The
methods are mesh-free and are formulated entirely in Cartesian coordinates,
thus avoiding any irregular clustering of nodes at artificial boundaries on the
sphere and naturally bypassing any apparent artificial singularities associated
with surface-based coordinate systems. For problems involving tracer transport
in a given velocity field, the semi-Lagrangian framework allows these new
methods to avoid the use of any stabilization terms (such as hyperviscosity)
during time-integration, thus reducing the number of parameters that have to be
tuned. The three new methods are based on interpolation using 1) global RBFs,
2) local RBF stencils, and 3) RBF partition of unity. For the latter two of
these methods, we find that it is crucial to include some low degree spherical
harmonics in the interpolants. Standard test cases consisting of solid body
rotation and deformational flow are used to compare and contrast the methods in
terms of their accuracy, efficiency, conservation properties, and
dissipation/dispersion errors. For global RBFs, spectral spatial convergence is
observed for smooth solutions on quasi-uniform nodes, while high-order accuracy
is observed for the local RBF stencil and partition of unity approaches.
",Cybersecurity
"  The goal of this article is to clarify the meaning of Computational Thinking.
We differentiate logical from computational reasoning and discuss the
importance of Computational Thinking in solving problems. The three pillars of
Computational Thinking - Abstraction, Automation and Analysis - are outlined,
highlighting the role of each one in developing the skills needed for the
problem-solving process.
-----
O objetivo deste artigo é esclarecer o significado de Pensamento
Computacional. Diferencia-se o raciocínio lógico do computacional e
discute-se a importância do Pensamento Computacional na resolução de
problemas. Os três pilares do Pensamento Computacional - Abstração,
Automação e Análise - são delineados, destacando-se o papel de cada
um deles no desenvolvimento das habilidades necessárias para o processo de
solução de problemas.
",Cybersecurity
"  Ability to continuously learn and adapt from limited experience in
nonstationary environments is an important milestone on the path towards
general intelligence. In this paper, we cast the problem of continuous
adaptation into the learning-to-learn framework. We develop a simple
gradient-based meta-learning algorithm suitable for adaptation in dynamically
changing and adversarial scenarios. Additionally, we design a new multi-agent
competitive environment, RoboSumo, and define iterated adaptation games for
testing various aspects of continuous adaptation strategies. We demonstrate
that meta-learning enables significantly more efficient adaptation than
reactive baselines in the few-shot regime. Our experiments with a population of
agents that learn and compete suggest that meta-learners are the fittest.
",Cybersecurity
"  In this work, we aim at building a bridge from poor behavioral data to an
effective, quick-response, and robust behavior model for online identity theft
detection. We concentrate on this issue in online social networks (OSNs) where
users usually have composite behavioral records, consisting of
multi-dimensional low-quality data, e.g., offline check-ins and online user
generated content (UGC). As an insightful result, we find that there is a
complementary effect among different dimensions of records for modeling users'
behavioral patterns. To deeply exploit such a complementary effect, we propose
a joint model to capture both online and offline features of a user's composite
behavior. We evaluate the proposed joint model by comparing with some typical
models on two real-world datasets: Foursquare and Yelp. In the widely-used
setting of theft simulation (simulating thefts via behavioral replacement), the
experimental results show that our model outperforms the existing ones, with
the AUC values $0.956$ in Foursquare and $0.947$ in Yelp, respectively.
Particularly, the recall (True Positive Rate) can reach up to $65.3\%$ in
Foursquare and $72.2\%$ in Yelp with the corresponding disturbance rate (False
Positive Rate) below $1\%$. It is worth mentioning that these performances can
be achieved by examining only one composite behavior (visiting a place and
posting a tip online simultaneously) per authentication, which guarantees the
low response latency of our method. This study would give the cybersecurity
community new insights into whether and how a real-time online identity
authentication can be improved via modeling users' composite behavioral
patterns.
",Cybersecurity
"  We present a generative method to estimate 3D human motion and body shape
from monocular video. Under the assumption that starting from an initial pose
optical flow constrains subsequent human motion, we exploit flow to find
temporally coherent human poses of a motion sequence. We estimate human motion
by minimizing the difference between computed flow fields and the output of an
artificial flow renderer. A single initialization step is required to estimate
motion over multiple frames. Several regularization functions enhance
robustness over time. Our test scenarios demonstrate that optical flow
effectively regularizes the under-constrained problem of human shape and motion
estimation from monocular video.
",Cybersecurity
"  This paper describes a new modelling language for the effective design and
validation of Java annotations. Since their inclusion in the 5th edition of
Java, annotations have grown from a useful tool for the addition of meta-data
to play a central role in many popular software projects. Usually they are not
conceived in isolation, but in groups, with dependency and integrity
constraints between them. However, the native support provided by Java for
expressing this design is very limited.
To overcome its deficiencies and make explicit the rich conceptual model
which lies behind a set of annotations, we propose a domain-specific modelling
language. The proposal has been implemented as an Eclipse plug-in, including an
editor and an integrated code generator that synthesises annotation processors.
The environment also integrates a model finder, able to detect unsatisfiable
constraints between different annotations, and to provide examples of correct
annotation usages for validation. The language has been tested using a real set
of annotations from the Java Persistence API (JPA). Within this subset we have
found enough rich semantics expressible with Ann and omitted nowadays by the
Java language, which shows the benefits of Ann in a relevant field of
application.
",Cybersecurity
"  In this paper, we present a system that associates faces with voices in a
video by fusing information from the audio and visual signals. The thesis
underlying our work is that an extremely simple approach to generating (weak)
speech clusters can be combined with visual signals to effectively associate
faces and voices by aggregating statistics across a video. This approach does
not need any training data specific to this task and leverages the natural
coherence of information in the audio and visual streams. It is particularly
applicable to tracking speakers in videos on the web where a priori information
about the environment (e.g., number of speakers, spatial signals for
beamforming) is not available. We performed experiments on a real-world dataset
using this analysis framework to determine the speaker in a video. Given a
ground truth labeling determined by human rater consensus, our approach had
~71% accuracy.
",Cybersecurity
"  Network embedding methods aim at learning low-dimensional latent
representation of nodes in a network. While achieving competitive performance
on a variety of network inference tasks such as node classification and link
prediction, these methods treat the relations between nodes as a binary
variable and ignore the rich semantics of edges. In this work, we attempt to
learn network embeddings which simultaneously preserve network structure and
relations between nodes. Experiments on several real-world networks illustrate
that by considering different relations between different node pairs, our
method is capable of producing node embeddings of higher quality than a number
of state-of-the-art network embedding methods, as evaluated on a challenging
multi-label node classification task.
",Cybersecurity
"  The need to efficiently calculate first- and higher-order derivatives of
increasingly complex models expressed in Python has stressed or exceeded the
capabilities of available tools. In this work, we explore techniques from the
field of automatic differentiation (AD) that can give researchers expressive
power, performance and strong usability. These include source-code
transformation (SCT), flexible gradient surgery, efficient in-place array
operations, higher-order derivatives as well as mixing of forward and reverse
mode AD. We implement and demonstrate these ideas in the Tangent software
library for Python, the first AD framework for a dynamic language that uses
SCT.
",Cybersecurity
"  In many modern machine learning applications, structures of underlying
mathematical models often yield nonconvex optimization problems. Due to the
intractability of nonconvexity, there is a rising need to develop efficient
methods for solving general nonconvex problems with certain performance
guarantee. In this work, we investigate the accelerated proximal gradient
method for nonconvex programming (APGnc). The method compares between a usual
proximal gradient step and a linear extrapolation step, and accepts the one
that has a lower function value to achieve a monotonic decrease. In specific,
under a general nonsmooth and nonconvex setting, we provide a rigorous argument
to show that the limit points of the sequence generated by APGnc are critical
points of the objective function. Then, by exploiting the
Kurdyka-{\L}ojasiewicz (\KL) property for a broad class of functions, we
establish the linear and sub-linear convergence rates of the function value
sequence generated by APGnc. We further propose a stochastic variance reduced
APGnc (SVRG-APGnc), and establish its linear convergence under a special case
of the \KL property. We also extend the analysis to the inexact version of
these methods and develop an adaptive momentum strategy that improves the
numerical performance.
",Cybersecurity
"  Precise trajectory control near ground is difficult for multi-rotor drones,
due to the complex ground effects caused by interactions between multi-rotor
airflow and the environment. Conventional control methods often fail to
properly account for these complex effects and fall short in accomplishing
smooth landing. In this paper, we present a novel deep-learning-based robust
nonlinear controller (Neural-Lander) that improves control performance of a
quadrotor during landing. Our approach blends together a nominal dynamics model
coupled with a Deep Neural Network (DNN) that learns the high-order
interactions. We employ a novel application of spectral normalization to
constrain the DNN to have bounded Lipschitz behavior. Leveraging this Lipschitz
property, we design a nonlinear feedback linearization controller using the
learned model and prove system stability with disturbance rejection. To the
best of our knowledge, this is the first DNN-based nonlinear feedback
controller with stability guarantees that can utilize arbitrarily large neural
nets. Experimental results demonstrate that the proposed controller
significantly outperforms a baseline linear proportional-derivative (PD)
controller in both 1D and 3D landing cases. In particular, we show that
compared to the PD controller, Neural-Lander can decrease error in z direction
from 0.13m to zero, and mitigate average x and y drifts by 90% and 34%
respectively, in 1D landing. Meanwhile, Neural-Lander can decrease z error from
0.12m to zero, in 3D landing. We also empirically show that the DNN generalizes
well to new test inputs outside the training domain.
",Cybersecurity
"  For accommodating more electric vehicles (EVs) to battle against fossil fuel
emission, the problem of charging station placement is inevitable and could be
costly if done improperly. Some researches consider a general setup, using
conditions such as driving ranges for planning. However, most of the EV growths
in the next decades will happen in the urban area, where driving ranges is not
the biggest concern. For such a need, we consider several practical aspects of
urban systems, such as voltage regulation cost and protection device upgrade
resulting from the large integration of EVs. Notably, our diversified objective
can reveal the trade-off between different factors in different cities
worldwide. To understand the global optimum of large-scale analysis, we add
constraint one-by-one to see how to preserve the problem convexity. Our
sensitivity analysis before and after convexification shows that our approach
is not only universally applicable but also has a small approximation error for
prioritizing the most urgent constraint in a specific setup. Finally, numerical
results demonstrate the trade-off, the relationship between different factors
and the global objective, and the small approximation error. A unique
observation in this study shows the importance of incorporating the protection
device upgrade in urban system planning on charging stations.
",Cybersecurity
"  Graph drawings are useful tools for exploring the structure and dynamics of
data that can be represented by pair-wise relationships among a set of objects.
Typical real-world social, biological or technological networks exhibit high
complexity resulting from a large number and broad heterogeneity of objects and
relationships. Thus, mapping these networks into a low-dimensional space to
visualize the dynamics of network-driven processes is a challenging task. Often
we want to analyze how a single node is influenced by or is influencing its
local network as the source of a spreading process. Here I present a network
layout algorithm for graphs with millions of nodes that visualizes spreading
phenomena from the perspective of a single node. The algorithm consists of
three stages to allow for an interactive graph exploration: First, a global
solution for the network layout is found in spherical space that minimizes
distance errors between all nodes. Second, a focal node is interactively
selected, and distances to this node are further optimized. Third, node
coordinates are mapped to a circular representation and drawn with additional
features to represent the network-driven phenomenon. The effectiveness and
scalability of this method are shown for a large collaboration network of
scientists, where we are interested in the citation dynamics around a focal
author.
",Cybersecurity
"  Person re-identification (Re-ID) usually suffers from noisy samples with
background clutter and mutual occlusion, which makes it extremely difficult to
distinguish different individuals across the disjoint camera views. In this
paper, we propose a novel deep self-paced learning (DSPL) algorithm to
alleviate this problem, in which we apply a self-paced constraint and symmetric
regularization to help the relative distance metric training the deep neural
network, so as to learn the stable and discriminative features for person
Re-ID. Firstly, we propose a soft polynomial regularizer term which can derive
the adaptive weights to samples based on both the training loss and model age.
As a result, the high-confidence fidelity samples will be emphasized and the
low-confidence noisy samples will be suppressed at early stage of the whole
training process. Such a learning regime is naturally implemented under a
self-paced learning (SPL) framework, in which samples weights are adaptively
updated based on both model age and sample loss using an alternative
optimization method. Secondly, we introduce a symmetric regularizer term to
revise the asymmetric gradient back-propagation derived by the relative
distance metric, so as to simultaneously minimize the intra-class distance and
maximize the inter-class distance in each triplet unit. Finally, we build a
part-based deep neural network, in which the features of different body parts
are first discriminately learned in the lower convolutional layers and then
fused in the higher fully connected layers. Experiments on several benchmark
datasets have demonstrated the superior performance of our method as compared
with the state-of-the-art approaches.
",Cybersecurity
"  Scholarly communication has the scope to transcend the limitations of the
physical world through social media extended coverage and shortened information
paths. Accordingly, publishers have created profiles for their journals in
Twitter to promote their publications and to initiate discussions with public.
This paper investigates the Twitter presence of humanities and social sciences
(HSS) journal titles obtained from mainstream citation indices, by analysing
the interaction and communication patterns. This study utilizes webometric data
collection, descriptive analysis, and social network analysis. Findings
indicate that the presence of HSS journals in Twitter across disciplines is not
yet substantial. Sharing of general websites appears to be the key activity
performed by HSS journals in Twitter. Among them, web content from news portals
and magazines are highly disseminated. Sharing of research articles and
retweeting was not majorly observed. Inter-journal communication is apparent
within the same citation index, but it is very minimal with journals from the
other index. However, there seems to be an effort to broaden communication
beyond the research community, reaching out to connect with the public.
",Cybersecurity
"  We propose a novel deep learning architecture for regressing disparity from a
rectified pair of stereo images. We leverage knowledge of the problem's
geometry to form a cost volume using deep feature representations. We learn to
incorporate contextual information using 3-D convolutions over this volume.
Disparity values are regressed from the cost volume using a proposed
differentiable soft argmin operation, which allows us to train our method
end-to-end to sub-pixel accuracy without any additional post-processing or
regularization. We evaluate our method on the Scene Flow and KITTI datasets and
on KITTI we set a new state-of-the-art benchmark, while being significantly
faster than competing approaches.
",Cybersecurity
"  Autonomous robots increasingly depend on third-party off-the-shelf components
and complex machine-learning techniques. This trend makes it challenging to
provide strong design-time certification of correct operation. To address this
challenge, we present SOTER, a programming framework that integrates the core
principles of runtime assurance to enable the use of uncertified controllers,
while still providing safety guarantees.
Runtime Assurance (RTA) is an approach used for safety-critical systems where
design-time analysis is coupled with run-time techniques to switch between
unverified advanced controllers and verified simple controllers. In this paper,
we present a runtime assurance programming framework for modular design of
provably-safe robotics software. \tool provides language primitives to
declaratively construct a \rta module consisting of an advanced controller
(untrusted), a safe controller (trusted), and the desired safety specification
(S). If the RTA module is well formed then the framework provides a formal
guarantee that it satisfies property S. The compiler generates code for
monitoring system state and switching control between the advanced and safe
controller in order to guarantee S. RTA allows complex systems to be
constructed through the composition of RTA modules.
To demonstrate the efficacy of our framework, we consider a real-world
case-study of building a safe drone surveillance system. Our experiments both
in simulation and on actual drones show that RTA-enabled RTA ensures safety of
the system, including when untrusted third-party components have bugs or
deviate from the desired behavior.
",Cybersecurity
"  Speechreading is the task of inferring phonetic information from visually
observed articulatory facial movements, and is a notoriously difficult task for
humans to perform. In this paper we present an end-to-end model based on a
convolutional neural network (CNN) for generating an intelligible and
natural-sounding acoustic speech signal from silent video frames of a speaking
person. We train our model on speakers from the GRID and TCD-TIMIT datasets,
and evaluate the quality and intelligibility of reconstructed speech using
common objective measurements. We show that speech predictions from the
proposed model attain scores which indicate significantly improved quality over
existing models. In addition, we show promising results towards reconstructing
speech from an unconstrained dictionary.
",Cybersecurity
"  We propose a map-aided vehicle localization method for GPS-denied
environments. This approach exploits prior knowledge of the road grade map and
vehicle on-board sensor measurements to accurately estimate the longitudinal
position of the vehicle. Real-time localization is crucial to systems that
utilize position-dependent information for planning and control. We validate
the effectiveness of the localization method on a hierarchical control system.
The higher level planner optimizes the vehicle velocity to minimize the energy
consumption for a given route by employing traffic condition and road grade
data. The lower level is a cruise control system that tracks the
position-dependent optimal reference velocity. Performance of the proposed
localization algorithm is evaluated using both simulations and experiments.
",Cybersecurity
"  We investigate quantifier alternation hierarchies in first-order logic on
finite words. Levels in these hierarchies are defined by counting the number of
quantifier alternations in formulas. We prove that one can decide membership of
a regular language in the levels $\mathcal{B}{\Sigma}_2$ (finite boolean
combinations of formulas having only one alternation) and ${\Sigma}_3$
(formulas having only two alternations and beginning with an existential
block). Our proofs work by considering a deeper problem, called separation,
which, once solved for lower levels, allows us to solve membership for higher
levels.
",Cybersecurity
"  Partially Observable Markov Decision Process (POMDP) is widely used to model
probabilistic behavior for complex systems. Compared with MDPs, POMDP models a
system more accurate but solving a POMDP generally takes exponential time in
the size of its state space. This makes the formal verification and synthesis
problems much more challenging for POMDPs, especially when multiple system
components are involved. As a promising technique to reduce the verification
complexity, the abstraction method tries to find an abstract system with a
smaller state space but preserves enough properties for the verification
purpose. While abstraction based verification has been explored extensively for
MDPs, in this paper, we present the first result of POMDP abstraction and its
refinement techniques. The main idea follows the counterexample-guided
abstraction refinement (CEGAR) framework. Starting with a coarse guess for the
POMDP abstraction, we iteratively use counterexamples from formal verification
to refine the abstraction until the abstract system can be used to infer the
verification result for the original POMDP. Our main contributions have two
folds: 1) we propose a novel abstract system model for POMDP and a new
simulation relation to capture the partial observability then prove the
preservation on a fragment of Probabilistic Computation Tree Logic (PCTL); 2)
to find a proper abstract system that can prove or disprove the satisfaction
relation on the concrete POMDP, we develop a novel refinement algorithm. Our
work leads to a sound and complete CEGAR framework for POMDP.
",Cybersecurity
"  With the volume of manuscripts submitted for publication growing every year,
the deficiencies of peer review (e.g. long review times) are becoming more
apparent. Editorial strategies, sets of guidelines designed to speed up the
process and reduce editors workloads, are treated as trade secrets by
publishing houses and are not shared publicly. To improve the effectiveness of
their strategies, editors in small publishing groups are faced with undertaking
an iterative trial-and-error approach. We show that Cartesian Genetic
Programming, a nature-inspired evolutionary algorithm, can dramatically improve
editorial strategies. The artificially evolved strategy reduced the duration of
the peer review process by 30%, without increasing the pool of reviewers (in
comparison to a typical human-developed strategy). Evolutionary computation has
typically been used in technological processes or biological ecosystems. Our
results demonstrate that genetic programs can improve real-world social systems
that are usually much harder to understand and control than physical systems.
",Cybersecurity
"  The 3rd International Workshop on Overlay Architectures for FPGAs (OLAF 2017)
was held on 22 Feb, 2017 as a co-located workshop at the 25th ACM/SIGDA
International Symposium on Field-Programmable Gate Arrays (FPGA 2017). This
year, the program committee selected 3 papers and 3 extended abstracts to be
presented at the workshop, which are subsequently collected in this online
volume.
",Cybersecurity
"  Among underwater perceptual sensors, imaging sonar has been highlighted for
its perceptual robustness underwater. The major challenge of imaging sonar,
however, arises from the difficulty in defining visual features despite limited
resolution and high noise levels. Recent developments in deep learning provide
a powerful solution for computer-vision researches using optical images.
Unfortunately, deep learning-based approaches are not well established for
imaging sonars, mainly due to the scant data in the training phase. Unlike the
abundant publically available terrestrial images, obtaining underwater images
is often costly, and securing enough underwater images for training is not
straightforward. To tackle this issue, this paper presents a solution to this
field's lack of data by introducing a novel end-to-end image-synthesizing
method in the training image preparation phase. The proposed method present
image synthesizing scheme to the images captured by an underwater simulator.
Our synthetic images are based on the sonar imaging models and noisy
characteristics to represent the real data obtained from the sea. We validate
the proposed scheme by training using a simulator and by testing the simulated
images with real underwater sonar images obtained from a water tank and the
sea.
",Cybersecurity
"  Artificial Neural Network computation relies on intensive vector-matrix
multiplications. Recently, the emerging nonvolatile memory (NVM) crossbar array
showed a feasibility of implementing such operations with high energy
efficiency, thus there are many works on efficiently utilizing emerging NVM
crossbar array as analog vector-matrix multiplier. However, its nonlinear I-V
characteristics restrain critical design parameters, such as the read voltage
and weight range, resulting in substantial accuracy loss. In this paper,
instead of optimizing hardware parameters to a given neural network, we propose
a methodology of reconstructing a neural network itself optimized to resistive
memory crossbar arrays. To verify the validity of the proposed method, we
simulated various neural network with MNIST and CIFAR-10 dataset using two
different specific Resistive Random Access Memory (RRAM) model. Simulation
results show that our proposed neural network produces significantly higher
inference accuracies than conventional neural network when the synapse devices
have nonlinear I-V characteristics.
",Cybersecurity
"  The growing pressure on cloud application scalability has accentuated storage
performance as a critical bottle- neck. Although cache replacement algorithms
have been extensively studied, cache prefetching - reducing latency by
retrieving items before they are actually requested remains an underexplored
area. Existing approaches to history-based prefetching, in particular, provide
too few benefits for real systems for the resources they cost. We propose
MITHRIL, a prefetching layer that efficiently exploits historical patterns in
cache request associations. MITHRIL is inspired by sporadic association rule
mining and only relies on the timestamps of requests. Through evaluation of 135
block-storage traces, we show that MITHRIL is effective, giving an average of a
55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain
over AMP at reasonable cost. We further show that MITHRIL can supplement any
cache replacement algorithm and be readily integrated into existing systems.
Furthermore, we demonstrate the improvement comes from MITHRIL being able to
capture mid-frequency blocks.
",Cybersecurity
"  Virtual reality simulation is becoming popular as a training platform in
surgical education. However, one important aspect of simulation-based surgical
training that has not received much attention is the provision of automated
real-time performance feedback to support the learning process. Performance
feedback is actionable advice that improves novice behaviour. In simulation,
automated feedback is typically extracted from prediction models trained using
data mining techniques. Existing techniques suffer from either low
effectiveness or low efficiency resulting in their inability to be used in
real-time. In this paper, we propose a random forest based method that finds a
balance between effectiveness and efficiency. Experimental results in a
temporal bone surgery simulation show that the proposed method is able to
extract highly effective feedback at a high level of efficiency.
",Cybersecurity
"  Separating an audio scene into isolated sources is a fundamental problem in
computer audition, analogous to image segmentation in visual scene analysis.
Source separation systems based on deep learning are currently the most
successful approaches for solving the underdetermined separation problem, where
there are more sources than channels. Traditionally, such systems are trained
on sound mixtures where the ground truth decomposition is already known. Since
most real-world recordings do not have such a decomposition available, this
limits the range of mixtures one can train on, and the range of mixtures the
learned models may successfully separate. In this work, we use a simple blind
spatial source separation algorithm to generate estimated decompositions of
stereo mixtures. These estimates, together with a weighting scheme in the
time-frequency domain, based on confidence in the separation quality, are used
to train a deep learning model that can be used for single-channel separation,
where no source direction information is available. This demonstrates how a
simple cue such as the direction of origin of source can be used to bootstrap a
model for source separation that can be used in situations where that cue is
not available.
",Cybersecurity
"  Both hybrid automata and action languages are formalisms for describing the
evolution of dynamic systems. This paper establishes a formal relationship
between them. We show how to succinctly represent hybrid automata in an action
language which in turn is defined as a high-level notation for answer set
programming modulo theories (ASPMT) --- an extension of answer set programs to
the first-order level similar to the way satisfiability modulo theories (SMT)
extends propositional satisfiability (SAT). We first show how to represent
linear hybrid automata with convex invariants by an action language modulo
theories. A further translation into SMT allows for computing them using SMT
solvers that support arithmetic over reals. Next, we extend the representation
to the general class of non-linear hybrid automata allowing even non-convex
invariants. We represent them by an action language modulo ODE (Ordinary
Differential Equations), which can be compiled into satisfiability modulo ODE.
We developed a prototype system cplus2aspmt based on these translations, which
allows for a succinct representation of hybrid transition systems that can be
computed effectively by the state-of-the-art SMT solver dReal.
",Cybersecurity
"  Diffusions and related random walk procedures are of central importance in
many areas of machine learning, data analysis, and applied mathematics. Because
they spread mass agnostically at each step in an iterative manner, they can
sometimes spread mass ""too aggressively,"" thereby failing to find the ""right""
clusters. We introduce a novel Capacity Releasing Diffusion (CRD) Process,
which is both faster and stays more local than the classical spectral diffusion
process. As an application, we use our CRD Process to develop an improved local
algorithm for graph clustering. Our local graph clustering method can find
local clusters in a model of clustering where one begins the CRD Process in a
cluster whose vertices are connected better internally than externally by an
$O(\log^2 n)$ factor, where $n$ is the number of nodes in the cluster. Thus,
our CRD Process is the first local graph clustering algorithm that is not
subject to the well-known quadratic Cheeger barrier. Our result requires a
certain smoothness condition, which we expect to be an artifact of our
analysis. Our empirical evaluation demonstrates improved results, in particular
for realistic social graphs where there are moderately good---but not very
good---clusters.
",Cybersecurity
"  In this study, we examine a collection of health-related news articles
published by reliable and unreliable media outlets. Our analysis shows that
there are structural, topical, and semantic differences in the way reliable and
unreliable media outlets conduct health journalism. We argue that the findings
from this study will be useful for combating health disinformation problem.
",Cybersecurity
"  Widespread use of social media has led to the generation of substantial
amounts of information about individuals, including health-related information.
Social media provides the opportunity to study health-related information about
selected population groups who may be of interest for a particular study. In
this paper, we explore the possibility of utilizing social media to perform
targeted data collection and analysis from a particular population group --
pregnant women. We hypothesize that we can use social media to identify cohorts
of pregnant women and follow them over time to analyze crucial health-related
information. To identify potentially pregnant women, we employ simple
rule-based searches that attempt to detect pregnancy announcements with
moderate precision. To further filter out false positives and noise, we employ
a supervised classifier using a small number of hand-annotated data. We then
collect their posts over time to create longitudinal health timelines and
attempt to divide the timelines into different pregnancy trimesters. Finally,
we assess the usefulness of the timelines by performing a preliminary analysis
to estimate drug intake patterns of our cohort at different trimesters. Our
rule-based cohort identification technique collected 53,820 users over thirty
months from Twitter. Our pregnancy announcement classification technique
achieved an F-measure of 0.81 for the pregnancy class, resulting in 34,895 user
timelines. Analysis of the timelines revealed that pertinent health-related
information, such as drug-intake and adverse reactions can be mined from the
data. Our approach to using user timelines in this fashion has produced very
encouraging results and can be employed for other important tasks where
cohorts, for which health-related information may not be available from other
sources, are required to be followed over time to derive population-based
estimates.
",Cybersecurity
"  Friendship and antipathy exist in concert with one another in real social
networks. Despite the role they play in social interactions, antagonistic ties
are poorly understood and infrequently measured. One important theory of
negative ties that has received relatively little empirical evaluation is
balance theory, the codification of the adage `the enemy of my enemy is my
friend' and similar sayings. Unbalanced triangles are those with an odd number
of negative ties, and the theory posits that such triangles are rare. To test
for balance, previous works have utilized a permutation test on the edge signs.
The flaw in this method, however, is that it assumes that negative and positive
edges are interchangeable. In reality, they could not be more different. Here,
we propose a novel test of balance that accounts for this discrepancy and show
that our test is more accurate at detecting balance. Along the way, we prove
asymptotic normality of the test statistic under our null model, which is of
independent interest. Our case study is a novel dataset of signed networks we
collected from 32 isolated, rural villages in Honduras. Contrary to previous
results, we find that there is only marginal evidence for balance in social tie
formation in this setting.
",Cybersecurity
"  We introduce a novel approach to Maximum A Posteriori inference based on
discrete graphical models. By utilizing local Wasserstein distances for
coupling assignment measures across edges of the underlying graph, a given
discrete objective function is smoothly approximated and restricted to the
assignment manifold. A corresponding multiplicative update scheme combines in a
single process (i) geometric integration of the resulting Riemannian gradient
flow and (ii) rounding to integral solutions that represent valid labelings.
Throughout this process, local marginalization constraints known from the
established LP relaxation are satisfied, whereas the smooth geometric setting
results in rapidly converging iterations that can be carried out in parallel
for every edge.
",Cybersecurity
"  Elasticity is a cloud property that enables applications and its execution
systems to dynamically acquire and release shared computational resources on
demand. Moreover, it unfolds the advantage of economies of scale in the cloud
through a drop in the average costs of these shared resources. However, it is
still an open challenge to achieve a perfect match between resource demand and
provision in autonomous elasticity management. Resource adaptation decisions
essentially involve a trade-off between economics and performance, which
produces a gap between the ideal and actual resource provisioning. This gap, if
not properly managed, can negatively impact the aggregate utility of a cloud
customer in the long run. To address this limitation, we propose a technical
debt-aware learning approach for autonomous elasticity management based on a
reinforcement learning of elasticity debts in resource provisioning; the
adaptation pursues strategic decisions that trades off economics against
performance. We extend CloudSim and Burlap to evaluate our approach. The
evaluation shows that a reinforcement learning of technical debts in elasticity
obtains a higher utility for a cloud customer, while conforming expected levels
of performance.
",Cybersecurity
"  This work develops techniques for the sequential detection and location
estimation of transient changes in the volatility (standard deviation) of time
series data. In particular, we introduce a class of change detection algorithms
based on the windowed volatility filter. The first method detects changes by
employing a convex combination of two such filters with differing window sizes,
such that the adaptively updated convex weight parameter is then used as an
indicator for the detection of instantaneous power changes. Moreover, the
proposed adaptive filtering based method is readily extended to the
multivariate case by using recent advances in distributed adaptive filters,
thereby using cooperation between the data channels for more effective
detection of change points. Furthermore, this work also develops a novel change
point location estimator based on the differenced output of the volatility
filter. Finally, the performance of the proposed methods were evaluated on both
synthetic and real world data.
",Cybersecurity
"  To efficiently answer queries, datalog systems often materialise all
consequences of a datalog program, so the materialisation must be updated
whenever the input facts change. Several solutions to the materialisation
update problem have been proposed. The Delete/Rederive (DRed) and the
Backward/Forward (B/F) algorithms solve this problem for general datalog, but
both contain steps that evaluate rules 'backwards' by matching their heads to a
fact and evaluating the partially instantiated rule bodies as queries. We show
that this can be a considerable source of overhead even on very small updates.
In contrast, the Counting algorithm does not evaluate the rules 'backwards',
but it can handle only nonrecursive rules. We present two hybrid approaches
that combine DRed and B/F with Counting so as to reduce or even eliminate
'backward' rule evaluation while still handling arbitrary datalog programs. We
show empirically that our hybrid algorithms are usually significantly faster
than existing approaches, sometimes by orders of magnitude.
",Cybersecurity
"  Previous research using evolutionary computation in Multi-Agent Systems
indicates that assigning fitness based on team vs.\ individual behavior has a
strong impact on the ability of evolved teams of artificial agents to exhibit
teamwork in challenging tasks. However, such research only made use of
single-objective evolution. In contrast, when a multiobjective evolutionary
algorithm is used, populations can be subject to individual-level objectives,
team-level objectives, or combinations of the two. This paper explores the
performance of cooperatively coevolved teams of agents controlled by artificial
neural networks subject to these types of objectives. Specifically, predator
agents are evolved to capture scripted prey agents in a torus-shaped grid
world. Because of the tension between individual and team behaviors, multiple
modes of behavior can be useful, and thus the effect of modular neural networks
is also explored. Results demonstrate that fitness rewarding individual
behavior is superior to fitness rewarding team behavior, despite being applied
to a cooperative task. However, the use of networks with multiple modules
allows predators to discover intelligent behavior, regardless of which type of
objectives are used.
",Cybersecurity
"  Gradient descent and coordinate descent are well understood in terms of their
asymptotic behavior, but less so in a transient regime often used for
approximations in machine learning. We investigate how proper initialization
can have a profound effect on finding near-optimal solutions quickly. We show
that a certain property of a data set, namely the boundedness of the
correlations between eigenfeatures and the response variable, can lead to
faster initial progress than expected by commonplace analysis. Convex
optimization problems can tacitly benefit from that, but this automatism does
not apply to their dual formulation. We analyze this phenomenon and devise
provably good initialization strategies for dual optimization as well as
heuristics for the non-convex case, relevant for deep learning. We find our
predictions and methods to be experimentally well-supported.
",Cybersecurity
"  The lack of diversity in a genetic algorithm's population may lead to a bad
performance of the genetic operators since there is not an equilibrium between
exploration and exploitation. In those cases, genetic algorithms present a fast
and unsuitable convergence.
In this paper we develop a novel hybrid genetic algorithm which attempts to
obtain a balance between exploration and exploitation. It confronts the
diversity problem using the named greedy diversification operator. Furthermore,
the proposed algorithm applies a competition between parent and children so as
to exploit the high quality visited solutions. These operators are complemented
by a simple selection mechanism designed to preserve and take advantage of the
population diversity.
Additionally, we extend our proposal to the field of memetic algorithms,
obtaining an improved model with outstanding results in practice.
The experimental study shows the validity of the approach as well as how
important is taking into account the exploration and exploitation concepts when
designing an evolutionary algorithm.
",Cybersecurity
"  We discuss different types of human-robot interaction paradigms in the
context of training end-to-end reinforcement learning algorithms. We provide a
taxonomy to categorize the types of human interaction and present our
Cycle-of-Learning framework for autonomous systems that combines different
human-interaction modalities with reinforcement learning. Two key concepts
provided by our Cycle-of-Learning framework are how it handles the integration
of the different human-interaction modalities (demonstration, intervention, and
evaluation) and how to define the switching criteria between them.
",Cybersecurity
"  A fundamental question in language learning concerns the role of a speaker's
first language in second language acquisition. We present a novel methodology
for studying this question: analysis of eye-movement patterns in second
language reading of free-form text. Using this methodology, we demonstrate for
the first time that the native language of English learners can be predicted
from their gaze fixations when reading English. We provide analysis of
classifier uncertainty and learned features, which indicates that differences
in English reading are likely to be rooted in linguistic divergences across
native languages. The presented framework complements production studies and
offers new ground for advancing research on multilingualism.
",Cybersecurity
"  The emergence of smart Wi-Fi APs (Access Point), which are equipped with huge
storage space, opens a new research area on how to utilize these resources at
the edge network to improve users' quality of experience (QoE) (e.g., a short
startup delay and smooth playback). One important research interest in this
area is content prefetching, which predicts and accurately fetches contents
ahead of users' requests to shift the traffic away during peak periods.
However, in practice, the different video watching patterns among users, and
the varying network connection status lead to the time-varying server load,
which eventually makes the content prefetching problem challenging. To
understand this challenge, this paper first performs a large-scale measurement
study on users' AP connection and TV series watching patterns using
real-traces. Then, based on the obtained insights, we formulate the content
prefetching problem as a Markov Decision Process (MDP). The objective is to
strike a balance between the increased prefetching&storage cost incurred by
incorrect prediction and the reduced content download delay because of
successful prediction. A learning-based approach is proposed to solve this
problem and another three algorithms are adopted as baselines. In particular,
first, we investigate the performance lower bound by using a random algorithm,
and the upper bound by using an ideal offline approach. Then, we present a
heuristic algorithm as another baseline. Finally, we design a reinforcement
learning algorithm that is more practical to work in the online manner. Through
extensive trace-based experiments, we demonstrate the performance gain of our
design. Remarkably, our learning-based algorithm achieves a better precision
and hit ratio (e.g., 80%) with about 70% (resp. 50%) cost saving compared to
the random (resp. heuristic) algorithm.
",Cybersecurity
"  This paper considers the problem of switching between two periodic motions,
also known as limit cycles, to create agile running motions. For each limit
cycle, we use a control Lyapunov function to estimate the region of attraction
at the apex of the flight phase. We switch controllers at the apex, only if the
current state of the robot is within the region of attraction of the subsequent
limit cycle. If the intersection between two limit cycles is the null set, then
we construct additional limit cycles till we are able to achieve sufficient
overlap of the region of attraction between sequential limit cycles.
Additionally, we impose an exponential convergence condition on the control
Lyapunov function that allows us to rapidly transition between limit cycles.
Using the approach we demonstrate switching between 5 limit cycles in about 5
steps with the speed changing from 2 m/s to 5 m/s.
",Cybersecurity
"  Symbolic computation is an important approach in automated program analysis.
Most state-of-the-art tools perform symbolic computation as interpreters and
directly maintain symbolic data. In this paper, we show that it is feasible,
and in fact practical, to use a compiler-based strategy instead. Using compiler
tooling, we propose and implement a transformation which takes a standard
program and outputs a program that performs semantically equivalent, but
partially symbolic, computation. The transformed program maintains symbolic
values internally and operates directly on them hence the program can be
processed by a tool without support for symbolic manipulation.
The main motivation for the transformation is in symbolic verification, but
there are many other possible use-cases, including test generation and concolic
testing. Moreover using the transformation simplifies tools, since the symbolic
computation is handled by the program directly. We have implemented the
transformation at the level of LLVM bitcode. The paper includes an experimental
evaluation, based on an explicit-state software model checker as a verification
backend.
",Cybersecurity
"  A promising research area that has recently emerged, is on how to use index
coding to improve the communication efficiency in distributed computing
systems, especially for data shuffling in iterative computations. In this
paper, we posit that pliable index coding can offer a more efficient framework
for data shuffling, as it can better leverage the many possible shuffling
choices to reduce the number of transmissions. We theoretically analyze pliable
index coding under data shuffling constraints, and design a hierarchical
data-shuffling scheme that uses pliable coding as a component. We find benefits
up to $O(ns/m)$ over index coding, where $ns/m$ is the average number of
workers caching a message, and $m$, $n$, and $s$ are the numbers of messages,
workers, and cache size, respectively.
",Cybersecurity
"  Given pairwise distinct vertices $\{\alpha_i , \beta_i\}^k_{i=1}$ of the
$n$-dimensional hypercube $Q_n$ such that the distance of $\alpha_i$ and
$\beta_i$ is odd, are there paths $P_i$ between $\alpha_i$ and $\beta_i$ such
that $\{V (P_i)\}^k_{i=1}$ partitions $V(Q_n)$? A positive solution for every
$n\ge1$ and $k=1$ is known as a Gray code of dimension $n$. In this paper we
settle this problem for small values of $n$.
",Cybersecurity
"  With applications to many disciplines, the traveling salesman problem (TSP)
is a classical computer science optimization problem with applications to
industrial engineering, theoretical computer science, bioinformatics, and
several other disciplines. In recent years, there have been a plethora of novel
approaches for approximate solutions ranging from simplistic greedy to
cooperative distributed algorithms derived from artificial intelligence. In
this paper, we perform an evaluation and analysis of cornerstone algorithms for
the Euclidean TSP. We evaluate greedy, 2-opt, and genetic algorithms. We use
several datasets as input for the algorithms including a small dataset, a
mediumsized dataset representing cities in the United States, and a synthetic
dataset consisting of 200 cities to test algorithm scalability. We discover
that the greedy and 2-opt algorithms efficiently calculate solutions for
smaller datasets. Genetic algorithm has the best performance for optimality for
medium to large datasets, but generally have longer runtime. Our
implementations is public available.
",Cybersecurity
"  Text password has long been the dominant user authentication technique and is
used by large numbers of Internet services. If they follow recommended
practice, users are faced with the almost insuperable problem of generating and
managing a large number of site-unique and strong (i.e. non-guessable)
passwords. One way of addressing this problem is through the use of a password
generator, i.e. a client-side scheme which generates (and regenerates)
site-specific strong passwords on demand, with the minimum of user input. This
paper provides a detailed specification and analysis of AutoPass, a password
generator scheme previously outlined as part of a general analysis of such
schemes. AutoPass has been designed to address issues identified in previously
proposed password generators, and incorporates novel techniques to address
these issues. Unlike almost all previously proposed schemes, AutoPass enables
the generation of passwords that meet important real-world requirements,
including forced password changes, use of pre-specified passwords, and
generation of passwords meeting site-specific requirements.
",Cybersecurity
"  A deep learning architecture is proposed to predict graspable locations for
robotic manipulation. It considers situations where no, one, or multiple
object(s) are seen. By defining the learning problem to be classification with
null hypothesis competition instead of regression, the deep neural network with
RGB-D image input predicts multiple grasp candidates for a single object or
multiple objects, in a single shot. The method outperforms state-of-the-art
approaches on the Cornell dataset with 96.0% and 96.1% accuracy on image-wise
and object- wise splits, respectively. Evaluation on a multi-object dataset
illustrates the generalization capability of the architecture. Grasping
experiments achieve 96.0% grasp localization and 88.0% grasping success rates
on a test set of household objects. The real-time process takes less than .25 s
from image to plan.
",Cybersecurity
"  Recent literature in the robotics community has focused on learning robot
behaviors that abstract out lower-level details of robot control. To fully
leverage the efficacy of such behaviors, it is necessary to select and sequence
them to achieve a given task. In this paper, we present an approach to both
learn and sequence robot behaviors, applied to the problem of visual navigation
of mobile robots. We construct a layered representation of control policies
composed of low- level behaviors and a meta-level policy. The low-level
behaviors enable the robot to locomote in a particular environment while
avoiding obstacles, and the meta-level policy actively selects the low-level
behavior most appropriate for the current situation based purely on visual
feedback. We demonstrate the effectiveness of our method on three simulated
robot navigation tasks: a legged hexapod robot which must successfully traverse
varying terrain, a wheeled robot which must navigate a maze-like course while
avoiding obstacles, and finally a wheeled robot navigating in the presence of
dynamic obstacles. We show that by learning control policies in a layered
manner, we gain the ability to successfully traverse new compound environments
composed of distinct sub-environments, and outperform both the low-level
behaviors in their respective sub-environments, as well as a hand-crafted
selection of low-level policies on these compound environments.
",Cybersecurity
"  In this work we formulate the problem of image captioning as a multimodal
translation task. Analogous to machine translation, we present a
sequence-to-sequence recurrent neural networks (RNN) model for image caption
generation. Different from most existing work where the whole image is
represented by convolutional neural network (CNN) feature, we propose to
represent the input image as a sequence of detected objects which feeds as the
source sequence of the RNN model. In this way, the sequential representation of
an image can be naturally translated to a sequence of words, as the target
sequence of the RNN model. To represent the image in a sequential way, we
extract the objects features in the image and arrange them in a order using
convolutional neural networks. To further leverage the visual information from
the encoded objects, a sequential attention layer is introduced to selectively
attend to the objects that are related to generate corresponding words in the
sentences. Extensive experiments are conducted to validate the proposed
approach on popular benchmark dataset, i.e., MS COCO, and the proposed model
surpasses the state-of-the-art methods in all metrics following the dataset
splits of previous work. The proposed approach is also evaluated by the
evaluation server of MS COCO captioning challenge, and achieves very
competitive results, e.g., a CIDEr of 1.029 (c5) and 1.064 (c40).
",Cybersecurity
"  The model-based control of building heating systems for energy saving
encounters severe physical, mathematical and calibration difficulties in the
numerous attempts that has been published until now. This topic is addressed
here via a new model-free control setting, where the need of any mathematical
description disappears. Several convincing computer simulations are presented.
Comparisons with classic PI controllers and flatness-based predictive control
are provided.
",Cybersecurity
"  Data cube materialization is a classical database operator introduced in Gray
et al.~(Data Mining and Knowledge Discovery, Vol.~1), which is critical for
many analysis tasks. Nandi et al.~(Transactions on Knowledge and Data
Engineering, Vol.~6) first studied cube materialization for large scale
datasets using the MapReduce framework, and proposed a sophisticated
modification of a simple broadcast algorithm to handle a dataset with a 216GB
cube size within 25 minutes with 2k machines in 2012. We take a different
approach, and propose a simple MapReduce algorithm which (1) minimizes the
total number of copy-add operations, (2) leverages locality of computation, and
(3) balances work evenly across machines. As a result, the algorithm shows
excellent performance, and materialized a real dataset with a cube size of
35.0G tuples and 1.75T bytes in 54 minutes, with 0.4k machines in 2014.
",Cybersecurity
"  In this paper, we present a spectral graph wavelet approach for shape
analysis of carpal bones of human wrist. We apply a metric called global
spectral graph wavelet signature for representation of cortical surface of the
carpal bone based on eigensystem of Laplace-Beltrami operator. Furthermore, we
propose a heuristic and efficient way of aggregating local descriptors of a
carpal bone surface to global descriptor. The resultant global descriptor is
not only isometric invariant, but also much more efficient and requires less
memory storage. We perform experiments on shape of the carpal bones of ten
women and ten men from a publicly-available database. Experimental results show
the excellency of the proposed GSGW compared to recent proposed GPS embedding
approach for comparing shapes of the carpal bones across populations.
",Cybersecurity
"  Mathematical models for physiological processes aid qualitative understanding
of the impact of various parameters on the underlying process. We analyse two
such models for human physiological processes: the Mackey-Glass and the Lasota
equations, which model the change in the concentration of blood cells in the
human body. We first study the local stability of these models, and derive
bounds on various model parameters and the feedback delay for the concentration
to equilibrate. We then deduce conditions for non-oscillatory convergence of
the solutions, which could ensure that the blood cell concentration does not
oscillate. Further, we define the convergence characteristics of the solutions
which govern the rate at which the concentration equilibrates when the system
is stable. Owing to the possibility that physiological parameters can seldom be
estimated precisely, we also derive bounds for robust stability\textemdash
which enable one to ensure that the blood cell concentration equilibrates
despite parametric uncertainty. We also highlight that when the necessary and
sufficient condition for local stability is violated, the system transits into
instability via a Hopf bifurcation, leading to limit cycles in the blood cell
concentration. We then outline a framework to characterise the type of the Hopf
bifurcation and determine the asymptotic orbital stability of limit cycles. The
analysis is complemented with numerical examples, stability charts and
bifurcation diagrams. The insights into the dynamical properties of the
mathematical models may serve to guide the study of dynamical diseases.
",Cybersecurity
"  We show that the task of question answering (QA) can significantly benefit
from the transfer learning of models trained on a different large, fine-grained
QA dataset. We achieve the state of the art in two well-studied QA datasets,
WikiQA and SemEval-2016 (Task 3A), through a basic transfer learning technique
from SQuAD. For WikiQA, our model outperforms the previous best model by more
than 8%. We demonstrate that finer supervision provides better guidance for
learning lexical and syntactic information than coarser supervision, through
quantitative results and visual analysis. We also show that a similar transfer
learning procedure achieves the state of the art on an entailment task.
",Cybersecurity
"  For nanotechnology nodes, the feature size is shrunk rapidly, the wire
becomes narrow and thin, it leads to high RC parasitic, especially for
resistance. The overall system performance are dominated by interconnect rather
than device. As such, it is imperative to accurately measure and model
interconnect parasitic in order to predict interconnect performance on silicon.
Despite many test structures developed in the past to characterize device
models and layout effects, only few of them are available for interconnects.
Nevertheless, they are either not suitable for real chip implementation or too
complicated to be embedded. A compact yet comprehensive test structure to
capture all interconnect parasitic in a real chip is needed. To address this
problem, this paper describes a set of test structures that can be used to
study the timing performance (i.e. propagation delay and crosstalk) of various
interconnect configurations. Moreover, an empirical model is developed to
estimate the actual RC parasitic. Compared with the state-of-the-art
interconnect test structures, the new structure is compact in size and can be
easily embedded on die as a parasitic variation monitor. We have validated the
proposed structure on a test chip in TSMC 28nm HPM process. Recently, the test
structure is further modified to identify the serious interconnect process
issues for critical path design using TSMC 7nm FF process.
",Cybersecurity
"  Reservoir characterization involves the estimation petrophysical properties
from well-log data and seismic data. Estimating such properties is a
challenging task due to the non-linearity and heterogeneity of the subsurface.
Various attempts have been made to estimate petrophysical properties using
machine learning techniques such as feed-forward neural networks and support
vector regression (SVR). Recent advances in machine learning have shown
promising results for recurrent neural networks (RNN) in modeling complex
sequential data such as videos and speech signals. In this work, we propose an
algorithm for property estimation from seismic data using recurrent neural
networks. An applications of the proposed workflow to estimate density and
p-wave impedance using seismic data shows promising results compared to
feed-forward neural networks.
",Cybersecurity
"  Mean square error (MSE) has been the preferred choice as loss function in the
current deep neural network (DNN) based speech separation techniques. In this
paper, we propose a new cost function with the aim of optimizing the extended
short time objective intelligibility (ESTOI) measure. We focus on applications
where low algorithmic latency ($\leq 10$ ms) is important. We use long
short-term memory networks (LSTM) and evaluate our proposed approach on four
sets of two-speaker mixtures from extended Danish hearing in noise (HINT)
dataset. We show that the proposed loss function can offer improved or at par
objective intelligibility (in terms of ESTOI) compared to an MSE optimized
baseline while resulting in lower objective separation performance (in terms of
the source to distortion ratio (SDR)). We then proceed to propose an approach
where the network is first initialized with weights optimized for MSE criterion
and then trained with the proposed ESTOI loss criterion. This approach
mitigates some of the losses in objective separation performance while
preserving the gains in objective intelligibility.
",Cybersecurity
"  Deep learning has been successfully applied to various tasks, but its
underlying mechanism remains unclear. Neural networks associate similar inputs
in the visible layer to the same state of hidden variables in deep layers. The
fraction of inputs that are associated to the same state is a natural measure
of similarity and is simply related to the cost in bits required to represent
these inputs. The degeneracy of states with the same information cost provides
instead a natural measure of noise and is simply related the entropy of the
frequency of states, that we call relevance. Representations with minimal
noise, at a given level of similarity (resolution), are those that maximise the
relevance. A signature of such efficient representations is that frequency
distributions follow power laws. We show, in extensive numerical experiments,
that deep neural networks extract a hierarchy of efficient representations from
data, because they i) achieve low levels of noise (i.e. high relevance) and ii)
exhibit power law distributions. We also find that the layer that is most
efficient to reliably generate patterns of training data is the one for which
relevance and resolution are traded at the same price, which implies that
frequency distribution follows Zipf's law.
",Cybersecurity
"  Illicit online pharmacies allow the purchase of prescription drugs online
without a prescription. Such pharmacies leverage social media platforms such as
Twit- ter as a promotion and marketing tool with the intent of reaching out to
a larger, potentially younger demographics of the population. Given the serious
negative health effects that arise from abusing such drugs, it is important to
identify the relevant content on social media and exterminate their presence as
quickly as pos- sible. In response, we collected all the tweets that contained
the names of certain preselected controlled substances over a period of 5
months. We found that an unsupervised topic modeling based methodology is able
to identify tweets that promote and market controlled substances with high
precision. We also study the meta-data characteristics of such tweets and the
users who post them and find that they have several distinguishing
characteristics that sets them apart. We were able to train supervised methods
and achieve high performance in detecting such content and the users who post
them.
",Cybersecurity
"  Treewidth is a parameter that measures how tree-like a relational instance
is, and whether it can reasonably be decomposed into a tree. Many computation
tasks are known to be tractable on databases of small treewidth, but computing
the treewidth of a given instance is intractable. This article is the first
large-scale experimental study of treewidth and tree decompositions of
real-world database instances (25 datasets from 8 different domains, with sizes
ranging from a few thousand to a few million vertices). The goal is to
determine which data, if any, can benefit of the wealth of algorithms for
databases of small treewidth. For each dataset, we obtain upper and lower bound
estimations of their treewidth, and study the properties of their tree
decompositions. We show in particular that, even when treewidth is high, using
partial tree decompositions can result in data structures that can assist
algorithms.
",Cybersecurity
"  Licas (lightweight internet-based communication for autonomic services) is a
distributed framework for building service-based systems. The framework
provides a p2p server and more intelligent processing of information through
its AI algorithms. Distributed communication includes XML-RPC, REST, HTTP and
Web Services. It can now provide a robust platform for building different types
of system, where Microservices or SOA would be possible. However, the system
may be equally suited for the IoT, as it provides classes to connect with
external sources and has an optional Autonomic Manager with a MAPE control loop
integrated into the communication process. The system is also mobile-compatible
with Android. This paper focuses in particular on the autonomic setup and how
that might be used. A novel linking mechanism has been described previously [5]
that can be used to dynamically link sources and this is also considered, as
part of the autonomous framework.
",Cybersecurity
"  We enumerate all circulant good matrices with odd orders divisible by 3 up to
order 70. As a consequence of this we find a previously overlooked set of good
matrices of order 27 and a new set of good matrices of order 57. We also find
that circulant good matrices do not exist in the orders 51, 63, and 69, thereby
finding three new counterexamples to the conjecture that such matrices exist in
all odd orders. Additionally, we prove a new relationship between the entries
of good matrices and exploit this relationship in our enumeration algorithm.
Our method applies the SAT+CAS paradigm of combining computer algebra
functionality with modern SAT solvers to efficiently search large spaces which
are specified by both algebraic and logical constraints.
",Cybersecurity
"  Recently, the advancement in industrial automation and high-speed printing
has raised numerous challenges related to the printing quality inspection of
final products. This paper proposes a machine vision based technique to assess
the printing quality of text on industrial objects. The assessment is based on
three quality defects such as text misalignment, varying printing shades, and
misprinted text. The proposed scheme performs the quality inspection through
stochastic assessment technique based on the second-order statistics of
printing. First: the text-containing area on printed product is identified
through image processing techniques. Second: the alignment testing of the
identified text-containing area is performed. Third: optical character
recognition is performed to divide the text into different small boxes and only
the intensity value of each text-containing box is taken as a random variable
and second-order statistics are estimated to determine the varying printing
defects in the text under one, two and three sigma thresholds. Fourth: the
K-Nearest Neighbors based supervised machine learning is performed to provide
the stochastic process for misprinted text detection. Finally, the technique is
deployed on an industrial image for the printing quality assessment with
varying values of n and m. The results have shown that the proposed SAML-QC
technique can perform real-time automated inspection for industrial printing.
",Cybersecurity
"  Our decision-making processes are becoming more data driven, based on data
from multiple sources, of different types, processed by a variety of
technologies. As technology becomes more relevant for decision processes, the
more likely they are to be subjects of attacks aimed at disrupting their
execution or changing their outcome. With the increasing complexity and
dependencies on technical components, such attempts grow more sophisticated and
their impact will be more severe. This is especially important in scenarios
with shared goals, which had to be previously agreed to, or decisions with
broad social impact. We need to think about our decisions-making and underlying
data analysis processes in a systemic way to correctly evaluate benefits and
risks of specific solutions and to design them to be resistant to attacks. To
reach these goals, we can apply experiences from threat modeling analysis used
in software security. We will need to adapt these practices to new types of
threats, protecting different assets and operating in socio-technical systems.
With these changes, threat modeling can become a foundation for implementing
detailed technical, organizational or legal mitigations and making our
decisions more reliable and trustworthy.
",Cybersecurity
"  During visuomotor tasks, robots must compensate for temporal delays inherent
in their sensorimotor processing systems. Delay compensation becomes crucial in
a dynamic environment where the visual input is constantly changing, e.g.,
during the interacting with a human demonstrator. For this purpose, the robot
must be equipped with a prediction mechanism for using the acquired perceptual
experience to estimate possible future motor commands. In this paper, we
present a novel neural network architecture that learns prototypical visuomotor
representations and provides reliable predictions on the basis of the visual
input. These predictions are used to compensate for the delayed motor behavior
in an online manner. We investigate the performance of our method with a set of
experiments comprising a humanoid robot that has to learn and generate visually
perceived arm motion trajectories. We evaluate the accuracy in terms of mean
prediction error and analyze the response of the network to novel movement
demonstrations. Additionally, we report experiments with incomplete data
sequences, showing the robustness of the proposed architecture in the case of a
noisy and faulty visual sensor.
",Cybersecurity
"  Distributed computing platforms provide a robust mechanism to perform
large-scale computations by splitting the task and data among multiple
locations, possibly located thousands of miles apart geographically. Although
such distribution of resources can lead to benefits, it also comes with its
associated problems such as rampant duplication of file transfers increasing
congestion, long job completion times, unexpected site crashing, suboptimal
data transfer rates, unpredictable reliability in a time range, and suboptimal
usage of storage elements. In addition, each sub-system becomes a potential
failure node that can trigger system wide disruptions. In this vision paper, we
outline our approach to leveraging Deep Learning algorithms to discover
solutions to unique problems that arise in a system with computational
infrastructure that is spread over a wide area. The presented vision, motivated
by a real scientific use case from Belle II experiments, is to develop
multilayer neural networks to tackle forecasting, anomaly detection and
optimization challenges in a complex and distributed data movement environment.
Through this vision based on Deep Learning principles, we aim to achieve
reduced congestion events, faster file transfer rates, and enhanced site
reliability.
",Cybersecurity
"  This paper considers the joint design of user power allocation and relay
beamforming in relaying communications, in which multiple pairs of
single-antenna users exchange information with each other via multiple-antenna
relays in two time slots. All users transmit their signals to the relays in the
first time slot while the relays broadcast the beamformed signals to all users
in the second time slot. The aim is to maximize the system's energy efficiency
(EE) subject to quality-of-service (QoS) constraints in terms of exchange
throughput requirements. The QoS constraints are nonconvex with many nonlinear
cross-terms, so finding a feasible point is already computationally
challenging. The sum throughput appears in the numerator while the total
consumption power appears in the denominator of the EE objective function. The
former is a nonconcave function and the latter is a nonconvex function, making
fractional programming useless for EE optimization. Nevertheless, efficient
iterations of low complexity to obtain its optimized solutions are developed.
The performances of the multiple-user and multiple-relay networks under various
scenarios are evaluated to show the merit of the paper development.
",Cybersecurity
"  Recent advances in generative adversarial networks (GANs) have shown
promising potentials in conditional image generation. However, how to generate
high-resolution images remains an open problem. In this paper, we aim at
generating high-resolution well-blended images given composited copy-and-paste
ones, i.e. realistic high-resolution image blending. To achieve this goal, we
propose Gaussian-Poisson GAN (GP-GAN), a framework that combines the strengths
of classical gradient-based approaches and GANs, which is the first work that
explores the capability of GANs in high-resolution image blending task to the
best of our knowledge. Particularly, we propose Gaussian-Poisson Equation to
formulate the high-resolution image blending problem, which is a joint
optimisation constrained by the gradient and colour information. Gradient
filters can obtain gradient information. For generating the colour information,
we propose Blending GAN to learn the mapping between the composited image and
the well-blended one. Compared to the alternative methods, our approach can
deliver high-resolution, realistic images with fewer bleedings and unpleasant
artefacts. Experiments confirm that our approach achieves the state-of-the-art
performance on Transient Attributes dataset. A user study on Amazon Mechanical
Turk finds that majority of workers are in favour of the proposed approach.
",Cybersecurity
"  Federated clouds raise a variety of challenges for managing identity,
resource access, naming, connectivity, and object access control. This paper
shows how to address these challenges in a comprehensive and uniform way using
a data-centric approach. The foundation of our approach is a trust logic in
which participants issue authenticated statements about principals, objects,
attributes, and relationships in a logic language, with reasoning based on
declarative policy rules. We show how to use the logic to implement a trust
infrastructure for cloud federation that extends the model of NSF GENI, a
federated IaaS testbed. It captures shared identity management, GENI authority
services, cross-site interconnection using L2 circuits, and a naming and access
control system similar to AWS Identity and Access Management (IAM), but
extended to a federated system without central control.
",Cybersecurity
"  In this work, we show that saturating output activation functions, such as
the softmax, impede learning on a number of standard classification tasks.
Moreover, we present results showing that the utility of softmax does not stem
from the normalization, as some have speculated. In fact, the normalization
makes things worse. Rather, the advantage is in the exponentiation of error
gradients. This exponential gradient boosting is shown to speed up convergence
and improve generalization. To this end, we demonstrate faster convergence and
better performance on diverse classification tasks: image classification using
CIFAR-10 and ImageNet, and semantic segmentation using PASCAL VOC 2012. In the
latter case, using the state-of-the-art neural network architecture, the model
converged 33% faster with our method (roughly two days of training less) than
with the standard softmax activation, and with a slightly better performance to
boot.
",Cybersecurity
"  Structured Peer Learning (SPL) is a form of peer-based supplemental
instruction that focuses on mentoring, guidance, and development of technical,
communication, and social skills in both the students receiving assistance and
the students in teaching roles. This paper explores the methodology, efficacy,
and reasoning behind the practical realization of a SPL program designed to
increase student knowledge and success in undergraduate Computer Science
courses. Students expressed an increased level of comfort when asking for help
from student teachers versus traditional educational resources, historically
showed an increased average grade in lower-level courses, and felt that the
program positively impacted their desire to continue in or switch to a Computer
major. Additionally, results indicated that advances in programming, analytical
thinking, and abstract analysis skills were evident in not only the students
but also the student teachers, suggesting a strong bidirectional flow of
knowledge.
",Cybersecurity
"  A graph is perfect if the chromatic number of every induced subgraph equals
the size of its largest clique, and an algorithm of Grötschel, Lovász, and
Schrijver from 1988 finds an optimal colouring of a perfect graph in polynomial
time. But this algorithm uses the ellipsoid method, and it is a well-known open
question to construct a ""combinatorial"" polynomial-time algorithm that yields
an optimal colouring of a perfect graph.
A skew partition in $G$ is a partition $(A,B)$ of $V(G)$ such that $G[A]$ is
not connected and $\bar{G}[B]$ is not connected, where $\bar{G}$ denotes the
complement graph ; and it is balanced if an additional parity condition of
paths in $G$ and $\bar{G}$ is satisfied.
In this paper we first give a polynomial-time algorithm that, with input a
perfect graph, outputs a balanced skew partition if there is one. Then we use
this to obtain a combinatorial algorithm that finds an optimal colouring of a
perfect graph with clique number $k$, in time that is polynomial for fixed $k$.
",Cybersecurity
"  Road networks in cities are massive and is a critical component of mobility.
Fast response to defects, that can occur not only due to regular wear and tear
but also because of extreme events like storms, is essential. Hence there is a
need for an automated system that is quick, scalable and cost-effective for
gathering information about defects. We propose a system for city-scale road
audit, using some of the most recent developments in deep learning and semantic
segmentation. For building and benchmarking the system, we curated a dataset
which has annotations required for road defects. However, many of the labels
required for road audit have high ambiguity which we overcome by proposing a
label hierarchy. We also propose a multi-step deep learning model that segments
the road, subdivide the road further into defects, tags the frame for each
defect and finally localizes the defects on a map gathered using GPS. We
analyze and evaluate the models on image tagging as well as segmentation at
different levels of the label hierarchy.
",Cybersecurity
"  Handheld Augmented Reality commonly implements some variant of magic lens
rendering, which turns only a fraction of the user's real environment into AR
while the rest of the environment remains unaffected. Since handheld AR devices
are commonly equipped with video see-through capabilities, AR magic lens
applications often suffer from spatial distortions, because the AR environment
is presented from the perspective of the camera of the mobile device. Recent
approaches counteract this distortion based on estimations of the user's head
position, rendering the scene from the user's perspective. To this end,
approaches usually apply face-tracking algorithms on the front camera of the
mobile device. However, this demands high computational resources and therefore
commonly affects the performance of the application beyond the already high
computational load of AR applications. In this paper, we present a method to
reduce the computational demands for user perspective rendering by applying
lightweight optical flow tracking and an estimation of the user's motion before
head tracking is started. We demonstrate the suitability of our approach for
computationally limited mobile devices and we compare it to device perspective
rendering, to head tracked user perspective rendering, as well as to fixed
point of view user perspective rendering.
",Cybersecurity
"  This paper presents a human-robot trust integrated task allocation and motion
planning framework for multi-robot systems (MRS) in performing a set of tasks
concurrently. A set of task specifications in parallel are conjuncted with MRS
to synthesize a task allocation automaton. Each transition of the task
allocation automaton is associated with the total trust value of human in
corresponding robots. Here, the human-robot trust model is constructed with a
dynamic Bayesian network (DBN) by considering individual robot performance,
safety coefficient, human cognitive workload and overall evaluation of task
allocation. Hence, a task allocation path with maximum encoded human-robot
trust can be searched based on the current trust value of each robot in the
task allocation automaton. Symbolic motion planning (SMP) is implemented for
each robot after they obtain the sequence of actions. The task allocation path
can be intermittently updated with this DBN based trust model. The overall
strategy is demonstrated by a simulation with 5 robots and 3 parallel subtask
automata.
",Cybersecurity
"  Event cameras are a paradigm shift in camera technology. Instead of full
frames, the sensor captures a sparse set of events caused by intensity changes.
Since only the changes are transferred, those cameras are able to capture quick
movements of objects in the scene or of the camera itself. In this work we
propose a novel method to perform camera tracking of event cameras in a
panoramic setting with three degrees of freedom. We propose a direct camera
tracking formulation, similar to state-of-the-art in visual odometry. We show
that the minimal information needed for simultaneous tracking and mapping is
the spatial position of events, without using the appearance of the imaged
scene point. We verify the robustness to fast camera movements and dynamic
objects in the scene on a recently proposed dataset and self-recorded
sequences.
",Cybersecurity
"  Polarization is a troubling phenomenon that can lead to societal divisions
and hurt the democratic process. It is therefore important to develop methods
to reduce it.
We propose an algorithmic solution to the problem of reducing polarization.
The core idea is to expose users to content that challenges their point of
view, with the hope broadening their perspective, and thus reduce their
polarity. Our method takes into account several aspects of the problem, such as
the estimated polarity of the user, the probability of accepting the
recommendation, the polarity of the content, and popularity of the content
being recommended.
We evaluate our recommendations via a large-scale user study on Twitter users
that were actively involved in the discussion of the US elections results.
Results shows that, in most cases, the factors taken into account in the
recommendation affect the users as expected, and thus capture the essential
features of the problem.
",Cybersecurity
"  Molecular dynamics simulates the~movements of atoms. Due to its high cost,
many methods have been developed to ""push the~simulation forward"". One of them,
metadynamics, can hasten the~molecular dynamics with the~help of variables
describing the~simulated process. However, the~evaluation of these variables
can include numerous mean square distance calculations that introduce
substantial computational demands, thus jeopardize the~benefit of the~approach.
Recently, we proposed an~approximative method that significantly reduces
the~number of these distance calculations. Here we evaluate the~performance and
the~scalability on two molecular systems. We assess the~maximal theoretical
speed-up based on the reduction of distance computations and Ahmdal's law and
compare it to the~practical speed-up achieved with our implementation.
",Cybersecurity
"  We study anisotropic undersampling schemes like those used in
multi-dimensional NMR spectroscopy and MR imaging, which sample exhaustively in
certain time dimensions and randomly in others.
Our analysis shows that anisotropic undersampling schemes are equivalent to
certain block-diagonal measurement systems. We develop novel exact formulas for
the sparsity/undersampling tradeoffs in such measurement systems. Our formulas
predict finite-N phase transition behavior differing substantially from the
well known asymptotic phase transitions for classical Gaussian undersampling.
Extensive empirical work shows that our formulas accurately describe observed
finite-N behavior, while the usual formulas based on universality are
substantially inaccurate.
We also vary the anisotropy, keeping the total number of samples fixed, and
for each variation we determine the precise sparsity/undersampling tradeoff
(phase transition). We show that, other things being equal, the ability to
recover a sparse object decreases with an increasing number of
exhaustively-sampled dimensions.
",Cybersecurity
"  We present a prototype of a software tool for exploration of multiple
combinatorial optimisation problems in large real-world and synthetic complex
networks. Our tool, called GraphCombEx (an acronym of Graph Combinatorial
Explorer), provides a unified framework for scalable computation and
presentation of high-quality suboptimal solutions and bounds for a number of
widely studied combinatorial optimisation problems. Efficient representation
and applicability to large-scale graphs and complex networks are particularly
considered in its design. The problems currently supported include maximum
clique, graph colouring, maximum independent set, minimum vertex clique
covering, minimum dominating set, as well as the longest simple cycle problem.
Suboptimal solutions and intervals for optimal objective values are estimated
using scalable heuristics. The tool is designed with extensibility in mind,
with the view of further problems and both new fast and high-performance
heuristics to be added in the future. GraphCombEx has already been successfully
used as a support tool in a number of recent research studies using
combinatorial optimisation to analyse complex networks, indicating its promise
as a research software tool.
",Cybersecurity
"  Example-based mesh deformation methods are powerful tools for realistic shape
editing. However, existing techniques typically combine all the example
deformation modes, which can lead to overfitting, i.e. using a overly
complicated model to explain the user-specified deformation. This leads to
implausible or unstable deformation results, including unexpected global
changes outside the region of interest. To address this fundamental limitation,
we propose a sparse blending method that automatically selects a smaller number
of deformation modes to compactly describe the desired deformation. This along
with a suitably chosen deformation basis including spatially localized
deformation modes leads to significant advantages, including more meaningful,
reliable, and efficient deformations because fewer and localized deformation
modes are applied. To cope with large rotations, we develop a simple but
effective representation based on polar decomposition of deformation gradients,
which resolves the ambiguity of large global rotations using an
as-consistent-as-possible global optimization. This simple representation has a
closed form solution for derivatives, making it efficient for sparse localized
representation and thus ensuring interactive performance. Experimental results
show that our method outperforms state-of-the-art data-driven mesh deformation
methods, for both quality of results and efficiency.
",Cybersecurity
"  Benford's law is an empirical observation, first reported by Simon Newcomb in
1881 and then independently by Frank Benford in 1938: the first significant
digits of numbers in large data are often distributed according to a
logarithmically decreasing function. Being contrary to intuition, the law was
forgotten as a mere curious observation. However, in the last two decades,
relevant literature has grown exponentially, - an evolution typical of
""Sleeping Beauties"" (SBs) publications that go unnoticed (sleep) for a long
time and then suddenly become center of attention (are awakened). Thus, in the
present study, we show that Newcomb (1881) and Benford (1938) papers are
clearly SBs. The former was in deep sleep for 110 years whereas the latter was
in deep sleep for a comparatively lesser period of 31 years up to 1968, and in
a state of less deep sleep for another 27 years up to 1995. Both SBs were
awakened in the year 1995 by Hill (1995a). In so doing, we show that the waking
prince (Hill, 1995a) is more often quoted than the SB whom he kissed, - in this
Benford's law case, wondering whether this is a general effect, - to be
usefully studied.
",Cybersecurity
"  Electronic Health Records (EHR) are data generated during routine clinical
care. EHR offer researchers unprecedented phenotypic breadth and depth and have
the potential to accelerate the pace of precision medicine at scale. A main EHR
use-case is creating phenotyping algorithms to define disease status, onset and
severity. Currently, no common machine-readable standard exists for defining
phenotyping algorithms which often are stored in human-readable formats. As a
result, the translation of algorithms to implementation code is challenging and
sharing across the scientific community is problematic. In this paper, we
evaluate openEHR, a formal EHR data specification, for computable
representations of EHR phenotyping algorithms.
",Cybersecurity
"  Synthesizing user-intended programs from a small number of input-output
examples is a challenging problem with several important applications like
spreadsheet manipulation, data wrangling and code refactoring. Existing
synthesis systems either completely rely on deductive logic techniques that are
extensively hand-engineered or on purely statistical models that need massive
amounts of data, and in general fail to provide real-time synthesis on
challenging benchmarks. In this work, we propose Neural Guided Deductive Search
(NGDS), a hybrid synthesis technique that combines the best of both symbolic
logic techniques and statistical models. Thus, it produces programs that
satisfy the provided specifications by construction and generalize well on
unseen examples, similar to data-driven systems. Our technique effectively
utilizes the deductive search framework to reduce the learning problem of the
neural component to a simple supervised learning setup. Further, this allows us
to both train on sparingly available real-world data and still leverage
powerful recurrent neural network encoders. We demonstrate the effectiveness of
our method by evaluating on real-world customer scenarios by synthesizing
accurate programs with up to 12x speed-up compared to state-of-the-art systems.
",Cybersecurity
"  Neural Machine Translation (NMT) models usually use large target vocabulary
sizes to capture most of the words in the target language. The vocabulary size
is a big factor when decoding new sentences as the final softmax layer
normalizes over all possible target words. To address this problem, it is
widely common to restrict the target vocabulary with candidate lists based on
the source sentence. Usually, the candidate lists are a combination of external
word-to-word aligner, phrase table entries or most frequent words. In this
work, we propose a simple and yet novel approach to learn candidate lists
directly from the attention layer during NMT training. The candidate lists are
highly optimized for the current NMT model and do not need any external
computation of the candidate pool. We show significant decoding speedup
compared with using the entire vocabulary, without losing any translation
quality for two language pairs.
",Cybersecurity
"  In this paper, a new approach is proposed for automated software maintenance.
The tool is able to perform 26 different refactorings. It also contains a large
selection of metrics to measure the impact of the refactorings on the software
and six different search based optimization algorithms to improve the software.
This tool contains both mono-objective and multi-objective search techniques
for software improvement and is fully automated. The paper describes the
various capabilities of the tool, the unique aspects of it, and also presents
some research results from experimentation. The individual metrics are tested
across five different codebases to deduce the most effective metrics for
general quality improvement. It is found that the metrics that relate to more
specific elements of the code are more useful for driving change in the search.
The mono-objective genetic algorithm is also tested against the multi-objective
algorithm to see how comparable the results gained are with three separate
objectives. When comparing the best solutions of each individual objective the
multi-objective approach generates suitable improvements in quality in less
time, allowing for rapid maintenance cycles.
",Cybersecurity
"  A lot of scientific works are published in different areas of science,
technology, engineering and mathematics. It is not easy, even for experts, to
judge the quality of authors, papers and venues (conferences and journals). An
objective measure to assign scores to these entities and to rank them is very
useful. Although, several metrics and indexes have been proposed earlier, they
suffer from various problems. In this paper, we propose a graph-based analytics
framework to assign scores and to rank authors, papers and venues. Our
algorithm considers only the link structures of the underlying graphs. It does
not take into account other aspects, such as the associated texts and the
reputation of these entities. In the limit of large number of iterations, the
solution of the iterative equations gives the unique entity scores. This
framework can be easily extended to other interdependent networks.
",Cybersecurity
"  Capturing both the structural and temporal aspects of interactions is crucial
for many real world datasets like contact between individuals. Using the link
stream formalism to capture the dynamic of the systems, we tackle the issue of
activity prediction in link streams, that is to say predicting the number of
links occurring during a given period of time and we present a protocol that
takes advantage of the temporal and structural information contained in the
link stream. Using a supervised learning method, we are able to model the
dynamic of our system to improve the prediction. We investigate the behavior of
our algorithm and crucial elements affecting the prediction. By introducing
different categories of pair of nodes, we are able to improve the quality as
well as increase the diversity of our prediction.
",Cybersecurity
"  Given a statistical model for the request frequencies and sizes of data
objects in a caching system, we derive the probability density of the size of
the file that accounts for the largest amount of data traffic. This is
equivalent to finding the required size of the cache for a caching placement
that maximizes the expected byte hit ratio for given file size and popularity
distributions. The file that maximizes the expected byte hit ratio is the file
for which the product of its size and popularity is the highest -- thus, it is
the file that incurs the greatest load on the network. We generalize this
theoretical problem to cover factors and addends of arbitrary order statistics
for given parent distributions. Further, we study the asymptotic behavior of
these distributions. We give several factor and addend densities of widely-used
distributions, and verify our results by extensive computer simulations.
",Cybersecurity
"  In Demand Response programs, price incentives might not be sufficient to
modify residential consumers load profile. Here, we consider that each consumer
has a preferred profile and a discomfort cost when deviating from it. Consumers
can value this discomfort at a varying level that we take as a parameter. This
work analyses Demand Response as a game theoretic environment. We study the
equilibria of the game between consumers with preferences within two different
dynamic pricing mechanisms, respectively the daily proportional mechanism
introduced by Mohsenian-Rad et al, and an hourly proportional mechanism. We
give new results about equilibria as functions of the preference level in the
case of quadratic system costs and prove that, whatever the preference level,
system costs are smaller with the hourly mechanism. We simulate the Demand
Response environment using real consumption data from PecanStreet database.
While the Price of Anarchy remains always close to one up to 0.1% with the
hourly mechanism, it can be more than 10% bigger with the daily mechanism.
",Cybersecurity
"  In this paper, we give a conditional lower bound of $n^{\Omega(k)}$ on
running time for the classic k-median and k-means clustering objectives (where
n is the size of the input), even in low-dimensional Euclidean space of
dimension four, assuming the Exponential Time Hypothesis (ETH). We also
consider k-median (and k-means) with penalties where each point need not be
assigned to a center, in which case it must pay a penalty, and extend our lower
bound to at least three-dimensional Euclidean space.
This stands in stark contrast to many other geometric problems such as the
traveling salesman problem, or computing an independent set of unit spheres.
While these problems benefit from the so-called (limited) blessing of
dimensionality, as they can be solved in time $n^{O(k^{1-1/d})}$ or
$2^{n^{1-1/d}}$ in d dimensions, our work shows that widely-used clustering
objectives have a lower bound of $n^{\Omega(k)}$, even in dimension four.
We complete the picture by considering the two-dimensional case: we show that
there is no algorithm that solves the penalized version in time less than
$n^{o(\sqrt{k})}$, and provide a matching upper bound of $n^{O(\sqrt{k})}$.
The main tool we use to establish these lower bounds is the placement of
points on the moment curve, which takes its inspiration from constructions of
point sets yielding Delaunay complexes of high complexity.
",Cybersecurity
"  For VSLAM (Visual Simultaneous Localization and Mapping), localization is a
challenging task, especially for some challenging situations: textureless
frames, motion blur, etc.. To build a robust exploration and localization
system in a given space or environment, a submap-based VSLAM system is proposed
in this paper. Our system uses a submap back-end and a visual front-end. The
main advantage of our system is its robustness with respect to tracking
failure, a common problem in current VSLAM algorithms. The robustness of our
system is compared with the state-of-the-art in terms of average tracking
percentage. The precision of our system is also evaluated in terms of ATE
(absolute trajectory error) RMSE (root mean square error) comparing the
state-of-the-art. The ability of our system in solving the `kidnapped' problem
is demonstrated. Our system can improve the robustness of visual localization
in challenging situations.
",Cybersecurity
"  Machine learning and data analysis now finds both scientific and industrial
application in biology, chemistry, geology, medicine, and physics. These
applications rely on large quantities of data gathered from automated sensors
and user input. Furthermore, the dimensionality of many datasets is extreme:
more details are being gathered about single user interactions or sensor
readings. All of these applications encounter problems with a common theme: use
observed data to make inferences about the world. Our work obtains the first
provably efficient algorithms for Independent Component Analysis (ICA) in the
presence of heavy-tailed data. The main tool in this result is the centroid
body (a well-known topic in convex geometry), along with optimization and
random walks for sampling from a convex body. This is the first algorithmic use
of the centroid body and it is of independent theoretical interest, since it
effectively replaces the estimation of covariance from samples, and is more
generally accessible.
This reduction relies on a non-linear transformation of samples from such an
intersection of halfspaces (i.e. a simplex) to samples which are approximately
from a linearly transformed product distribution. Through this transformation
of samples, which can be done efficiently, one can then use an ICA algorithm to
recover the vertices of the intersection of halfspaces.
Finally, we again use ICA as an algorithmic primitive to construct an
efficient solution to the widely-studied problem of learning the parameters of
a Gaussian mixture model. Our algorithm again transforms samples from a
Gaussian mixture model into samples which fit into the ICA model and, when
processed by an ICA algorithm, result in recovery of the mixture parameters.
Our algorithm is effective even when the number of Gaussians in the mixture
grows polynomially with the ambient dimension
",Cybersecurity
"  Convolutional neural nets (CNNs) have become a practical means to perform
vision tasks, particularly in the area of image classification. FPGAs are well
known to be able to perform convolutions efficiently, however, most recent
efforts to run CNNs on FPGAs have shown limited advantages over other devices
such as GPUs. Previous approaches on FPGAs have often been memory bound due to
the limited external memory bandwidth on the FPGA device. We show a novel
architecture written in OpenCL(TM), which we refer to as a Deep Learning
Accelerator (DLA), that maximizes data reuse and minimizes external memory
bandwidth. Furthermore, we show how we can use the Winograd transform to
significantly boost the performance of the FPGA. As a result, when running our
DLA on Intel's Arria 10 device we can achieve a performance of 1020 img/s, or
23 img/s/W when running the AlexNet CNN benchmark. This comes to 1382 GFLOPs
and is 10x faster with 8.4x more GFLOPS and 5.8x better efficiency than the
state-of-the-art on FPGAs. Additionally, 23 img/s/W is competitive against the
best publicly known implementation of AlexNet on nVidia's TitanX GPU.
",Cybersecurity
"  The paradigm shift from shallow classifiers with hand-crafted features to
end-to-end trainable deep learning models has shown significant improvements on
supervised learning tasks. Despite the promising power of deep neural networks
(DNN), how to alleviate overfitting during training has been a research topic
of interest. In this paper, we present a Generative-Discriminative Variational
Model (GDVM) for visual classification, in which we introduce a latent variable
inferred from inputs for exhibiting generative abilities towards prediction. In
other words, our GDVM casts the supervised learning task as a generative
learning process, with data discrimination to be jointly exploited for improved
classification. In our experiments, we consider the tasks of multi-class
classification, multi-label classification, and zero-shot learning. We show
that our GDVM performs favorably against the baselines or recent generative DNN
models.
",Cybersecurity
"  Estimation of a hand grip force is essential for the understanding of force
pattern during the execution of assembly or disassembly operations. Human
demonstration of a correct way of doing an operation is a powerful source of
information which can be used for guided robot teaching. Typically to assess
this problem instrumented approach is used, which requires hand or object
mounted devices and poses an inconvenience for an operator or limits the scope
of addressable objects. The work demonstrates that contact force may be
estimated using a noninvasive contactless method with the help of vision system
alone. We propose a two-stream approach for video processing, which utilizes
both spatial information of each frame and dynamic information of frame change.
In this work, image processing and machine learning techniques are used along
with dense optical flow for frame change tracking and Kalman filter is used for
stream fusion. Our studies show that the proposed method can successfully
estimate contact grip force with RMSE < 10% of sensor range (RMSE $\approx 0.2$
N), the performances of each stream and overall method performance are
reported. The proposed method has a wide range of applications, including robot
teaching through demonstration, haptic force feedback, and validation of human-
performed operations.
",Cybersecurity
"  This work proposes a novel approach to restricting the access for blacklisted
Android system API calls. Main feature of the suggested method introduced in
this paper is that it requires only rootless or (user-mode) access to the
system unlike previous works. For that reason this method is valuable for
end-users due to the possibility of project distribution via Play Market and it
does not require any phone system modifications and/or updates. This paper
explains the required background of Android OS necessary for understanding and
describes the method for modification Android application. In this paper the
proof-of-concept implementation. That is able to block the application's IMEI
requests is introduced. Also this paper lists unsuccessful methods that tried
to provide the user security. Obviously with those restrictions application may
lack some of features that can only be granted in unsecured environment.
",Cybersecurity
"  Our experience of the world is multimodal - we see objects, hear sounds, feel
texture, smell odors, and taste flavors. Modality refers to the way in which
something happens or is experienced and a research problem is characterized as
multimodal when it includes multiple such modalities. In order for Artificial
Intelligence to make progress in understanding the world around us, it needs to
be able to interpret such multimodal signals together. Multimodal machine
learning aims to build models that can process and relate information from
multiple modalities. It is a vibrant multi-disciplinary field of increasing
importance and with extraordinary potential. Instead of focusing on specific
multimodal applications, this paper surveys the recent advances in multimodal
machine learning itself and presents them in a common taxonomy. We go beyond
the typical early and late fusion categorization and identify broader
challenges that are faced by multimodal machine learning, namely:
representation, translation, alignment, fusion, and co-learning. This new
taxonomy will enable researchers to better understand the state of the field
and identify directions for future research.
",Cybersecurity
"  In cloud storage systems, hot data is usually replicated over multiple nodes
in order to accommodate simultaneous access by multiple users as well as
increase the fault tolerance of the system. Recent cloud storage research has
proposed using availability codes, which is a special class of erasure codes,
as a more storage efficient way to store hot data. These codes enable data
recovery from multiple, small disjoint groups of servers. The number of the
recovery groups is referred to as the availability and the size of each group
as the locality of the code. Until now, we have very limited knowledge on how
code locality and availability affect data access time. Data download from
these systems involves multiple fork-join queues operating in-parallel, making
the analysis of access time a very challenging problem. In this paper, we
present an approximate analysis of data access time in storage systems that
employ simplex codes, which are an important and in certain sense optimal class
of availability codes. We consider and compare three strategies in assigning
download requests to servers; first one aggressively exploits the storage
availability for faster download, second one implements only load balancing,
and the last one employs storage availability only for hot data download
without incurring any negative impact on the cold data download.
",Cybersecurity
"  We present a new approach to testing file-system crash consistency: bounded
black-box crash testing (B3). B3 tests the file system in a black-box manner
using workloads of file-system operations. Since the space of possible
workloads is infinite, B3 bounds this space based on parameters such as the
number of file-system operations or which operations to include, and
exhaustively generates workloads within this bounded space. Each workload is
tested on the target file system by simulating power-loss crashes while the
workload is being executed, and checking if the file system recovers to a
correct state after each crash. B3 builds upon insights derived from our study
of crash-consistency bugs reported in Linux file systems in the last five
years. We observed that most reported bugs can be reproduced using small
workloads of three or fewer file-system operations on a newly-created file
system, and that all reported bugs result from crashes after fsync() related
system calls. We build two tools, CrashMonkey and ACE, to demonstrate the
effectiveness of this approach. Our tools are able to find 24 out of the 26
crash-consistency bugs reported in the last five years. Our tools also revealed
10 new crash-consistency bugs in widely-used, mature Linux file systems, seven
of which existed in the kernel since 2014. Our tools also found a
crash-consistency bug in a verified file system, FSCQ. The new bugs result in
severe consequences like broken rename atomicity and loss of persisted files.
",Cybersecurity
"  In this paper, we present a set of simulation models to more realistically
mimic the behaviour of users reading messages. We propose a User Behaviour
Model, where a simulated user reacts to a message by a flexible set of possible
reactions (e.g. ignore, read, like, save, etc.) and a mobility-based reaction
(visit a place, run away from danger, etc.). We describe our models and their
implementation in OMNeT++. We strongly believe that these models will
significantly contribute to the state of the art of simulating realistically
opportunistic networks.
",Cybersecurity
"  Grigni and Hung~\cite{GH12} conjectured that H-minor-free graphs have
$(1+\epsilon)$-spanners that are light, that is, of weight $g(|H|,\epsilon)$
times the weight of the minimum spanning tree for some function $g$. This
conjecture implies the {\em efficient} polynomial-time approximation scheme
(PTAS) of the traveling salesperson problem in $H$-minor free graphs; that is,
a PTAS whose running time is of the form $2^{f(\epsilon)}n^{O(1)}$ for some
function $f$. The state of the art PTAS for TSP in H-minor-free-graphs has
running time $n^{1/\epsilon^c}$. We take a further step toward proving this
conjecture by showing that if the bounded treewidth graphs have light greedy
spanners, then the conjecture is true. We also prove that the greedy spanner of
a bounded pathwidth graph is light and discuss the possibility of extending our
proof to bounded treewidth graphs.
",Cybersecurity
"  In this paper, we reconsider the unfolding-based technique that we have
introduced previously for detecting loops in standard term rewriting. We
improve it by guiding the unfolding process, using distinguished positions in
the rewrite rules. This results in a depth-first computation of the unfoldings,
whereas the original technique was breadth-first. We have implemented this new
approach in our tool NTI and compared it to the previous one on a bunch of
rewrite systems. The results we get are promising (better times, more
successful proofs).
",Cybersecurity
"  Spectral topic modeling algorithms operate on matrices/tensors of word
co-occurrence statistics to learn topic-specific word distributions. This
approach removes the dependence on the original documents and produces
substantial gains in efficiency and provable topic inference, but at a cost:
the model can no longer provide information about the topic composition of
individual documents. Recently Thresholded Linear Inverse (TLI) is proposed to
map the observed words of each document back to its topic composition. However,
its linear characteristics limit the inference quality without considering the
important prior information over topics. In this paper, we evaluate Simple
Probabilistic Inverse (SPI) method and novel Prior-aware Dual Decomposition
(PADD) that is capable of learning document-specific topic compositions in
parallel. Experiments show that PADD successfully leverages topic correlations
as a prior, notably outperforming TLI and learning quality topic compositions
comparable to Gibbs sampling on various data.
",Cybersecurity
"  Imaging assays of cellular function, especially those using fluorescent
stains, are ubiquitous in the biological and medical sciences. Despite advances
in computer vision, such images are often analyzed using only manual or
rudimentary automated processes. Watershed-based segmentation is an effective
technique for identifying objects in images; it outperforms commonly used image
analysis methods, but requires familiarity with computer-vision techniques to
be applied successfully. In this report, we present and implement a
watershed-based image analysis and classification algorithm in a GUI, enabling
a broad set of users to easily understand the algorithm and adjust the
parameters to their specific needs. As an example, we implement this algorithm
to find and classify cells in a complex imaging assay for mitochondrial
function. In a second example, we demonstrate a workflow using manual
comparisons and receiver operator characteristics to optimize the algorithm
parameters for finding live and dead cells in a standard viability assay.
Overall, this watershed-based algorithm is more advanced than traditional
thresholding and can produce optimized, automated results. By incorporating
associated pre-processing steps in the GUI, the algorithm is also easily
adjusted, rendering it user-friendly.
",Cybersecurity
"  This paper proposes a privacy-preserving distributed recommendation
framework, Secure Distributed Collaborative Filtering (SDCF), to preserve the
privacy of value, model and existence altogether. That says, not only the
ratings from the users to the items, but also the existence of the ratings as
well as the learned recommendation model are kept private in our framework. Our
solution relies on a distributed client-server architecture and a two-stage
Randomized Response algorithm, along with an implementation on the popular
recommendation model, Matrix Factorization (MF). We further prove SDCF to meet
the guarantee of Differential Privacy so that clients are allowed to specify
arbitrary privacy levels. Experiments conducted on numerical rating prediction
and one-class rating action prediction exhibit that SDCF does not sacrifice too
much accuracy for privacy.
",Cybersecurity
"  Training deep neural network policies end-to-end for real-world applications
so far requires big demonstration datasets in the real world or big sets
consisting of a large variety of realistic and closely related 3D CAD models.
These real or virtual data should, moreover, have very similar characteristics
to the conditions expected at test time. These stringent requirements and the
time consuming data collection processes that they entail, are currently the
most important impediment that keeps deep reinforcement learning from being
deployed in real-world applications. Therefore, in this work we advocate an
alternative approach, where instead of avoiding any domain shift by carefully
selecting the training data, the goal is to learn a policy that can cope with
it. To this end, we propose the DoShiCo challenge: to train a model in very
basic synthetic environments, far from realistic, in a way that it can be
applied in more realistic environments as well as take the control decisions on
real-world data. In particular, we focus on the task of collision avoidance for
drones. We created a set of simulated environments that can be used as
benchmark and implemented a baseline method, exploiting depth prediction as an
auxiliary task to help overcome the domain shift. Even though the policy is
trained in very basic environments, it can learn to fly without collisions in a
very different realistic simulated environment. Of course several benchmarks
for reinforcement learning already exist - but they never include a large
domain shift. On the other hand, several benchmarks in computer vision focus on
the domain shift, but they take the form of a static datasets instead of
simulated environments. In this work we claim that it is crucial to take the
two challenges together in one benchmark.
",Cybersecurity
"  Participatory budgeting is one of the exciting developments in deliberative
grassroots democracy. We concentrate on approval elections and propose
proportional representation axioms in participatory budgeting, by generalizing
relevant axioms for approval-based multi-winner elections. We observe a rich
landscape with respect to the computational complexity of identifying
proportional budgets and computing such, and present budgeting methods that
satisfy these axioms by identifying budgets that are representative to the
demands of vast segments of the voters.
",Cybersecurity
"  We consider the task of fine-grained sentiment analysis from the perspective
of multiple instance learning (MIL). Our neural model is trained on document
sentiment labels, and learns to predict the sentiment of text segments, i.e.
sentences or elementary discourse units (EDUs), without segment-level
supervision. We introduce an attention-based polarity scoring method for
identifying positive and negative text snippets and a new dataset which we call
SPOT (as shorthand for Segment-level POlariTy annotations) for evaluating
MIL-style sentiment models like ours. Experimental results demonstrate superior
performance against multiple baselines, whereas a judgement elicitation study
shows that EDU-level opinion extraction produces more informative summaries
than sentence-based alternatives.
",Cybersecurity
"  The performance of deep learning in natural language processing has been
spectacular, but the reasons for this success remain unclear because of the
inherent complexity of deep learning. This paper provides empirical evidence of
its effectiveness and of a limitation of neural networks for language
engineering. Precisely, we demonstrate that a neural language model based on
long short-term memory (LSTM) effectively reproduces Zipf's law and Heaps' law,
two representative statistical properties underlying natural language. We
discuss the quality of reproducibility and the emergence of Zipf's law and
Heaps' law as training progresses. We also point out that the neural language
model has a limitation in reproducing long-range correlation, another
statistical property of natural language. This understanding could provide a
direction for improving the architectures of neural networks.
",Cybersecurity
"  Knowledge base completion (KBC) aims to predict missing information in a
knowledge base.In this paper, we address the out-of-knowledge-base (OOKB)
entity problem in KBC:how to answer queries concerning test entities not
observed at training time. Existing embedding-based KBC models assume that all
test entities are available at training time, making it unclear how to obtain
embeddings for new entities without costly retraining. To solve the OOKB entity
problem without retraining, we use graph neural networks (Graph-NNs) to compute
the embeddings of OOKB entities, exploiting the limited auxiliary knowledge
provided at test time.The experimental results show the effectiveness of our
proposed model in the OOKB setting.Additionally, in the standard KBC setting in
which OOKB entities are not involved, our model achieves state-of-the-art
performance on the WordNet dataset. The code and dataset are available at
this https URL
",Cybersecurity
"  The impact of the maximally possible batch size (for the better runtime) on
performance of graphic processing units (GPU) and tensor processing units (TPU)
during training and inference phases is investigated. The numerous runs of the
selected deep neural network (DNN) were performed on the standard MNIST and
Fashion-MNIST datasets. The significant speedup was obtained even for extremely
low-scale usage of Google TPUv2 units (8 cores only) in comparison to the quite
powerful GPU NVIDIA Tesla K80 card with the speedup up to 10x for training
stage (without taking into account the overheads) and speedup up to 2x for
prediction stage (with and without taking into account overheads). The precise
speedup values depend on the utilization level of TPUv2 units and increase with
the increase of the data volume under processing, but for the datasets used in
this work (MNIST and Fashion-MNIST with images of sizes 28x28) the speedup was
observed for batch sizes >512 images for training phase and >40 000 images for
prediction phase. It should be noted that these results were obtained without
detriment to the prediction accuracy and loss that were equal for both GPU and
TPU runs up to the 3rd significant digit for MNIST dataset, and up to the 2nd
significant digit for Fashion-MNIST dataset.
",Cybersecurity
"  In multi-server distributed queueing systems, the access of stochastically
arriving jobs to resources is often regulated by a dispatcher, also known as
load balancer. A fundamental problem consists in designing a load balancing
algorithm that minimizes the delays experienced by jobs. During the last two
decades, the power-of-$d$-choice algorithm, based on the idea of dispatching
each job to the least loaded server out of $d$ servers randomly sampled at the
arrival of the job itself, has emerged as a breakthrough in the foundations of
this area due to its versatility and appealing asymptotic properties. In this
paper, we consider the power-of-$d$-choice algorithm with the addition of a
local memory that keeps track of the latest observations collected over time on
the sampled servers. Then, each job is sent to a server with the lowest
observation. We show that this algorithm is asymptotically optimal in the sense
that the load balancer can always assign each job to an idle server in the
large-server limit. This holds true if and only if the system load $\lambda$ is
less than $1-\frac{1}{d}$. If this condition is not satisfied, we show that
queue lengths are bounded by $j^\star+1$, where $j^\star\in\mathbb{N}$ is given
by the solution of a polynomial equation. This is in contrast with the classic
version of the power-of-$d$-choice algorithm, where queue lengths are
unbounded. Our upper bound on the size of the most loaded server, $j^*+1$, is
tight and increases slowly when $\lambda$ approaches its critical value from
below. For instance, when $\lambda= 0.995$ and $d=2$ (respectively, $d=3$), we
find that no server will contain more than just $5$ ($3$) jobs in equilibrium.
Our results quantify and highlight the importance of using memory as a means to
enhance performance in randomized load balancing.
",Cybersecurity
"  We propose a constraint-based flow-sensitive static analysis for concurrent
programs by iteratively composing thread-modular abstract interpreters via the
use of a system of lightweight constraints. Our method is compositional in that
it first applies sequential abstract interpreters to individual threads and
then composes their results. It is flow-sensitive in that the causality
ordering of interferences (flow of data from global writes to reads) is modeled
by a system of constraints. These interference constraints are lightweight
since they only refer to the execution order of program statements as opposed
to their numerical properties: they can be decided efficiently using an
off-the-shelf Datalog engine. Our new method has the advantage of being more
accurate than existing, flow-insensitive, static analyzers while remaining
scalable and providing the expected soundness and termination guarantees even
for programs with unbounded data. We implemented our method and evaluated it on
a large number of benchmarks, demonstrating its effectiveness at increasing the
accuracy of thread-modular abstract interpretation.
",Cybersecurity
"  When a human drives a car along a road for the first time, they later
recognize where they are on the return journey typically without needing to
look in their rear-view mirror or turn around to look back, despite significant
viewpoint and appearance change. Such navigation capabilities are typically
attributed to our semantic visual understanding of the environment [1] beyond
geometry to recognizing the types of places we are passing through such as
""passing a shop on the left"" or ""moving through a forested area"". Humans are in
effect using place categorization [2] to perform specific place recognition
even when the viewpoint is 180 degrees reversed. Recent advances in deep neural
networks have enabled high-performance semantic understanding of visual places
and scenes, opening up the possibility of emulating what humans do. In this
work, we develop a novel methodology for using the semantics-aware higher-order
layers of deep neural networks for recognizing specific places from within a
reference database. To further improve the robustness to appearance change, we
develop a descriptor normalization scheme that builds on the success of
normalization schemes for pure appearance-based techniques such as SeqSLAM [3].
Using two different datasets - one road-based, one pedestrian-based, we
evaluate the performance of the system in performing place recognition on
reverse traversals of a route with a limited field of view camera and no
turn-back-and-look behaviours, and compare to existing state-of-the-art
techniques and vanilla off-the-shelf features. The results demonstrate
significant improvements over the existing state of the art, especially for
extreme perceptual challenges that involve both great viewpoint change and
environmental appearance change. We also provide experimental analyses of the
contributions of the various system components.
",Cybersecurity
"  There has been relatively little attention to incorporating linguistic prior
to neural machine translation. Much of the previous work was further
constrained to considering linguistic prior on the source side. In this paper,
we propose a hybrid model, called NMT+RNNG, that learns to parse and translate
by combining the recurrent neural network grammar into the attention-based
neural machine translation. Our approach encourages the neural machine
translation model to incorporate linguistic prior during training, and lets it
translate on its own afterward. Extensive experiments with four language pairs
show the effectiveness of the proposed NMT+RNNG.
",Cybersecurity
"  Consumers often react expressively to products such as food samples, perfume,
jewelry, sunglasses, and clothing accessories. This research discusses a
multimodal affect recognition system developed to classify whether a consumer
likes or dislikes a product tested at a counter or kiosk, by analyzing the
consumer's facial expression, body posture, hand gestures, and voice after
testing the product. A depth-capable camera and microphone system - Kinect for
Windows - is utilized. An emotion identification engine has been developed to
analyze the images and voice to determine affective state of the customer. The
image is segmented using skin color and adaptive threshold. Face, body and
hands are detected using the Haar cascade classifier. Canny edges are
identified and the lip, body and hand contours are extracted using spatial
filtering. Edge count and orientation around the mouth, cheeks, eyes,
shoulders, fingers and the location of the edges are used as features.
Classification is done by an emotion template mapping algorithm and training a
classifier using support vector machines. The real-time performance, accuracy
and feasibility for multimodal affect recognition in feedback assessment are
evaluated.
",Cybersecurity
"  The use of standard platforms in the field of humanoid robotics can
accelerate research, and lower the entry barrier for new research groups. While
many affordable humanoid standard platforms exist in the lower size ranges of
up to 60cm, beyond this the few available standard platforms quickly become
significantly more expensive, and difficult to operate and maintain. In this
paper, the igus Humanoid Open Platform is presented---a new, affordable,
versatile and easily customisable standard platform for humanoid robots in the
child-sized range. At 90cm, the robot is large enough to interact with a
human-scale environment in a meaningful way, and is equipped with enough torque
and computing power to foster research in many possible directions. The
structure of the robot is entirely 3D printed, allowing for a lightweight and
appealing design. The electrical and mechanical designs of the robot are
presented, and the main features of the corresponding open-source ROS software
are discussed. The 3D CAD files for all of the robot parts have been released
open-source in conjunction with this paper.
",Cybersecurity
"  The problem of reliable communication over the multiple-access channel (MAC)
with states is investigated. We propose a new coding scheme for this problem
which uses quasi-group codes (QGC). We derive a new computable single-letter
characterization of the achievable rate region. As an example, we investigate
the problem of doubly-dirty MAC with modulo-$4$ addition. It is shown that the
sum-rate $R_1+R_2=1$ bits per channel use is achievable using the new scheme.
Whereas, the natural extension of the Gel'fand-Pinsker scheme, sum-rates
greater than $0.32$ are not achievable.
",Cybersecurity
"  Program synthesis is the process of automatically translating a specification
into computer code. Traditional synthesis settings require a formal, precise
specification. Motivated by computer education applications where a student
learns to code simple turtle-style drawing programs, we study a novel synthesis
setting where only a noisy user-intention drawing is specified. This allows
students to sketch their intended output, optionally together with their own
incomplete program, to automatically produce a completed program. We formulate
this synthesis problem as search in the space of programs, with the score of a
state being the Hausdorff distance between the program output and the user
drawing. We compare several search algorithms on a corpus consisting of real
user drawings and the corresponding programs, and demonstrate that our
algorithms can synthesize programs optimally satisfying the specification.
",Cybersecurity
"  Machine scheduling problems are a long-time key domain of algorithms and
complexity research. A novel approach to machine scheduling problems are
fixed-parameter algorithms. To stimulate this thriving research direction, we
propose 15 open questions in this area whose resolution we expect to lead to
the discovery of new approaches and techniques both in scheduling and
parameterized complexity theory.
",Cybersecurity
"  This article describes the final solution of team monkeytyping, who finished
in second place in the YouTube-8M video understanding challenge. The dataset
used in this challenge is a large-scale benchmark for multi-label video
classification. We extend the work in [1] and propose several improvements for
frame sequence modeling. We propose a network structure called Chaining that
can better capture the interactions between labels. Also, we report our
approaches in dealing with multi-scale information and attention pooling. In
addition, We find that using the output of model ensemble as a side target in
training can boost single model performance. We report our experiments in
bagging, boosting, cascade, and stacking, and propose a stacking algorithm
called attention weighted stacking. Our final submission is an ensemble that
consists of 74 sub models, all of which are listed in the appendix.
",Cybersecurity
"  The degree splitting problem requires coloring the edges of a graph red or
blue such that each node has almost the same number of edges in each color, up
to a small additive discrepancy. The directed variant of the problem requires
orienting the edges such that each node has almost the same number of incoming
and outgoing edges, again up to a small additive discrepancy.
We present deterministic distributed algorithms for both variants, which
improve on their counterparts presented by Ghaffari and Su [SODA'17]: our
algorithms are significantly simpler and faster, and have a much smaller
discrepancy. This also leads to a faster and simpler deterministic algorithm
for $(2+o(1))\Delta$-edge-coloring, improving on that of Ghaffari and Su.
",Cybersecurity
"  In today's cyber-enabled smart grids, high penetration of uncertain
renewables, purposeful manipulation of meter readings, and the need for
wide-area situational awareness, call for fast, accurate, and robust power
system state estimation. The least-absolute-value (LAV) estimator is known for
its robustness relative to the weighted least-squares (WLS) one. However, due
to nonconvexity and nonsmoothness, existing LAV solvers based on linear
programming are typically slow, hence inadequate for real-time system
monitoring. This paper develops two novel algorithms for efficient LAV
estimation, which draw from recent advances in composite optimization. The
first is a deterministic linear proximal scheme that handles a sequence of
convex quadratic problems, each efficiently solvable either via off-the-shelf
algorithms or through the alternating direction method of multipliers.
Leveraging the sparse connectivity inherent to power networks, the second
scheme is stochastic, and updates only \emph{a few} entries of the complex
voltage state vector per iteration. In particular, when voltage magnitude and
(re)active power flow measurements are used only, this number reduces to one or
two, \emph{regardless of} the number of buses in the network. This
computational complexity evidently scales well to large-size power systems.
Furthermore, by carefully \emph{mini-batching} the voltage and power flow
measurements, accelerated implementation of the stochastic iterations becomes
possible. The developed algorithms are numerically evaluated using a variety of
benchmark power networks. Simulated tests corroborate that improved robustness
can be attained at comparable or markedly reduced computation times for medium-
or large-size networks relative to the ""workhorse"" WLS-based Gauss-Newton
iterations.
",Cybersecurity
"  We evaluate a curious determinant, first mentioned by George Andrews in 1980
in the context of descending plane partitions. Our strategy is to combine the
famous Desnanot-Jacobi-Dodgson identity with automated proof techniques. More
precisely, we follow the holonomic ansatz that was proposed by Doron Zeilberger
in 2007. We derive a compact and nice formula for Andrews's determinant, and
use it to solve a challenge problem that we posed in a previous paper. By
noting that Andrews's determinant is a special case of a two-parameter family
of determinants, we find closed forms for several one-parameter subfamilies.
The interest in these determinants arises because they count cyclically
symmetric rhombus tilings of a hexagon with several triangular holes inside.
",Cybersecurity
"  In recent years, the proliferation of online resumes and the need to evaluate
large populations of candidates for on-site and virtual teams have led to a
growing interest in automated team-formation. Given a large pool of candidates,
the general problem requires the selection of a team of experts to complete a
given task. Surprisingly, while ongoing research has studied numerous
variations with different constraints, it has overlooked a factor with a
well-documented impact on team cohesion and performance: team faultlines.
Addressing this gap is challenging, as the available measures for faultlines in
existing teams cannot be efficiently applied to faultline optimization. In this
work, we meet this challenge with a new measure that can be efficiently used
for both faultline measurement and minimization. We then use the measure to
solve the problem of automatically partitioning a large population into
low-faultline teams. By introducing faultlines to the team-formation
literature, our work creates exciting opportunities for algorithmic work on
faultline optimization, as well as on work that combines and studies the
connection of faultlines with other influential team characteristics.
",Cybersecurity
"  We propose an approach to estimate 3D human pose in real world units from a
single RGBD image and show that it exceeds performance of monocular 3D pose
estimation approaches from color as well as pose estimation exclusively from
depth. Our approach builds on robust human keypoint detectors for color images
and incorporates depth for lifting into 3D. We combine the system with our
learning from demonstration framework to instruct a service robot without the
need of markers. Experiments in real world settings demonstrate that our
approach enables a PR2 robot to imitate manipulation actions observed from a
human teacher.
",Cybersecurity
"  In this paper we revisit some classic board games like Pachisi or the Game of
Gosse. The main contribution of the paper is to design and add some
functionalities to the games in order to transform them in serious games, that
is, in games with learning and educational purposes. To do that, at the
beginning of the game, players choose one or several topics and during the
game, players have to anwers questions on these topics in order to move their
markers. We choose classic board games because a lot of people are familiar
with them so it is very easy to start to play without wasting time learning
game rules and, we think that this is an important element to make the game
more attractive to people. To enlarge the number of potential users we have
implement the games just using html and javascript and the games can be used in
any web browser, in any computer (including tablets) , in any computer
arquitecture (Windows, Mac, Linux) and no internet/server conexion is required.
Associated software is distributed under Creative Commons
Attribution-NonCommercial-ShareAlike 3.0 licence and can be obtained at
this http URL
",Cybersecurity
"  Sound event detection (SED) is typically posed as a supervised learning
problem requiring training data with strong temporal labels of sound events.
However, the production of datasets with strong labels normally requires
unaffordable labor cost. It limits the practical application of supervised SED
methods. The recent advances in SED approaches focuses on detecting sound
events by taking advantages of weakly labeled or unlabeled training data. In
this paper, we propose a joint framework to solve the SED task using
large-scale unlabeled in-domain data. In particular, a state-of-the-art general
audio tagging model is first employed to predict weak labels for unlabeled
data. On the other hand, a weakly supervised architecture based on the
convolutional recurrent neural network (CRNN) is developed to solve the strong
annotations of sound events with the aid of the unlabeled data with predicted
labels. It is found that the SED performance generally increases as more
unlabeled data is added into the training. To address the noisy label problem
of unlabeled data, an ensemble strategy is applied to increase the system
robustness. The proposed system is evaluated on the SED dataset of DCASE 2018
challenge. It reaches a F1-score of 21.0%, resulting in an improvement of 10%
over the baseline system.
",Cybersecurity
"  Generative Adversarial Networks (GAN) have received wide attention in the
machine learning field for their potential to learn high-dimensional, complex
real data distribution. Specifically, they do not rely on any assumptions about
the distribution and can generate real-like samples from latent space in a
simple manner. This powerful property leads GAN to be applied to various
applications such as image synthesis, image attribute editing, image
translation, domain adaptation and other academic fields. In this paper, we aim
to discuss the details of GAN for those readers who are familiar with, but do
not comprehend GAN deeply or who wish to view GAN from various perspectives. In
addition, we explain how GAN operates and the fundamental meaning of various
objective functions that have been suggested recently. We then focus on how the
GAN can be combined with an autoencoder framework. Finally, we enumerate the
GAN variants that are applied to various tasks and other fields for those who
are interested in exploiting GAN for their research.
",Cybersecurity
"  Transformer lifetime assessments plays a vital role in reliable operation of
power systems. In this paper, leveraging sensory data, an approach in
estimating transformer lifetime is presented. The winding hottest-spot
temperature, which is the pivotal driver that impacts transformer aging, is
measured hourly via a temperature sensor, then transformer loss of life is
calculated based on the IEEE Std. C57.91-2011. A Cumulative Moving Average
(CMA) model is subsequently applied to the data stream of the transformer loss
of life to provide hourly estimates until convergence. Numerical examples
demonstrate the effectiveness of the proposed approach for the transformer
lifetime estimation, and explores its efficiency and practical merits.
",Cybersecurity
"  We study the problem of computing the \textsc{Maxima} of a set of $n$
$d$-dimensional points. For dimensions 2 and 3, there are algorithms to solve
the problem with order-oblivious instance-optimal running time. However, in
higher dimensions there is still room for improvements. We present an algorithm
sensitive to the structural entropy of the input set, which improves the
running time, for large classes of instances, on the best solution for
\textsc{Maxima} to date for $d \ge 4$.
",Cybersecurity
"  We address personalization issues of image captioning, which have not been
discussed yet in previous research. For a query image, we aim to generate a
descriptive sentence, accounting for prior knowledge such as the user's active
vocabularies in previous documents. As applications of personalized image
captioning, we tackle two post automation tasks: hashtag prediction and post
generation, on our newly collected Instagram dataset, consisting of 1.1M posts
from 6.3K users. We propose a novel captioning model named Context Sequence
Memory Network (CSMN). Its unique updates over previous memory network models
include (i) exploiting memory as a repository for multiple types of context
information, (ii) appending previously generated words into memory to capture
long-term information without suffering from the vanishing gradient problem,
and (iii) adopting CNN memory structure to jointly represent nearby ordered
memory slots for better context understanding. With quantitative evaluation and
user studies via Amazon Mechanical Turk, we show the effectiveness of the three
novel features of CSMN and its performance enhancement for personalized image
captioning over state-of-the-art captioning models.
",Cybersecurity
"  In this paper we introduce a new framework to detect elephant flows at very
high speed rates and under uncertainty. The framework provides exact
mathematical formulas to compute the detection likelihood and introduces a new
flow reconstruction lemma under partial information. These theoretical results
lead to the design of BubbleCache, a new elephant flow detection algorithm
designed to operate near the optimal tradeoff between computational scalability
and accuracy by dynamically tracking the traffic's natural cutoff sampling
rate. We demonstrate on a real world 100 Gbps network that the BubbleCache
algorithm helps reduce the computational cost by a factor of 1000 and the
memory requirements by a factor of 100 while detecting the top flows on the
network with very high probability.
",Cybersecurity
"  We propose an optimization approach for determining both hardware and
software parameters for the efficient implementation of a (family of)
applications called dense stencil computations on programmable GPGPUs. We first
introduce a simple, analytical model for the silicon area usage of accelerator
architectures and a workload characterization of stencil computations. We
combine this characterization with a parametric execution time model and
formulate a mathematical optimization problem. That problem seeks to maximize a
common objective function of 'all the hardware and software parameters'. The
solution to this problem, therefore ""solves"" the codesign problem:
simultaneously choosing software-hardware parameters to optimize total
performance.
We validate this approach by proposing architectural variants of the NVIDIA
Maxwell GTX-980 (respectively, Titan X) specifically tuned to a predetermined
workload of four common 2D stencils (Heat, Jacobi, Laplacian, and Gradient) and
two 3D ones (Heat and Laplacian). Our model predicts that performance would
potentially improve by 28% (respectively, 33%) with simple tweaks to the
hardware parameters such as adapting coarse and fine-grained parallelism by
changing the number of streaming multiprocessors and the number of compute
cores each contains. We propose a set of Pareto-optimal design points to
exploit the trade-off between performance and silicon area and show that by
additionally eliminating GPU caches, we can get a further 2-fold improvement.
",Cybersecurity
"  We study the height of a spanning tree $T$ of a graph $G$ obtained by
starting with a single vertex of $G$ and repeatedly selecting, uniformly at
random, an edge of $G$ with exactly one endpoint in $T$ and adding this edge to
$T$.
",Cybersecurity
"  Weighting pixel contribution considering its location is a key feature in
many fundamental image processing tasks including filtering, object modeling
and distance matching. Several techniques have been proposed that incorporate
Spatial information to increase the accuracy and boost the performance of
detection, tracking and recognition systems at the cost of speed. But, it is
still not clear how to efficiently ex- tract weighted local histograms in
constant time using integral histogram. This paper presents a novel algorithm
to compute accurately multi-scale Spatially weighted local histograms in
constant time using Weighted Integral Histogram (SWIH) for fast search. We
applied our spatially weighted integral histogram approach for fast tracking
and obtained more accurate and robust target localization result in comparison
with using plain histogram.
",Cybersecurity
"  This paper studies the problem of remote state estimation in the presence of
a passive eavesdropper. A sensor measures a linear plant's state and transmits
it to an authorized user over a packet-dropping channel, which is susceptible
to eavesdropping. Our goal is to design a coding scheme such that the
eavesdropper cannot infer the plant's current state, while the user
successfully decodes the sent messages. We employ a novel class of codes,
termed State-Secrecy Codes, which are fast and efficient for dynamical systems.
They apply linear time-varying transformations to the current and past states
received by the user. In this way, they force the eavesdropper's information
matrix to decrease with asymptotically the same rate as in the open-loop
prediction case, i.e. when the eavesdropper misses all messages. As a result,
the eavesdropper's minimum mean square error (mmse) for the unstable states
grows unbounded, while the respective error for the stable states converges to
the open-loop prediction one. These secrecy guarantees are achieved under
minimal conditions, which require that, at least once, the user receives the
corresponding packet while the eavesdropper fails to intercept it. Meanwhile,
the user's estimation performance remains optimal. The theoretical results are
illustrated in simulations.
",Cybersecurity
"  Networked system often relies on distributed algorithms to achieve a global
computation goal with iterative local information exchanges between neighbor
nodes. To preserve data privacy, a node may add a random noise to its original
data for information exchange at each iteration. Nevertheless, a neighbor node
can estimate other's original data based on the information it received. The
estimation accuracy and data privacy can be measured in terms of $(\epsilon,
\delta)$-data-privacy, defined as the probability of $\epsilon$-accurate
estimation (the difference of an estimation and the original data is within
$\epsilon$) is no larger than $\delta$ (the disclosure probability). How to
optimize the estimation and analyze data privacy is a critical and open issue.
In this paper, a theoretical framework is developed to investigate how to
optimize the estimation of neighbor's original data using the local information
received, named optimal distributed estimation. Then, we study the disclosure
probability under the optimal estimation for data privacy analysis. We further
apply the developed framework to analyze the data privacy of the
privacy-preserving average consensus algorithm and identify the optimal noises
for the algorithm.
",Cybersecurity
"  An extensive, precise and robust recognition and modeling of the environment
is a key factor for next generations of Advanced Driver Assistance Systems and
development of autonomous vehicles. In this paper, a real-time approach for the
perception of multiple lanes on highways is proposed. Lane markings detected by
camera systems and observations of other traffic participants provide the input
data for the algorithm. The information is accumulated and fused using
GraphSLAM and the result constitutes the basis for a multilane clothoid model.
To allow incorporation of additional information sources, input data is
processed in a generic format. Evaluation of the method is performed by
comparing real data, collected with an experimental vehicle on highways, to a
ground truth map. The results show that ego and adjacent lanes are robustly
detected with high quality up to a distance of 120 m. In comparison to serial
lane detection, an increase in the detection range of the ego lane and a
continuous perception of neighboring lanes is achieved. The method can
potentially be utilized for the longitudinal and lateral control of
self-driving vehicles.
",Cybersecurity
"  In this paper we explore the role of duality principles within the problem of
rotation averaging, a fundamental task in a wide range of computer vision
applications. In its conventional form, rotation averaging is stated as a
minimization over multiple rotation constraints. As these constraints are
non-convex, this problem is generally considered challenging to solve globally.
We show how to circumvent this difficulty through the use of Lagrangian
duality. While such an approach is well-known it is normally not guaranteed to
provide a tight relaxation. Based on spectral graph theory, we analytically
prove that in many cases there is no duality gap unless the noise levels are
severe. This allows us to obtain certifiably global solutions to a class of
important non-convex problems in polynomial time.
We also propose an efficient, scalable algorithm that out-performs general
purpose numerical solvers and is able to handle the large problem instances
commonly occurring in structure from motion settings. The potential of this
proposed method is demonstrated on a number of different problems, consisting
of both synthetic and real-world data.
",Cybersecurity
"  Cellular Automata (CA) theory is a discrete model that represents the state
of each of its cells from a finite set of possible values which evolve in time
according to a pre-defined set of transition rules. CA have been applied to a
number of image processing tasks such as Convex Hull Detection, Image Denoising
etc. but mostly under the limitation of restricting the input to binary images.
In general, a gray-scale image may be converted to a number of different binary
images which are finally recombined after CA operations on each of them
individually. We have developed a multinomial regression based weighed
summation method to recombine binary images for better performance of CA based
Image Processing algorithms. The recombination algorithm is tested for the
specific case of denoising Salt and Pepper Noise to test against standard
benchmark algorithms such as the Median Filter for various images and noise
levels. The results indicate several interesting invariances in the application
of the CA, such as the particular noise realization and the choice of
sub-sampling of pixels to determine recombination weights. Additionally, it
appears that simpler algorithms for weight optimization which seek local minima
work as effectively as those that seek global minima such as Simulated
Annealing.
",Cybersecurity
"  Recent work on encoder-decoder models for sequence-to-sequence mapping has
shown that integrating both temporal and spatial attention mechanisms into
neural networks increases the performance of the system substantially. In this
work, we report on the application of an attentional signal not on temporal and
spatial regions of the input, but instead as a method of switching among inputs
themselves. We evaluate the particular role of attentional switching in the
presence of dynamic noise in the sensors, and demonstrate how the attentional
signal responds dynamically to changing noise levels in the environment to
achieve increased performance on both audio and visual tasks in three
commonly-used datasets: TIDIGITS, Wall Street Journal, and GRID. Moreover, the
proposed sensor transformation network architecture naturally introduces a
number of advantages that merit exploration, including ease of adding new
sensors to existing architectures, attentional interpretability, and increased
robustness in a variety of noisy environments not seen during training.
Finally, we demonstrate that the sensor selection attention mechanism of a
model trained only on the small TIDIGITS dataset can be transferred directly to
a pre-existing larger network trained on the Wall Street Journal dataset,
maintaining functionality of switching between sensors to yield a dramatic
reduction of error in the presence of noise.
",Cybersecurity
"  We explore the properties of byte-level recurrent language models. When given
sufficient amounts of capacity, training data, and compute time, the
representations learned by these models include disentangled features
corresponding to high-level concepts. Specifically, we find a single unit which
performs sentiment analysis. These representations, learned in an unsupervised
manner, achieve state of the art on the binary subset of the Stanford Sentiment
Treebank. They are also very data efficient. When using only a handful of
labeled examples, our approach matches the performance of strong baselines
trained on full datasets. We also demonstrate the sentiment unit has a direct
influence on the generative process of the model. Simply fixing its value to be
positive or negative generates samples with the corresponding positive or
negative sentiment.
",Cybersecurity
"  Memristive crossbars have become a popular means for realizing unsupervised
and supervised learning techniques. In previous neuromorphic architectures with
leaky integrate-and-fire neurons, the crossbar itself has been separated from
the neuron capacitors to preserve mathematical rigor. In this work, we sought
to simplify the design, creating a fast circuit that consumed significantly
lower power at a minimal cost of accuracy. We also showed that connecting the
neurons directly to the crossbar resulted in a more efficient sparse coding
architecture, and alleviated the need to pre-normalize receptive fields. This
work provides derivations for the design of such a network, named the Simple
Spiking Locally Competitive Algorithm, or SSLCA, as well as CMOS designs and
results on the CIFAR and MNIST datasets. Compared to a non-spiking model which
scored 33% on CIFAR-10 with a single-layer classifier, this hardware scored 32%
accuracy. When used with a state-of-the-art deep learning classifier, the
non-spiking model achieved 82% and our simplified, spiking model achieved 80%,
while compressing the input data by 92%. Compared to a previously proposed
spiking model, our proposed hardware consumed 99% less energy to do the same
work at 21x the throughput. Accuracy held out with online learning to a write
variance of 3%, suitable for the often-reported 4-bit resolution required for
neuromorphic algorithms; with offline learning to a write variance of 27%; and
with read variance to 40%. The proposed architecture's excellent accuracy,
throughput, and significantly lower energy usage demonstrate the utility of our
innovations.
",Cybersecurity
"  A variety of real-world processes (over networks) produce sequences of data
whose complex temporal dynamics need to be studied. More especially, the event
timestamps can carry important information about the underlying network
dynamics, which otherwise are not available from the time-series evenly sampled
from continuous signals. Moreover, in most complex processes, event sequences
and evenly-sampled times series data can interact with each other, which
renders joint modeling of those two sources of data necessary. To tackle the
above problems, in this paper, we utilize the rich framework of (temporal)
point processes to model event data and timely update its intensity function by
the synergic twin Recurrent Neural Networks (RNNs). In the proposed
architecture, the intensity function is synergistically modulated by one RNN
with asynchronous events as input and another RNN with time series as input.
Furthermore, to enhance the interpretability of the model, the attention
mechanism for the neural point process is introduced. The whole model with
event type and timestamp prediction output layers can be trained end-to-end and
allows a black-box treatment for modeling the intensity. We substantiate the
superiority of our model in synthetic data and three real-world benchmark
datasets.
",Cybersecurity
"  Behavioral annotation using signal processing and machine learning is highly
dependent on training data and manual annotations of behavioral labels.
Previous studies have shown that speech information encodes significant
behavioral information and be used in a variety of automated behavior
recognition tasks. However, extracting behavior information from speech is
still a difficult task due to the sparseness of training data coupled with the
complex, high-dimensionality of speech, and the complex and multiple
information streams it encodes. In this work we exploit the slow varying
properties of human behavior. We hypothesize that nearby segments of speech
share the same behavioral context and hence share a similar underlying
representation in a latent space. Specifically, we propose a Deep Neural
Network (DNN) model to connect behavioral context and derive the behavioral
manifold in an unsupervised manner. We evaluate the proposed manifold in the
couples therapy domain and also provide examples from publicly available data
(e.g. stand-up comedy). We further investigate training within the couples'
therapy domain and from movie data. The results are extremely encouraging and
promise improved behavioral quantification in an unsupervised manner and
warrants further investigation in a range of applications.
",Cybersecurity
"  To aid a variety of research studies, we propose TWIROLE, a hybrid model for
role-related user classification on Twitter, which detects male-related,
female-related, and brand-related (i.e., organization or institution) users.
TWIROLE leverages features from tweet contents, user profiles, and profile
images, and then applies our hybrid model to identify a user's role. To
evaluate it, we used two existing large datasets about Twitter users, and
conducted both intra- and inter-comparison experiments. TWIROLE outperforms
existing methods and obtains more balanced results over the several roles. We
also confirm that user names and profile images are good indicators for this
task. Our research extends prior work that does not consider brand-related
users, and is an aid to future evaluation efforts relative to investigations
that rely upon self-labeled datasets.
",Cybersecurity
"  Clustering problems are well-studied in a variety of fields such as data
science, operations research, and computer science. Such problems include
variants of centre location problems, $k$-median, and $k$-means to name a few.
In some cases, not all data points need to be clustered; some may be discarded
for various reasons.
We study clustering problems with outliers. More specifically, we look at
Uncapacitated Facility Location (UFL), $k$-Median, and $k$-Means. In UFL with
outliers, we have to open some centres, discard up to $z$ points of $\cal X$
and assign every other point to the nearest open centre, minimizing the total
assignment cost plus centre opening costs. In $k$-Median and $k$-Means, we have
to open up to $k$ centres but there are no opening costs. In $k$-Means, the
cost of assigning $j$ to $i$ is $\delta^2(j,i)$. We present several results.
Our main focus is on cases where $\delta$ is a doubling metric or is the
shortest path metrics of graphs from a minor-closed family of graphs. For
uniform-cost UFL with outliers on such metrics we show that a multiswap simple
local search heuristic yields a PTAS. With a bit more work, we extend this to
bicriteria approximations for the $k$-Median and $k$-Means problems in the same
metrics where, for any constant $\epsilon > 0$, we can find a solution using
$(1+\epsilon)k$ centres whose cost is at most a $(1+\epsilon)$-factor of the
optimum and uses at most $z$ outliers. We also show that natural local search
heuristics that do not violate the number of clusters and outliers for
$k$-Median (or $k$-Means) will have unbounded gap even in Euclidean metrics.
Furthermore, we show how our analysis can be extended to general metrics for
$k$-Means with outliers to obtain a $(25+\epsilon,1+\epsilon)$ bicriteria.
",Cybersecurity
"  Understanding shading effects in images is critical for a variety of vision
and graphics problems, including intrinsic image decomposition, shadow removal,
image relighting, and inverse rendering. As is the case with other vision
tasks, machine learning is a promising approach to understanding shading - but
there is little ground truth shading data available for real-world images. We
introduce Shading Annotations in the Wild (SAW), a new large-scale, public
dataset of shading annotations in indoor scenes, comprised of multiple forms of
shading judgments obtained via crowdsourcing, along with shading annotations
automatically generated from RGB-D imagery. We use this data to train a
convolutional neural network to predict per-pixel shading information in an
image. We demonstrate the value of our data and network in an application to
intrinsic images, where we can reduce decomposition artifacts produced by
existing algorithms. Our database is available at
this http URL.
",Cybersecurity
"  Smartphones have ubiquitously integrated into our home and work environments,
however, users normally rely on explicit but inefficient identification
processes in a controlled environment. Therefore, when a device is stolen, a
thief can have access to the owner's personal information and services against
the stored password/s. As a result of this potential scenario, this work
demonstrates the possibilities of legitimate user identification in a
semi-controlled environment through the built-in smartphones motion dynamics
captured by two different sensors. This is a two-fold process: sub-activity
recognition followed by user/impostor identification. Prior to the
identification; Extended Sammon Projection (ESP) method is used to reduce the
redundancy among the features. To validate the proposed system, we first
collected data from four users walking with their device freely placed in one
of their pants pockets. Through extensive experimentation, we demonstrate that
together time and frequency domain features optimized by ESP to train the
wavelet kernel based extreme learning machine classifier is an effective system
to identify the legitimate user or an impostor with \(97\%\) accuracy.
",Cybersecurity
"  This work presents a methodology to design trajectory tracking feedback
control laws, which embed non-parametric statistical models, such as Gaussian
Processes (GPs). The aim is to minimize unmodeled dynamics such as undesired
slippages. The proposed approach has the benefit of avoiding complex
terramechanics analysis to directly estimate from data the robot dynamics on a
wide class of trajectories. Experiments in both real and simulated environments
prove that the proposed methodology is promising.
",Cybersecurity
"  This paper presents two novel control methodologies for the cooperative
manipulation of an object by N robotic agents. Firstly, we design an adaptive
control protocol which employs quaternion feedback for the object orientation
to avoid potential representation singularities. Secondly, we propose a control
protocol that guarantees predefined transient and steady-state performance for
the object trajectory. Both methodologies are decentralized, since the agents
calculate their own signals without communicating with each other, as well as
robust to external disturbances and model uncertainties. Moreover, we consider
that the grasping points are rigid, and avoid the need for force/torque
measurements. Load distribution is also included via a grasp matrix
pseudo-inverse to account for potential differences in the agents' power
capabilities. Finally, simulation and experimental results with two robotic
arms verify the theoretical findings.
",Cybersecurity
"  Next Generation Sequencing (NGS) technology has resulted in massive amounts
of proteomics and genomics data. This data is of no use if it is not properly
analyzed. ETL (Extraction, Transformation, Loading) is an important step in
designing data analytics applications. ETL requires proper understanding of
features of data. Data format plays a key role in understanding of data,
representation of data, space required to store data, data I/O during
processing of data, intermediate results of processing, in-memory analysis of
data and overall time required to process data. Different data mining and
machine learning algorithms require input data in specific types and formats.
This paper explores the data formats used by different tools and algorithms and
also presents modern data formats that are used on Big Data Platform. It will
help researchers and developers in choosing appropriate data format to be used
for a particular tool or algorithm.
",Cybersecurity
"  The use of standard robotic platforms can accelerate research and lower the
entry barrier for new research groups. There exist many affordable humanoid
standard platforms in the lower size ranges of up to 60cm, but larger humanoid
robots quickly become less affordable and more difficult to operate, maintain
and modify. The igus Humanoid Open Platform is a new and affordable, fully
open-source humanoid platform. At 92cm in height, the robot is capable of
interacting in an environment meant for humans, and is equipped with enough
sensors, actuators and computing power to support researchers in many fields.
The structure of the robot is entirely 3D printed, leading to a lightweight and
visually appealing design. The main features of the platform are described in
this article.
",Cybersecurity
"  The domain name system translates human friendly web addresses to a computer
readable internet protocol address. This basic infrastructure is insecure and
can be manipulated. Deployment of technology to secure the DNS system has been
slow, reaching about 20% of all web sites based in the USA. Little is known
about the efforts hospitals and health systems make to secure the domain name
system for their websites. To investigate the prevalence of implementing Domain
Name System Security Extensions (DNSSEC), we analyzed the websites of the 210
public hospitals in the state of Illinois, USA. Only one Illinois hospital
website was found to have implemented DNSSEC by December, 2017.
",Cybersecurity
"  In this paper we address the problem of generating all elements obtained by
the saturation of an initial set by some operations. More precisely, we prove
that we can generate the closure of a boolean relation (a set of boolean
vectors) by polymorphisms with a polynomial delay. Therefore we can compute
with polynomial delay the closure of a family of sets by any set of ""set
operations"": union, intersection, symmetric difference, subsets, supersets
$\dots$). To do so, we study the $Membership_{\mathcal{F}}$ problem: for a set
of operations $\mathcal{F}$, decide whether an element belongs to the closure
by $\mathcal{F}$ of a family of elements. In the boolean case, we prove that
$Membership_{\mathcal{F}}$ is in P for any set of boolean operations
$\mathcal{F}$. When the input vectors are over a domain larger than two
elements, we prove that the generic enumeration method fails, since
$Membership_{\mathcal{F}}$ is NP-hard for some $\mathcal{F}$. We also study the
problem of generating minimal or maximal elements of closures and prove that
some of them are related to well known enumeration problems such as the
enumeration of the circuits of a matroid or the enumeration of maximal
independent sets of a hypergraph. This article improves on previous works of
the same authors.
",Cybersecurity
"  An extremely simple, description of Karmarkar's algorithm with very few
technical terms is given.
",Cybersecurity
"  Traditional intelligent fault diagnosis of rolling bearings work well only
under a common assumption that the labeled training data (source domain) and
unlabeled testing data (target domain) are drawn from the same distribution.
When the distribution changes, most fault diagnosis models need to be rebuilt
from scratch using newly recollected labeled training data. However, it is
expensive or impossible to annotate huge amount of training data to rebuild
such new model. Meanwhile, large amounts of labeled training data have not been
fully utilized yet, which is apparently a waste of resources. As one of the
important research directions of transfer learning, domain adaptation (DA)
typically aims at minimizing the differences between distributions of different
domains in order to minimize the cross-domain prediction error by taking full
advantage of information coming from both source and target domains. In this
paper, we present one of the first studies on unsupervised DA in the field of
fault diagnosis of rolling bearings under varying working conditions and a
novel diagnosis strategy based on unsupervised DA using subspace alignment (SA)
is proposed. After processed by unsupervised DA with SA, the distributions of
training data and testing data become close and the classifier trained on
training data can be used to classify the testing data. Experimental results on
the 60 domain adaptation diagnosis problems under varying working condition in
Case Western Reserve benchmark data and 12 domain adaptation diagnosis problems
under varying working conditions in our new data are given to demonstrate the
effectiveness of the proposed method. The proposed methods can effectively
distinguish not only bearing faults categories but also fault severities.
",Cybersecurity
"  We present a practical approach for processing mobile sensor time series data
for continual deep learning predictions. The approach comprises data cleaning,
normalization, capping, time-based compression, and finally classification with
a recurrent neural network. We demonstrate the effectiveness of the approach in
a case study with 279 participants. On the basis of sparse sensor events, the
network continually predicts whether the participants would attend to a
notification within 10 minutes. Compared to a random baseline, the classifier
achieves a 40% performance increase (AUC of 0.702) on a withheld test set. This
approach allows to forgo resource-intensive, domain-specific, error-prone
feature engineering, which may drastically increase the applicability of
machine learning to mobile phone sensor data.
",Cybersecurity
"  Recent studies have shown that sketches and diagrams play an important role
in the daily work of software developers. If these visual artifacts are
archived, they are often detached from the source code they document, because
there is no adequate tool support to assist developers in capturing, archiving,
and retrieving sketches related to certain source code artifacts. This paper
presents SketchLink, a tool that aims at increasing the value of sketches and
diagrams created during software development by supporting developers in these
tasks. Our prototype implementation provides a web application that employs the
camera of smartphones and tablets to capture analog sketches, but can also be
used on desktop computers to upload, for instance, computer-generated diagrams.
We also implemented a plugin for a Java IDE that embeds the links in Javadoc
comments and visualizes them in situ in the source code editor as graphical
icons.
",Cybersecurity
"  In this paper, we consider the problem of formally verifying the safety of an
autonomous robot equipped with a Neural Network (NN) controller that processes
LiDAR images to produce control actions. Given a workspace that is
characterized by a set of polytopic obstacles, our objective is to compute the
set of safe initial conditions such that a robot trajectory starting from these
initial conditions is guaranteed to avoid the obstacles. Our approach is to
construct a finite state abstraction of the system and use standard
reachability analysis over the finite state abstraction to compute the set of
the safe initial states. The first technical problem in computing the finite
state abstraction is to mathematically model the imaging function that maps the
robot position to the LiDAR image. To that end, we introduce the notion of
imaging-adapted sets as partitions of the workspace in which the imaging
function is guaranteed to be affine. We develop a polynomial-time algorithm to
partition the workspace into imaging-adapted sets along with computing the
corresponding affine imaging functions. Given this workspace partitioning, a
discrete-time linear dynamics of the robot, and a pre-trained NN controller
with Rectified Linear Unit (ReLU) nonlinearity, the second technical challenge
is to analyze the behavior of the neural network. To that end, we utilize a
Satisfiability Modulo Convex (SMC) encoding to enumerate all the possible
segments of different ReLUs. SMC solvers then use a Boolean satisfiability
solver and a convex programming solver and decompose the problem into smaller
subproblems. To accelerate this process, we develop a pre-processing algorithm
that could rapidly prune the space feasible ReLU segments. Finally, we
demonstrate the efficiency of the proposed algorithms using numerical
simulations with increasing complexity of the neural network controller.
",Cybersecurity
"  The Vocal Joystick Vowel Corpus, by Washington University, was used to study
monophthongs pronounced by native English speakers. The objective of this study
was to quantitatively measure the extent at which speech recognition methods
can distinguish between similar sounding vowels. In particular, the phonemes
/\textipa{@}/, /{\ae}/, /\textipa{A}:/ and /\textipa{2}/ were analysed. 748
sound files from the corpus were used and subjected to Linear Predictive Coding
(LPC) to compute their formants, and to Mel Frequency Cepstral Coefficients
(MFCC) algorithm, to compute the cepstral coefficients. A Decision Tree
Classifier was used to build a predictive model that learnt the patterns of the
two first formants measured in the data set, as well as the patterns of the 13
cepstral coefficients. An accuracy of 70\% was achieved using formants for the
mentioned phonemes. For the MFCC analysis an accuracy of 52 \% was achieved and
an accuracy of 71\% when /\textipa{@}/ was ignored. The results obtained show
that the studied algorithms are far from mimicking the ability of
distinguishing subtle differences in sounds like human hearing does.
",Cybersecurity
"  We describe algorithms to compute elliptic functions and their relatives
(Jacobi theta functions, modular forms, elliptic integrals, and the
arithmetic-geometric mean) numerically to arbitrary precision with rigorous
error bounds for arbitrary complex variables. Implementations in ball
arithmetic are available in the open source Arb library. We discuss the
algorithms from a concrete implementation point of view, with focus on
performance at tens to thousands of digits of precision.
",Cybersecurity
"  This paper studies an auction design problem for a seller to sell a commodity
in a social network, where each individual (the seller or a buyer) can only
communicate with her neighbors. The challenge to the seller is to design a
mechanism to incentivize the buyers, who are aware of the auction, to further
propagate the information to their neighbors so that more buyers will
participate in the auction and hence, the seller will be able to make a higher
revenue. We propose a novel auction mechanism, called information diffusion
mechanism (IDM), which incentivizes the buyers to not only truthfully report
their valuations on the commodity to the seller, but also further propagate the
auction information to all their neighbors. In comparison, the direct extension
of the well-known Vickrey-Clarke-Groves (VCG) mechanism in social networks can
also incentivize the information diffusion, but it will decrease the seller's
revenue or even lead to a deficit sometimes. The formalization of the problem
has not yet been addressed in the literature of mechanism design and our
solution is very significant in the presence of large-scale online social
networks.
",Cybersecurity
"  PAWS is a tool to analyse the behaviour of weighted automata and conditional
transition systems. At its core PAWS is based on a generic implementation of
algorithms for checking language equivalence in weighted automata and
bisimulation in conditional transition systems. This architecture allows for
the use of arbitrary user-defined semirings. New semirings can be generated
during run-time and the user can rely on numerous automatisation techniques to
create new semiring structures for PAWS' algorithms. Basic semirings such as
distributive complete lattices and fields of fractions can be defined by
specifying few parameters, more exotic semirings can be generated from other
semirings or defined from scratch using a built-in semiring generator. In the
most general case, users can define new semirings by programming (in C#) the
base operations of the semiring and a procedure to solve linear equations and
use their newly generated semiring in the analysis tools that PAWS offers.
",Cybersecurity
"  Drafting strong players is crucial for the team success. We describe a new
data-driven interpretable approach for assessing draft prospects in the
National Hockey League. Successful previous approaches have built a predictive
model based on player features, or derived performance predictions from the
observed performance of comparable players in a cohort. This paper develops
model tree learning, which incorporates strengths of both model-based and
cohort-based approaches. A model tree partitions the feature space according to
the values of discrete features, or learned thresholds for continuous features.
Each leaf node in the tree defines a group of players, easily described to
hockey experts, with its own group regression model. Compared to a single
model, the model tree forms an ensemble that increases predictive power.
Compared to cohort-based approaches, the groups of comparables are discovered
from the data, without requiring a similarity metric. The performance
predictions of the model tree are competitive with the state-of-the-art
methods, which validates our model empirically. We show in case studies that
the model tree player ranking can be used to highlight strong and weak points
of players.
",Cybersecurity
"  With the purpose of modeling, specifying and reasoning in an integrated
fashion with procedural and declarative aspects (both commonly present in cases
or scenarios), the paper introduces Logic Programming Petri Nets (LPPN), an
extension to the Petri Net notation providing an interface to logic programming
constructs. Two semantics are presented. First, a hybrid operational semantics
that separates the process component, treated with Petri nets, from the
constraint/terminological component, treated with Answer Set Programming (ASP).
Second, a denotational semantics maps the notation to ASP fully, via Event
Calculus. These two alternative specifications enable a preliminary evaluation
in terms of reasoning efficiency.
",Cybersecurity
"  The spot pricing scheme has been considered to be resource-efficient for
providers and cost-effective for consumers in the Cloud market. Nevertheless,
unlike the static and straightforward strategies of trading on-demand and
reserved Cloud services, the market-driven mechanism for trading spot service
would be complicated for both implementation and understanding. The largely
invisible market activities and their complex interactions could especially
make Cloud consumers hesitate to enter the spot market. To reduce the
complexity in understanding the Cloud spot market, we decided to reveal the
backend information behind spot price variations. Inspired by the methodology
of reverse engineering, we developed a Predator-Prey model that can simulate
the interactions between demand and resource based on the visible spot price
traces. The simulation results have shown some basic regular patterns of market
activities with respect to Amazon's spot instance type m3.large. Although the
findings of this study need further validation by using practical data, our
work essentially suggests a promising approach (i.e.~using a Predator-Prey
model) to investigate spot market activities.
",Cybersecurity
"  In this paper, we extend state of the art Model Predictive Control (MPC)
approaches to generate safe bipedal walking on slippery surfaces. In this
setting, we formulate walking as a trade off between realizing a desired
walking velocity and preserving robust foot-ground contact. Exploiting this
formulation inside MPC, we show that safe walking on various flat terrains can
be achieved by compromising three main attributes, i. e. walking velocity
tracking, the Zero Moment Point (ZMP) modulation, and the Required Coefficient
of Friction (RCoF) regulation. Simulation results show that increasing the
walking velocity increases the possibility of slippage, while reducing the
slippage possibility conflicts with reducing the tip-over possibility of the
contact and vice versa.
",Cybersecurity
"  We explore the power of spatial context as a self-supervisory signal for
learning visual representations. In particular, we propose spatial context
networks that learn to predict a representation of one image patch from another
image patch, within the same image, conditioned on their real-valued relative
spatial offset. Unlike auto-encoders, that aim to encode and reconstruct
original image patches, our network aims to encode and reconstruct intermediate
representations of the spatially offset patches. As such, the network learns a
spatially conditioned contextual representation. By testing performance with
various patch selection mechanisms we show that focusing on object-centric
patches is important, and that using object proposal as a patch selection
mechanism leads to the highest improvement in performance. Further, unlike
auto-encoders, context encoders [21], or other forms of unsupervised feature
learning, we illustrate that contextual supervision (with pre-trained model
initialization) can improve on existing pre-trained model performance. We build
our spatial context networks on top of standard VGG_19 and CNN_M architectures
and, among other things, show that we can achieve improvements (with no
additional explicit supervision) over the original ImageNet pre-trained VGG_19
and CNN_M models in object categorization and detection on VOC2007.
",Cybersecurity
"  Existing shape estimation methods for deformable object manipulation suffer
from the drawbacks of being off-line, model dependent, noise-sensitive or
occlusion-sensitive, and thus are not appropriate for manipulation tasks
requiring high precision. In this paper, we present a real-time shape
estimation approach for autonomous robotic manipulation of 3D deformable
objects. Our method fulfills all the requirements necessary for the
high-quality deformable object manipulation in terms of being real-time,
model-free and robust to noise and occlusion. These advantages are accomplished
using a joint tracking and reconstruction framework, in which we track the
object deformation by aligning a reference shape model with the stream input
from the RGB-D camera, and simultaneously upgrade the reference shape model
according to the newly captured RGB-D data. We have evaluated the quality and
robustness of our real-time shape estimation pipeline on a set of deformable
manipulation tasks implemented on physical robots. Videos are available at
this https URL
",Cybersecurity
"  Tensor factorization with hard and/or soft constraints has played an
important role in signal processing and data analysis. However, existing
algorithms for constrained tensor factorization have two drawbacks: (i) they
require matrix-inversion; and (ii) they cannot (or at least is very difficult
to) handle structured regularizations. We propose a new tensor factorization
algorithm that circumvents these drawbacks. The proposed method is built upon
alternating optimization, and each subproblem is solved by a primal-dual
splitting algorithm, yielding an efficient and flexible algorithmic framework
to constrained tensor factorization. The advantages of the proposed method over
a state-of-the-art constrained tensor factorization algorithm, called AO-ADMM,
are demonstrated on regularized nonnegative tensor factorization.
",Cybersecurity
"  Context: Poor usability of cryptographic APIs is a severe source of
vulnerabilities. Aim: We wanted to find out what kind of cryptographic
libraries are present in Rust and how usable they are. Method: We explored
Rust's cryptographic libraries through a systematic search, conducted an
exploratory study on the major libraries and a controlled experiment on two of
these libraries with 28 student participants. Results: Only half of the major
libraries explicitly focus on usability and misuse resistance, which is
reflected in their current APIs. We found that participants were more
successful using rust-crypto which we considered less usable than ring before
the experiment. Conclusion: We discuss API design insights and make
recommendations for the design of crypto libraries in Rust regarding the detail
and structure of the documentation, higher-level APIs as wrappers for the
existing low-level libraries, and selected, good-quality example code to
improve the emerging cryptographic libraries of Rust.
",Cybersecurity
"  This paper describes a massively parallel code for a state-of-the art thermal
lattice- Boltzmann method. Our code has been carefully optimized for
performance on one GPU and to have a good scaling behavior extending to a large
number of GPUs. Versions of this code have been already used for large-scale
studies of convective turbulence. GPUs are becoming increasingly popular in HPC
applications, as they are able to deliver higher performance than traditional
processors. Writing efficient programs for large clusters is not an easy task
as codes must adapt to increasingly parallel architectures, and the overheads
of node-to-node communications must be properly handled. We describe the
structure of our code, discussing several key design choices that were guided
by theoretical models of performance and experimental benchmarks. We present an
extensive set of performance measurements and identify the corresponding main
bot- tlenecks; finally we compare the results of our GPU code with those
measured on other currently available high performance processors. Our results
are a production-grade code able to deliver a sustained performance of several
tens of Tflops as well as a design and op- timization methodology that can be
used for the development of other high performance applications for
computational physics.
",Cybersecurity
"  We explore inflectional morphology as an example of the relationship of the
discrete and the continuous in linguistics. The grammar requests a form of a
lexeme by specifying a set of feature values, which corresponds to a corner M
of a hypercube in feature value space. The morphology responds to that request
by providing a morpheme, or a set of morphemes, whose vector sum is
geometrically closest to the corner M. In short, the chosen morpheme $\mu$ is
the morpheme (or set of morphemes) that maximizes the inner product of $\mu$
and M.
",Cybersecurity
"  Context: Information Technology consumes up to 10\% of the world's
electricity generation, contributing to CO2 emissions and high energy costs.
Data centers, particularly databases, use up to 23% of this energy. Therefore,
building an energy-efficient (green) database engine could reduce energy
consumption and CO2 emissions.
Goal: To understand the factors driving databases' energy consumption and
execution time throughout their evolution.
Method: We conducted an empirical case study of energy consumption by two
MySQL database engines, InnoDB and MyISAM, across 40 releases. We examined the
relationships of four software metrics to energy consumption and execution time
to determine which metrics reflect the greenness and performance of a database.
Results: Our analysis shows that database engines' energy consumption and
execution time increase as databases evolve. Moreover, the Lines of Code metric
is correlated moderately to strongly with energy consumption and execution time
in 88% of cases.
Conclusions: Our findings provide insights to both practitioners and
researchers. Database administrators may use them to select a fast, green
release of the MySQL database engine. MySQL database-engine developers may use
the software metric to assess products' greenness and performance. Researchers
may use our findings to further develop new hypotheses or build models to
predict greenness and performance of databases.
",Cybersecurity
"  The identification of reduced-order models from high-dimensional data is a
challenging task, and even more so if the identified system should not only be
suitable for a certain data set, but generally approximate the input-output
behavior of the data source. In this work, we consider the input-output dynamic
mode decomposition method for system identification. We compare excitation
approaches for the data-driven identification process and describe an
optimization-based stabilization strategy for the identified systems.
",Cybersecurity
"  Preference elicitation is the task of suggesting a highly preferred
configuration to a decision maker. The preferences are typically learned by
querying the user for choice feedback over pairs or sets of objects. In its
constructive variant, new objects are synthesized ""from scratch"" by maximizing
an estimate of the user utility over a combinatorial (possibly infinite) space
of candidates. In the constructive setting, most existing elicitation
techniques fail because they rely on exhaustive enumeration of the candidates.
A previous solution explicitly designed for constructive tasks comes with no
formal performance guarantees, and can be very expensive in (or unapplicable
to) problems with non-Boolean attributes. We propose the Choice Perceptron, a
Perceptron-like algorithm for learning user preferences from set-wise choice
feedback over constructive domains and hybrid Boolean-numeric feature spaces.
We provide a theoretical analysis on the attained regret that holds for a large
class of query selection strategies, and devise a heuristic strategy that aims
at optimizing the regret in practice. Finally, we demonstrate its effectiveness
by empirical evaluation against existing competitors on constructive scenarios
of increasing complexity.
",Cybersecurity
"  Disjoint-Set forests, consisting of Union-Find trees, are data structures
having a widespread practical application due to their efficiency. Despite them
being well-known, no exact structural characterization of these trees is known
(such a characterization exists for Union trees which are constructed without
using path compression) for the case assuming union-by-rank strategy for
merging. In this paper we provide such a characterization by means of a simple
push operation and show that the decision problem whether a given tree (along
with the rank info of its nodes) is a Union-Find tree is NP-complete,
complementing our earlier similar result for the union-by-size strategy.
",Cybersecurity
"  Deep Learning (DL) methods show very good performance when trained on large,
balanced data sets. However, many practical problems involve imbalanced data
sets, or/and classes with a small number of training samples. The performance
of DL methods as well as more traditional classifiers drops significantly in
such settings. Most of the existing solutions for imbalanced problems focus on
customizing the data for training. A more principled solution is to use mixed
Hinge-Minimax risk [19] specifically designed to solve binary problems with
imbalanced training sets. Here we propose a Latent Hinge Minimax (LHM) risk and
a training algorithm that generalizes this paradigm to an ensemble of
hyperplanes that can form arbitrary complex, piecewise linear boundaries. To
extract good features, we combine LHM model with CNN via transfer learning. To
solve multi-class problem we map pre-trained category-specific LHM classifiers
to a multi-class neural network and adjust the weights with very fast tuning.
LHM classifier enables the use of unlabeled data in its training and the
mapping allows for multi-class inference, resulting in a classifier that
performs better than alternatives when trained on a small number of training
samples.
",Cybersecurity
"  Memory-safety violations are a prevalent cause of both reliability and
security vulnerabilities in systems software written in unsafe languages like
C/C++. Unfortunately, all the existing software-based solutions to this problem
exhibit high performance overheads preventing them from wide adoption in
production runs. To address this issue, Intel recently released a new ISA
extension - Memory Protection Extensions (Intel MPX), a hardware-assisted
full-stack solution to protect against memory safety violations. In this work,
we perform an exhaustive study of the Intel MPX architecture to understand its
advantages and caveats. We base our study along three dimensions: (a)
performance overheads, (b) security guarantees, and (c) usability issues. To
put our results in perspective, we compare Intel MPX with three prominent
software-based approaches: (1) trip-wire - AddressSanitizer, (2) object-based -
SAFECode, and (3) pointer-based - SoftBound. Our main conclusion is that Intel
MPX is a promising technique that is not yet practical for widespread adoption.
Intel MPX's performance overheads are still high (roughly 50% on average), and
the supporting infrastructure has bugs which may cause compilation or runtime
errors. Moreover, we showcase the design limitations of Intel MPX: it cannot
detect temporal errors, may have false positives and false negatives in
multithreaded code, and its restrictions on memory layout require substantial
code changes for some programs.
",Cybersecurity
"  As robotic systems are moved out of factory work cells into human-facing
environments questions of choreography become central to their design,
placement, and application. With a human viewer or counterpart present, a
system will automatically be interpreted within context, style of movement, and
form factor by human beings as animate elements of their environment. The
interpretation by this human counterpart is critical to the success of the
system's integration: knobs on the system need to make sense to a human
counterpart; an artificial agent should have a way of notifying a human
counterpart of a change in system state, possibly through motion profiles; and
the motion of a human counterpart may have important contextual clues for task
completion. Thus, professional choreographers, dance practitioners, and
movement analysts are critical to research in robotics. They have design
methods for movement that align with human audience perception, can identify
simplified features of movement for human-robot interaction goals, and have
detailed knowledge of the capacity of human movement. This article provides
approaches employed by one research lab, specific impacts on technical and
artistic projects within, and principles that may guide future such work. The
background section reports on choreography, somatic perspectives,
improvisation, the Laban/Bartenieff Movement System, and robotics. From this
context methods including embodied exercises, writing prompts, and community
building activities have been developed to facilitate interdisciplinary
research. The results of this work is presented as an overview of a smattering
of projects in areas like high-level motion planning, software development for
rapid prototyping of movement, artistic output, and user studies that help
understand how people interpret movement. Finally, guiding principles for other
groups to adopt are posited.
",Cybersecurity
"  School bus planning is usually divided into routing and scheduling due to the
complexity of solving them concurrently. However, the separation between these
two steps may lead to worse solutions with higher overall costs than that from
solving them together. When finding the minimal number of trips in the routing
problem, neglecting the importance of trip compatibility may increase the
number of buses actually needed in the scheduling problem. This paper proposes
a new formulation for the multi-school homogeneous fleet routing problem that
maximizes trip compatibility while minimizing total travel time. This
incorporates the trip compatibility for the scheduling problem in the routing
problem. Since the problem is inherently just a routing problem, finding a good
solution is not cumbersome. To compare the performance of the model with
traditional routing problems, we generate eight mid-size data sets. Through
importing the generated trips of the routing problems into the bus scheduling
(blocking) problem, it is shown that the proposed model uses up to 13% fewer
buses than the common traditional routing models.
",Cybersecurity
"  Objective: The Learning Health System (LHS) requires integration of research
into routine practice. eSource or embedding clinical trial functionalities into
routine electronic health record (EHR) systems has long been put forward as a
solution to the rising costs of research. We aimed to create and validate an
eSource solution that would be readily extensible as part of a LHS.
Materials and Methods: The EU FP7 TRANSFoRm project's approach is based on
dual modelling, using the Clinical Research Information Model (CRIM) and the
Clinical Data Integration Model of meaning (CDIM) to bridge the gap between
clinical and research data structures, using the CDISC Operational Data Model
(ODM) standard. Validation against GCP requirements was conducted in a clinical
site, and a cluster randomised evaluation by site nested into a live clinical
trial.
Results: Using the form definition element of ODM, we linked precisely
modelled data queries to data elements, constrained against CDIM concepts, to
enable automated patient identification for specific protocols and
prepopulation of electronic case report forms (e-CRF). Both control and eSource
sites recruited better than expected with no significant difference.
Completeness of clinical forms was significantly improved by eSource, but
Patient Related Outcome Measures (PROMs) were less well completed on
smartphones than paper in this population.
Discussion: The TRANSFoRm approach provides an ontologically-based approach
to eSource in a low-resource, heterogeneous, highly distributed environment,
that allows precise prospective mapping of data elements in the EHR.
Conclusion: Further studies using this approach to CDISC should optimise the
delivery of PROMS, whilst building a sustainable infrastructure for eSource
with research networks, trials units and EHR vendors.
",Cybersecurity
"  In February 2016, World Health Organization declared the Zika outbreak a
Public Health Emergency of International Concern. With developing evidence it
can cause birth defects, and the Summer Olympics coming up in the worst
affected country, Brazil, the virus caught fire on social media. In this work,
use Zika as a case study in building a tool for tracking the misinformation
around health concerns on Twitter. We collect more than 13 million tweets --
spanning the initial reports in February 2016 and the Summer Olympics --
regarding the Zika outbreak and track rumors outlined by the World Health
Organization and Snopes fact checking website. The tool pipeline, which
incorporates health professionals, crowdsourcing, and machine learning, allows
us to capture health-related rumors around the world, as well as clarification
campaigns by reputable health organizations. In the case of Zika, we discover
an extremely bursty behavior of rumor-related topics, and show that, once the
questionable topic is detected, it is possible to identify rumor-bearing tweets
using automated techniques. Thus, we illustrate insights the proposed tools
provide into potentially harmful information on social media, allowing public
health researchers and practitioners to respond with a targeted and timely
action.
",Cybersecurity
"  We study the two-dimensional geometric knapsack problem (2DK) in which we are
given a set of n axis-aligned rectangular items, each one with an associated
profit, and an axis-aligned square knapsack. The goal is to find a
(non-overlapping) packing of a maximum profit subset of items inside the
knapsack (without rotating items). The best-known polynomial-time approximation
factor for this problem (even just in the cardinality case) is (2 + \epsilon)
[Jansen and Zhang, SODA 2004].
In this paper, we break the 2 approximation barrier, achieving a
polynomial-time (17/9 + \epsilon) < 1.89 approximation, which improves to
(558/325 + \epsilon) < 1.72 in the cardinality case. Essentially all prior work
on 2DK approximation packs items inside a constant number of rectangular
containers, where items inside each container are packed using a simple greedy
strategy. We deviate for the first time from this setting: we show that there
exists a large profit solution where items are packed inside a constant number
of containers plus one L-shaped region at the boundary of the knapsack which
contains items that are high and narrow and items that are wide and thin. As a
second major and the main algorithmic contribution of this paper, we present a
PTAS for this case. We believe that this will turn out to be useful in future
work in geometric packing problems.
We also consider the variant of the problem with rotations (2DKR), where
items can be rotated by 90 degrees. Also, in this case, the best-known
polynomial-time approximation factor (even for the cardinality case) is (2 +
\epsilon) [Jansen and Zhang, SODA 2004]. Exploiting part of the machinery
developed for 2DK plus a few additional ideas, we obtain a polynomial-time (3/2
+ \epsilon)-approximation for 2DKR, which improves to (4/3 + \epsilon) in the
cardinality case.
",Cybersecurity
"  The problem of three-user multiple-access channel (MAC) with noiseless
feedback is investigated. A new coding strategy is presented. The coding scheme
builds upon the natural extension of the Cover-Leung (CL) scheme; and uses
quasi-linear codes. A new single-letter achievable rate region is derived. The
new achievable region strictly contains the CL region. This is shown through an
example. In this example, the coding scheme achieves optimality in terms of
transmission rates. It is shown that any optimality achieving scheme for this
example must have a specific algebraic structure. Particularly, the codebooks
must be closed under binary addition.
",Cybersecurity
"  Numerous embedding models have been recently explored to incorporate semantic
knowledge into visual recognition. Existing methods typically focus on
minimizing the distance between the corresponding images and texts in the
embedding space but do not explicitly optimize the underlying structure. Our
key observation is that modeling the pairwise image-image relationship improves
the discrimination ability of the embedding model. In this paper, we propose
the structured discriminative and difference constraints to learn
visual-semantic embeddings. First, we exploit the discriminative constraints to
capture the intra- and inter-class relationships of image embeddings. The
discriminative constraints encourage separability for image instances of
different classes. Second, we align the difference vector between a pair of
image embeddings with that of the corresponding word embeddings. The difference
constraints help regularize image embeddings to preserve the semantic
relationships among word embeddings. Extensive evaluations demonstrate the
effectiveness of the proposed structured embeddings for single-label
classification, multi-label classification, and zero-shot recognition.
",Cybersecurity
"  We present a method to improve the accuracy of a foot-mounted,
zero-velocity-aided inertial navigation system (INS) by varying estimator
parameters based on a real-time classification of motion type. We train a
support vector machine (SVM) classifier using inertial data recorded by a
single foot-mounted sensor to differentiate between six motion types (walking,
jogging, running, sprinting, crouch-walking, and ladder-climbing) and report
mean test classification accuracy of over 90% on a dataset with five different
subjects. From these motion types, we select two of the most common (walking
and running), and describe a method to compute optimal zero-velocity detection
parameters tailored to both a specific user and motion type by maximizing the
detector F-score. By combining the motion classifier with a set of optimal
detection parameters, we show how we can reduce INS position error during mixed
walking and running motion. We evaluate our adaptive system on a total of 5.9
km of indoor pedestrian navigation performed by five different subjects moving
along a 130 m path with surveyed ground truth markers.
",Cybersecurity
"  Spectral shape descriptors have been used extensively in a broad spectrum of
geometry processing applications ranging from shape retrieval and segmentation
to classification. In this pa- per, we propose a spectral graph wavelet
approach for 3D shape classification using the bag-of-features paradigm. In an
effort to capture both the local and global geometry of a 3D shape, we present
a three-step feature description framework. First, local descriptors are
extracted via the spectral graph wavelet transform having the Mexican hat
wavelet as a generating ker- nel. Second, mid-level features are obtained by
embedding lo- cal descriptors into the visual vocabulary space using the soft-
assignment coding step of the bag-of-features model. Third, a global descriptor
is constructed by aggregating mid-level fea- tures weighted by a geodesic
exponential kernel, resulting in a matrix representation that describes the
frequency of appearance of nearby codewords in the vocabulary. Experimental
results on two standard 3D shape benchmarks demonstrate the effective- ness of
the proposed classification approach in comparison with state-of-the-art
methods.
",Cybersecurity
"  Intel software guard extensions (SGX) aims to provide an isolated execution
environment, known as an enclave, for a user-level process to maximize its
confidentiality and integrity. In this paper, we study how uninitialized data
inside a secure enclave can be leaked via structure padding. We found that,
during ECALL and OCALL, proxy functions that are automatically generated by the
Intel SGX Software Development Kit (SDK) fully copy structure variables from an
enclave to the normal memory to return the result of an ECALL function and to
pass input parameters to an OCALL function. If the structure variables contain
padding bytes, uninitialized enclave memory, which might contain confidential
data like a private key, can be copied to the normal memory through the padding
bytes. We also consider potential countermeasures against these security
threats.
",Cybersecurity
"  The tasks of identifying separation structures and clusters in flow data are
fundamental to flow visualization. Significant work has been devoted to these
tasks in flow represented by vector fields, but there are unique challenges in
addressing these tasks for time-varying particle data. The unstructured nature
of particle data, nonuniform and sparse sampling, and the inability to access
arbitrary particles in space-time make it difficult to define separation and
clustering for particle data. We observe that weaker notions of separation and
clustering through continuous measures of these structures are meaningful when
coupled with user exploration. We achieve this goal by defining a measure of
particle similarity between pairs of particles. More specifically, separation
occurs when spatially-localized particles are dissimilar, while clustering is
characterized by sets of particles that are similar to one another. To be
robust to imperfections in sampling we use diffusion geometry to compute
particle similarity. Diffusion geometry is parameterized by a scale that allows
a user to explore separation and clustering in a continuous manner. We
illustrate the benefits of our technique on a variety of 2D and 3D flow
datasets, from particles integrated in fluid simulations based on time-varying
vector fields, to particle-based simulations in astrophysics.
",Cybersecurity
"  This paper describes our participation in Task 5 track 2 of SemEval 2017 to
predict the sentiment of financial news headlines for a specific company on a
continuous scale between -1 and 1. We tackled the problem using a number of
approaches, utilising a Support Vector Regression (SVR) and a Bidirectional
Long Short-Term Memory (BLSTM). We found an improvement of 4-6% using the LSTM
model over the SVR and came fourth in the track. We report a number of
different evaluations using a finance specific word embedding model and reflect
on the effects of using different evaluation metrics.
",Cybersecurity
"  This paper considers the problem of achieving attitude consensus in
spacecraft formations with bounded, time-varying communication delays between
spacecraft connected as specified by a strongly connected topology. A state
feedback con- troller is proposed and investigated using a time domain approach
(via LMIs) and a frequency domain approach (via the small-gain theorem) to
obtain delay depen- dent stability criteria to achieve the desired consensus.
Simulations are presented to demonstrate the application of the strategy in a
specific scenario.
",Cybersecurity
"  Accurate state estimation of large-scale lithium-ion battery packs is
necessary for the advanced control of batteries, which could potentially
increase their lifetime through e.g. reconfiguration. To tackle this problem,
an enhanced reduced-order electrochemical model is used here. This model allows
considering a wider operating range and thermal coupling between cells, the
latter turning out to be significant. The resulting nonlinear model is
exploited for state estimation through unscented Kalman filters (UKF). A sensor
network composed of one sensor node per battery cell is deployed. Each sensor
node is equipped with a local UKF, which uses available local measurements
together with additional information coming from neighboring sensor nodes. Such
state estimation scheme gives rise to a partition-based unscented Kalman filter
(PUKF). The method is validated on data from a detailed simulator for a battery
pack comprised of six cells, with reconfiguration capabilities. The results
show that the distributed approach outperforms the centralized one in terms of
computation time at the expense of a very low increase of mean-square
estimation error.
",Cybersecurity
"  Volunteer computing (VC) or distributed computing projects are common in the
citizen cyberscience (CCS) community and present extensive opportunities for
scientists to make use of computing power donated by volunteers to undertake
large-scale scientific computing tasks. Volunteer computing is generally a
non-interactive process for those contributing computing resources to a project
whereas volunteer thinking (VT) or distributed thinking, which allows
volunteers to participate interactively in citizen cyberscience projects to
solve human computation tasks. In this paper we describe the integration of
three tools, the Virtual Atom Smasher (VAS) game developed by CERN, LiveQ, a
job distribution middleware, and CitizenGrid, an online platform for hosting
and providing computation to CCS projects. This integration demonstrates the
combining of volunteer computing and volunteer thinking to help address the
scientific and educational goals of games like VAS. The paper introduces the
three tools and provides details of the integration process along with further
potential usage scenarios for the resulting platform.
",Cybersecurity
"  This paper presents a reliable method to verify the existence of loops along
the uncertain trajectory of a robot, based on proprioceptive measurements only,
within a bounded-error context. The loop closure detection is one of the key
points in SLAM methods, especially in homogeneous environments with difficult
scenes recognitions. The proposed approach is generic and could be coupled with
conventional SLAM algorithms to reliably reduce their computing burden, thus
improving the localization and mapping processes in the most challenging
environments such as unexplored underwater extents.
To prove that a robot performed a loop whatever the uncertainties in its
evolution, we employ the notion of topological degree that originates in the
field of differential topology. We show that a verification tool based on the
topological degree is an optimal method for proving robot loops. This is
demonstrated both on datasets from real missions involving autonomous
underwater vehicles, and by a mathematical discussion.
",Cybersecurity
"  In this paper, a comparative study was conducted between complex networks
representing origin and destination survey data. Similarities were found
between the characteristics of the networks of Brazilian cities with networks
of foreign cities. Power laws were found in the distributions of edge weights
and this scale - free behavior can occur due to the economic characteristics of
the cities.
",Cybersecurity
"  Solving the global method of Weighted Least Squares (WLS) model in image
filtering is both time- and memory-consuming. In this paper, we present an
alternative approximation in a time- and memory- efficient manner which is
denoted as Semi-Global Weighed Least Squares (SG-WLS). Instead of solving a
large linear system, we propose to iteratively solve a sequence of subsystems
which are one-dimensional WLS models. Although each subsystem is
one-dimensional, it can take two-dimensional neighborhood information into
account due to the proposed special neighborhood construction. We show such a
desirable property makes our SG-WLS achieve close performance to the original
two-dimensional WLS model but with much less time and memory cost. While
previous related methods mainly focus on the 4-connected/8-connected
neighborhood system, our SG-WLS can handle a more general and larger
neighborhood system thanks to the proposed fast solution. We show such a
generalization can achieve better performance than the 4-connected/8-connected
neighborhood system in some applications. Our SG-WLS is $\sim20$ times faster
than the WLS model. For an image of $M\times N$, the memory cost of SG-WLS is
at most at the magnitude of $max\{\frac{1}{M}, \frac{1}{N}\}$ of that of the
WLS model. We show the effectiveness and efficiency of our SG-WLS in a range of
applications.
",Cybersecurity
"  With the wide application of machine learning algorithms to the real world,
class imbalance and concept drift have become crucial learning issues. Class
imbalance happens when the data categories are not equally represented, i.e.,
at least one category is minority compared to other categories. It can cause
learning bias towards the majority class and poor generalization. Concept drift
is a change in the underlying distribution of the problem, and is a significant
issue specially when learning from data streams. It requires learners to be
adaptive to dynamic changes.
Class imbalance and concept drift can significantly hinder predictive
performance, and the problem becomes particularly challenging when they occur
simultaneously. This challenge arises from the fact that one problem can affect
the treatment of the other. For example, drift detection algorithms based on
the traditional classification error may be sensitive to the imbalanced degree
and become less effective; and class imbalance techniques need to be adaptive
to changing imbalance rates, otherwise the class receiving the preferential
treatment may not be the correct minority class at the current moment.
Therefore, the mutual effect of class imbalance and concept drift should be
considered during algorithm design.
The aim of this workshop is to bring together researchers from the areas of
class imbalance learning and concept drift in order to encourage discussions
and new collaborations on solving the combined issue of class imbalance and
concept drift. It provides a forum for international researchers and
practitioners to share and discuss their original work on addressing new
challenges and research issues in class imbalance learning, concept drift, and
the combined issues of class imbalance and concept drift. The proceedings
include 8 papers on these topics.
",Cybersecurity
"  In this paper, we show how controllers created using data driven designs,
such as neural networks, can be used together with model based controllers in a
way that combines the performance guarantees of the model based controllers
with the efficiency of the data driven controllers. The considered performance
guarantees include both safety, in terms of avoiding designated unsafe parts of
the state space, and convergence, in terms of reaching a given beneficial part
of the state space. Using the framework Behavior Trees, we are able to show how
this can be done on the top level, concerning just two controllers, as
described above, but also note that the same approach can be used in arbitrary
sub-trees. The price for introducing the new controller is that the upper bound
on the time needed to reach the desired part of the state space increases. The
approach is illustrated with an inverted pendulum example.
",Cybersecurity
"  Observability of complex systems/networks is the focus of this paper, which
is shown to be closely related to the concept of contraction. Indeed, for
observable network tracking it is necessary/sufficient to have one node in each
contraction measured. Therefore, nodes in a contraction are equivalent to
recover for loss of observability, implying that contraction size is a key
factor for observability recovery. Here, using a polynomial order contraction
detection algorithm, we analyze the distribution of contractions, studying its
relation with key network properties. Our results show that contraction size is
related to network clustering coefficient and degree heterogeneity.
Particularly, in networks with power-law degree distribution, if the clustering
coefficient is high there are less contractions with smaller size on average.
The implication is that estimation/tracking of such systems requires less
number of measurements, while their observational recovery is more restrictive
in case of sensor failure. Further, in Small-World networks higher degree
heterogeneity implies that there are more contractions with smaller size on
average. Therefore, the estimation of representing system requires more
measurements, and also the recovery of measurement failure is more limited.
These results imply that one can tune the properties of synthetic networks to
alleviate their estimation/observability recovery.
",Cybersecurity
"  The entropy of a random variable is well-known to equal the exponential
growth rate of the volumes of its typical sets. In this paper, we show that for
any log-concave random variable $X$, the sequence of the $\lfloor n\theta
\rfloor^{\text{th}}$ intrinsic volumes of the typical sets of $X$ in dimensions
$n \geq 1$ grows exponentially with a well-defined rate. We denote this rate by
$h_X(\theta)$, and call it the $\theta^{\text{th}}$ intrinsic entropy of $X$.
We show that $h_X(\theta)$ is a continuous function of $\theta$ over the range
$[0,1]$, thereby providing a smooth interpolation between the values 0 and
$h(X)$ at the endpoints 0 and 1, respectively.
",Cybersecurity
"  For its high coefficient of performance and zero local emissions, the heat
pump (HP) has recently become popular in North Europe and China. However, the
integration of HPs may aggravate the daily peak-valley gap in distribution
networks significantly.
",Cybersecurity
"  In this paper, we present a new algorithm for parallel Monte Carlo tree
search (MCTS). It is based on the pipeline pattern and allows flexible
management of the control flow of the operations in parallel MCTS. The pipeline
pattern provides for the first structured parallel programming approach to
MCTS. Moreover, we propose a new lock-free tree data structure for parallel
MCTS which removes synchronization overhead. The Pipeline Pattern for Parallel
MCTS algorithm (called 3PMCTS), scales very well to higher numbers of cores
when compared to the existing methods.
",Cybersecurity
"  Wireless engineers and business planners commonly raise the question on
where, when, and how millimeter-wave (mmWave) will be used in 5G and beyond.
Since the next generation network is not just a new radio access standard, but
instead an integration of networks for vertical markets with diverse
applications, answers to the question depend on scenarios and use cases to be
deployed. This paper gives four 5G mmWave deployment examples and describes in
chronological order the scenarios and use cases of their probable deployment,
including expected system architectures and hardware prototypes. The paper
starts with 28 GHz outdoor backhauling for fixed wireless access and moving
hotspots, which will be demonstrated at the PyeongChang winter Olympic games in
2018. The second deployment example is a 60 GHz unlicensed indoor access system
at the Tokyo-Narita airport, which is combined with Mobile Edge Computing (MEC)
to enable ultra-high speed content download with low latency. The third example
is mmWave mesh network to be used as a micro Radio Access Network ({\mu}-RAN),
for cost-effective backhauling of small-cell Base Stations (BSs) in dense urban
scenarios. The last example is mmWave based Vehicular-to-Vehicular (V2V) and
Vehicular-to-Everything (V2X) communications system, which enables automated
driving by exchanging High Definition (HD) dynamic map information between cars
and Roadside Units (RSUs). For 5G and beyond, mmWave and MEC will play
important roles for a diverse set of applications that require both ultra-high
data rate and low latency communications.
",Cybersecurity
"  Population protocols are a well established model of computation by
anonymous, identical finite state agents. A protocol is well-specified if from
every initial configuration, all fair executions reach a common consensus. The
central verification question for population protocols is the
well-specification problem: deciding if a given protocol is well-specified.
Esparza et al. have recently shown that this problem is decidable, but with
very high complexity: it is at least as hard as the Petri net reachability
problem, which is EXPSPACE-hard, and for which only algorithms of non-primitive
recursive complexity are currently known.
In this paper we introduce the class WS3 of well-specified strongly-silent
protocols and we prove that it is suitable for automatic verification. More
precisely, we show that WS3 has the same computational power as general
well-specified protocols, and captures standard protocols from the literature.
Moreover, we show that the membership problem for WS3 reduces to solving
boolean combinations of linear constraints over N. This allowed us to develop
the first software able to automatically prove well-specification for all of
the infinitely many possible inputs.
",Cybersecurity
"  Across smart-grid and smart-city applications, there are problems where an
ensemble of agents is to be controlled such that both the aggregate behaviour
and individual-level perception of the system's performance are acceptable. In
many applications, traditional PI control is used to regulate aggregate
ensemble performance. Our principal contribution in this note is to demonstrate
that PI control may not be always suitable for this purpose, and in some
situations may lead to a loss of ergodicity for closed-loop systems. Building
on this observation, a theoretical framework is proposed to both analyse and
design control systems for the regulation of large scale ensembles of agents
with a probabilistic intent. Examples are given to illustrate our results.
",Cybersecurity
"  Turkish Wikipedia Named-Entity Recognition and Text Categorization (TWNERTC)
dataset is a collection of automatically categorized and annotated sentences
obtained from Wikipedia. We constructed large-scale gazetteers by using a graph
crawler algorithm to extract relevant entity and domain information from a
semantic knowledge base, Freebase. The constructed gazetteers contains
approximately 300K entities with thousands of fine-grained entity types under
77 different domains. Since automated processes are prone to ambiguity, we also
introduce two new content specific noise reduction methodologies. Moreover, we
map fine-grained entity types to the equivalent four coarse-grained types:
person, loc, org, misc. Eventually, we construct six different dataset versions
and evaluate the quality of annotations by comparing ground truths from human
annotators. We make these datasets publicly available to support studies on
Turkish named-entity recognition (NER) and text categorization (TC).
",Cybersecurity
"  Multi-label classification is a practical yet challenging task in machine
learning related fields, since it requires the prediction of more than one
label category for each input instance. We propose a novel deep neural networks
(DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this
task. Aiming at better relating feature and label domain data for improved
classification, we uniquely perform joint feature and label embedding by
deriving a deep latent space, followed by the introduction of label-correlation
sensitive loss function for recovering the predicted label outputs. Our C2AE is
achieved by integrating the DNN architectures of canonical correlation analysis
and autoencoder, which allows end-to-end learning and prediction with the
ability to exploit label dependency. Moreover, our C2AE can be easily extended
to address the learning problem with missing labels. Our experiments on
multiple datasets with different scales confirm the effectiveness and
robustness of our proposed method, which is shown to perform favorably against
state-of-the-art methods for multi-label classification.
",Cybersecurity
"  Optimization plays a key role in machine learning. Recently, stochastic
second-order methods have attracted much attention due to their low
computational cost in each iteration. However, these algorithms might perform
poorly especially if it is hard to approximate the Hessian well and
efficiently. As far as we know, there is no effective way to handle this
problem. In this paper, we resort to Nesterov's acceleration technique to
improve the convergence performance of a class of second-order methods called
approximate Newton. We give a theoretical analysis that Nesterov's acceleration
technique can improve the convergence performance for approximate Newton just
like for first-order methods. We accordingly propose an accelerated regularized
sub-sampled Newton. Our accelerated algorithm performs much better than the
original regularized sub-sampled Newton in experiments, which validates our
theory empirically. Besides, the accelerated regularized sub-sampled Newton has
good performance comparable to or even better than classical algorithms.
",Cybersecurity
"  Industrie 4.0 is originally a future vision described in the high-tech
strategy of the German government that is conceived upon the information and
communication technologies like Cyber-Physical Systems, Internet of Things,
Physical Internet and Internet of Services to achieve a high degree of
flexibility in production, higher productivity rates through real-time
monitoring and diagnosis, and a lower wastage rate of material in production.
An important part of the tasks in the preparation for Industrie 4.0 is the
adaption of the higher education to the requirements of this vision, in
particular the engineering education. In this work, we introduce a road map
consisting of three pillars describing the changes/enhancements to be conducted
in the areas of curriculum development, lab concept, and student club
activities. We also report our current application of this road map at the
Turkish-German University, Istanbul.
",Cybersecurity
"  In recent years, work has been done to develop the theory of General
Reinforcement Learning (GRL). However, there are few examples demonstrating
these results in a concrete way. In particular, there are no examples
demonstrating the known results regarding gener- alised discounting. We have
added to the GRL simulation platform AIXIjs the functionality to assign an
agent arbitrary discount functions, and an environment which can be used to
determine the effect of discounting on an agent's policy. Using this, we
investigate how geometric, hyperbolic and power discounting affect an informed
agent in a simple MDP. We experimentally reproduce a number of theoretical
results, and discuss some related subtleties. It was found that the agent's
behaviour followed what is expected theoretically, assuming appropriate
parameters were chosen for the Monte-Carlo Tree Search (MCTS) planning
algorithm.
",Cybersecurity
"  This paper presents a proposal (story) of how statically detecting
unreachable objects (in Java) could be used to improve a particular runtime
verification approach (for Java), namely parametric trace slicing. Monitoring
algorithms for parametric trace slicing depend on garbage collection to (i)
cleanup data-structures storing monitored objects, ensuring they do not become
unmanageably large, and (ii) anticipate the violation of (non-safety)
properties that cannot be satisfied as a monitored object can no longer appear
later in the trace. The proposal is that both usages can be improved by making
the unreachability of monitored objects explicit in the parametric property and
statically introducing additional instrumentation points generating related
events. The ideas presented in this paper are still exploratory and the
intention is to integrate the described techniques into the MarQ monitoring
tool for quantified event automata.
",Cybersecurity
"  We study a number of graph exploration problems in the following natural
scenario: an algorithm starts exploring an undirected graph from some seed
node; the algorithm, for an arbitrary node $v$ that it is aware of, can ask an
oracle to return the set of the neighbors of $v$. (In social network analysis,
a call to this oracle corresponds to downloading the profile page of user $v$
in a social network.) The goal of the algorithm is to either learn something
(e.g., average degree) about the graph, or to return some random function of
the graph (e.g., a uniform-at-random node), while accessing/downloading as few
nodes of the graph as possible. Motivated by practical applications, we study
the complexities of a variety of problems in terms of the graph's mixing time
and average degree -- two measures that are believed to be quite small in
real-world social networks, and that have often been used in the applied
literature to bound the performance of online exploration algorithms. Our main
result is that the algorithm has to access $\Omega\left(t_{\rm mix} d_{\rm avg}
\epsilon^{-2} \ln \delta^{-1}\right)$ nodes to obtain, with probability at
least $1-\delta$, an $\epsilon$-additive approximation of the average of a
bounded function on the nodes of a graph -- this lower bound matches the
performance of an algorithm that was proposed in the literature. We also give
tight bounds for the problem of returning a close-to-uniform-at-random node
from the graph. Finally, we give lower bounds for the problems of estimating
the average degree of the graph, and the number of nodes of the graph.
",Cybersecurity
"  In recent years, bullying and aggression against users on social media have
grown significantly, causing serious consequences to victims of all
demographics. In particular, cyberbullying affects more than half of young
social media users worldwide, and has also led to teenage suicides, prompted by
prolonged and/or coordinated digital harassment. Nonetheless, tools and
technologies for understanding and mitigating it are scarce and mostly
ineffective. In this paper, we present a principled and scalable approach to
detect bullying and aggressive behavior on Twitter. We propose a robust
methodology for extracting text, user, and network-based attributes, studying
the properties of cyberbullies and aggressors, and what features distinguish
them from regular users. We find that bully users post less, participate in
fewer online communities, and are less popular than normal users, while
aggressors are quite popular and tend to include more negativity in their
posts. We evaluate our methodology using a corpus of 1.6M tweets posted over 3
months, and show that machine learning classification algorithms can accurately
detect users exhibiting bullying and aggressive behavior, achieving over 90%
AUC.
",Cybersecurity
"  The study of subblock-constrained codes has recently gained attention due to
their application in diverse fields. We present bounds on the size and
asymptotic rate for two classes of subblock-constrained codes. The first class
is binary constant subblock-composition codes (CSCCs), where each codeword is
partitioned into equal sized subblocks, and every subblock has the same fixed
weight. The second class is binary subblock energy-constrained codes (SECCs),
where the weight of every subblock exceeds a given threshold. We present novel
upper and lower bounds on the code sizes and asymptotic rates for binary CSCCs
and SECCs. For a fixed subblock length and small relative distance, we show
that the asymptotic rate for CSCCs (resp. SECCs) is strictly lower than the
corresponding rate for constant weight codes (CWCs) (resp. heavy weight codes
(HWCs)). Further, for codes with high weight and low relative distance, we show
that the asymptotic rates for CSCCs is strictly lower than that of SECCs, which
contrasts that the asymptotic rate for CWCs is equal to that of HWCs. We also
provide a correction to an earlier result by Chee et al. (2014) on the
asymptotic CSCC rate. Additionally, we present several numerical examples
comparing the rates for CSCCs and SECCs with those for constant weight codes
and heavy weight codes.
",Cybersecurity
"  Several temporal logics have been proposed to formalise timing diagram
requirements over hardware and embedded controllers. These include LTL,
discrete time MTL and the recent industry standard PSL. However, succintness
and visual structure of a timing diagram are not adequately captured by their
formulae. Interval temporal logic QDDC is a highly succint and visual notation
for specifying patterns of behaviours.
In this paper, we propose a practically useful notation called SeCeCntnl
which enhances negation free fragment of QDDC with features of nominals and
limited liveness. We show that timing diagrams can be naturally
(compositionally) and succintly formalized in SeCeCntnl as compared with PSL
and MTL. We give a linear time translation from timing diagrams to SeCeCntnl.
As our second main result, we propose a linear time translation of SeCeCntnl
into QDDC. This allows QDDC tools such as DCVALID and DCSynth to be used for
checking consistency of timing diagram requirements as well as for automatic
synthesis of property monitors and controllers. We give examples of a minepump
controller and a bus arbiter to illustrate our tools. Giving a theoretical
analysis, we show that for the proposed SeCeCntnl, the satisfiability and model
checking have elementary complexity as compared to the non-elementary
complexity for the full logic QDDC.
",Cybersecurity
"  Trivial events are ubiquitous in human to human conversations, e.g., cough,
laugh and sniff. Compared to regular speech, these trivial events are usually
short and unclear, thus generally regarded as not speaker discriminative and so
are largely ignored by present speaker recognition research. However, these
trivial events are highly valuable in some particular circumstances such as
forensic examination, as they are less subjected to intentional change, so can
be used to discover the genuine speaker from disguised speech. In this paper,
we collect a trivial event speech database that involves 75 speakers and 6
types of events, and report preliminary speaker recognition results on this
database, by both human listeners and machines. Particularly, the deep feature
learning technique recently proposed by our group is utilized to analyze and
recognize the trivial events, which leads to acceptable equal error rates
(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.
Comparing different types of events, 'hmm' seems more speaker discriminative.
",Cybersecurity
"  The family of Information Dispersal Algorithms is applied to distributed
systems for secure and reliable storage and transmission. In comparison with
perfect secret sharing it achieves a significantly smaller memory overhead and
better performance, but provides only incremental confidentiality. Therefore,
even if it is not possible to explicitly reconstruct data from less than the
required amount of fragments, it is still possible to deduce some information
about the nature of data by looking at preserved data patterns inside a
fragment. The idea behind this paper is to provide a lightweight data
fragmentation scheme, that would combine the space efficiency and simplicity
that could be find in Information Dispersal Algorithms with a computational
level of data confidentiality.
",Cybersecurity
"  The Android OS has become the most popular mobile operating system leading to
a significant increase in the spread of Android malware. Consequently, several
static and dynamic analysis systems have been developed to detect Android
malware. With dynamic analysis, efficient test input generation is needed in
order to trigger the potential run-time malicious behaviours. Most existing
dynamic analysis systems employ random-based input generation methods usually
built using the Android Monkey tool. Random-based input generation has several
shortcomings including limited code coverage, which motivates us to explore
combining it with a state-based method in order to improve efficiency. Hence,
in this paper, we present a novel hybrid test input generation approach
designed to improve dynamic analysis on real devices. We implemented the hybrid
system by integrating a random based tool (Monkey) with a state based tool
(DroidBot) in order to improve code coverage and potentially uncover more
malicious behaviours. The system is evaluated using 2,444 Android apps
containing 1222 benign and 1222 malware samples from the Android malware genome
project. Three scenarios, random only, state-based only, and our proposed
hybrid approach were investigated to comparatively evaluate their performances.
Our study shows that the hybrid approach significantly improved the amount of
dynamic features extracted from both benign and malware samples over the
state-based and commonly used random test input generation method.
",Cybersecurity
"  There is an increased interest in building data analytics frameworks with
advanced algebraic capabilities both in industry and academia. Many of these
frameworks, e.g., TensorFlow and BIDMach, implement their compute-intensive
primitives in two flavors---as multi-thread routines for multi-core CPUs and as
highly-parallel kernels executed on GPU. Stochastic gradient descent (SGD) is
the most popular optimization method for model training implemented extensively
on modern data analytics platforms. While the data-intensive properties of SGD
are well-known, there is an intense debate on which of the many SGD variants is
better in practice. In this paper, we perform a comprehensive study of parallel
SGD for training generalized linear models. We consider the impact of three
factors -- computing architecture (multi-core CPU or GPU), synchronous or
asynchronous model updates, and data sparsity -- on three measures---hardware
efficiency, statistical efficiency, and time to convergence. In the process, we
design an optimized asynchronous SGD algorithm for GPU that leverages warp
shuffling and cache coalescing for data and model access. We draw several
interesting findings from our extensive experiments with logistic regression
(LR) and support vector machines (SVM) on five real datasets. For synchronous
SGD, GPU always outperforms parallel CPU---they both outperform a sequential
CPU solution by more than 400X. For asynchronous SGD, parallel CPU is the
safest choice while GPU with data replication is better in certain situations.
The choice between synchronous GPU and asynchronous CPU depends on the task and
the characteristics of the data. As a reference, our best implementation
outperforms TensorFlow and BIDMach consistently. We hope that our insights
provide a useful guide for applying parallel SGD to generalized linear models.
",Cybersecurity
"  In this paper, we propose a new method to tackle the mapping challenge from
time-series data to spatial image in the field of seismic exploration, i.e.,
reconstructing the velocity model directly from seismic data by deep neural
networks (DNNs). The conventional way to address this ill-posed seismic
inversion problem is through iterative algorithms, which suffer from poor
nonlinear mapping and strong non-uniqueness. Other attempts may either import
human intervention errors or underuse seismic data. The challenge for DNNs
mainly lies in the weak spatial correspondence, the uncertain
reflection-reception relationship between seismic data and velocity model as
well as the time-varying property of seismic data. To approach these
challenges, we propose an end-to-end Seismic Inversion Networks (SeisInvNet for
short) with novel components to make the best use of all seismic data.
Specifically, we start with every seismic trace and enhance it with its
neighborhood information, its observation setup and global context of its
corresponding seismic profile. Then from enhanced seismic traces, the spatially
aligned feature maps can be learned and further concatenated to reconstruct
velocity model. In general, we let every seismic trace contribute to the
reconstruction of the whole velocity model by finding spatial correspondence.
The proposed SeisInvNet consistently produces improvements over the baselines
and achieves promising performance on our proposed SeisInv dataset according to
various evaluation metrics, and the inversion results are more consistent with
the target from the aspects of velocity value, subsurface structure and
geological interface. In addition to the superior performance, the mechanism is
also carefully discussed, and some potential problems are identified for
further study.
",Cybersecurity
"  We present a hardware mechanism called HourGlass to predictably share data in
a multi-core system where cores are explicitly designated as critical or
non-critical. HourGlass is a time-based cache coherence protocol for
dual-critical multi-core systems that ensures worst-case latency (WCL) bounds
for memory requests originating from critical cores. Although HourGlass does
not provide either WCL or bandwidth guarantees for memory requests from
non-critical cores, it promotes the use of timers to improve its bandwidth
utilization while still maintaining WCL bounds for critical cores. This
encourages a trade-off between the WCL bounds for critical cores, and the
improved memory bandwidth for non-critical cores via timer configurations. We
evaluate HourGlass using gem5, and with multithreaded benchmark suites
including SPLASH-2, and synthetic workloads. Our results show that the WCL for
critical cores with HourGlass is always within the analytical WCL bounds, and
provides a tighter WCL bound on critical cores compared to the state-of-the-art
real-time cache coherence protocol. Further, we show that HourGlass enables a
trade-off between provable WCL bounds for critical cores, and improved
bandwidth utilization for non-critical cores. The average-case performance of
HourGlass is comparable to the state-of-the-art real-time cache coherence
protocol, and suffers a slowdown of 1.43x and 1.46x compared to the
conventional MSI and MESI protocols.
",Cybersecurity
"  Many systems of structured argumentation explicitly require that the facts
and rules that make up the argument for a conclusion be the minimal set
required to derive the conclusion. ASPIC+ does not place such a requirement on
arguments, instead requiring that every rule and fact that are part of an
argument be used in its construction. Thus ASPIC+ arguments are minimal in the
sense that removing any element of the argument would lead to a structure that
is not an argument. In this brief note we discuss these two types of minimality
and show how the first kind of minimality can, if desired, be recovered in
ASPIC+.
",Cybersecurity
"  Differential privacy promises to enable general data analytics while
protecting individual privacy, but existing differential privacy mechanisms do
not support the wide variety of features and databases used in real-world
SQL-based analytics systems.
This paper presents the first practical approach for differential privacy of
SQL queries. Using 8.1 million real-world queries, we conduct an empirical
study to determine the requirements for practical differential privacy, and
discuss limitations of previous approaches in light of these requirements. To
meet these requirements we propose elastic sensitivity, a novel method for
approximating the local sensitivity of queries with general equijoins. We prove
that elastic sensitivity is an upper bound on local sensitivity and can
therefore be used to enforce differential privacy using any local
sensitivity-based mechanism.
We build FLEX, a practical end-to-end system to enforce differential privacy
for SQL queries using elastic sensitivity. We demonstrate that FLEX is
compatible with any existing database, can enforce differential privacy for
real-world SQL queries, and incurs negligible (0.03%) performance overhead.
",Cybersecurity
"  Cross-lingual representations of words enable us to reason about word meaning
in multilingual contexts and are a key facilitator of cross-lingual transfer
when developing natural language processing models for low-resource languages.
In this survey, we provide a comprehensive typology of cross-lingual word
embedding models. We compare their data requirements and objective functions.
The recurring theme of the survey is that many of the models presented in the
literature optimize for the same objectives, and that seemingly different
models are often equivalent modulo optimization strategies, hyper-parameters,
and such. We also discuss the different ways cross-lingual word embeddings are
evaluated, as well as future challenges and research horizons.
",Cybersecurity
"  Network classification has a variety of applications, such as detecting
communities within networks and finding similarities between those representing
different aspects of the real world. However, most existing work in this area
focus on examining static undirected networks without considering directed
edges or temporality. In this paper, we propose a new methodology that utilizes
feature representation for network classification based on the temporal motif
distribution of the network and a null model for comparing against random
graphs. Experimental results show that our method improves accuracy by up
$10\%$ compared to the state-of-the-art embedding method in network
classification, for tasks such as classifying network type, identifying
communities in email exchange network, and identifying users given their
app-switching behaviors.
",Cybersecurity
"  Massive multiple-input multiple-output (MIMO) systems, which utilize a large
number of antennas at the base station, are expected to enhance network
throughput by enabling improved multiuser MIMO techniques. To deploy many
antennas in reasonable form factors, base stations are expected to employ
antenna arrays in both horizontal and vertical dimensions, which is known as
full-dimension (FD) MIMO. The most popular two-dimensional array is the uniform
planar array (UPA), where antennas are placed in a grid pattern. To exploit the
full benefit of massive MIMO in frequency division duplexing (FDD), the
downlink channel state information (CSI) should be estimated, quantized, and
fed back from the receiver to the transmitter. However, it is difficult to
accurately quantize the channel in a computationally efficient manner due to
the high dimensionality of the massive MIMO channel. In this paper, we develop
both narrowband and wideband CSI quantizers for FD-MIMO taking the properties
of realistic channels and the UPA into consideration. To improve quantization
quality, we focus on not only quantizing dominant radio paths in the channel,
but also combining the quantized beams. We also develop a hierarchical beam
search approach, which scans both vertical and horizontal domains jointly with
moderate computational complexity. Numerical simulations verify that the
performance of the proposed quantizers is better than that of previous CSI
quantization techniques.
",Cybersecurity
"  BigDatalog is an extension of Datalog that achieves performance and
scalability on both Apache Spark and multicore systems to the point that its
graph analytics outperform those written in GraphX. Looking back, we see how
this realizes the ambitious goal pursued by deductive database researchers
beginning forty years ago: this is the goal of combining the rigor and power of
logic in expressing queries and reasoning with the performance and scalability
by which relational databases managed Big Data. This goal led to Datalog which
is based on Horn Clauses like Prolog but employs implementation techniques,
such as Semi-naive Fixpoint and Magic Sets, that extend the bottom-up
computation model of relational systems, and thus obtain the performance and
scalability that relational systems had achieved, as far back as the 80s, using
data-parallelization on shared-nothing architectures. But this goal proved
difficult to achieve because of major issues at (i) the language level and (ii)
at the system level. The paper describes how (i) was addressed by simple rules
under which the fixpoint semantics extends to programs using count, sum and
extrema in recursion, and (ii) was tamed by parallel compilation techniques
that achieve scalability on multicore systems and Apache Spark. This paper is
under consideration for acceptance in Theory and Practice of Logic Programming
(TPLP).
",Cybersecurity
"  This paper introduces a new surgical end-effector probe, which allows to
accurately apply a contact force on a tissue, while at the same time allowing
for high resolution and highly repeatable probe movement. These are achieved by
implementing a cable-driven parallel manipulator arrangement, which is deployed
at the distal-end of a robotic instrument. The combination of the offered
qualities can be advantageous in several ways, with possible applications
including: large area endomicroscopy and multi-spectral imaging, micro-surgery,
tissue palpation, safe energy-based and conventional tissue resection. To
demonstrate the concept and its adaptability, the probe is integrated with a
modified da Vinci robot instrument.
",Cybersecurity
"  In this paper we present a novel joint approach for optimising surface
curvature and pose alignment. We present two implementations of this joint
optimisation strategy, including a fast implementation that uses two frames and
an offline multi-frame approach. We demonstrate an order of magnitude
improvement in simulation over state of the art dense relative point-to-plane
Iterative Closest Point (ICP) pose alignment using our dense joint
frame-to-frame approach and show comparable pose drift to dense point-to-plane
ICP bundle adjustment using low-cost depth sensors. Additionally our improved
joint quadric based approach can be used to more accurately estimate surface
curvature on noisy point clouds than previous approaches.
",Cybersecurity
"  For decades, conventional computers based on the von Neumann architecture
have performed computation by repeatedly transferring data between their
processing and their memory units, which are physically separated. As
computation becomes increasingly data-centric and as the scalability limits in
terms of performance and power are being reached, alternative computing
paradigms are searched for in which computation and storage are collocated. A
fascinating new approach is that of computational memory where the physics of
nanoscale memory devices are used to perform certain computational tasks within
the memory unit in a non-von Neumann manner. Here we present a large-scale
experimental demonstration using one million phase-change memory devices
organized to perform a high-level computational primitive by exploiting the
crystallization dynamics. Also presented is an application of such a
computational memory to process real-world data-sets. The results show that
this co-existence of computation and storage at the nanometer scale could be
the enabler for new, ultra-dense, low power, and massively parallel computing
systems.
",Cybersecurity
"  In this paper, we report on the visualization capabilities of an Explainable
AI Planning (XAIP) agent that can support human in the loop decision making.
Imposing transparency and explainability requirements on such agents is
especially important in order to establish trust and common ground with the
end-to-end automated planning system. Visualizing the agent's internal
decision-making processes is a crucial step towards achieving this. This may
include externalizing the ""brain"" of the agent -- starting from its sensory
inputs, to progressively higher order decisions made by it in order to drive
its planning components. We also show how the planner can bootstrap on the
latest techniques in explainable planning to cast plan visualization as a plan
explanation problem, and thus provide concise model-based visualization of its
plans. We demonstrate these functionalities in the context of the automated
planning components of a smart assistant in an instrumented meeting space.
",Cybersecurity
"  We present a monitoring approach for verifying systems at runtime. Our
approach targets systems whose components communicate with the monitors over
unreliable channels, where messages can be delayed or lost. In contrast to
prior works, whose property specification languages are limited to
propositional temporal logics, our approach handles an extension of the
real-time logic MTL with freeze quantifiers for reasoning about data values. We
present its underlying theory based on a new three-valued semantics that is
well suited to soundly and completely reason online about event streams in the
presence of message delay or loss. We also evaluate our approach
experimentally. Our prototype implementation processes hundreds of events per
second in settings where messages are received out of order.
",Cybersecurity
"  Object detection in wide area motion imagery (WAMI) has drawn the attention
of the computer vision research community for a number of years. WAMI proposes
a number of unique challenges including extremely small object sizes, both
sparse and densely-packed objects, and extremely large search spaces (large
video frames). Nearly all state-of-the-art methods in WAMI object detection
report that appearance-based classifiers fail in this challenging data and
instead rely almost entirely on motion information in the form of background
subtraction or frame-differencing. In this work, we experimentally verify the
failure of appearance-based classifiers in WAMI, such as Faster R-CNN and a
heatmap-based fully convolutional neural network (CNN), and propose a novel
two-stage spatio-temporal CNN which effectively and efficiently combines both
appearance and motion information to significantly surpass the state-of-the-art
in WAMI object detection. To reduce the large search space, the first stage
(ClusterNet) takes in a set of extremely large video frames, combines the
motion and appearance information within the convolutional architecture, and
proposes regions of objects of interest (ROOBI). These ROOBI can contain from
one to clusters of several hundred objects due to the large video frame size
and varying object density in WAMI. The second stage (FoveaNet) then estimates
the centroid location of all objects in that given ROOBI simultaneously via
heatmap estimation. The proposed method exceeds state-of-the-art results on the
WPAFB 2009 dataset by 5-16% for moving objects and nearly 50% for stopped
objects, as well as being the first proposed method in wide area motion imagery
to detect completely stationary objects.
",Cybersecurity
"  There are large amounts of insight and social discovery potential in mining
crowd-sourced comments left on popular news forums like Reddit.com, Tumblr.com,
Facebook.com and Hacker News. Unfortunately, due the overwhelming amount of
participation with its varying quality of commentary, extracting value out of
such data isn't always obvious nor timely. By designing efficient, single-pass
and adaptive natural language filters to quickly prune spam, noise, copy-cats,
marketing diversions, and out-of-context posts, we can remove over a third of
entries and return the comments with a higher probability of relatedness to the
original article in question. The approach presented here uses an adaptive,
two-step filtering process. It first leverages the original article posted in
the thread as a starting corpus to parse comments by matching intersecting
words and term-ratio balance per sentence then grows the corpus by adding new
words harvested from high-matching comments to increase filtering accuracy over
time.
",Cybersecurity
"  Network navigability is a key feature of complex networked systems. For a
network embedded in a geometrical space, maximization of greedy routing (GR)
measures based on the node geometrical coordinates can ensure efficient greedy
navigability. In PNAS, Seguin et al. (PNAS 2018, vol. 115, no. 24) define a
measure for quantifying the efficiency of brain network navigability in the
Euclidean space, referred to as the efficiency ratio, whose formula exactly
coincides with the GR-score (GR-efficiency) previously published by Muscoloni
et al. (Nature Communications 2017, vol. 8, no. 1615). In this Letter, we point
out potential flaws in the study of Seguin et al. regarding the discussion of
the GR evaluation. In particular, we revise the concept of GR navigability,
together with a careful discussion of the advantage offered by the new proposed
GR-efficiency measure in comparison to the main measures previously adopted in
literature. Finally, we clarify and standardize the GR-efficiency terminology
in order to simplify and facilitate the discussion in future studies.
",Cybersecurity
"  Length-matching is an important technique to bal- ance delays of bus signals
in high-performance PCB routing. Existing routers, however, may generate very
dense meander segments. Signals propagating along these meander segments
exhibit a speedup effect due to crosstalk between the segments of the same
wire, thus leading to mismatch of arrival times even under the same physical
wire length. In this paper, we present a post-processing method to enlarge the
width and the distance of meander segments and hence distribute them more
evenly on the board so that crosstalk can be reduced. In the proposed
framework, we model the sharing of available routing areas after removing dense
meander segments from the initial routing, as well as the generation of relaxed
meander segments and their groups for wire length compensation. This model is
transformed into an ILP problem and solved for a balanced distribution of wire
patterns. In addition, we adjust the locations of long wire segments according
to wire priorities to swap free spaces toward critical wires that need much
length compensation. To reduce the problem space of the ILP model, we also
introduce a progressive fixing technique so that wire patterns are grown
gradually from the edge of the routing toward the center area. Experimental
results show that the proposed method can expand meander segments significantly
even under very tight area constraints, so that the speedup effect can be
alleviated effectively in high- performance PCB designs.
",Cybersecurity
"  The CREATE database is composed of 14 hours of multimodal recordings from a
mobile robotic platform based on the iRobot Create. The various sensors cover
vision, audition, motors and proprioception. The dataset has been designed in
the context of a mobile robot that can learn multimodal representations of its
environment, thanks to its ability to navigate the environment. This ability
can also be used to learn the dependencies and relationships between the
different modalities of the robot (e.g. vision, audition), as they reflect both
the external environment and the internal state of the robot. The provided
multimodal dataset is expected to have multiple usages, such as multimodal
unsupervised object learning, multimodal prediction and egomotion/causality
detection.
",Cybersecurity
"  This workshop invites researchers and practitioners to participate in
exploring behavioral change support intelligent transportation applications. We
welcome submissions that explore intelligent transportation systems (ITS),
which interact with travelers in order to persuade them or nudge them towards
sustainable transportation behaviors and decisions. Emerging opportunities
including the use of data and information generated by ITS and users' mobile
devices in order to render personalized, contextualized and timely transport
behavioral change interventions are in our focus. We invite submissions and
ideas from domains of ITS including, but not limited to, multi-modal journey
planners, advanced traveler information systems and in-vehicle systems. The
expected outcome will be a deeper understanding of the challenges and future
research directions with respect to behavioral change support through ITS.
",Cybersecurity
"  In the article, we discuss the architecture of the polynomial neural network
that corresponds to the matrix representation of Lie transform. The matrix form
of Lie transform is an approximation of general solution for the nonlinear
system of ordinary differential equations. Thus, it can be used for simulation
and modeling task. On the other hand, one can identify dynamical system from
time series data simply by optimization of the coefficient matrices of the Lie
transform. Representation of the approach by polynomial neural networks
integrates the strength of both neural networks and traditional model-based
methods for dynamical systems investigation. We provide a theoretical
explanation of learning dynamical systems from time series for the proposed
method, as well as demonstrate it in several applications. Namely, we show
results of modeling and identification for both well-known systems like
Lotka-Volterra equation and more complicated examples from retail,
biochemistry, and accelerator physics.
",Cybersecurity
"  This paper presents a new approach in understanding how deep neural networks
(DNNs) work by applying homomorphic signal processing techniques. Focusing on
the task of multi-pitch estimation (MPE), this paper demonstrates the
equivalence relation between a generalized cepstrum and a DNN in terms of their
structures and functionality. Such an equivalence relation, together with pitch
perception theories and the recently established
rectified-correlations-on-a-sphere (RECOS) filter analysis, provide an
alternative way in explaining the role of the nonlinear activation function and
the multi-layer structure, both of which exist in a cepstrum and a DNN. To
validate the efficacy of this new approach, a new feature designed in the same
fashion is proposed for pitch salience function. The new feature outperforms
the one-layer spectrum in the MPE task and, as predicted, it addresses the
issue of the missing fundamental effect and also achieves better robustness to
noise.
",Cybersecurity
"  Data sharing among partners---users, organizations, companies---is crucial
for the advancement of data analytics in many domains. Sharing through secure
computation and differential privacy allows these partners to perform private
computations on their sensitive data in controlled ways. However, in reality,
there exist complex relationships among members. Politics, regulations,
interest, trust, data demands and needs are one of the many reasons. Thus,
there is a need for a mechanism to meet these conflicting relationships on data
sharing. This paper presents Curie, an approach to exchange data among members
whose membership has complex relationships. The CPL policy language that allows
members to define the specifications of data exchange requirements is
introduced. Members (partners) assert who and what to exchange through their
local policies and negotiate a global sharing agreement. The agreement is
implemented in a multi-party computation that guarantees sharing among members
will comply with the policy as negotiated. The use of Curie is validated
through an example of a health care application built on recently introduced
secure multi-party computation and differential privacy frameworks, and policy
and performance trade-offs are explored.
",Cybersecurity
"  In this paper, we tackle the accurate and consistent Structure from Motion
(SfM) problem, in particular camera registration, far exceeding the memory of a
single computer in parallel. Different from the previous methods which
drastically simplify the parameters of SfM and sacrifice the accuracy of the
final reconstruction, we try to preserve the connectivities among cameras by
proposing a camera clustering algorithm to divide a large SfM problem into
smaller sub-problems in terms of camera clusters with overlapping. We then
exploit a hybrid formulation that applies the relative poses from local
incremental SfM into a global motion averaging framework and produce accurate
and consistent global camera poses. Our scalable formulation in terms of camera
clusters is highly applicable to the whole SfM pipeline including track
generation, local SfM, 3D point triangulation and bundle adjustment. We are
even able to reconstruct the camera poses of a city-scale data-set containing
more than one million high-resolution images with superior accuracy and
robustness evaluated on benchmark, Internet, and sequential data-sets.
",Cybersecurity
"  Fifth Generation (5G) telecommunication system is going to deliver a flexible
radio access network (RAN). Security functions such as authorization,
authentication and accounting (AAA) are expected to be distributed from central
clouds to edge clouds. We propose a novel architectural security solution that
applies to 5G networks. It is called Trust Zone (TZ) that is designed as an
enhancement of the 5G AAA in the edge cloud. TZ also provides an autonomous and
decentralized security policy for different tenants under variable network
conditions. TZ also initiates an ability of disaster cognition and extends the
security functionalities to a set of flexible and highly available emergency
services in the edge cloud.
",Cybersecurity
"  We propose a general framework for interactively learning models, such as
(binary or non-binary) classifiers, orderings/rankings of items, or clusterings
of data points. Our framework is based on a generalization of Angluin's
equivalence query model and Littlestone's online learning model: in each
iteration, the algorithm proposes a model, and the user either accepts it or
reveals a specific mistake in the proposal. The feedback is correct only with
probability $p > 1/2$ (and adversarially incorrect with probability $1 - p$),
i.e., the algorithm must be able to learn in the presence of arbitrary noise.
The algorithm's goal is to learn the ground truth model using few iterations.
Our general framework is based on a graph representation of the models and
user feedback. To be able to learn efficiently, it is sufficient that there be
a graph $G$ whose nodes are the models and (weighted) edges capture the user
feedback, with the property that if $s, s^*$ are the proposed and target
models, respectively, then any (correct) user feedback $s'$ must lie on a
shortest $s$-$s^*$ path in $G$. Under this one assumption, there is a natural
algorithm reminiscent of the Multiplicative Weights Update algorithm, which
will efficiently learn $s^*$ even in the presence of noise in the user's
feedback.
From this general result, we rederive with barely any extra effort classic
results on learning of classifiers and a recent result on interactive
clustering; in addition, we easily obtain new interactive learning algorithms
for ordering/ranking.
",Cybersecurity
"  The challenge of sharing and communicating information is crucial in complex
human-robot interaction (HRI) scenarios. Ontologies and symbolic reasoning are
the state-of-the-art approaches for a natural representation of knowledge,
especially within the Semantic Web domain. In such a context, scripted
paradigms have been adopted to achieve high expressiveness. Nevertheless, since
symbolic reasoning is a high complexity problem, optimizing its performance
requires a careful design of the knowledge. Specifically, a robot architecture
requires the integration of several components implementing different behaviors
and generating a series of beliefs. Most of the components are expected to
access, manipulate, and reason upon a run-time generated semantic
representation of knowledge grounding robot behaviors and perceptions through
formal axioms, with soft real-time requirements.
",Cybersecurity
"  In this paper, a new Smartphone sensor based algorithm is proposed to detect
accurate distance estimation. The algorithm consists of two phases, the first
phase is for detecting the peaks from the Smartphone accelerometer sensor. The
other one is for detecting the step length which varies from step to step. The
proposed algorithm is tested and implemented in real environment and it showed
promising results. Unlike the conventional approaches, the error of the
proposed algorithm is fixed and is not affected by the long distance.
Keywords distance estimation, peaks, step length, accelerometer.
",Cybersecurity
"  Vagueness is something everyone is familiar with. In fact, most people think
that vagueness is closely related to language and exists only there. However,
vagueness is a property of the physical world. Quantum computers harness
superposition and entanglement to perform their computational tasks. Both
superposition and entanglement are vague processes. Thus quantum computers,
which process exact data without ""exploiting"" vagueness, are actually vague
computers.
",Cybersecurity
"  Soft microrobots based on photoresponsive materials and controlled by light
fields can generate a variety of different gaits. This inherent flexibility can
be exploited to maximize their locomotion performance in a given environment
and used to adapt them to changing conditions. Albeit, because of the lack of
accurate locomotion models, and given the intrinsic variability among
microrobots, analytical control design is not possible. Common data-driven
approaches, on the other hand, require running prohibitive numbers of
experiments and lead to very sample-specific results. Here we propose a
probabilistic learning approach for light-controlled soft microrobots based on
Bayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach
results in a learning scheme that is data-efficient, enabling gait optimization
with a limited experimental budget, and robust against differences among
microrobot samples. These features are obtained by designing the learning
scheme through the comparison of different GP priors and BO settings on a
semi-synthetic data set. The developed learning scheme is validated in
microrobot experiments, resulting in a 115% improvement in a microrobot's
locomotion performance with an experimental budget of only 20 tests. These
encouraging results lead the way toward self-adaptive microrobotic systems
based on light-controlled soft microrobots and probabilistic learning control.
",Cybersecurity
"  A data-based policy for iterative control task is presented. The proposed
strategy is model-free and can be applied whenever safe input and state
trajectories of a system performing an iterative task are available. These
trajectories, together with a user-defined cost function, are exploited to
construct a piecewise affine approximation to the value function. Approximated
value functions are then used to evaluate the control policy by solving a
linear program. We show that for linear system subject to convex cost and
constraints, the proposed strategy guarantees closed-loop constraint
satisfaction and performance bounds on the closed-loop trajectory. We evaluate
the proposed strategy in simulations and experiments, the latter carried out on
the Berkeley Autonomous Race Car (BARC) platform. We show that the proposed
strategy is able to reduce the computation time by one order of magnitude while
achieving the same performance as our model-based control algorithm.
",Cybersecurity
"  Graphs are a commonly used construct for representing relationships between
elements in complex high dimensional datasets. Many real-world phenomenon are
dynamic in nature, meaning that any graph used to represent them is inherently
temporal. However, many of the machine learning models designed to capture
knowledge about the structure of these graphs ignore this rich temporal
information when creating representations of the graph. This results in models
which do not perform well when used to make predictions about the future state
of the graph -- especially when the delta between time stamps is not small. In
this work, we explore a novel training procedure and an associated unsupervised
model which creates graph representations optimised to predict the future state
of the graph. We make use of graph convolutional neural networks to encode the
graph into a latent representation, which we then use to train our temporal
offset reconstruction method, inspired by auto-encoders, to predict a later
time point -- multiple time steps into the future. Using our method, we
demonstrate superior performance for the task of future link prediction
compared with none-temporal state-of-the-art baselines. We show our approach to
be capable of outperforming non-temporal baselines by 38% on a real world
dataset.
",Cybersecurity
"  Lack of moderation in online communities enables participants to incur in
personal aggression, harassment or cyberbullying, issues that have been
accentuated by extremist radicalisation in the contemporary post-truth politics
scenario. This kind of hostility is usually expressed by means of toxic
language, profanity or abusive statements. Recently Google has developed a
machine-learning-based toxicity model in an attempt to assess the hostility of
a comment; unfortunately, it has been suggested that said model can be deceived
by adversarial attacks that manipulate the text sequence of the comment. In
this paper we firstly characterise such adversarial attacks as using
obfuscation and polarity transformations. The former deceives by corrupting
toxic trigger content with typographic edits, whereas the latter deceives by
grammatical negation of the toxic content. Then, we propose a two--stage
approach to counter--attack these anomalies, bulding upon a recently proposed
text deobfuscation method and the toxicity scoring model. Lastly, we conducted
an experiment with approximately 24000 distorted comments, showing how in this
way it is feasible to restore toxicity of the adversarial variants, while
incurring roughly on a twofold increase in processing time. Even though novel
adversary challenges would keep coming up derived from the versatile nature of
written language, we anticipate that techniques combining machine learning and
text pattern recognition methods, each one targeting different layers of
linguistic features, would be needed to achieve robust detection of toxic
language, thus fostering aggression--free digital interaction.
",Cybersecurity
"  Heterogeneity has been studied as one of the most common explanations of the
puzzle of cooperation in social dilemmas. A large number of papers have been
published discussing the effects of increasing heterogeneity in structured
populations of agents, where it has been established that heterogeneity may
favour cooperative behaviour if it supports agents to locally coordinate their
strategies. In this paper, assuming an existing model of a heterogeneous
weighted network, we aim to further this analysis by exploring the relationship
(if any) between heterogeneity and cooperation. We adopt a weighted network
which is fully populated by agents playing both the Prisoner's Dilemma or the
Optional Prisoner's Dilemma games with coevolutionary rules, i.e., not only the
strategies but also the link weights evolve over time. Surprisingly, results
show that the heterogeneity of link weights (states) on their own does not
always promote cooperation; rather cooperation is actually favoured by the
increase in the number of overlapping states and not by the heterogeneity
itself. We believe that these results can guide further research towards a more
accurate analysis of the role of heterogeneity in social dilemmas.
",Cybersecurity
"  In this paper we extend the known results of analytic connectivity to
non-uniform hypergraphs. We prove a modified Cheeger's inequality and also give
a bound on analytic connectivity with respect to the degree sequence and
diameter of a hypergraph.
",Cybersecurity
"  In this paper we design information elicitation mechanisms for Bayesian
auctions. While in Bayesian mechanism design the distributions of the players'
private types are often assumed to be common knowledge, information elicitation
considers the situation where the players know the distributions better than
the decision maker. To weaken the information assumption in Bayesian auctions,
we consider an information structure where the knowledge about the
distributions is arbitrarily scattered among the players. In such an
unstructured information setting, we design mechanisms for unit-demand auctions
and additive auctions that aggregate the players' knowledge, generating revenue
that are constant approximations to the optimal Bayesian mechanisms with a
common prior. Our mechanisms are 2-step dominant-strategy truthful and the
revenue increases gracefully with the amount of knowledge the players
collectively have.
",Cybersecurity
"  This work bridges the technical concepts underlying distributed computing and
blockchain technologies with their profound socioeconomic and sociopolitical
implications, particularly on academic research and the healthcare industry.
Several examples from academia, industry, and healthcare are explored
throughout this paper. The limiting factor in contemporary life sciences
research is often funding: for example, to purchase expensive laboratory
equipment and materials, to hire skilled researchers and technicians, and to
acquire and disseminate data through established academic channels. In the case
of the U.S. healthcare system, hospitals generate massive amounts of data, only
a small minority of which is utilized to inform current and future medical
practice. Similarly, corporations too expend large amounts of money to collect,
secure and transmit data from one centralized source to another. In all three
scenarios, data moves under the traditional paradigm of centralization, in
which data is hosted and curated by individuals and organizations and of
benefit to only a small subset of people.
",Cybersecurity
"  Availability of research datasets is keystone for health and life science
study reproducibility and scientific progress. Due to the heterogeneity and
complexity of these data, a main challenge to be overcome by research data
management systems is to provide users with the best answers for their search
queries. In the context of the 2016 bioCADDIE Dataset Retrieval Challenge, we
investigate a novel ranking pipeline to improve the search of datasets used in
biomedical experiments. Our system comprises a query expansion model based on
word embeddings, a similarity measure algorithm that takes into consideration
the relevance of the query terms, and a dataset categorisation method that
boosts the rank of datasets matching query constraints. The system was
evaluated using a corpus with 800k datasets and 21 annotated user queries. Our
system provides competitive results when compared to the other challenge
participants. In the official run, it achieved the highest infAP among the
participants, being +22.3% higher than the median infAP of the participant's
best submissions. Overall, it is ranked at top 2 if an aggregated metric using
the best official measures per participant is considered. The query expansion
method showed positive impact on the system's performance increasing our
baseline up to +5.0% and +3.4% for the infAP and infNDCG metrics, respectively.
Our similarity measure algorithm seems to be robust, in particular compared to
Divergence From Randomness framework, having smaller performance variations
under different training conditions. Finally, the result categorization did not
have significant impact on the system's performance. We believe that our
solution could be used to enhance biomedical dataset management systems. In
particular, the use of data driven query expansion methods could be an
alternative to the complexity of biomedical terminologies.
",Cybersecurity
"  A GelSight sensor uses an elastomeric slab covered with a reflective membrane
to measure tactile signals. It measures the 3D geometry and contact force
information with high spacial resolution, and successfully helped many
challenging robot tasks. A previous sensor, based on a semi-specular membrane,
produces high resolution but with limited geometry accuracy. In this paper, we
describe a new design of GelSight for robot gripper, using a Lambertian
membrane and new illumination system, which gives greatly improved geometric
accuracy while retaining the compact size. We demonstrate its use in measuring
surface normals and reconstructing height maps using photometric stereo. We
also use it for the task of slip detection, using a combination of information
about relative motions on the membrane surface and the shear distortions. Using
a robotic arm and a set of 37 everyday objects with varied properties, we find
that the sensor can detect translational and rotational slip in general cases,
and can be used to improve the stability of the grasp.
",Cybersecurity
"  We present four logic puzzles and after that their solutions. Joseph Yeo
designed 'Cheryl's Birthday'. Mike Hartley came up with a novel solution for
'One Hundred Prisoners and a Light Bulb'. Jonathan Welton designed 'A Blind
Guess' and 'Abby's Birthday'. Hans van Ditmarsch and Barteld Kooi authored the
puzzlebook 'One Hundred Prisoners and a Light Bulb' that contains other
knowledge puzzles, and that can also be found on the webpage
this http URL dedicated to the book.
",Cybersecurity
"  We present the latest major release version 6.0 of the quantified Boolean
formula (QBF) solver DepQBF, which is based on QCDCL. QCDCL is an extension of
the conflict-driven clause learning (CDCL) paradigm implemented in state of the
art propositional satisfiability (SAT) solvers. The Q-resolution calculus
(QRES) is a QBF proof system which underlies QCDCL. QCDCL solvers can produce
QRES proofs of QBFs in prenex conjunctive normal form (PCNF) as a byproduct of
the solving process. In contrast to traditional QCDCL based on QRES, DepQBF 6.0
implements a variant of QCDCL which is based on a generalization of QRES. This
generalization is due to a set of additional axioms and leaves the original
Q-resolution rules unchanged. The generalization of QRES enables QCDCL to
potentially produce exponentially shorter proofs than the traditional variant.
We present an overview of the features implemented in DepQBF and report on
experimental results which demonstrate the effectiveness of generalized QRES in
QCDCL.
",Cybersecurity
"  Text-dependent speaker verification is becoming popular in the speaker
recognition society. However, the conventional i-vector framework which has
been successful for speaker identification and other similar tasks works
relatively poorly in this task. Researchers have proposed several new methods
to improve performance, but it is still unclear that which model is the best
choice, especially when the pass-phrases are prompted during enrollment and
test. In this paper, we introduce four modeling methods and compare their
performance on the newly published RedDots dataset. To further explore the
influence of different frame alignments, Viterbi and forward-backward
algorithms are both used in the HMM-based models. Several bottleneck features
are also investigated. Our experiments show that, by explicitly modeling the
lexical content, the HMM-based modeling achieves good results in the
fixed-phrase condition. In the prompted-phrase condition, GMM-HMM and
i-vector/HMM are not as successful. In both conditions, the forward-backward
algorithm brings more benefits to the i-vector/HMM system. Additionally, we
also find that even though bottleneck features perform well for
text-independent speaker verification, they do not outperform MFCCs on the most
challenging Imposter-Correct trials on RedDots.
",Cybersecurity
"  According to tastes, a person could show preference for a given category of
content to a greater or lesser extent. However, quantifying people's amount of
interest in a certain topic is a challenging task, especially considering the
massive digital information they are exposed to. For example, in the context of
Twitter, aligned with his/her preferences a user may tweet and retweet more
about technology than sports and do not share any music-related content. The
problem we address in this paper is the identification of users' implicit topic
preferences by analyzing the content categories they tend to post on Twitter.
Our proposal is significant given that modeling their multi-topic profile may
be useful to find patterns or association between preferences for categories,
discover trending topics and cluster similar users to generate better group
recommendations of content. In the present work, we propose a method based on
the Mixed Gaussian Model to extract the multidimensional preference
representation for 399 Ecuadorian tweeters concerning twenty-two different
topics (or dimensions) which became known by manually categorizing 68.186
tweets. Our experiment findings indicate that the proposed approach is
effective at detecting the topic interests of users.
",Cybersecurity
"  We investigate the association between musical chords and lyrics by analyzing
a large dataset of user-contributed guitar tablatures. Motivated by the idea
that the emotional content of chords is reflected in the words used in
corresponding lyrics, we analyze associations between lyrics and chord
categories. We also examine the usage patterns of chords and lyrics in
different musical genres, historical eras, and geographical regions. Our
overall results confirms a previously known association between Major chords
and positive valence. We also report a wide variation in this association
across regions, genres, and eras. Our results suggest possible existence of
different emotional associations for other types of chords.
",Cybersecurity
"  Big, fine-grained enterprise registration data that includes time and
location information enables us to quantitatively analyze, visualize, and
understand the patterns of industries at multiple scales across time and space.
However, data quality issues like incompleteness and ambiguity, hinder such
analysis and application. These issues become more challenging when the volume
of data is immense and constantly growing. High Performance Computing (HPC)
frameworks can tackle big data computational issues, but few studies have
systematically investigated imputation methods for enterprise registration data
in this type of computing environment. In this paper, we propose a big data
imputation workflow based on Apache Spark as well as a bare-metal computing
cluster, to impute enterprise registration data. We integrated external data
sources, employed Natural Language Processing (NLP), and compared several
machine-learning methods to address incompleteness and ambiguity problems found
in enterprise registration data. Experimental results illustrate the
feasibility, efficiency, and scalability of the proposed HPC-based imputation
framework, which also provides a reference for other big georeferenced text
data processing. Using these imputation results, we visualize and briefly
discuss the spatiotemporal distribution of industries in China, demonstrating
the potential applications of such data when quality issues are resolved.
",Cybersecurity
"  Repairing locality is an appreciated feature for distributed storage, in
which a damaged or lost data share can be repaired by accessing a subset of
other shares much smaller than is required for decoding the complete data.
However for Secret Sharing (SS) schemes, it has been proven theoretically that
local repairing can not be achieved with perfect security for the majority of
threshold SS schemes, where all the shares are equally regarded in both secret
recovering and share repairing. In this paper we make an attempt on decoupling
the two processes to make secure local repairing possible. Dedicated repairing
redundancies only for the repairing process are generated, which are random
numbers to the original secret. Through this manner a threshold SS scheme with
improved repairing locality is achieved on the condition that security of
repairing redundancies is ensured, or else our scheme degenerates into a
perfect access structure that is equivalent to the best existing schemes can
do. To maximize security of the repairing redundancies, a random placement
mechanism is also proposed.
",Cybersecurity
"  We introduce $\Psi$ec, a local spectral exterior calculus that provides a
discretization of Cartan's exterior calculus of differential forms using
wavelet functions. Our construction consists of differential form wavelets with
flexible directional localization, between fully isotropic and curvelet- and
ridgelet-like, that provide tight frames for the spaces of $k$-forms in
$\mathbb{R}^2$ and $\mathbb{R}^3$. By construction, these wavelets satisfy the
de Rahm co-chain complex, the Hodge decomposition, and that the integral of a
$k+1$-form is a $k$-form. They also enforce Stokes' theorem for differential
forms, and we show that with a finite number of wavelet levels it is most
efficiently approximated using anisotropic curvelet- or ridgelet-like forms.
Our construction is based on the intrinsic geometric properties of the exterior
calculus in the Fourier domain. To reveal these, we extend existing results on
the Fourier transform of differential forms to a frequency domain description
of the exterior calculus, including, for example, a Parseval theorem for forms
and a description of the symbols of all important operators.
",Cybersecurity
"  As both light transport simulation and reinforcement learning are ruled by
the same Fredholm integral equation of the second kind, reinforcement learning
techniques may be used for photorealistic image synthesis: Efficiency may be
dramatically improved by guiding light transport paths by an approximate
solution of the integral equation that is learned during rendering. In the
light of the recent advances in reinforcement learning for playing games, we
investigate the representation of an approximate solution of an integral
equation by artificial neural networks and derive a loss function for that
purpose. The resulting Monte Carlo and quasi-Monte Carlo methods train neural
networks with standard information instead of linear information and naturally
are able to generate an arbitrary number of training samples. The methods are
demonstrated for applications in light transport simulation.
",Cybersecurity
"  A simulation model based on parallel systems is established, aiming to
explore the relation between the number of submissions and the overall quality
of academic journals within a similar discipline under peer review. The model
can effectively simulate the submission, review and acceptance behaviors of
academic journals, in a distributed manner. According to the simulation
experiments, it could possibly happen that the overall standard of academic
journals may deteriorate due to excessive submissions.
",Cybersecurity
"  Improved Phantom cell is a new scenario which has been introduced recently to
enhance the capacity of Heterogeneous Networks (HetNets). The main trait of
this scenario is that, besides maximizing the total network capacity in both
indoor and outdoor environments, it claims to reduce the handover number
compared to the conventional scenarios. In this paper, by a comprehensive
review of the Improved Phantom cells structure, an appropriate algorithm will
be introduced for the handover procedure of this scenario. To reduce the number
of handover in the proposed algorithm, various parameters such as the received
Signal to Interference plus Noise Ratio (SINR) at the user equipment (UE),
users access conditions to the phantom cells, and users staying time in the
target cell based on its velocity, has been considered. Theoretical analyses
and simulation results show that applying the suggested algorithm the improved
phantom cell structure has a much better performance than conventional HetNets
in terms of the number of handover.
",Cybersecurity
"  A new area in which passive WiFi analytics have promise for delivering value
is the real-time monitoring of public transport systems. One example is
determining the true (as opposed to the published) timetable of a public
transport system in real-time. In most cases, there are no other
publicly-available sources for this information. Yet, it is indispensable for
the real-time monitoring of public transport service levels. Furthermore, this
information, if accurate and temporally fine-grained, can be used for very
low-latency incident detection. In this work, we propose using spectral
clustering based on trajectories derived from passive WiFi traces of users of a
public transport system to infer the true timetable and two key performance
indicators of the transport service, namely public transport vehicle headway
and in-station dwell time. By detecting anomalous dwell times or headways, we
demonstrate that a fast and accurate real-time incident-detection procedure can
be obtained. The method we introduce makes use of the advantages of the
high-frequency WiFi data, which provides very low-latency,
universally-accessible information, while minimizing the impact of the noise in
the data.
",Cybersecurity
"  We consider the potential for positioning with a system where antenna arrays
are deployed as a large intelligent surface (LIS). We derive
Fisher-informations and Cramér-Rao lower bounds (CRLB) in closed-form for
terminals along the central perpendicular line (CPL) of the LIS for all three
Cartesian dimensions. For terminals at positions other than the CPL,
closed-form expressions for the Fisher-informations and CRLBs seem out of
reach, and we alternatively provide approximations (in closed-form) which are
shown to be very accurate. We also show that under mild conditions, the CRLBs
in general decrease quadratically in the surface-area for both the $x$ and $y$
dimensions. For the $z$-dimension (distance from the LIS), the CRLB decreases
linearly in the surface-area when terminals are along the CPL. However, when
terminals move away from the CPL, the CRLB is dramatically increased and then
also decreases quadratically in the surface-area. We also extensively discuss
the impact of different deployments (centralized and distributed) of the LIS.
",Cybersecurity
"  Given a list of k source-sink pairs in an edge-weighted graph G, the minimum
multicut problem consists in selecting a set of edges of minimum total weight
in G, such that removing these edges leaves no path from each source to its
corresponding sink. To the best of our knowledge, no non-trivial FPT result for
special cases of this problem, which is APX-hard in general graphs for any
fixed k>2, is known with respect to k only. When the graph G is planar, this
problem is known to be polynomial-time solvable if k=O(1), but cannot be FPT
with respect to k under the Exponential Time Hypothesis.
In this paper, we show that, if G is planar and in addition all sources and
sinks lie on the outer face, then this problem does admit an FPT algorithm when
parameterized by k (although it remains APX-hard when k is part of the input,
even in stars). To do this, we provide a new characterization of optimal
solutions in this case, and then use it to design a ""divide-and-conquer""
approach: namely, some edges that are part of any such solution actually define
an optimal solution for a polynomial-time solvable multiterminal variant of the
problem on some of the sources and sinks (which can be identified thanks to a
reduced enumeration phase). Removing these edges from the graph cuts it into
several smaller instances, which can then be solved recursively.
",Cybersecurity
"  With the future likely to see even more pervasive computation, computational
thinking (problem-solving skills incorporating computing knowledge) is now
being recognized as a fundamental skill needed by all students. Computational
thinking is conceptualizing as opposed to programming, promotes natural human
thinking style than algorithmic reasoning, complements and combines
mathematical and engineering thinking, and it emphasizes ideas, not artifacts.
In this paper, we outline a new visual language, called Patch, using which
students are able to express their solutions to eScience computational problems
in abstract visual tools. Patch is closer to high level procedural languages
such as C++ or Java than Scratch or Snap! but similar to them in ease of use
and combines simplicity and expressive power in one single platform.
",Cybersecurity
"  One important problem in a network is to locate an (invisible) moving entity
by using distance-detectors placed at strategical locations. For instance, the
metric dimension of a graph $G$ is the minimum number $k$ of detectors placed
in some vertices $\{v_1,\cdots,v_k\}$ such that the vector $(d_1,\cdots,d_k)$
of the distances $d(v_i,r)$ between the detectors and the entity's location $r$
allows to uniquely determine $r \in V(G)$. In a more realistic setting, instead
of getting the exact distance information, given devices placed in
$\{v_1,\cdots,v_k\}$, we get only relative distances between the entity's
location $r$ and the devices (for every $1\leq i,j\leq k$, it is provided
whether $d(v_i,r) >$, $<$, or $=$ to $d(v_j,r)$). The centroidal dimension of a
graph $G$ is the minimum number of devices required to locate the entity in
this setting.
We consider the natural generalization of the latter problem, where vertices
may be probed sequentially until the moving entity is located. At every turn, a
set $\{v_1,\cdots,v_k\}$ of vertices is probed and then the relative distances
between the vertices $v_i$ and the current location $r$ of the entity are
given. If not located, the moving entity may move along one edge. Let $\zeta^*
(G)$ be the minimum $k$ such that the entity is eventually located, whatever it
does, in the graph $G$.
We prove that $\zeta^* (T)\leq 2$ for every tree $T$ and give an upper bound
on $\zeta^*(G\square H)$ in cartesian product of graphs $G$ and $H$. Our main
result is that $\zeta^* (G)\leq 3$ for any outerplanar graph $G$. We then prove
that $\zeta^* (G)$ is bounded by the pathwidth of $G$ plus 1 and that the
optimization problem of determining $\zeta^* (G)$ is NP-hard in general graphs.
Finally, we show that approximating (up to any constant distance) the entity's
location in the Euclidean plane requires at most two vertices per turn.
",Cybersecurity
"  Can we perform an end-to-end sound source separation (SSS) with a variable
number of sources using a deep learning model? This paper presents an extension
of the Wave-U-Net model which allows end-to-end monaural source separation with
a non-fixed number of sources. Furthermore, we propose multiplicative
conditioning with instrument labels at the bottleneck of the Wave-U-Net and
show its effect on the separation results. This approach can be further
extended to other types of conditioning such as audio-visual SSS and
score-informed SSS.
",Cybersecurity
"  Insertion is a challenging haptic and visual control problem with significant
practical value for manufacturing. Existing approaches in the model-based
robotics community can be highly effective when task geometry is known, but are
complex and cumbersome to implement, and must be tailored to each individual
problem by a qualified engineer. Within the learning community there is a long
history of insertion research, but existing approaches are typically either too
sample-inefficient to run on real robots, or assume access to high-level object
features, e.g. socket pose. In this paper we show that relatively minor
modifications to an off-the-shelf Deep-RL algorithm (DDPG), combined with a
small number of human demonstrations, allows the robot to quickly learn to
solve these tasks efficiently and robustly. Our approach requires no modeling
or simulation, no parameterized search or alignment behaviors, no vision system
aside from raw images, and no reward shaping. We evaluate our approach on a
narrow-clearance peg-insertion task and a deformable clip-insertion task, both
of which include variability in the socket position. Our results show that
these tasks can be solved reliably on the real robot in less than 10 minutes of
interaction time, and that the resulting policies are robust to variance in the
socket position and orientation.
",Cybersecurity
"  Application Programming Interfaces (APIs) often have usage constraints, such
as restrictions on call order or call conditions. API misuses, i.e., violations
of these constraints, may lead to software crashes, bugs, and vulnerabilities.
Though researchers developed many API-misuse detectors over the last two
decades, recent studies show that API misuses are still prevalent. Therefore,
we need to understand the capabilities and limitations of existing detectors in
order to advance the state of the art. In this paper, we present the first-ever
qualitative and quantitative evaluation that compares static API-misuse
detectors along the same dimensions, and with original author validation. To
accomplish this, we develop MUC, a classification of API misuses, and
MUBenchPipe, an automated benchmark for detector comparison, on top of our
misuse dataset, MUBench. Our results show that the capabilities of existing
detectors vary greatly and that existing detectors, though capable of detecting
misuses, suffer from extremely low precision and recall. A systematic
root-cause analysis reveals that, most importantly, detectors need to go beyond
the naive assumption that a deviation from the most-frequent usage corresponds
to a misuse and need to obtain additional usage examples to train their models.
We present possible directions towards more-powerful API-misuse detectors.
",Cybersecurity
"  Intersections are hazardous places. Threats arise from interactions among
pedestrians, bicycles and vehicles, more complicated vehicle trajectories in
the absence of lane markings, phases that prevent determining who has the right
of way, invisible vehicle approaches, vehicle obstructions, and illegal
movements. These challenges are not fully addressed by the ""road diet"" and road
redesign prescribed in Vision Zero plans, nor will they be completely overcome
by autonomous vehicles with their many sensors and tireless attention to
surroundings. Accidents can also occur because drivers, cyclists and
pedestrians do not have the information they need to avoid wrong decisions. In
these cases, the missing information can be computed and broadcast by an
intelligent intersection. The information gives the current full signal phase,
an estimate of the time when the phase will change, and the occupancy of the
blind spots of the driver or autonomous vehicle. The paper develops a design of
the intelligent intersection, motivated by the analysis of an accident at an
intersection in Tempe, AZ, between an automated Uber Volvo and a manual Honda
CRV and culminates in a proposal for an intelligent intersection
infrastructure. The intelligent intersection also serves as a software-enabled
version of the `protected intersection' design to improve the passage of
cyclists and pedestrians through an intersection.
",Cybersecurity
"  We investigated a way to predict the gender of a name using character-level
Long-Short Term Memory (char-LSTM). We compared our method with some
conventional machine learning methods, namely Naive Bayes, logistic regression,
and XGBoost with n-grams as the features. We evaluated the models on a dataset
consisting of the names of Indonesian people. It is not common to use a family
name as the surname in Indonesian culture, except in some ethnicities.
Therefore, we inferred the gender from both full names and first names. The
results show that we can achieve 92.25% accuracy from full names, while using
first names only yields 90.65% accuracy. These results are better than the ones
from applying the classical machine learning algorithms to n-grams.
",Cybersecurity
"  Very important breakthroughs in data centric deep learning algorithms led to
impressive performance in transactional point applications of Artificial
Intelligence (AI) such as Face Recognition, or EKG classification. With all due
appreciation, however, knowledge blind data only machine learning algorithms
have severe limitations for non-transactional AI applications, such as medical
diagnosis beyond the EKG results. Such applications require deeper and broader
knowledge in their problem solving capabilities, e.g. integrating anatomy and
physiology knowledge with EKG results and other patient findings. Following a
review and illustrations of such limitations for several real life AI
applications, we point at ways to overcome them. The proposed Wikipedia for
Smart Machines initiative aims at building repositories of software structures
that represent humanity science & technology knowledge in various parts of
life; knowledge that we all learn in schools, universities and during our
professional life. Target readers for these repositories are smart machines;
not human. AI software developers will have these Reusable Knowledge structures
readily available, hence, the proposed name ReKopedia. Big Data is by now a
mature technology, it is time to focus on Big Knowledge. Some will be derived
from data, some will be obtained from mankind gigantic repository of knowledge.
Wikipedia for smart machines along with the new Double Deep Learning approach
offer a paradigm for integrating datacentric deep learning algorithms with
algorithms that leverage deep knowledge, e.g. evidential reasoning and
causality reasoning. For illustration, a project is described to produce
ReKopedia knowledge modules for medical diagnosis of about 1,000 disorders.
Data is important, but knowledge deep, basic, and commonsense is equally
important.
",Cybersecurity
"  Program synthesis is a class of regression problems where one seeks a
solution, in the form of a source-code program, mapping the inputs to their
corresponding outputs exactly. Due to its precise and combinatorial nature,
program synthesis is commonly formulated as a constraint satisfaction problem,
where input-output examples are encoded as constraints and solved with a
constraint solver. A key challenge of this formulation is scalability: while
constraint solvers work well with a few well-chosen examples, a large set of
examples can incur significant overhead in both time and memory. We describe a
method to discover a subset of examples that is both small and representative:
the subset is constructed iteratively, using a neural network to predict the
probability of unchosen examples conditioned on the chosen examples in the
subset, and greedily adding the least probable example. We empirically evaluate
the representativeness of the subsets constructed by our method, and
demonstrate such subsets can significantly improve synthesis time and
stability.
",Cybersecurity
"  The wide adoption of smartphones and mobile applications has brought
significant changes to not only how individuals behave in the real world, but
also how groups of users interact with each other when organizing group events.
Understanding how users make event decisions as a group and identifying the
contributing factors can offer important insights for social group studies and
more effective system and application design for group event scheduling.
In this work, we have designed a new mobile application called
OutWithFriendz, which enables users of our mobile app to organize group events,
invite friends, suggest and vote on event time and venue. We have deployed
OutWithFriendz at both Apple App Store and Google Play, and conducted a
large-scale user study spanning over 500 users and 300 group events. Our
analysis has revealed several important observations regarding group event
planning process including the importance of user mobility, individual
preferences, host preferences, and group voting process.
",Cybersecurity
"  The application domains of civilian unmanned aerial systems (UASs) include
agriculture, exploration, transportation, and entertainment. The expected
growth of the UAS industry brings along new challenges: Unmanned aerial vehicle
(UAV) flight control signaling requires low throughput, but extremely high
reliability, whereas the data rate for payload data can be significant. This
paper develops UAV number projections and concludes that small and micro UAVs
will dominate the US airspace with accelerated growth between 2028 and 2032. We
analyze the orthogonal frequency division multiplexing (OFDM) waveform because
it can provide the much needed flexibility, spectral efficiency, and,
potentially, reliability and derive suitable OFDM waveform parameters as a
function of UAV flight characteristics. OFDM also lends itself to agile
spectrum access. Based on our UAV growth predictions, we conclude that dynamic
spectrum access is needed and discuss the applicability of spectrum sharing
techniques for future UAS communications.
",Cybersecurity
"  Artificial intelligence methods have often been applied to perform specific
functions or tasks in the cyber-defense realm. However, as adversary methods
become more complex and difficult to divine, piecemeal efforts to understand
cyber-attacks, and malware-based attacks in particular, are not providing
sufficient means for malware analysts to understand the past, present and
future characteristics of malware.
In this paper, we present the Malware Analysis and Attributed using Genetic
Information (MAAGI) system. The underlying idea behind the MAAGI system is that
there are strong similarities between malware behavior and biological organism
behavior, and applying biologically inspired methods to corpora of malware can
help analysts better understand the ecosystem of malware attacks. Due to the
sophistication of the malware and the analysis, the MAAGI system relies heavily
on artificial intelligence techniques to provide this capability. It has
already yielded promising results over its development life, and will hopefully
inspire more integration between the artificial intelligence and cyber--defense
communities.
",Cybersecurity
"  In this paper, the formulas of some exponential sums over finite field,
related to the Coulter's polynomial, are settled based on the Coulter's
theorems on Weil sums, which may have potential application in the construction
of linear codes with few weights.
",Cybersecurity
"  Online social platforms are beset with hateful speech - content that
expresses hatred for a person or group of people. Such content can frighten,
intimidate, or silence platform users, and some of it can inspire other users
to commit violence. Despite widespread recognition of the problems posed by
such content, reliable solutions even for detecting hateful speech are lacking.
In the present work, we establish why keyword-based methods are insufficient
for detection. We then propose an approach to detecting hateful speech that
uses content produced by self-identifying hateful communities as training data.
Our approach bypasses the expensive annotation process often required to train
keyword systems and performs well across several established platforms, making
substantial improvements over current state-of-the-art approaches.
",Cybersecurity
"  The manuscript discusses still preliminary considerations with regard to the
dynamics and kinematics of an egg shaped robot with an gyro driven inertia
actuator. The method of calculation follows the idea that we would like to
express the entire dynamic equations in terms of moments instead of forces.
Also we avoid to derive the equations from a Lagrange function with
constraints. The result of the calculations is meant to be applicable to two
robot prototypes that have been build at the AES\&R Laboratory at the National
Chung Cheng University in Taiwan.
",Cybersecurity
"  We present a simple encoding for unlabeled noncrossing graphs and show how
its latent counterpart helps us to represent several families of directed and
undirected graphs used in syntactic and semantic parsing of natural language as
context-free languages. The families are separated purely on the basis of
forbidden patterns in latent encoding, eliminating the need to differentiate
the families of non-crossing graphs in inference algorithms: one algorithm
works for all when the search space can be controlled in parser input.
",Cybersecurity
"  The practical success of Boolean Satisfiability (SAT) solvers stems from the
CDCL (Conflict-Driven Clause Learning) approach to SAT solving. However, from a
propositional proof complexity perspective, CDCL is no more powerful than the
resolution proof system, for which many hard examples exist. This paper
proposes a new problem transformation, which enables reducing the decision
problem for formulas in conjunctive normal form (CNF) to the problem of solving
maximum satisfiability over Horn formulas. Given the new transformation, the
paper proves a polynomial bound on the number of MaxSAT resolution steps for
pigeonhole formulas. This result is in clear contrast with earlier results on
the length of proofs of MaxSAT resolution for pigeonhole formulas. The paper
also establishes the same polynomial bound in the case of modern core-guided
MaxSAT solvers. Experimental results, obtained on CNF formulas known to be hard
for CDCL SAT solvers, show that these can be efficiently solved with modern
MaxSAT solvers.
",Cybersecurity
"  This paper presents a realization of the approach to spatial 3D stereo of
visualization of 3D images with use parallel Graphics processing unit (GPU).
The experiments of realization of synthesis of images of a 3D stage by a method
of trace of beams on GPU with Compute Unified Device Architecture (CUDA) have
shown that 60 % of the time is spent for the decision of a computing problem
approximately, the major part of time (40 %) is spent for transfer of data
between the central processing unit and GPU for computations and the
organization process of visualization. The study of the influence of increase
in the size of the GPU network at the speed of computations showed importance
of the correct task of structure of formation of the parallel computer network
and general mechanism of parallelization. Keywords: Volumetric 3D
visualization, stereo 3D visualization, ray tracing, parallel computing on GPU,
CUDA
",Cybersecurity
"  We describe some necessary conditions for the existence of a Hamiltonian path
in any graph (in other words, for a graph to be traceable). These conditions
result in a linear time algorithm to decide the Hamiltonian path problem for
cactus graphs. We apply this algorithm to several molecular databases to report
the numbers of graphs that are traceable cactus graphs.
",Cybersecurity
"  The purpose of this study is to analyze cyber security and security practices
of electronic information and network system, network threats, and techniques
to prevent the cyber attacks in hotels. Helping the information technology
directors and chief information officers (CIO) is the aim of this study to
advance policy for security of electronic information in hotels and suggesting
some techniques and tools to secure the computer networks. This research is
completely qualitative while the case study and interviews have done in 5
random hotels in Reno, Nevada, United States of America. The interview has done
with 50 hotel guests, 10 front desk employees, 3 IT manager and 2 assistant of
General manager. The results show that hotels' cyber security is very low and
hotels are very vulnerable in this regard and at the end, the implications and
contribution of the study is mentioned.
",Cybersecurity
"  In this work, we propose an end-to-end deep architecture that jointly learns
to detect obstacles and estimate their depth for MAV flight applications. Most
of the existing approaches either rely on Visual SLAM systems or on depth
estimation models to build 3D maps and detect obstacles. However, for the task
of avoiding obstacles this level of complexity is not required. Recent works
have proposed multi task architectures to both perform scene understanding and
depth estimation. We follow their track and propose a specific architecture to
jointly estimate depth and obstacles, without the need to compute a global map,
but maintaining compatibility with a global SLAM system if needed. The network
architecture is devised to exploit the joint information of the obstacle
detection task, that produces more reliable bounding boxes, with the depth
estimation one, increasing the robustness of both to scenario changes. We call
this architecture J-MOD$^{2}$. We test the effectiveness of our approach with
experiments on sequences with different appearance and focal lengths and
compare it to SotA multi task methods that jointly perform semantic
segmentation and depth estimation. In addition, we show the integration in a
full system using a set of simulated navigation experiments where a MAV
explores an unknown scenario and plans safe trajectories by using our detection
model.
",Cybersecurity
"  A graph $G$ is called B$_k$-VPG (resp., B$_k$-EPG), for some constant $k\geq
0$, if it has a string representation on a grid such that each vertex is an
orthogonal path with at most $k$ bends and two vertices are adjacent in $G$ if
and only if the corresponding strings intersect (resp., the corresponding
strings share at least one grid edge). If two adjacent strings of a B$_k$-VPG
graph intersect exactly once, then the graph is called a one-string B$_k$-VPG
graph.
In this paper, we study the Maximum Independent Set and Minimum Dominating
Set problems on B$_1$-VPG and B$_1$-EPG graphs. We first give a simple $O(\log
n)$-approximation algorithm for the Maximum Independent Set problem on
B$_1$-VPG graphs, improving the previous $O((\log n)^2)$-approximation
algorithm of Lahiri et al. (COCOA 2015). Then, we consider the Minimum
Dominating Set problem. We give an $O(1)$-approximation algorithm for this
problem on one-string B$_1$-VPG graphs, providing the first constant-factor
approximation algorithm for this problem. Moreover, we show that the Minimum
Dominating Set problem is APX-hard on B$_1$-EPG graphs, ruling out the
possibility of a PTAS unless P=NP. Finally, we give constant-factor
approximation algorithms for this problem on two non-trivial subclasses of
B$_1$-EPG graphs. To our knowledge, these are the first results for the Minimum
Dominating Set problem on B$_1$-EPG graphs, partially answering a question
posed by Epstein et al. (WADS 2013).
",Cybersecurity
"  Approximate model counting for bit-vector SMT formulas (generalizing \#SAT)
has many applications such as probabilistic inference and quantitative
information-flow security, but it is computationally difficult. Adding random
parity constraints (XOR streamlining) and then checking satisfiability is an
effective approximation technique, but it requires a prior hypothesis about the
model count to produce useful results. We propose an approach inspired by
statistical estimation to continually refine a probabilistic estimate of the
model count for a formula, so that each XOR-streamlined query yields as much
information as possible. We implement this approach, with an approximate
probability model, as a wrapper around an off-the-shelf SMT solver or SAT
solver. Experimental results show that the implementation is faster than the
most similar previous approaches which used simpler refinement strategies. The
technique also lets us model count formulas over floating-point constraints,
which we demonstrate with an application to a vulnerability in differential
privacy mechanisms.
",Cybersecurity
"  In this paper, a novel method using 3D Convolutional Neural Network (3D-CNN)
architecture has been proposed for speaker verification in the text-independent
setting. One of the main challenges is the creation of the speaker models. Most
of the previously-reported approaches create speaker models based on averaging
the extracted features from utterances of the speaker, which is known as the
d-vector system. In our paper, we propose an adaptive feature learning by
utilizing the 3D-CNNs for direct speaker model creation in which, for both
development and enrollment phases, an identical number of spoken utterances per
speaker is fed to the network for representing the speakers' utterances and
creation of the speaker model. This leads to simultaneously capturing the
speaker-related information and building a more robust system to cope with
within-speaker variation. We demonstrate that the proposed method significantly
outperforms the traditional d-vector verification system. Moreover, the
proposed system can also be an alternative to the traditional d-vector system
which is a one-shot speaker modeling system by utilizing 3D-CNNs.
",Cybersecurity
"  Decades of psychological research have been aimed at modeling how people
learn features and categories. The empirical validation of these theories is
often based on artificial stimuli with simple representations. Recently, deep
neural networks have reached or surpassed human accuracy on tasks such as
identifying objects in natural images. These networks learn representations of
real-world stimuli that can potentially be leveraged to capture psychological
representations. We find that state-of-the-art object classification networks
provide surprisingly accurate predictions of human similarity judgments for
natural images, but fail to capture some of the structure represented by
people. We show that a simple transformation that corrects these discrepancies
can be obtained through convex optimization. We use the resulting
representations to predict the difficulty of learning novel categories of
natural images. Our results extend the scope of psychological experiments and
computational modeling by enabling tractable use of large natural stimulus
sets.
",Cybersecurity
"  Accurately predicting and detecting interstitial lung disease (ILD) patterns
given any computed tomography (CT) slice without any pre-processing
prerequisites, such as manually delineated regions of interest (ROIs), is a
clinically desirable, yet challenging goal. The majority of existing work
relies on manually-provided ILD ROIs to extract sampled 2D image patches from
CT slices and, from there, performs patch-based ILD categorization. Acquiring
manual ROIs is labor intensive and serves as a bottleneck towards
fully-automated CT imaging ILD screening over large-scale populations.
Furthermore, despite the considerable high frequency of more than one ILD
pattern on a single CT slice, previous works are only designed to detect one
ILD pattern per slice or patch.
To tackle these two critical challenges, we present multi-label deep
convolutional neural networks (CNNs) for detecting ILDs from holistic CT slices
(instead of ROIs or sub-images). Conventional single-labeled CNN models can be
augmented to cope with the possible presence of multiple ILD pattern labels,
via 1) continuous-valued deep regression based robust norm loss functions or 2)
a categorical objective as the sum of element-wise binary logistic losses. Our
methods are evaluated and validated using a publicly available database of 658
patient CT scans under five-fold cross-validation, achieving promising
performance on detecting four major ILD patterns: Ground Glass, Reticular,
Honeycomb, and Emphysema. We also investigate the effectiveness of a CNN
activation-based deep-feature encoding scheme using Fisher vector encoding,
which treats ILD detection as spatially-unordered deep texture classification.
",Cybersecurity
"  The entropy power inequality (EPI) and the Brascamp-Lieb inequality (BLI) can
be viewed as information inequalities concerning entropies of linear
transformations of random variables. The EPI provides lower bounds for the
entropy of linear transformations of random vectors with independent
components. The BLI, on the other hand, provides upper bounds on the entropy of
a random vector in terms of the entropies of its linear transformations. In
this paper, we present a new entropy inequality that generalizes both the BLI
and EPI by considering a variety of independence relations among the components
of a random vector. Our main technical contribution is in the proof strategy
that leverages the ""doubling trick"" to prove Gaussian optimality for certain
entropy expressions under independence constraints.
",Cybersecurity
"  Background: In silico drug-target interaction (DTI) prediction plays an
integral role in drug repositioning: the discovery of new uses for existing
drugs. One popular method of drug repositioning is network-based DTI
prediction, which uses complex network theory to predict DTIs from a
drug-target network. Currently, most network-based DTI prediction is based on
machine learning methods such as Restricted Boltzmann Machines (RBM) or Support
Vector Machines (SVM). These methods require additional information about the
characteristics of drugs, targets and DTIs, such as chemical structure, genome
sequence, binding types, causes of interactions, etc., and do not perform
satisfactorily when such information is unavailable. We propose a new,
alternative method for DTI prediction that makes use of only network topology
information attempting to solve this problem.
Results: We compare our method for DTI prediction against the well-known RBM
approach. We show that when applied to the MATADOR database, our approach based
on node neighborhoods yield higher precision for high-ranking predictions than
RBM when no information regarding DTI types is available.
Conclusion: This demonstrates that approaches purely based on network
topology provide a more suitable approach to DTI prediction in the many
real-life situations where little or no prior knowledge is available about the
characteristics of drugs, targets, or their interactions.
",Cybersecurity
"  In this paper we introduce MATMPC, an open source software built in MATLAB
for nonlinear model predictive control (NMPC). It is designed to facilitate
modelling, controller design and simulation for a wide class of NMPC
applications. MATMPC has a number of algorithmic modules, including automatic
differentiation, direct multiple shooting, condensing, linear quadratic program
(QP) solver and globalization. It also supports a unique Curvature-like Measure
of Nonlinearity (CMoN) MPC algorithm. MATMPC has been designed to provide
state-of-the-art performance while making the prototyping easy, also with
limited programming knowledge. This is achieved by writing each module directly
in MATLAB API for C. As a result, MATMPC modules can be compiled into MEX
functions with performance comparable to plain C/C++ solvers. MATMPC has been
successfully used in operating systems including WINDOWS, LINUX AND OS X.
Selected examples are shown to highlight the effectiveness of MATMPC.
",Cybersecurity
"  Image-guided radiation therapy can benefit from accurate motion tracking by
ultrasound imaging, in order to minimize treatment margins and radiate moving
anatomical targets, e.g., due to breathing. One way to formulate this tracking
problem is the automatic localization of given tracked anatomical landmarks
throughout a temporal ultrasound sequence. For this, we herein propose a
fully-convolutional Siamese network that learns the similarity between pairs of
image regions containing the same landmark. Accordingly, it learns to localize
and thus track arbitrary image features, not only predefined anatomical
structures. We employ a temporal consistency model as a location prior, which
we combine with the network-predicted location probability map to track a
target iteratively in ultrasound sequences. We applied this method on the
dataset of the Challenge on Liver Ultrasound Tracking (CLUST) with competitive
results, where our work is the first to effectively apply CNNs on this tracking
problem, thanks to our temporal regularization.
",Cybersecurity
"  The increasing uptake of residential batteries has led to suggestions that
the prevalence of batteries on LV networks will serendipitously mitigate the
technical problems induced by PV installations. However, in general, the
effects of PV-battery systems on LV networks have not been well studied. Given
this background, in this paper, we test the assertion that the uncoordinated
operation of batteries improves network performance. In order to carry out this
assessment, we develop a methodology for incorporating home energy management
(HEM) operational decisions within a Monte Carlo (MC) power flow analysis
comprising three parts. First, due to the unavailability of large number of
load and PV traces required for MC analysis, we used a maximum a-posteriori
Dirichlet process to generate statistically representative synthetic profiles.
Second, a policy function approximation (PFA) that emulates the outputs of the
HEM solver is implemented to provide battery scheduling policies for a pool of
customers, making simulation of optimization-based HEM feasible within MC
studies. Third, the resulting net loads are used in a MC power flow time series
study. The efficacy of our method is shown on three typical LV feeders. Our
assessment finds that uncoordinated PV-battery systems have little beneficial
impact on LV networks.
",Cybersecurity
"  Multicopters are becoming increasingly important in both civil and military
fields. Currently, most multicopter propulsion systems are designed by
experience and trial-and-error experiments, which are costly and ineffective.
This paper proposes a simple and practical method to help designers find the
optimal propulsion system according to the given design requirements. First,
the modeling methods for four basic components of the propulsion system
including propellers, motors, electric speed controls, and batteries are
studied respectively. Secondly, the whole optimization design problem is
simplified and decoupled into several sub-problems. By solving these
sub-problems, the optimal parameters of each component can be obtained
respectively. Finally, based on the obtained optimal component parameters, the
optimal product of each component can be quickly located and determined from
the corresponding database. Experiments and statistical analyses demonstrate
the effectiveness of the proposed method.
",Cybersecurity
"  In this paper, we present a unified end-to-end approach to build a large
scale Visual Search and Recommendation system for e-commerce. Previous works
have targeted these problems in isolation. We believe a more effective and
elegant solution could be obtained by tackling them together. We propose a
unified Deep Convolutional Neural Network architecture, called VisNet, to learn
embeddings to capture the notion of visual similarity, across several semantic
granularities. We demonstrate the superiority of our approach for the task of
image retrieval, by comparing against the state-of-the-art on the Exact
Street2Shop dataset. We then share the design decisions and trade-offs made
while deploying the model to power Visual Recommendations across a catalog of
50M products, supporting 2K queries a second at Flipkart, India's largest
e-commerce company. The deployment of our solution has yielded a significant
business impact, as measured by the conversion-rate.
",Cybersecurity
"  In most process control systems nowadays, process measurements are
periodically collected and archived in historians. Analytics applications
process the data, and provide results offline or in a time period that is
considerably slow in comparison to the performance of the manufacturing
process. Along with the proliferation of Internet-of-Things (IoT) and the
introduction of ""pervasive sensors"" technology in process industries,
increasing number of sensors and actuators are installed in process plants for
pervasive sensing and control, and the volume of produced process data is
growing exponentially. To digest these data and meet the ever-growing
requirements to increase production efficiency and improve product quality,
there needs to be a way to both improve the performance of the analytics system
and scale the system to closely monitor a much larger set of plant resources.
In this paper, we present a real-time data analytics platform, called RT-DAP,
to support large-scale continuous data analytics in process industries. RT-DAP
is designed to be able to stream, store, process and visualize a large volume
of realtime data flows collected from heterogeneous plant resources, and
feedback to the control system and operators in a realtime manner. A prototype
of the platform is implemented on Microsoft Azure. Our extensive experiments
validate the design methodologies of RT-DAP and demonstrate its efficiency in
both component and system levels.
",Cybersecurity
"  In this paper, we propose a novel and elegant solution to ""Multi-Source
Neural Machine Translation"" (MSNMT) which only relies on preprocessing a N-way
multilingual corpus without modifying the Neural Machine Translation (NMT)
architecture or training procedure. We simply concatenate the source sentences
to form a single long multi-source input sentence while keeping the target side
sentence as it is and train an NMT system using this preprocessed corpus. We
evaluate our method in resource poor as well as resource rich settings and show
its effectiveness (up to 4 BLEU using 2 source languages and up to 6 BLEU using
5 source languages) by comparing against existing methods for MSNMT. We also
provide some insights on how the NMT system leverages multilingual information
in such a scenario by visualizing attention.
",Cybersecurity
"  In this work we establish the relation between optimal control and training
deep Convolution Neural Networks (CNNs). We show that the forward propagation
in CNNs can be interpreted as a time-dependent nonlinear differential equation
and learning as controlling the parameters of the differential equation such
that the network approximates the data-label relation for given training data.
Using this continuous interpretation we derive two new methods to scale CNNs
with respect to two different dimensions. The first class of multiscale methods
connects low-resolution and high-resolution data through prolongation and
restriction of CNN parameters. We demonstrate that this enables classifying
high-resolution images using CNNs trained with low-resolution images and vice
versa and warm-starting the learning process. The second class of multiscale
methods connects shallow and deep networks and leads to new training strategies
that gradually increase the depths of the CNN while re-using parameters for
initializations.
",Cybersecurity
"  Let $m(n)$ denote the maximum size of a family of subsets which does not
contain two disjoint sets along with their union. In 1968 Kleitman proved that
$m(n) = {n\choose m+1}+\ldots +{n\choose 2m+1}$ if $n=3m+1$. Confirming the
conjecture of Kleitman, we establish the same equality for the cases $n=3m$ and
$n=3m+2$, and also determine all extremal families. Unlike the case $n=3m+1$,
the extremal families are not unique. This is a plausible reason behind the
relative difficulty of our proofs. We completely settle the case of several
families as well.
",Cybersecurity
"  Autonomous robot manipulation often involves both estimating the pose of the
object to be manipulated and selecting a viable grasp point. Methods using
RGB-D data have shown great success in solving these problems. However, there
are situations where cost constraints or the working environment may limit the
use of RGB-D sensors. When limited to monocular camera data only, both the
problem of object pose estimation and of grasp point selection are very
challenging. In the past, research has focused on solving these problems
separately. In this work, we introduce a novel method called SilhoNet that
bridges the gap between these two tasks. We use a Convolutional Neural Network
(CNN) pipeline that takes in ROI proposals to simultaneously predict an
intermediate silhouette representation for objects with an associated occlusion
mask. The 3D pose is then regressed from the predicted silhouettes. Grasp
points from a precomputed database are filtered by back-projecting them onto
the occlusion mask to find which points are visible in the scene. We show that
our method achieves better overall performance than the state-of-the art
PoseCNN network for 3D pose estimation on the YCB-video dataset.
",Cybersecurity
"  It is well-known that exploiting label correlations is important to
multi-label learning. Existing approaches either assume that the label
correlations are global and shared by all instances; or that the label
correlations are local and shared only by a data subset. In fact, in the
real-world applications, both cases may occur that some label correlations are
globally applicable and some are shared only in a local group of instances.
Moreover, it is also a usual case that only partial labels are observed, which
makes the exploitation of the label correlations much more difficult. That is,
it is hard to estimate the label correlations when many labels are absent. In
this paper, we propose a new multi-label approach GLOCAL dealing with both the
full-label and the missing-label cases, exploiting global and local label
correlations simultaneously, through learning a latent label representation and
optimizing label manifolds. The extensive experimental studies validate the
effectiveness of our approach on both full-label and missing-label data.
",Cybersecurity
"  We study the relationship between performance and practice by analyzing the
activity of many players of a casual online game. We find significant
heterogeneity in the improvement of player performance, given by score, and
address this by dividing players into similar skill levels and segmenting each
player's activity into sessions, i.e., sequence of game rounds without an
extended break. After disaggregating data, we find that performance improves
with practice across all skill levels. More interestingly, players are more
likely to end their session after an especially large improvement, leading to a
peak score in their very last game of a session. In addition, success is
strongly correlated with a lower quitting rate when the score drops, and only
weakly correlated with skill, in line with psychological findings about the
value of persistence and ""grit"": successful players are those who persist in
their practice despite lower scores. Finally, we train an epsilon-machine, a
type of hidden Markov model, and find a plausible mechanism of game play that
can predict player performance and quitting the game. Our work raises the
possibility of real-time assessment and behavior prediction that can be used to
optimize human performance.
",Cybersecurity
"  We present a probabilistic approach to generate a small, query-able summary
of a dataset for interactive data exploration. Departing from traditional
summarization techniques, we use the Principle of Maximum Entropy to generate a
probabilistic representation of the data that can be used to give approximate
query answers. We develop the theoretical framework and formulation of our
probabilistic representation and show how to use it to answer queries. We then
present solving techniques and give three critical optimizations to improve
preprocessing time and query accuracy. Lastly, we experimentally evaluate our
work using a 5 GB dataset of flights within the United States and a 210 GB
dataset from an astronomy particle simulation. While our current work only
supports linear queries, we show that our technique can successfully answer
queries faster than sampling while introducing, on average, no more error than
sampling and can better distinguish between rare and nonexistent values.
",Cybersecurity
"  The problem of how to coordinate a large fleet of trucks with given itinerary
to enable fuel-efficient platooning is considered. Platooning is a promising
technology that enables trucks to save significant amounts of fuel by driving
close together and thus reducing air drag. A setting is considered in which
each truck in a fleet is provided with a start location, a destination, a
departure time, and an arrival deadline from a higher planning level.
Fuel-efficient plans should be computed. The plans consist of routes and speed
profiles that allow trucks to arrive by their arrival deadlines. Hereby, trucks
can meet on common parts of their routes and form platoons, resulting in
decreased fuel consumption.
We formulate a combinatorial optimization problem that combines plans
involving only two vehicles. We show that this problem is hard to solve for
large problem instances. Hence a heuristic algorithm is proposed. The resulting
plans are further optimized using convex optimization techniques. The method is
evaluated with Monte Carlo simulations in a realistic setting. We demonstrate
that the proposed algorithm can compute plans for thousands of trucks and that
significant fuel savings can be achieved.
",Cybersecurity
"  We investigate the computational complexity of various problems for simple
recurrent neural networks (RNNs) as formal models for recognizing weighted
languages. We focus on the single-layer, ReLU-activation, rational-weight RNNs
with softmax, which are commonly used in natural language processing
applications. We show that most problems for such RNNs are undecidable,
including consistency, equivalence, minimization, and the determination of the
highest-weighted string. However, for consistent RNNs the last problem becomes
decidable, although the solution length can surpass all computable bounds. If
additionally the string is limited to polynomial length, the problem becomes
NP-complete and APX-hard. In summary, this shows that approximations and
heuristic algorithms are necessary in practical applications of those RNNs.
",Cybersecurity
"  We introduce a novel method for defining geographic districts in road
networks using stable matching. In this approach, each geographic district is
defined in terms of a center, which identifies a location of interest, such as
a post office or polling place, and all other network vertices must be labeled
with the center to which they are associated. We focus on defining geographic
districts that are equitable, in that every district has the same number of
vertices and the assignment is stable in terms of geographic distance. That is,
there is no unassigned vertex-center pair such that both would prefer each
other over their current assignments. We solve this problem using a version of
the classic stable matching problem, called symmetric stable matching, in which
the preferences of the elements in both sets obey a certain symmetry. In our
case, we study a graph-based version of stable matching in which nodes are
stably matched to a subset of nodes denoted as centers, prioritized by their
shortest-path distances, so that each center is apportioned a certain number of
nodes. We show that, for a planar graph or road network with $n$ nodes and $k$
centers, the problem can be solved in $O(n\sqrt{n}\log n)$ time, which improves
upon the $O(nk)$ runtime of using the classic Gale-Shapley stable matching
algorithm when $k$ is large. Finally, we provide experimental results on road
networks for these algorithms and a heuristic algorithm that performs better
than the Gale-Shapley algorithm for any range of values of $k$.
",Cybersecurity
"  We give a new analysis of a tuning problem in music theory, pertaining
specifically to the approximation of harmonics on a two-dimensional keyboard.
We formulate the question as a linear programming problem on families of
constraints and provide exact solutions for many new keyboard dimensions. We
also show that an optimal tuning for harmonic approximation can be obtained for
any keyboard of given width, provided sufficiently many rows of octaves.
",Cybersecurity
"  Contemporary software documentation is as complicated as the software itself.
During its lifecycle, the documentation accumulates a lot of near duplicate
fragments, i.e. chunks of text that were copied from a single source and were
later modified in different ways. Such near duplicates decrease documentation
quality and thus hamper its further utilization. At the same time, they are
hard to detect manually due to their fuzzy nature. In this paper we give a
formal definition of near duplicates and present an algorithm for their
detection in software documents. This algorithm is based on the exact software
clone detection approach: the software clone detection tool Clone Miner was
adapted to detect exact duplicates in documents. Then, our algorithm uses these
exact duplicates to construct near ones. We evaluate the proposed algorithm
using the documentation of 19 open source and commercial projects. Our
evaluation is very comprehensive - it covers various documentation types:
design and requirement specifications, programming guides and API
documentation, user manuals. Overall, the evaluation shows that all kinds of
software documentation contain a significant number of both exact and near
duplicates. Next, we report on the performed manual analysis of the detected
near duplicates for the Linux Kernel Documentation. We present both quantative
and qualitative results of this analysis, demonstrate algorithm strengths and
weaknesses, and discuss the benefits of duplicate management in software
documents.
",Cybersecurity
"  Understanding smart grid cyber attacks is key for developing appropriate
protection and recovery measures. Advanced attacks pursue maximized impact at
minimized costs and detectability. This paper conducts risk analysis of
combined data integrity and availability attacks against the power system state
estimation. We compare the combined attacks with pure integrity attacks - false
data injection (FDI) attacks. A security index for vulnerability assessment to
these two kinds of attacks is proposed and formulated as a mixed integer linear
programming problem. We show that such combined attacks can succeed with fewer
resources than FDI attacks. The combined attacks with limited knowledge of the
system model also expose advantages in keeping stealth against the bad data
detection. Finally, the risk of combined attacks to reliable system operation
is evaluated using the results from vulnerability assessment and attack impact
analysis. The findings in this paper are validated and supported by a detailed
case study.
",Cybersecurity
"  Image Registration is the process of aligning two or more images of the same
scene with reference to a particular image. The images are captured from
various sensors at different times and at multiple view-points. Thus to get a
better picture of any change of a scene or object over a considerable period of
time image registration is important. Image registration finds application in
medical sciences, remote sensing and in computer vision. This paper presents a
detailed review of several approaches which are classified accordingly along
with their contributions and drawbacks. The main steps of an image registration
procedure are also discussed. Different performance measures are presented that
determine the registration quality and accuracy. The scope for the future
research are presented as well.
",Cybersecurity
"  The radio interferometric positioning system (RIPS) is an accurate node
localization method featuring a novel phase-based ranging process. Multipath is
the limiting error source for RIPS in ground-deployed scenarios or indoor
applications. There are four distinct channels involved in the ranging process
for RIPS. Multipath reflections affect both the phase and amplitude of the
ranging signal for each channel. By exploiting untapped amplitude information,
we put forward a scheme to estimate each channel's multipath profile, which is
then subsequently used to correct corresponding errors in phase measurements.
Simulations show that such a scheme is very effective in reducing multipath
phase errors, which are essentially brought down to the level of receiver noise
under moderate multipath conditions. It is further demonstrated that ranging
errors in RIPS are also greatly reduced via the proposed scheme.
",Cybersecurity
"  Location-based augmented reality games have entered the mainstream with the
nearly overnight success of Niantic's Pokémon Go. Unlike traditional video
games, the fact that players of such games carry out actions in the external,
physical world to accomplish in-game objectives means that the large-scale
adoption of such games motivate people, en masse, to do things and go places
they would not have otherwise done in unprecedented ways. The social
implications of such mass-mobilisation of individual players are, in general,
difficult to anticipate or characterise, even for the short-term. In this work,
we focus on disaster relief, and the short- and long-term implications that a
proliferation of AR games like Pokémon Go, may have in disaster-prone regions
of the world. We take a distributed cognition approach and focus on one natural
disaster-prone region of New Zealand, the city of Wellington.
",Cybersecurity
"  Adversarially trained deep neural networks have significantly improved
performance of single image super resolution, by hallucinating photorealistic
local textures, thereby greatly reducing the perception difference between a
real high resolution image and its super resolved (SR) counterpart. However,
application to medical imaging requires preservation of diagnostically relevant
features while refraining from introducing any diagnostically confusing
artifacts. We propose using a deep convolutional super resolution network
(SRNet) trained for (i) minimising reconstruction loss between the real and SR
images, and (ii) maximally confusing learned relativistic visual Turing test
(rVTT) networks to discriminate between (a) pair of real and SR images (T1) and
(b) pair of patches in real and SR selected from region of interest (T2). The
adversarial loss of T1 and T2 while backpropagated through SRNet helps it learn
to reconstruct pathorealism in the regions of interest such as white blood
cells (WBC) in peripheral blood smears or epithelial cells in histopathology of
cancerous biopsy tissues, which are experimentally demonstrated here.
Experiments performed for measuring signal distortion loss using peak signal to
noise ratio (pSNR) and structural similarity (SSIM) with variation of SR scale
factors, impact of rVTT adversarial losses, and impact on reporting using SR on
a commercially available artificial intelligence (AI) digital pathology system
substantiate our claims.
",Cybersecurity
"  We define the \emph{visual complexity} of a plane graph drawing to be the
number of basic geometric objects needed to represent all its edges. In
particular, one object may represent multiple edges (e.g., one needs only one
line segment to draw a path with an arbitrary number of edges). Let $n$ denote
the number of vertices of a graph. We show that trees can be drawn with $3n/4$
straight-line segments on a polynomial grid, and with $n/2$ straight-line
segments on a quasi-polynomial grid. Further, we present an algorithm for
drawing planar 3-trees with $(8n-17)/3$ segments on an $O(n)\times O(n^2)$
grid. This algorithm can also be used with a small modification to draw maximal
outerplanar graphs with $3n/2$ edges on an $O(n)\times O(n^2)$ grid. We also
study the problem of drawing maximal planar graphs with circular arcs and
provide an algorithm to draw such graphs using only $(5n - 11)/3$ arcs. This is
significantly smaller than the lower bound of $2n$ for line segments for a
nontrivial graph class.
",Cybersecurity
"  Fitch-style modal deduction, in which modalities are eliminated by opening a
subordinate proof, and introduced by shutting one, were investigated in the
1990s as a basis for lambda calculi. We show that such calculi have good
computational properties for a variety of intuitionistic modal logics.
Semantics are given in cartesian closed categories equipped with an adjunction
of endofunctors, with the necessity modality interpreted by the right adjoint.
Where this functor is an idempotent comonad, a coherence result on the
semantics allows us to present a calculus for intuitionistic S4 that is simpler
than others in the literature. We show the calculi can be extended à la
tense logic with the left adjoint of necessity, and are then complete for the
categorical semantics.
",Cybersecurity
"  We show that some results from the theory of group automata and monoid
automata still hold for more general classes of monoids and models. Extending
previous work for finite automata over commutative groups, we demonstrate a
context-free language that can not be recognized by any rational monoid
automaton over a finitely generated permutable monoid. We show that the class
of languages recognized by rational monoid automata over finitely generated
completely simple or completely 0-simple permutable monoids is a semi-linear
full trio. Furthermore, we investigate valence pushdown automata, and prove
that they are only as powerful as (finite) valence automata. We observe that
certain results proven for monoid automata can be easily lifted to the case of
context-free valence grammars.
",Cybersecurity
"  We present FLASH (\textbf{F}ast \textbf{L}SH \textbf{A}lgorithm for
\textbf{S}imilarity search accelerated with \textbf{H}PC), a similarity search
system for ultra-high dimensional datasets on a single machine, that does not
require similarity computations and is tailored for high-performance computing
platforms. By leveraging a LSH style randomized indexing procedure and
combining it with several principled techniques, such as reservoir sampling,
recent advances in one-pass minwise hashing, and count based estimations, we
reduce the computational and parallelization costs of similarity search, while
retaining sound theoretical guarantees.
We evaluate FLASH on several real, high-dimensional datasets from different
domains, including text, malicious URL, click-through prediction, social
networks, etc. Our experiments shed new light on the difficulties associated
with datasets having several million dimensions. Current state-of-the-art
implementations either fail on the presented scale or are orders of magnitude
slower than FLASH. FLASH is capable of computing an approximate k-NN graph,
from scratch, over the full webspam dataset (1.3 billion nonzeros) in less than
10 seconds. Computing a full k-NN graph in less than 10 seconds on the webspam
dataset, using brute-force ($n^2D$), will require at least 20 teraflops. We
provide CPU and GPU implementations of FLASH for replicability of our results.
",Cybersecurity
"  Racetrack memory is a non-volatile memory engineered to provide both high
density and low latency, that is subject to synchronization or shift errors.
This paper describes a fast coding solution, in which delimiter bits assist in
identifying the type of shift error, and easily implementable graph-based codes
are used to correct the error, once identified. A code that is able to detect
and correct double shift errors is described in detail.
",Cybersecurity
"  This chapter revisits the concept of excitability, a basic system property of
neurons. The focus is on excitable systems regarded as behaviors rather than
dynamical systems. By this we mean open systems modulated by specific
interconnection properties rather than closed systems classified by their
parameter ranges. Modeling, analysis, and synthesis questions can be formulated
in the classical language of circuit theory. The input-output characterization
of excitability is in terms of the local sensitivity of the current-voltage
relationship. It suggests the formulation of novel questions for non-linear
system theory, inspired by questions from experimental neurophysiology.
",Cybersecurity
"  We address unsupervised optical flow estimation for ego-centric motion. We
argue that optical flow can be cast as a geometrical warping between two
successive video frames and devise a deep architecture to estimate such
transformation in two stages. First, a dense pixel-level flow is computed with
a geometric prior imposing strong spatial constraints. Such prior is typical of
driving scenes, where the point of view is coherent with the vehicle motion. We
show how such global transformation can be approximated with an homography and
how spatial transformer layers can be employed to compute the flow field
implied by such transformation. The second stage then refines the prediction
feeding a second deeper network. A final reconstruction loss compares the
warping of frame X(t) with the subsequent frame X(t+1) and guides both
estimates. The model, which we named TransFlow, performs favorably compared to
other unsupervised algorithms, and shows better generalization compared to
supervised methods with a 3x reduction in error on unseen data.
",Cybersecurity
"  Software engineering considers performance evaluation to be one of the key
portions of software quality assurance. Unfortunately, there seems to be a lack
of standard methodologies for performance evaluation even in the scope of
experimental computer science. Inspired by the concept of ""instantiation"" in
object-oriented programming, we distinguish the generic performance evaluation
logic from the distributed and ad-hoc relevant studies, and develop an abstract
evaluation methodology (by analogy of ""class"") we name Domain Knowledge-driven
Methodology (DoKnowMe). By replacing five predefined domain-specific knowledge
artefacts, DoKnowMe could be instantiated into specific methodologies (by
analogy of ""object"") to guide evaluators in performance evaluation of different
software and even computing systems. We also propose a generic validation
framework with four indicators (i.e.~usefulness, feasibility, effectiveness and
repeatability), and use it to validate DoKnowMe in the Cloud services
evaluation domain. Given the positive and promising validation result, we plan
to integrate more common evaluation strategies to improve DoKnowMe and further
focus on the performance evaluation of Cloud autoscaler systems.
",Cybersecurity
"  Proposed the computerized method for calculating the relative level of order
composites. Correlation between a level of structure order and properties of
solids is shown. Discussed the possibility of clarifying the terminology used
in describing the structure.
",Cybersecurity
"  We develop a linear algebraic framework for the shape-from-shading problem,
because tensors arise when scalar (e.g. image) and vector (e.g. surface normal)
fields are differentiated multiple times. The work is in two parts. In this
first part we investigate when image derivatives exhibit invariance to changing
illumination by calculating the statistics of image derivatives under general
distributions on the light source. We computationally validate the hypothesis
that image orientations (derivatives) provide increased invariance to
illumination by showing (for a Lambertian model) that a shape-from-shading
algorithm matching gradients instead of intensities provides more accurate
reconstructions when illumination is incorrectly estimated under a flatness
prior.
",Cybersecurity
"  In an $\mathsf{L}$-embedding of a graph, each vertex is represented by an
$\mathsf{L}$-segment, and two segments intersect each other if and only if the
corresponding vertices are adjacent in the graph. If the corner of each
$\mathsf{L}$-segment in an $\mathsf{L}$-embedding lies on a straight line, we
call it a monotone $\mathsf{L}$-embedding. In this paper we give a full
characterization of monotone $\mathsf{L}$-embeddings by introducing a new class
of graphs which we call ""non-jumping"" graphs. We show that a graph admits a
monotone $\mathsf{L}$-embedding if and only if the graph is a non-jumping
graph. Further, we show that outerplanar graphs, convex bipartite graphs,
interval graphs, 3-leaf power graphs, and complete graphs are subclasses of
non-jumping graphs. Finally, we show that distance-hereditary graphs and
$k$-leaf power graphs ($k\le 4$) admit $\mathsf{L}$-embeddings.
",Cybersecurity
"  This article presents the novel breakthrough general purpose algorithm for
large scale optimization problems. The novel algorithm is capable of achieving
breakthrough speeds for very large-scale optimization on general purpose
laptops and embedded systems. Application of the algorithm to the Griewank
function was possible in up to 1 billion decision variables in double precision
took only 64485 seconds (~18 hours) to solve, while consuming 7,630 MB (7.6 GB)
or RAM on a single threaded laptop CPU. It shows that the algorithm is
computationally and memory (space) linearly efficient, and can find the optimal
or near-optimal solution in a fraction of the time and memory that many
conventional algorithms require. It is envisaged that this will open up new
possibilities of real-time large-scale problems on personal laptops and
embedded systems.
",Cybersecurity
"  Recent developments in quaternion-valued widely linear processing have
established that the exploitation of complete second-order statistics requires
consideration of both the standard covariance and the three complementary
covariance matrices. Although such matrices have a tremendous amount of
structure and their decomposition is a powerful tool in a variety of
applications, the non-commutative nature of the quaternion product has been
prohibitive to the development of quaternion uncorrelating transforms. To this
end, we introduce novel techniques for a simultaneous decomposition of the
covariance and complementary covariance matrices in the quaternion domain,
whereby the quaternion version of the Takagi factorisation is explored to
diagonalise symmetric quaternion-valued matrices. This gives new insights into
the quaternion uncorrelating transform (QUT) and forms a basis for the proposed
quaternion approximate uncorrelating transform (QAUT) which simultaneously
diagonalises all four covariance matrices associated with improper quaternion
signals. The effectiveness of the proposed uncorrelating transforms is
validated by simulations on both synthetic and real-world quaternion-valued
signals.
",Cybersecurity
"  We consider the quantum complexity of computing Schatten $p$-norms and
related quantities, and find that the problem of estimating these quantities is
closely related to the one clean qubit model of computation. We show that the
problem of approximating $\text{Tr}\, (|A|^p)$ for a log-local $n$-qubit
Hamiltonian $A$ and $p=\text{poly}(n)$, up to a suitable level of accuracy, is
contained in DQC1; and that approximating this quantity up to a somewhat higher
level of accuracy is DQC1-hard. In some cases the level of accuracy achieved by
the quantum algorithm is substantially better than a natural classical
algorithm for the problem. The same problem can be solved for arbitrary sparse
matrices in BQP. One application of the algorithm is the approximate
computation of the energy of a graph.
",Cybersecurity
"  We revisit a classical scenario in communication theory: a source is
generating a waveform which we sample at regular intervals; we wish to
transform the signal in such a way as to minimize distortion in its
reconstruction, despite noise. The transformation must be online (also called
causal), in order to enable real-time signaling. The noise model we consider is
adversarial $\ell_1$-bounded; this is the ""atomic norm"" convex relaxation of
the standard adversary model in discrete-alphabet communications, namely
sparsity (low Hamming weight). We require that our encoding not increase the
power of the original signal.
In the ""block coding"" setting such encoding is possible due to the existence
of large almost-Euclidean sections in $\ell_1$ spaces (established in the work
of Dvoretzky, Milman, Kašin, and Figiel, Lindenstrauss and Milman).
Our main result is that an analogous result is achievable even online.
Equivalently, we show a ""lower triangular"" version of $\ell_1$ Dvoretzky
theorems. In terms of communication, the result has the following form: If the
signal is a stream of reals $x_1,\ldots$, one per unit time, which we encode
causally into $\rho$ (a constant) reals per unit time (forming altogether an
output stream $\mathcal{E}(x)$), and if the adversarial noise added to this
encoded stream up to time $s$ is a vector $\vec{y}$, then at time $s$ the
decoder's reconstruction of the input prefix $x_{[s]}$ is accurate in a
time-weighted $\ell_2$ norm, to within $s^{-1/2+\delta}$ (any $\delta>0$) times
the adversary's noise as measured in a time-weighted $\ell_1$ norm. The
time-weighted decoding norm forces increasingly accurate reconstruction of the
distant past, while the time-weighted noise norm permits only vanishing effect
from noise in the distant past.
Encoding is linear, and decoding is performed by an LP analogous to those
used in compressed sensing.
",Cybersecurity
"  We consider a multitask estimation problem where nodes in a network are
divided into several connected clusters, with each cluster performing a
least-mean-squares estimation of a different random parameter vector. Inspired
by the adapt-then-combine diffusion strategy, we propose a multitask diffusion
strategy whose mean stability can be ensured whenever individual nodes are
stable in the mean, regardless of the inter-cluster cooperation weights. In
addition, the proposed strategy is able to achieve an asymptotically unbiased
estimation, when the parameters have same mean. We also develop an
inter-cluster cooperation weights selection scheme that allows each node in the
network to locally optimize its inter-cluster cooperation weights. Numerical
results demonstrate that our approach leads to a lower average steady-state
network mean-square deviation, compared with using weights selected by various
other commonly adopted methods in the literature.
",Cybersecurity
"  Sensors are present in various forms all around the world such as mobile
phones, surveillance cameras, smart televisions, intelligent refrigerators and
blood pressure monitors. Usually, most of the sensors are a part of some other
system with similar sensors that compose a network. One of such networks is
composed of millions of sensors connect to the Internet which is called
Internet of things (IoT). With the advances in wireless communication
technologies, multimedia sensors and their networks are expected to be major
components in IoT. Many studies have already been done on wireless multimedia
sensor networks in diverse domains like fire detection, city surveillance,
early warning systems, etc. All those applications position sensor nodes and
collect their data for a long time period with real-time data flow, which is
considered as big data. Big data may be structured or unstructured and needs to
be stored for further processing and analyzing. Analyzing multimedia big data
is a challenging task requiring a high-level modeling to efficiently extract
valuable information/knowledge from data. In this study, we propose a big
database model based on graph database model for handling data generated by
wireless multimedia sensor networks. We introduce a simulator to generate
synthetic data and store and query big data using graph model as a big
database. For this purpose, we evaluate the well-known graph-based NoSQL
databases, Neo4j and OrientDB, and a relational database, MySQL.We have run a
number of query experiments on our implemented simulator to show that which
database system(s) for surveillance in wireless multimedia sensor networks is
efficient and scalable.
",Cybersecurity
"  The Canonical Polyadic decomposition (CPD) is a convenient and intuitive tool
for tensor factorization; however, for higher-order tensors, it often exhibits
high computational cost and permutation of tensor entries, these undesirable
effects grow exponentially with the tensor order. Prior compression of tensor
in-hand can reduce the computational cost of CPD, but this is only applicable
when the rank $R$ of the decomposition does not exceed the tensor dimensions.
To resolve these issues, we present a novel method for CPD of higher-order
tensors, which rests upon a simple tensor network of representative
inter-connected core tensors of orders not higher than 3. For rigour, we
develop an exact conversion scheme from the core tensors to the factor matrices
in CPD, and an iterative algorithm with low complexity to estimate these factor
matrices for the inexact case. Comprehensive simulations over a variety of
scenarios support the approach.
",Cybersecurity
"  Scientific legacy code in MATLAB/Octave not compatible with modernization of
research workflows is vastly abundant throughout academic community.
Performance of non-vectorized code written in MATLAB/Octave represents a major
burden. A new programming language for technical computing Julia, promises to
address these issues. Although Julia syntax is similar to MATLAB/Octave,
porting code to Julia may be cumbersome for researchers. Here we present
MatlabCompat.jl - a library aimed at simplifying the conversion of your
MATLAB/Octave code to Julia. We show using a simplistic image analysis use case
that MATLAB/Octave code can be easily ported to high performant Julia using
MatlabCompat.jl.
",Cybersecurity
"  Natural language and symbols are intimately correlated. Recent advances in
machine learning (ML) and in natural language processing (NLP) seem to
contradict the above intuition: symbols are fading away, erased by vectors or
tensors called distributed and distributional representations. However, there
is a strict link between distributed/distributional representations and
symbols, being the first an approximation of the second. A clearer
understanding of the strict link between distributed/distributional
representations and symbols will certainly lead to radically new deep learning
networks. In this paper we make a survey that aims to draw the link between
symbolic representations and distributed/distributional representations. This
is the right time to revitalize the area of interpreting how symbols are
represented inside neural networks.
",Cybersecurity
"  Spiking neural networks (SNNs) enable power-efficient implementations due to
their sparse, spike-based coding scheme. This paper develops a bio-inspired SNN
that uses unsupervised learning to extract discriminative features from speech
signals, which can subsequently be used in a classifier. The architecture
consists of a spiking convolutional/pooling layer followed by a fully connected
spiking layer for feature discovery. The convolutional layer of leaky,
integrate-and-fire (LIF) neurons represents primary acoustic features. The
fully connected layer is equipped with a probabilistic spike-timing-dependent
plasticity learning rule. This layer represents the discriminative features
through probabilistic, LIF neurons. To assess the discriminative power of the
learned features, they are used in a hidden Markov model (HMM) for spoken digit
recognition. The experimental results show performance above 96% that compares
favorably with popular statistical feature extraction methods. Our results
provide a novel demonstration of unsupervised feature acquisition in an SNN.
",Cybersecurity
"  Email cryptography applications often suffer from major problems that prevent
their widespread implementation. MEG, or the Mobile Encryption Gateway aims to
fix the issues associated with email encryption by ensuring that encryption is
easy to perform while still maintaining data security. MEG performs automatic
decryption and encryption of all emails using PGP. Users do not need to
understand the internal workings of the encryption process to use the
application. MEG is meant to be email-client-agnostic, enabling users to employ
virtually any email service to send messages. Encryption actions are performed
on the user's mobile device, which means their keys and data remain personal.
MEG can also tackle network effect problems by inviting non-users to join. Most
importantly, MEG uses end-to-end encryption, which ensures that all aspects of
the encrypted information remains private. As a result, we are hopeful that MEG
will finally solve the problem of practical email encryption.
",Cybersecurity
"  We carry out a comprehensive analysis of letter frequencies in contemporary
written Marathi. We determine sets of letters which statistically predominate
any large generic Marathi text, and use these sets to estimate the entropy of
Marathi.
",Cybersecurity
"  We approach the development of models and control strategies of
susceptible-infected-susceptible (SIS) epidemic processes from the perspective
of marked temporal point processes and stochastic optimal control of stochastic
differential equations (SDEs) with jumps. In contrast to previous work, this
novel perspective is particularly well-suited to make use of fine-grained data
about disease outbreaks and lets us overcome the shortcomings of current
control strategies. Our control strategy resorts to treatment intensities to
determine who to treat and when to do so to minimize the amount of infected
individuals over time. Preliminary experiments with synthetic data show that
our control strategy consistently outperforms several alternatives. Looking
into the future, we believe our methodology provides a promising step towards
the development of practical data-driven control strategies of epidemic
processes.
",Cybersecurity
"  In this paper, we establish a baseline for object symmetry detection in
complex backgrounds by presenting a new benchmark and an end-to-end deep
learning approach, opening up a promising direction for symmetry detection in
the wild. The new benchmark, named Sym-PASCAL, spans challenges including
object diversity, multi-objects, part-invisibility, and various complex
backgrounds that are far beyond those in existing datasets. The proposed
symmetry detection approach, named Side-output Residual Network (SRN),
leverages output Residual Units (RUs) to fit the errors between the object
symmetry groundtruth and the outputs of RUs. By stacking RUs in a
deep-to-shallow manner, SRN exploits the 'flow' of errors among multiple scales
to ease the problems of fitting complex outputs with limited layers,
suppressing the complex backgrounds, and effectively matching object symmetry
of different scales. Experimental results validate both the benchmark and its
challenging aspects related to realworld images, and the state-of-the-art
performance of our symmetry detection approach. The benchmark and the code for
SRN are publicly available at this https URL.
",Cybersecurity
"  This paper aims to design quadrotor swarm performances, where the swarm acts
as an integrated, coordinated unit embodying moving and deforming objects. We
divide the task of creating a choreography into three basic steps: designing
swarm motion primitives, transitioning between those movements, and
synchronizing the motion of the drones. The result is a flexible framework for
designing choreographies comprised of a wide variety of motions. The motion
primitives can be intuitively designed using few parameters, providing a rich
library for choreography design. Moreover, we combine and adapt existing goal
assignment and trajectory generation algorithms to maximize the smoothness of
the transitions between motion primitives. Finally, we propose a correction
algorithm to compensate for motion delays and synchronize the motion of the
drones to a desired periodic motion pattern. The proposed methodology was
validated experimentally by generating and executing choreographies on a swarm
of 25 quadrotors.
",Cybersecurity
"  This paper analyzes publication efficiency in terms of Hirsch-index or
h-index and total citations, with an analogy to the Carnot efficiency used in
thermodynamics. Such publication efficiency, with typical value of 30%, can be
utilized to normalize the research output judgment, favoring quality outputs in
reduced quantity, which is currently lacking in many discipline.
",Cybersecurity
"  The profitability of fraud in online systems such as app markets and social
networks marks the failure of existing defense mechanisms. In this paper, we
propose FraudSys, a real-time fraud preemption approach that imposes
Bitcoin-inspired computational puzzles on the devices that post online system
activities, such as reviews and likes. We introduce and leverage several novel
concepts that include (i) stateless, verifiable computational puzzles, that
impose minimal performance overhead, but enable the efficient verification of
their authenticity, (ii) a real-time, graph-based solution to assign fraud
scores to user activities, and (iii) mechanisms to dynamically adjust puzzle
difficulty levels based on fraud scores and the computational capabilities of
devices. FraudSys does not alter the experience of users in online systems, but
delays fraudulent actions and consumes significant computational resources of
the fraudsters. Using real datasets from Google Play and Facebook, we
demonstrate the feasibility of FraudSys by showing that the devices of honest
users are minimally impacted, while fraudster controlled devices receive daily
computational penalties of up to 3,079 hours. In addition, we show that with
FraudSys, fraud does not pay off, as a user equipped with mining hardware
(e.g., AntMiner S7) will earn less than half through fraud than from honest
Bitcoin mining.
",Cybersecurity
"  We introduce and analyze an extension to the matching problem on a weighted
bipartite graph: Assignment with Type Constraints. The two parts of the graph
are partitioned into subsets called types and blocks; we seek a matching with
the largest sum of weights under the constraint that there is a pre-specified
cap on the number of vertices matched in every type-block pair. Our primary
motivation stems from the public housing program of Singapore, accounting for
over 70% of its residential real estate. To promote ethnic diversity within its
housing projects, Singapore imposes ethnicity quotas: each new housing
development comprises blocks of flats and each ethnicity-based group in the
population must not own more than a certain percentage of flats in a block.
Other domains using similar hard capacity constraints include matching
prospective students to schools or medical residents to hospitals. Limiting
agents' choices for ensuring diversity in this manner naturally entails some
welfare loss. One of our goals is to study the trade-off between diversity and
social welfare in such settings. We first show that, while the classic
assignment program is polynomial-time computable, adding diversity constraints
makes it computationally intractable; however, we identify a
$\tfrac{1}{2}$-approximation algorithm, as well as reasonable assumptions on
the weights that permit poly-time algorithms. Next, we provide two upper bounds
on the price of diversity -- a measure of the loss in welfare incurred by
imposing diversity constraints -- as functions of natural problem parameters.
We conclude the paper with simulations based on publicly available data from
two diversity-constrained allocation problems -- Singapore Public Housing and
Chicago School Choice -- which shed light on how the constrained maximization
as well as lottery-based variants perform in practice.
",Cybersecurity
"  Type inference is an application domain that is a natural fit for logic
programming (LP). LP systems natively support unification, which serves as a
basic building block of typical type inference algorithms. In particular,
polymorphic type inference in the Hindley--Milner type system (HM) can be
succinctly specified and executed in Prolog. In our previous work, we have
demonstrated that more advanced features of parametric polymorphism beyond HM,
such as type-constructor polymorphism and kind polymorphism, can be similarly
specified in Prolog. Here, we demonstrate a specification for records, which is
one of the most widely supported compound data structures in real-world
programming languages, and discuss the advantages and limitations of Prolog as
a specification language for type systems. Record types are specified as
order-irrelevant collections of named fields mapped to their corresponding
types. In addition, an open-ended collection is used to support row
polymorphism for record types to be extensible.
",Cybersecurity
"  Reconstruction of skilled humans sensation and control system often leads to
a development of robust control for the robots. We are developing an unscrewing
robot for the automated disassembly which requires a comprehensive control
system, but unscrewing experiments with robots are often limited to several
conditions. On the contrary, humans typically have a broad range of screwing
experiences and sensations throughout their lives, and we conducted an
experiment to find these haptic patterns. Results show that people apply axial
force to the screws to avoid screwdriver slippage (cam-outs), which is one of
the key problems during screwing and unscrewing, and this axial force is
proportional to the torque which is required for screwing. We have found that
type of the screw head influences the amount of axial force applied. Using this
knowledge an unscrewing robot for the smart disassembly factory RecyBot is
developed, and experiments confirm the optimality of the strategy, used by
humans. Finally, a methodology for robust unscrewing algorithm design is
presented as a generalization of the findings. It can seriously speed up the
development of the screwing and unscrewing robots and tools.
",Cybersecurity
"  Decide Madrid is the civic technology of Madrid City Council which allows
users to create and support online petitions. Despite the initial success, the
platform is encountering problems with the growth of petition signing because
petitions are far from the minimum number of supporting votes they must gather.
Previous analyses have suggested that this problem is produced by the
interface: a paginated list of petitions which applies a non-optimal ranking
algorithm. For this reason, we present an interactive system for the discovery
of topics and petitions. This approach leads us to reflect on the usefulness of
data visualization techniques to address relevant societal challenges.
",Cybersecurity
"  Procedural textures are normally generated from mathematical models with
parameters carefully selected by experienced users. However, for naive users,
the intuitive way to obtain a desired texture is to provide semantic
descriptions such as ""regular,"" ""lacelike,"" and ""repetitive"" and then a
procedural model with proper parameters will be automatically suggested to
generate the corresponding textures. By contrast, it is less practical for
users to learn mathematical models and tune parameters based on multiple
examinations of large numbers of generated textures. In this study, we propose
a novel framework that generates procedural textures according to user-defined
semantic descriptions, and we establish a mapping between procedural models and
semantic texture descriptions. First, based on a vocabulary of semantic
attributes collected from psychophysical experiments, a multi-label learning
method is employed to annotate a large number of textures with semantic
attributes to form a semantic procedural texture dataset. Then, we derive a low
dimensional semantic space in which the semantic descriptions can be separated
from one other. Finally, given a set of semantic descriptions, the diverse
properties of the samples in the semantic space can lead the framework to find
an appropriate generation model that uses appropriate parameters to produce a
desired texture. The experimental results show that the proposed framework is
effective and that the generated textures closely correlate with the input
semantic descriptions.
",Cybersecurity
"  This paper presents contributions on nonlinear tracking control systems for a
quadrotor unmanned micro aerial vehicle. New controllers are proposed based on
nonlinear surfaces composed by tracking errors that evolve directly on the
nonlinear configuration manifold thus inherently including in the control
design the nonlinear characteristics of the SE(3) configuration space. In
particular geometric surface-based controllers are developed, and through
rigorous stability proofs they are shown to have desirable closed loop
properties that are almost global. A region of attraction, independent of the
position error, is produced and its effects are analyzed. A strategy allowing
the quadrotor to achieve precise attitude tracking while simultaneously
following a desired position command and complying to actuator constraints in a
computationally inexpensive manner is derived. This important contribution
differentiates this work from existing Geometric Nonlinear Control System
solutions (GNCSs) since the commanded thrusts can be realized by the majority
of quadrotors produced by the industry. The new features of the proposed GNCSs
are illustrated by numerical simulations of aggressive maneuvers and a
comparison with a GNCSs from the bibliography.
",Cybersecurity
"  The displacement calculus $\mathbf{D}$ is a conservative extension of the
Lambek calculus $\mathbf{L1}$ (with empty antecedents allowed in sequents).
$\mathbf{L1}$ can be said to be the logic of concatenation, while $\mathbf{D}$
can be said to be the logic of concatenation and intercalation. In many senses,
it can be claimed that $\mathbf{D}$ mimics $\mathbf{L1}$ in that the proof
theory, generative capacity and complexity of the former calculus are natural
extensions of the latter calculus. In this paper, we strengthen this claim. We
present the appropriate classes of models for $\mathbf{D}$ and prove some
completeness results; strikingly, we see that these results and proofs are
natural extensions of the corresponding ones for $\mathbf{L1}$.
",Cybersecurity
"  Modern knowledge base systems frequently need to combine a collection of
databases in different formats: e.g., relational databases, XML databases, rule
bases, ontologies, etc. In the deductive database system DDBASE, we can manage
these different formats of knowledge and reason about them. Even the file
systems on different computers can be part of the knowledge base. Often, it is
necessary to handle different versions of a knowledge base. E.g., we might want
to find out common parts or differences of two versions of a relational
database.
We will examine the use of abstractions of rule bases by predicate dependency
and rule predicate graphs. Also the proof trees of derived atoms can help to
compare different versions of a rule base. Moreover, it might be possible to
have derivations joining rules with other formalisms of knowledge
representation.
Ontologies have shown their benefits in many applications of intelligent
systems, and there have been many proposals for rule languages compatible with
the semantic web stack, e.g., SWRL, the semantic web rule language. Recently,
ontologies are used in hybrid systems for specifying the provenance of the
different components.
",Cybersecurity
"  This work explores the feasibility of steering a drone with a (recurrent)
neural network, based on input from a forward looking camera, in the context of
a high-level navigation task. We set up a generic framework for training a
network to perform navigation tasks based on imitation learning. It can be
applied to both aerial and land vehicles. As a proof of concept we apply it to
a UAV (Unmanned Aerial Vehicle) in a simulated environment, learning to cross a
room containing a number of obstacles. So far only feedforward neural networks
(FNNs) have been used to train UAV control. To cope with more complex tasks, we
propose the use of recurrent neural networks (RNN) instead and successfully
train an LSTM (Long-Short Term Memory) network for controlling UAVs. Vision
based control is a sequential prediction problem, known for its highly
correlated input data. The correlation makes training a network hard,
especially an RNN. To overcome this issue, we investigate an alternative
sampling method during training, namely window-wise truncated backpropagation
through time (WW-TBPTT). Further, end-to-end training requires a lot of data
which often is not available. Therefore, we compare the performance of
retraining only the Fully Connected (FC) and LSTM control layers with networks
which are trained end-to-end. Performing the relatively simple task of crossing
a room already reveals important guidelines and good practices for training
neural control networks. Different visualizations help to explain the behavior
learned.
",Cybersecurity
"  In fairly elementary terms this paper presents how the theory of preordered
fuzzy sets, more precisely quantale-valued preorders on quantale-valued fuzzy
sets, is established under the guidance of enriched category theory. Motivated
by several key results from the theory of quantaloid-enriched categories, this
paper develops all needed ingredients purely in order-theoretic languages for
the readership of fuzzy set theorists, with particular attention paid to fuzzy
Galois connections between preordered fuzzy sets.
",Cybersecurity
"  Rural building mapping is paramount to support demographic studies and plan
actions in response to crisis that affect those areas. Rural building
annotations exist in OpenStreetMap (OSM), but their quality and quantity are
not sufficient for training models that can create accurate rural building
maps. The problems with these annotations essentially fall into three
categories: (i) most commonly, many annotations are geometrically misaligned
with the updated imagery; (ii) some annotations do not correspond to buildings
in the images (they are misannotations or the buildings have been destroyed);
and (iii) some annotations are missing for buildings in the images (the
buildings were never annotated or were built between subsequent image
acquisitions). First, we propose a method based on Markov Random Field (MRF) to
align the buildings with their annotations. The method maximizes the
correlation between annotations and a building probability map while enforcing
that nearby buildings have similar alignment vectors. Second, the annotations
with no evidence in the building probability map are removed. Third, we present
a method to detect non-annotated buildings with predefined shapes and add their
annotation. The proposed methodology shows considerable improvement in accuracy
of the OSM annotations for two regions of Tanzania and Zimbabwe, being more
accurate than state-of-the-art baselines.
",Cybersecurity
"  With progress in enabling autonomous cars to drive safely on the road, it is
time to start asking how they should be driving. A common answer is that they
should be adopting their users' driving style. This makes the assumption that
users want their autonomous cars to drive like they drive - aggressive drivers
want aggressive cars, defensive drivers want defensive cars. In this paper, we
put that assumption to the test. We find that users tend to prefer a
significantly more defensive driving style than their own. Interestingly, they
prefer the style they think is their own, even though their actual driving
style tends to be more aggressive. We also find that preferences do depend on
the specific driving scenario, opening the door for new ways of learning
driving style preference.
",Cybersecurity
"  The Lanczos method is one of the standard approaches for computing a few
eigenpairs of a large, sparse, symmetric matrix. It is typically used with
restarting to avoid unbounded growth of memory and computational requirements.
Thick-restart Lanczos is a popular restarted variant because of its simplicity
and numerically robustness. However, convergence can be slow for highly
clustered eigenvalues so more effective restarting techniques and the use of
preconditioning is needed. In this paper, we present a thick-restart
preconditioned Lanczos method, TRPL+K, that combines the power of locally
optimal restarting (+K) and preconditioning techniques with the efficiency of
the thick-restart Lanczos method. TRPL+K employs an inner-outer scheme where
the inner loop applies Lanczos on a preconditioned operator while the outer
loop augments the resulting Lanczos subspace with certain vectors from the
previous restart cycle to obtain eigenvector approximations with which it thick
restarts the outer subspace. We first identify the differences from various
relevant methods in the literature. Then, based on an optimization perspective,
we show an asymptotic global quasi-optimality of a simplified TRPL+K method
compared to an unrestarted global optimal method. Finally, we present extensive
experiments showing that TRPL+K either outperforms or matches other
state-of-the-art eigenmethods in both matrix-vector multiplications and
computational time.
",Cybersecurity
"  The UFMC modulation is among the most considered solutions for the
realization of beyond-OFDM air interfaces for future wireless networks. This
paper focuses on the design and analysis of an UFMC transceiver equipped with
multiple antennas and operating at millimeter wave carrier frequencies. The
paper provides the full mathematical model of a MIMO-UFMC transceiver, taking
into account the presence of hybrid analog/digital beamformers at both ends of
the communication links. Then, several detection structures are proposed, both
for the case of single-packet isolated transmission, and for the case of
multiple-packet continuous transmission. In the latter situation, the paper
also considers the case in which no guard time among adjacent packets is
inserted, trading off an increased level of interference with higher values of
spectral efficiency. At the analysis stage, the several considered detection
structures and transmission schemes are compared in terms of bit-error-rate,
root-mean-square-error, and system throughput. The numerical results show that
the proposed transceiver algorithms are effective and that the linear MMSE data
detector is capable of well managing the increased interference brought by the
removal of guard times among consecutive packets, thus yielding throughput
gains of about 10 - 13 $\%$. The effect of phase noise at the receiver is also
numerically assessed, and it is shown that the recursive implementation of the
linear MMSE exhibits some degree of robustness against this disturbance.
",Cybersecurity
"  The Rate Control Protocol (RCP) is a congestion control protocol that relies
on explicit feedback from routers. RCP estimates the flow rate using two forms
of feedback: rate mismatch and queue size. However, it remains an open design
question whether queue size feedback in RCP is useful, given the presence of
rate mismatch. The model we consider has RCP flows operating over a single
bottleneck, with heterogeneous time delays. We first derive a sufficient
condition for global stability, and then highlight how this condition favors
the design choice of having only rate mismatch in the protocol definition.
",Cybersecurity
"  It is well-known that the verification of partial correctness properties of
imperative programs can be reduced to the satisfiability problem for
constrained Horn clauses (CHCs). However, state-of-the-art solvers for CHCs
(CHC solvers) based on predicate abstraction are sometimes unable to verify
satisfiability because they look for models that are definable in a given class
A of constraints, called A-definable models. We introduce a transformation
technique, called Predicate Pairing (PP), which is able, in many interesting
cases, to transform a set of clauses into an equisatisfiable set whose
satisfiability can be proved by finding an A-definable model, and hence can be
effectively verified by CHC solvers. We prove that, under very general
conditions on A, the unfold/fold transformation rules preserve the existence of
an A-definable model, i.e., if the original clauses have an A-definable model,
then the transformed clauses have an A-definable model. The converse does not
hold in general, and we provide suitable conditions under which the transformed
clauses have an A-definable model iff the original ones have an A-definable
model. Then, we present the PP strategy which guides the application of the
transformation rules with the objective of deriving a set of clauses whose
satisfiability can be proved by looking for A-definable models. PP introduces a
new predicate defined by the conjunction of two predicates together with some
constraints. We show through some examples that an A-definable model may exist
for the new predicate even if it does not exist for its defining atomic
conjuncts. We also present some case studies showing that PP plays a crucial
role in the verification of relational properties of programs (e.g., program
equivalence and non-interference). Finally, we perform an experimental
evaluation to assess the effectiveness of PP in increasing the power of CHC
solving.
",Cybersecurity
"  Do visual tasks have a relationship, or are they unrelated? For instance,
could having surface normals simplify estimating the depth of an image?
Intuition answers these questions positively, implying existence of a structure
among visual tasks. Knowing this structure has notable values; it is the
concept underlying transfer learning and provides a principled way for
identifying redundancies across tasks, e.g., to seamlessly reuse supervision
among related tasks or solve many tasks in one system without piling up the
complexity.
We proposes a fully computational approach for modeling the structure of
space of visual tasks. This is done via finding (first and higher-order)
transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,
and semantic tasks in a latent space. The product is a computational taxonomic
map for task transfer learning. We study the consequences of this structure,
e.g. nontrivial emerged relationships, and exploit them to reduce the demand
for labeled data. For example, we show that the total number of labeled
datapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3
(compared to training independently) while keeping the performance nearly the
same. We provide a set of tools for computing and probing this taxonomical
structure including a solver that users can employ to devise efficient
supervision policies for their use cases.
",Cybersecurity
"  Effective file transfer between vehicles is fundamental to many emerging
vehicular infotainment applications in the highway Vehicular Ad Hoc Networks
(VANETs), such as content distribution and social networking. However, due to
fast mobility, the connection between vehicles tends to be short-lived and
lossy, which makes intact file transfer extremely challenging. To tackle this
problem, we presents a novel Cluster-based File Transfer (CFT) scheme for
highway VANETs in this paper. With CFT, when a vehicle requests a file, the
transmission capacity between the resource vehicle and the destination vehicle
is evaluated. If the requested file can be successfully transferred over the
direct Vehicular-to-Vehicular (V2V) connection, the file transfer will be
completed by the resource and the destination themselves. Otherwise, a cluster
will be formed to help the file transfer. As a fully-distributed scheme that
relies on the collaboration of cluster members, CFT does not require any
assistance from roadside units or access points. Our experimental results
indicate that CFT outperforms the existing file transfer schemes for highway
VANETs.
",Cybersecurity
"  Automata expressiveness is an essential feature in understanding which of the
formalisms available should be chosen for modelling a particular problem.
Probabilistic and stochastic automata are suitable for modelling systems
exhibiting probabilistic behavior and their expressiveness has been studied
relative to non-probabilistic transition systems and Markov chains. In this
paper, we consider previous formalisms of Timed, Probabilistic and Stochastic
Timed Automata, we present our new model of Timed Automata with Polynomial
Delay, we introduce a measure of expressiveness for automata we call trace
expressiveness and we characterize the expressiveness of these models relative
to each other under this new measure.
",Cybersecurity
"  In this work, we propose a goal-driven collaborative task that contains
language, vision, and action in a virtual environment as its core components.
Specifically, we develop a Collaborative image-Drawing game between two agents,
called CoDraw. Our game is grounded in a virtual world that contains movable
clip art objects. The game involves two players: a Teller and a Drawer. The
Teller sees an abstract scene containing multiple clip art pieces in a
semantically meaningful configuration, while the Drawer tries to reconstruct
the scene on an empty canvas using available clip art pieces. The two players
communicate via two-way communication using natural language. We collect the
CoDraw dataset of ~10K dialogs consisting of ~138K messages exchanged between
human agents. We define protocols and metrics to evaluate the effectiveness of
learned agents on this testbed, highlighting the need for a novel crosstalk
condition which pairs agents trained independently on disjoint subsets of the
training data for evaluation. We present models for our task, including simple
but effective nearest-neighbor techniques and neural network approaches trained
using a combination of imitation learning and goal-driven training. All models
are benchmarked using both fully automated evaluation and by playing the game
with live human agents.
",Cybersecurity
"  This paper introduces assume/guarantee contracts on continuous-time control
systems, hereby extending contract theories for discrete systems to certain new
model classes and specifications. Contracts are regarded as formal
characterizations of control specifications, providing an alternative to
specifications in terms of dissipativity properties or set-invariance. The
framework has the potential to capture a richer class of specifications more
suitable for complex engineering systems. The proposed contracts are supported
by results that enable the verification of contract implementation and the
comparison of contracts. These results are illustrated by an example of a
vehicle following system.
",Cybersecurity
"  Let $\mathcal{F}$ be a finite alphabet and $\mathcal{D}$ be a finite set of
distributions over $\mathcal{F}$. A Generalized Santha-Vazirani (GSV) source of
type $(\mathcal{F}, \mathcal{D})$, introduced by Beigi, Etesami and Gohari
(ICALP 2015, SICOMP 2017), is a random sequence $(F_1, \dots, F_n)$ in
$\mathcal{F}^n$, where $F_i$ is a sample from some distribution $d \in
\mathcal{D}$ whose choice may depend on $F_1, \dots, F_{i-1}$.
We show that all GSV source types $(\mathcal{F}, \mathcal{D})$ fall into one
of three categories: (1) non-extractable; (2) extractable with error
$n^{-\Theta(1)}$; (3) extractable with error $2^{-\Omega(n)}$. This rules out
other error rates like $1/\log n$ or $2^{-\sqrt{n}}$.
We provide essentially randomness-optimal extraction algorithms for
extractable sources. Our algorithm for category (2) sources extracts with error
$\varepsilon$ from $n = \mathrm{poly}(1/\varepsilon)$ samples in time linear in
$n$. Our algorithm for category (3) sources extracts $m$ bits with error
$\varepsilon$ from $n = O(m + \log 1/\varepsilon)$ samples in time
$\min\{O(nm2^m),n^{O(\lvert\mathcal{F}\rvert)}\}$.
We also give algorithms for classifying a GSV source type $(\mathcal{F},
\mathcal{D})$: Membership in category (1) can be decided in $\mathrm{NP}$,
while membership in category (3) is polynomial-time decidable.
",Cybersecurity
"  We propose a framework for adversarial training that relies on a sample
rather than a single sample point as the fundamental unit of discrimination.
Inspired by discrepancy measures and two-sample tests between probability
distributions, we propose two such distributional adversaries that operate and
predict on samples, and show how they can be easily implemented on top of
existing models. Various experimental results show that generators trained with
our distributional adversaries are much more stable and are remarkably less
prone to mode collapse than traditional models trained with pointwise
prediction discriminators. The application of our framework to domain
adaptation also results in considerable improvement over recent
state-of-the-art.
",Cybersecurity
"  A set function $f$ on a finite set $V$ is submodular if $f(X) + f(Y) \geq f(X
\cup Y) + f(X \cap Y)$ for any pair $X, Y \subseteq V$. The symmetric
difference transformation (SD-transformation) of $f$ by a canonical set $S
\subseteq V$ is a set function $g$ given by $g(X) = f(X \vartriangle S)$ for $X
\subseteq V$,where $X \vartriangle S = (X \setminus S) \cup (S \setminus X)$
denotes the symmetric difference between $X$ and $S$. Submodularity and
SD-transformations are regarded as the counterparts of convexity and affine
transformations in a discrete space, respectively. However, submodularity is
not preserved under SD-transformations, in contrast to the fact that convexity
is invariant under affine transformations. This paper presents a
characterization of SD-stransformations preserving submodularity. Then, we are
concerned with the problem of discovering a canonical set $S$, given the
SD-transformation $g$ of a submodular function $f$ by $S$, provided that $g(X)$
is given by a function value oracle. A submodular function $f$ on $V$ is said
to be strict if $f(X) + f(Y) > f(X \cup Y) + f(X \cap Y)$ holds whenever both
$X \setminus Y$ and $Y \setminus X$ are nonempty. We show that the problem is
solved by using ${\rm O}(|V|)$ oracle calls when $f$ is strictly submodular,
although it requires exponentially many oracle calls in general.
",Cybersecurity
"  The crowdsourcing consists in the externalisation of tasks to a crowd of
people remunerated to execute this ones. The crowd, usually diversified, can
include users without qualification and/or motivation for the tasks. In this
paper we will introduce a new method of user expertise modelization in the
crowdsourcing platforms based on the theory of belief functions in order to
identify serious and qualificated users.
",Cybersecurity
"  We present an adaptive grasping method that finds stable grasps on novel
objects. The main contributions of this paper is in the computation of the
probability of success of grasps in the vicinity of an already applied grasp.
Our method performs grasp adaptions by simulating tactile data for grasps in
the vicinity of the current grasp. The simulated data is used to evaluate
hypothetical grasps and thereby guide us toward better grasps. We demonstrate
the applicability of our method by constructing a system that can plan, apply
and adapt grasps on novel objects. Experiments are conducted on objects from
the YCB object set and the success rate of our method is 88%. Our experiments
show that the application of our grasp adaption method improves grasp stability
significantly.
",Cybersecurity
"  The navigation problem is classically approached in two steps: an exploration
step, where map-information about the environment is gathered; and an
exploitation step, where this information is used to navigate efficiently. Deep
reinforcement learning (DRL) algorithms, alternatively, approach the problem of
navigation in an end-to-end fashion. Inspired by the classical approach, we ask
whether DRL algorithms are able to inherently explore, gather and exploit
map-information over the course of navigation. We build upon Mirowski et al.
[2017] work and introduce a systematic suite of experiments that vary three
parameters: the agent's starting location, the agent's target location, and the
maze structure. We choose evaluation metrics that explicitly measure the
algorithm's ability to gather and exploit map-information. Our experiments show
that when trained and tested on the same maps, the algorithm successfully
gathers and exploits map-information. However, when trained and tested on
different sets of maps, the algorithm fails to transfer the ability to gather
and exploit map-information to unseen maps. Furthermore, we find that when the
goal location is randomized and the map is kept static, the algorithm is able
to gather and exploit map-information but the exploitation is far from optimal.
We open-source our experimental suite in the hopes that it serves as a
framework for the comparison of future algorithms and leads to the discovery of
robust alternatives to classical navigation methods.
",Cybersecurity
"  In article the basic principles put in a basis of algorithmicallysoftware of
hypercomplex number calculations, structure of a software, structure of
functional subsystems are considered. The most important procedures included in
subsystems are considered, program listings and examples of their application
are given.
",Cybersecurity
"  Let $f:\{0,1\}^n \rightarrow \{0,1\}$ be a Boolean function. The certificate
complexity $C(f)$ is a complexity measure that is quadratically tight for the
zero-error randomized query complexity $R_0(f)$: $C(f) \leq R_0(f) \leq
C(f)^2$. In this paper we study a new complexity measure that we call
expectational certificate complexity $EC(f)$, which is also a quadratically
tight bound on $R_0(f)$: $EC(f) \leq R_0(f) = O(EC(f)^2)$. We prove that $EC(f)
\leq C(f) \leq EC(f)^2$ and show that there is a quadratic separation between
the two, thus $EC(f)$ gives a tighter upper bound for $R_0(f)$. The measure is
also related to the fractional certificate complexity $FC(f)$ as follows:
$FC(f) \leq EC(f) = O(FC(f)^{3/2})$. This also connects to an open question by
Aaronson whether $FC(f)$ is a quadratically tight bound for $R_0(f)$, as
$EC(f)$ is in fact a relaxation of $FC(f)$.
In the second part of the work, we upper bound the distributed query
complexity $D^\mu_\epsilon(f)$ for product distributions $\mu$ by the square of
the query corruption bound ($\mathrm{corr}_\epsilon(f)$) which improves upon a
result of Harsha, Jain and Radhakrishnan [2015]. A similar statement for
communication complexity is open.
",Cybersecurity
"  Multiple sequence alignment (MSA) plays a key role in biological sequence
analyses, especially in phylogenetic tree construction. Extreme increase in
next-generation sequencing results in shortage of efficient ultra-large
biological sequence alignment approaches for coping with different sequence
types. Distributed and parallel computing represents a crucial technique for
accelerating ultra-large sequence analyses. Based on HAlign and Spark
distributed computing system, we implement a highly cost-efficient and
time-efficient HAlign-II tool to address ultra-large multiple biological
sequence alignment and phylogenetic tree construction. After comparing with
most available state-of-the-art methods, our experimental results indicate the
following: 1) HAlign-II can efficiently carry out MSA and construct
phylogenetic trees with ultra-large biological sequences; 2) HAlign-II shows
extremely high memory efficiency and scales well with increases in computing
resource; 3) HAlign-II provides a user-friendly web server based on our
distributed computing infrastructure. HAlign-II with open-source codes and
datasets was established at this http URL.
",Cybersecurity
"  Advertisements are unavoidable in modern society. Times Square is notorious
for its incessant display of advertisements. Its popularity is worldwide and
smaller cities possess miniature versions of the display, such as Pittsburgh
and its digital works in Oakland on Forbes Avenue. Tokyo's Ginza district
recently rose to popularity due to its upscale shops and constant onslaught of
advertisements to pedestrians. Advertisements arise in other mediums as well.
For example, they help popular streaming services, such as Spotify, Hulu, and
Youtube TV gather significant streams of revenue to reduce the cost of monthly
subscriptions for consumers. Ads provide an additional source of money for
companies and entire industries to allocate resources toward alternative
business motives. They are attractive to companies and nearly unavoidable for
consumers. One challenge for advertisers is examining a advertisement's
effectiveness or usefulness in conveying a message to their targeted
demographics. Rather than constructing a single, static image of content, a
video advertisement possesses hundreds of frames of data with varying scenes,
actors, objects, and complexity. Therefore, measuring effectiveness of video
advertisements is important to impacting a billion-dollar industry. This paper
explores the combination of human-annotated features and common video
processing techniques to predict effectiveness ratings of advertisements
collected from Youtube. This task is seen as a binary (effective vs.
non-effective), four-way, and five-way machine learning classification task.
The first findings in terms of accuracy and inference on this dataset, as well
as some of the first ad research, on a small dataset are presented. Accuracies
of 84\%, 65\%, and 55\% are reached on the binary, four-way, and five-way tasks
respectively.
",Cybersecurity
"  The Internet of Things (IoT) is continuously growing to connect billions of
smart devices anywhere and anytime in an Internet-like structure, which enables
a variety of applications, services and interactions between human and objects.
In the future, the smart devices are supposed to be able to autonomously
discover a target device with desired features and generate a set of entirely
new services and applications that are not supervised or even imagined by human
beings. The pervasiveness of smart devices, as well as the heterogeneity of
their design and functionalities, raise a major concern: How can a smart device
efficiently discover a desired target device? In this paper, we propose a
Social-Aware and Distributed (SAND) scheme that achieves a fast, scalable and
efficient device discovery in the IoT. The proposed SAND scheme adopts a novel
device ranking criteria that measures the device's degree, social relationship
diversity, clustering coefficient and betweenness. Based on the device ranking
criteria, the discovery request can be guided to travel through critical
devices that stand at the major intersections of the network, and thus quickly
reach the desired target device by contacting only a limited number of
intermediate devices. With the help of such an intelligent device discovery as
SAND, the IoT devices, as well as other computing facilities, software and data
on the Internet, can autonomously establish new social connections with each
other as human being do. They can formulate self-organized computing groups to
perform required computing tasks, facilitate a fusion of a variety of computing
service, network service and data to generate novel applications and services,
evolve from the individual aritificial intelligence to the collaborative
intelligence, and eventually enable the birth of a robot society.
",Cybersecurity
"  Nowadays, online video platforms mostly recommend related videos by analyzing
user-driven data such as viewing patterns, rather than the content of the
videos. However, content is more important than any other element when videos
aim to deliver knowledge. Therefore, we have developed a web application which
recommends related TED lecture videos to the users, considering the content of
the videos from the transcripts. TED Talk Recommender constructs a network for
recommending videos that are similar content-wise and providing a user
interface.
",Cybersecurity
"  The main goal of modeling human conversation is to create agents which can
interact with people in both open-ended and goal-oriented scenarios. End-to-end
trained neural dialog systems are an important line of research for such
generalized dialog models as they do not resort to any situation-specific
handcrafting of rules. However, incorporating personalization into such systems
is a largely unexplored topic as there are no existing corpora to facilitate
such work. In this paper, we present a new dataset of goal-oriented dialogs
which are influenced by speaker profiles attached to them. We analyze the
shortcomings of an existing end-to-end dialog system based on Memory Networks
and propose modifications to the architecture which enable personalization. We
also investigate personalization in dialog as a multi-task learning problem,
and show that a single model which shares features among various profiles
outperforms separate models for each profile.
",Cybersecurity
"  The goal of semantic parsing is to map natural language to a machine
interpretable meaning representation language (MRL). One of the constraints
that limits full exploration of deep learning technologies for semantic parsing
is the lack of sufficient annotation training data. In this paper, we propose
using sequence-to-sequence in a multi-task setup for semantic parsing with a
focus on transfer learning. We explore three multi-task architectures for
sequence-to-sequence modeling and compare their performance with an
independently trained model. Our experiments show that the multi-task setup
aids transfer learning from an auxiliary task with large labeled data to a
target task with smaller labeled data. We see absolute accuracy gains ranging
from 1.0% to 4.4% in our in- house data set, and we also see good gains ranging
from 2.5% to 7.0% on the ATIS semantic parsing tasks with syntactic and
semantic auxiliary tasks.
",Cybersecurity
"  We establish lower bounds on the volume and the surface area of a geometric
body using the size of its slices along different directions. In the first part
of the paper, we derive volume bounds for convex bodies using generalized
subadditivity properties of entropy combined with entropy bounds for
log-concave random variables. In the second part, we investigate a new notion
of Fisher information which we call the $L_1$-Fisher information, and show that
certain superadditivity properties of the $L_1$-Fisher information lead to
lower bounds for the surface areas of polyconvex sets in terms of its slices.
",Cybersecurity
"  We present DeepPicar, a low-cost deep neural network based autonomous car
platform. DeepPicar is a small scale replication of a real self-driving car
called DAVE-2 by NVIDIA. DAVE-2 uses a deep convolutional neural network (CNN),
which takes images from a front-facing camera as input and produces car
steering angles as output. DeepPicar uses the same network architecture---9
layers, 27 million connections and 250K parameters---and can drive itself in
real-time using a web camera and a Raspberry Pi 3 quad-core platform. Using
DeepPicar, we analyze the Pi 3's computing capabilities to support end-to-end
deep learning based real-time control of autonomous vehicles. We also
systematically compare other contemporary embedded computing platforms using
the DeepPicar's CNN-based real-time control workload. We find that all tested
platforms, including the Pi 3, are capable of supporting the CNN-based
real-time control, from 20 Hz up to 100 Hz, depending on hardware platform.
However, we find that shared resource contention remains an important issue
that must be considered in applying CNN models on shared memory based embedded
computing platforms; we observe up to 11.6X execution time increase in the CNN
based control loop due to shared resource contention. To protect the CNN
workload, we also evaluate state-of-the-art cache partitioning and memory
bandwidth throttling techniques on the Pi 3. We find that cache partitioning is
ineffective, while memory bandwidth throttling is an effective solution.
",Cybersecurity
"  Fast, byte-addressable non-volatile memory (NVM) embraces both near-DRAM
latency and disk-like persistence, which has generated considerable interests
to revolutionize system software stack and programming models. However, it is
less understood how NVM can be combined with managed runtime like Java virtual
machine (JVM) to ease persistence management. This paper proposes Espresso, a
holistic extension to Java and its runtime, to enable Java programmers to
exploit NVM for persistence management with high performance. Espresso first
provides a general persistent heap design called Persistent Java Heap (PJH) to
manage persistent data as normal Java objects. The heap is then strengthened
with a recoverable mechanism to provide crash consistency for heap metadata. It
then provides a new abstraction called Persistent Java Object (PJO) to provide
an easy-to-use but safe persistent programming model for programmers to persist
application data. The evaluation confirms that Espresso significantly
outperforms state-of-art NVM support for Java (i.e., JPA and PCJ) while being
compatible to existing data structures in Java programs.
",Cybersecurity
"  Traditional web search forces the developers to leave their working
environments and look for solutions in the web browsers. It often does not
consider the context of their programming problems. The context-switching
between the web browser and the working environment is time-consuming and
distracting, and the keyword-based traditional search often does not help much
in problem solving. In this paper, we propose an Eclipse IDE-based web search
solution that collects the data from three web search APIs-- Google, Yahoo,
Bing and a programming Q & A site-- Stack Overflow. It then provides search
results within IDE taking not only the content of the selected error into
account but also the problem context, popularity and search engine
recommendation of the result links. Experiments with 25 run time errors and
exceptions show that the proposed approach outperforms the keyword-based search
approaches with a recommendation accuracy of 96%. We also validate the results
with a user study involving five prospective participants where we get a result
agreement of 64.28%. While the preliminary results are promising, the approach
needs to be further validated with more errors and exceptions followed by a
user study with more participants to establish itself as a complete IDE-based
web search solution.
",Cybersecurity
"  We propose a novel method for 3D object pose estimation in RGB images, which
does not require pose annotations of objects in images in the training stage.
We tackle the pose estimation problem by learning how to establish
correspondences between RGB images and rendered depth images of CAD models.
During training, our approach only requires textureless CAD models and aligned
RGB-D frames of a subset of object instances, without explicitly requiring pose
annotations for the RGB images. We employ a deep quadruplet convolutional
neural network for joint learning of suitable keypoints and their associated
descriptors in pairs of rendered depth images which can be matched across
modalities with aligned RGB-D views. During testing, keypoints are extracted
from a query RGB image and matched to keypoints extracted from rendered depth
images, followed by establishing 2D-3D correspondences. The object's pose is
then estimated using the RANSAC and PnP algorithms. We conduct experiments on
the recently introduced Pix3D dataset and demonstrate the efficacy of our
proposed approach in object pose estimation as well as generalization to object
instances not seen during training.
",Cybersecurity
"  Deep learning based speech enhancement and source separation systems have
recently reached unprecedented levels of quality, to the point that performance
is reaching a new ceiling. Most systems rely on estimating the magnitude of a
target source by estimating a real-valued mask to be applied to a
time-frequency representation of the mixture signal. A limiting factor in such
approaches is a lack of phase estimation: the phase of the mixture is most
often used when reconstructing the estimated time-domain signal. Here, we
propose `MagBook', `phasebook', and `Combook', three new types of layers based
on discrete representations that can be used to estimate complex time-frequency
masks. MagBook layers extend classical sigmoidal units and a recently
introduced convex softmax activation for mask-based magnitude estimation.
Phasebook layers use a similar structure to give an estimate of the phase mask
without suffering from phase wrapping issues. Combook layers are an alternative
to the MagBook-Phasebook combination that directly estimate complex masks. We
present various training and inference regimes involving these representations,
and explain in particular how to include them in an end-to-end learning
framework. We also present an oracle study to assess upper bounds on
performance for various types of masks using discrete phase representations. We
evaluate the proposed methods on the wsj0-2mix dataset, a well-studied corpus
for single-channel speaker-independent speaker separation, matching the
performance of state-of-the-art mask-based approaches without requiring
additional phase reconstruction steps.
",Cybersecurity
"  Stacking-based deep neural network (S-DNN), in general, denotes a deep neural
network (DNN) resemblance in terms of its very deep, feedforward network
architecture. The typical S-DNN aggregates a variable number of individually
learnable modules in series to assemble a DNN-alike alternative to the targeted
object recognition tasks. This work likewise devises an S-DNN instantiation,
dubbed deep analytic network (DAN), on top of the spectral histogram (SH)
features. The DAN learning principle relies on ridge regression, and some key
DNN constituents, specifically, rectified linear unit, fine-tuning, and
normalization. The DAN aptitude is scrutinized on three repositories of varying
domains, including FERET (faces), MNIST (handwritten digits), and CIFAR10
(natural objects). The empirical results unveil that DAN escalates the SH
baseline performance over a sufficiently deep layer.
",Cybersecurity
"  This paper maps out the relation between different approaches for handling
preferences in argumentation with strict rules and defeasible assumptions by
offering translations between them. The systems we compare are: non-prioritized
defeats i.e. attacks, preference-based defeats, and preference-based defeats
extended with reverse defeat.
",Cybersecurity
"  In this work, we study the problem of dispersion of mobile robots on dynamic
rings. The problem of dispersion of $n$ robots on an $n$ node graph, introduced
by Augustine and Moses Jr. [1], requires robots to coordinate with each other
and reach a configuration where exactly one robot is present on each node. This
problem has real world applications and applies whenever we want to minimize
the total cost of $n$ agents sharing $n$ resources, located at various places,
subject to the constraint that the cost of an agent moving to a different
resource is comparatively much smaller than the cost of multiple agents sharing
a resource (e.g. smart electric cars sharing recharge stations). The study of
this problem also provides indirect benefits to the study of scattering on
graphs, the study of exploration by mobile robots, and the study of load
balancing on graphs.
We solve the problem of dispersion in the presence of two types of dynamism
in the underlying graph: (i) vertex permutation and (ii) 1-interval
connectivity. We introduce the notion of vertex permutation dynamism and have
it mean that for a given set of nodes, in every round, the adversary ensures a
ring structure is maintained, but the connections between the nodes may change.
We use the idea of 1-interval connectivity from Di Luna et al. [10], where for
a given ring, in each round, the adversary chooses at most one edge to remove.
We assume robots have full visibility and present asymptotically time optimal
algorithms to achieve dispersion in the presence of both types of dynamism when
robots have chirality. When robots do not have chirality, we present
asymptotically time optimal algorithms to achieve dispersion subject to certain
constraints. Finally, we provide impossibility results for dispersion when
robots have no visibility.
",Cybersecurity
"  A method is presented for solving the discrete-time finite-horizon Linear
Quadratic Regulator (LQR) problem subject to auxiliary linear equality
constraints, such as fixed end-point constraints. The method explicitly
determines an affine relationship between the control and state variables, as
in standard Riccati recursion, giving rise to feedback control policies that
account for constraints. Since the linearly-constrained LQR problem arises
commonly in robotic trajectory optimization, having a method that can
efficiently compute these solutions is important. We demonstrate some of the
useful properties and interpretations of said control policies, and we compare
the computation time of our method against existing methods.
",Cybersecurity
"  The environmental impacts of medium to large scale buildings receive
substantial attention in research, industry, and media. This paper studies the
energy savings potential of a commercial soccer stadium during day-to-day
operation. Buildings of this kind are characterized by special purpose system
installations like grass heating systems and by event-driven usage patterns.
This work presents a methodology to holistically analyze the stadiums
characteristics and integrate its existing instrumentation into a
Cyber-Physical System, enabling to deploy different control strategies
flexibly. In total, seven different strategies for controlling the studied
stadiums grass heating system are developed and tested in operation.
Experiments in winter season 2014/2015 validated the strategies impacts within
the real operational setup of the Commerzbank Arena, Frankfurt, Germany. With
95% confidence, these experiments saved up to 66% of median daily
weather-normalized energy consumption. Extrapolated to an average heating
season, this corresponds to savings of 775 MWh and 148 t of CO2 emissions. In
winter 2015/2016 an additional predictive nighttime heating experiment targeted
lower temperatures, which increased the savings to up to 85%, equivalent to 1
GWh (197 t CO2) in an average winter. Beyond achieving significant energy
savings, the different control strategies also met the target temperature
levels to the satisfaction of the stadiums operational staff. While the case
study constitutes a significant part, the discussions dedicated to the
transferability of this work to other stadiums and other building types show
that the concepts and the approach are of general nature. Furthermore, this
work demonstrates the first successful application of Deep Belief Networks to
regress and predict the thermal evolution of building systems.
",Cybersecurity
"  Application of humanoid robots has been common in the field of healthcare and
education. It has been recurrently used to improve social behavior and mollify
distress level among children with autism, cancer and cerebral palsy. This
article discusses the same from a human factors perspective. It shows how
people of different age and gender have a different opinion towards the
application and acceptance of humanoid robots. Additionally, this article
highlights the influence of cerebral condition and social interaction on a user
behavior and attitude towards humanoid robots. Our study performed a literature
review and found that (a) children and elderly individuals prefer humanoid
robots due to inactive social interaction, (b) The deterministic behavior of
humanoid robots can be acknowledged to improve social behavior of autistic
children, (c) Trust on humanoid robots is highly driven by its application and
a user age, gender, and social life.
",Cybersecurity
"  When performing localization and mapping, working at the level of structure
can be advantageous in terms of robustness to environmental changes and
differences in illumination. This paper presents SegMap: a map representation
solution to the localization and mapping problem based on the extraction of
segments in 3D point clouds. In addition to facilitating the computationally
intensive task of processing 3D point clouds, working at the level of segments
addresses the data compression requirements of real-time single- and
multi-robot systems. While current methods extract descriptors for the single
task of localization, SegMap leverages a data-driven descriptor in order to
extract meaningful features that can also be used for reconstructing a dense 3D
map of the environment and for extracting semantic information. This is
particularly interesting for navigation tasks and for providing visual feedback
to end-users such as robot operators, for example in search and rescue
scenarios. These capabilities are demonstrated in multiple urban driving and
search and rescue experiments. Our method leads to an increase of area under
the ROC curve of 28.3% over current state of the art using eigenvalue based
features. We also obtain very similar reconstruction capabilities to a model
specifically trained for this task. The SegMap implementation will be made
available open-source along with easy to run demonstrations at
www.github.com/ethz-asl/segmap. A video demonstration is available at
this https URL.
",Cybersecurity
"  This paper is on active learning where the goal is to reduce the data
annotation burden by interacting with a (human) oracle during training.
Standard active learning methods ask the oracle to annotate data samples.
Instead, we take a profoundly different approach: we ask for annotations of the
decision boundary. We achieve this using a deep generative model to create
novel instances along a 1d line. A point on the decision boundary is revealed
where the instances change class. Experimentally we show on three data sets
that our method can be plugged-in to other active learning schemes, that human
oracles can effectively annotate points on the decision boundary, that our
method is robust to annotation noise, and that decision boundary annotations
improve over annotating data samples.
",Cybersecurity
"  Soft Random Geometric Graphs (SRGGs) have been widely applied to various
models including those of wireless sensor, communication, social and neural
networks. SRGGs are constructed by randomly placing nodes in some space and
making pairwise links probabilistically using a connection function that is
system specific and usually decays with distance. In this paper we focus on the
application of SRGGs to wireless communication networks where information is
relayed in a multi hop fashion, although the analysis is more general and can
be applied elsewhere by using different distributions of nodes and/or
connection functions. We adopt a general non-uniform density which can model
the stationary distribution of different mobility models, with the interesting
case being when the density goes to zero along the boundaries. The global
connectivity properties of these non-uniform networks are likely to be
determined by highly isolated nodes, where isolation can be caused by the
spatial distribution or the local geometry (boundaries). We extend the analysis
to temporal-spatial networks where we fix the underlying non-uniform
distribution of points and the dynamics are caused by the temporal variations
in the link set, and explore the probability a node near the corner is isolated
at time $T$. This work allows for insight into how non-uniformity (caused by
mobility) and boundaries impact the connectivity features of temporal-spatial
networks. We provide a simple method for approximating these probabilities for
a range of different connection functions and verify them against simulations.
Boundary nodes are numerically shown to dominate the connectivity properties of
these finite networks with non-uniform measure.
",Cybersecurity
"  We quantify the accuracy of various simulators compared to a real world
robotic reaching and interaction task. Simulators are used in robotics to
design solutions for real world hardware without the need for physical access.
The `reality gap' prevents solutions developed or learnt in simulation from
performing well, or at at all, when transferred to real-world hardware. Making
use of a Kinova robotic manipulator and a motion capture system, we record a
ground truth enabling comparisons with various simulators, and present
quantitative data for various manipulation-oriented robotic tasks. We show the
relative strengths and weaknesses of numerous contemporary simulators,
highlighting areas of significant discrepancy, and assisting researchers in the
field in their selection of appropriate simulators for their use cases. All
code and parameter listings are publicly available from:
this https URL .
",Cybersecurity
"  Component-based development is a software engineering paradigm that can
facilitate the construction of embedded systems and tackle its complexities.
The modern embedded systems have more and more demanding requirements. One way
to cope with such versatile and growing set of requirements is to employ
heterogeneous processing power, i.e., CPU-GPU architectures. The new CPU-GPU
embedded boards deliver an increased performance but also introduce additional
complexity and challenges. In this work, we address the component-to-hardware
allocation for CPU-GPU embedded systems. The allocation for such systems is
much complex due to the increased amount of GPU-related information. For
example, while in traditional embedded systems the allocation mechanism may
consider only the CPU memory usage of components to find an appropriate
allocation scheme, in heterogeneous systems, the GPU memory usage needs also to
be taken into account in the allocation process. This paper aims at decreasing
the component-to-hardware allocation complexity by introducing a 2-layer
component-based architecture for heterogeneous embedded systems. The detailed
CPU-GPU information of the system is abstracted at a high-layer by compacting
connected components into single units that behave as regular components. The
allocator, based on the compacted information received from the high-level
layer, computes, with a decreased complexity, feasible allocation schemes. In
the last part of the paper, the 2-layer allocation method is evaluated using an
existing embedded system demonstrator; namely, an underwater robot.
",Cybersecurity
"  We study the Steiner Tree problem, in which a set of terminal vertices needs
to be connected in the cheapest possible way in an edge-weighted graph. This
problem has been extensively studied from the viewpoint of approximation and
also parametrization. In particular, on one hand Steiner Tree is known to be
APX-hard, and W[2]-hard on the other, if parameterized by the number of
non-terminals (Steiner vertices) in the optimum solution. In contrast to this
we give an efficient parameterized approximation scheme (EPAS), which
circumvents both hardness results. Moreover, our methods imply the existence of
a polynomial size approximate kernelization scheme (PSAKS) for the considered
parameter.
We further study the parameterized approximability of other variants of
Steiner Tree, such as Directed Steiner Tree and Steiner Forest. For neither of
these an EPAS is likely to exist for the studied parameter: for Steiner Forest
an easy observation shows that the problem is APX-hard, even if the input graph
contains no Steiner vertices. For Directed Steiner Tree we prove that
approximating within any function of the studied parameter is W[1]-hard.
Nevertheless, we show that an EPAS exists for Unweighted Directed Steiner Tree,
but a PSAKS does not. We also prove that there is an EPAS and a PSAKS for
Steiner Forest if in addition to the number of Steiner vertices, the number of
connected components of an optimal solution is considered to be a parameter.
",Cybersecurity
"  The hardness of the learning with errors (LWE) problem is one of the most
fruitful resources of modern cryptography. In particular, it is one of the most
prominent candidates for secure post-quantum cryptography. Understanding its
quantum complexity is therefore an important goal. We show that under quantum
polynomial time reductions, LWE is equivalent to a relaxed version of the
dihedral coset problem (DCP), which we call extrapolated DCP (eDCP). The extent
of extrapolation varies with the LWE noise rate. By considering different
extents of extrapolation, our result generalizes Regev's famous proof that if
DCP is in BQP (quantum poly-time) then so is LWE (FOCS'02). We also discuss a
connection between eDCP and Childs and Van Dam's algorithm for generalized
hidden shift problems (SODA'07). Our result implies that a BQP solution for LWE
might not require the full power of solving DCP, but rather only a solution for
its relaxed version, eDCP, which could be easier.
",Cybersecurity
"  Sketch-based modeling strives to bring the ease and immediacy of drawing to
the 3D world. However, while drawings are easy for humans to create, they are
very challenging for computers to interpret due to their sparsity and
ambiguity. We propose a data-driven approach that tackles this challenge by
learning to reconstruct 3D shapes from one or more drawings. At the core of our
approach is a deep convolutional neural network (CNN) that predicts occupancy
of a voxel grid from a line drawing. This CNN provides us with an initial 3D
reconstruction as soon as the user completes a single drawing of the desired
shape. We complement this single-view network with an updater CNN that refines
an existing prediction given a new drawing of the shape created from a novel
viewpoint. A key advantage of our approach is that we can apply the updater
iteratively to fuse information from an arbitrary number of viewpoints, without
requiring explicit stroke correspondences between the drawings. We train both
CNNs by rendering synthetic contour drawings from hand-modeled shape
collections as well as from procedurally-generated abstract shapes. Finally, we
integrate our CNNs in a minimal modeling interface that allows users to
seamlessly draw an object, rotate it to see its 3D reconstruction, and refine
it by re-drawing from another vantage point using the 3D reconstruction as
guidance. The main strengths of our approach are its robustness to freehand
bitmap drawings, its ability to adapt to different object categories, and the
continuum it offers between single-view and multi-view sketch-based modeling.
",Cybersecurity
"  Many works in collaborative robotics and human-robot interaction focuses on
identifying and predicting human behaviour while considering the information
about the robot itself as given. This can be the case when sensors and the
robot are calibrated in relation to each other and often the reconfiguration of
the system is not possible, or extra manual work is required. We present a deep
learning based approach to remove the constraint of having the need for the
robot and the vision sensor to be fixed and calibrated in relation to each
other. The system learns the visual cues of the robot body and is able to
localise it, as well as estimate the position of robot joints in 3D space by
just using a 2D color image. The method uses a cascaded convolutional neural
network, and we present the structure of the network, describe our own
collected dataset, explain the network training and achieved results. A fully
trained system shows promising results in providing an accurate mask of where
the robot is located and a good estimate of its joints positions in 3D. The
accuracy is not good enough for visual servoing applications yet, however, it
can be sufficient for general safety and some collaborative tasks not requiring
very high precision. The main benefit of our method is the possibility of the
vision sensor to move freely. This allows it to be mounted on moving objects,
for example, a body of the person or a mobile robot working in the same
environment as the robots are operating in.
",Cybersecurity
"  New features and enhancements for the SPIKE banded solver are presented.
Among all the SPIKE algorithm versions, we focus our attention on the recursive
SPIKE technique which provides the best trade-off between generality and
parallel efficiency, but was known for its lack of flexibility. Its application
was essentially limited to power of two number of cores/processors. This
limitation is successfully addressed in this paper. In addition, we present a
new transpose solve option, a standard feature of most numerical solver
libraries which has never been addressed by the SPIKE algorithm so far. A
pivoting recursive SPIKE strategy is finally presented as an alternative to
non-pivoting scheme for systems with large condition numbers. All these new
enhancements participate to create a feature complete SPIKE algorithm and a new
black-box SPIKE-OpenMP package that significantly outperforms the performance
and scalability obtained with other state-of-the-art banded solvers.
",Cybersecurity
"  We present adaptive strategies for antenna selection for Direction of Arrival
(DoA) estimation of a far-field source using TDM MIMO radar with linear arrays.
Our treatment is formulated within a general adaptive sensing framework that
uses one-step ahead predictions of the Bayesian MSE using a parametric family
of Weiss-Weinstein bounds that depend on previous measurements. We compare in
simulations our strategy with adaptive policies that optimize the Bobrovsky-
Zaka{\i} bound and the Expected Cramér-Rao bound, and show the performance
for different levels of measurement noise.
",Cybersecurity
"  As researchers use computational methods to study complex social behaviors at
scale, the validity of this computational social science depends on the
integrity of the data. On July 2, 2015, Jason Baumgartner published a dataset
advertised to include ``every publicly available Reddit comment'' which was
quickly shared on Bittorrent and the Internet Archive. This data quickly became
the basis of many academic papers on topics including machine learning, social
behavior, politics, breaking news, and hate speech. We have discovered
substantial gaps and limitations in this dataset which may contribute to bias
in the findings of that research. In this paper, we document the dataset,
substantial missing observations in the dataset, and the risks to research
validity from those gaps. In summary, we identify strong risks to research that
considers user histories or network analysis, moderate risks to research that
compares counts of participation, and lesser risk to machine learning research
that avoids making representative claims about behavior and participation on
Reddit.
",Cybersecurity
"  Several recent works have proposed and implemented cryptography as a means to
preserve privacy and security of patients health data. Nevertheless, the
weakest point of electronic health record (EHR) systems that relied on these
cryptographic schemes is key management. Thus, this paper presents the
development of privacy and security system for cryptography-based-EHR by taking
advantage of the uniqueness of fingerprint and iris characteristic features to
secure cryptographic keys in a bio-cryptography framework. The results of the
system evaluation showed significant improvements in terms of time efficiency
of this approach to cryptographic-based-EHR. Both the fuzzy vault and fuzzy
commitment demonstrated false acceptance rate (FAR) of 0%, which reduces the
likelihood of imposters gaining successful access to the keys protecting
patients protected health information. This result also justifies the
feasibility of implementing fuzzy key binding scheme in real applications,
especially fuzzy vault which demonstrated a better performance during key
reconstruction.
",Cybersecurity
"  Recognizing human activities in a sequence is a challenging area of research
in ubiquitous computing. Most approaches use a fixed size sliding window over
consecutive samples to extract features---either handcrafted or learned
features---and predict a single label for all samples in the window. Two key
problems emanate from this approach: i) the samples in one window may not
always share the same label. Consequently, using one label for all samples
within a window inevitably lead to loss of information; ii) the testing phase
is constrained by the window size selected during training while the best
window size is difficult to tune in practice. We propose an efficient algorithm
that can predict the label of each sample, which we call dense labeling, in a
sequence of human activities of arbitrary length using a fully convolutional
network. In particular, our approach overcomes the problems posed by the
sliding window step. Additionally, our algorithm learns both the features and
classifier automatically. We release a new daily activity dataset based on a
wearable sensor with hospitalized patients. We conduct extensive experiments
and demonstrate that our proposed approach is able to outperform the
state-of-the-arts in terms of classification and label misalignment measures on
three challenging datasets: Opportunity, Hand Gesture, and our new dataset.
",Cybersecurity
"  Most of the existing medicine recommendation systems that are mainly based on
electronic medical records (EMRs) are significantly assisting doctors to make
better clinical decisions benefiting both patients and caregivers. Even though
the growth of EMRs is at a lighting fast speed in the era of big data, content
limitations in EMRs restrain the existed recommendation systems to reflect
relevant medical facts, such as drug-drug interactions. Many medical knowledge
graphs that contain drug-related information, such as DrugBank, may give hope
for the recommendation systems. However, the direct use of these knowledge
graphs in the systems suffers from robustness caused by the incompleteness of
the graphs. To address these challenges, we stand on recent advances in graph
embedding learning techniques and propose a novel framework, called Safe
Medicine Recommendation (SMR), in this paper. Specifically, SMR first
constructs a high-quality heterogeneous graph by bridging EMRs (MIMIC-III) and
medical knowledge graphs (ICD-9 ontology and DrugBank). Then, SMR jointly
embeds diseases, medicines, patients, and their corresponding relations into a
shared lower dimensional space. Finally, SMR uses the embeddings to decompose
the medicine recommendation into a link prediction process while considering
the patient's diagnoses and adverse drug reactions. To our best knowledge, SMR
is the first to learn embeddings of a patient-disease-medicine graph for
medicine recommendation in the world. Extensive experiments on real datasets
are conducted to evaluate the effectiveness of proposed framework.
",Cybersecurity
"  Study shows that software developers spend about 19% of their time looking
for information in the web during software development and maintenance.
Traditional web search forces them to leave the working environment (e.g., IDE)
and look for information in the web browser. It also does not consider the
context of the problems that the developers search solutions for. The frequent
switching between web browser and the IDE is both time-consuming and
distracting, and the keyword-based traditional web search often does not help
much in problem solving. In this paper, we propose an Eclipse IDE-based web
search solution that exploits the APIs provided by three popular web search
engines-- Google, Yahoo, Bing and a popular programming Q & A site, Stack
Overflow, and captures the content-relevance, context-relevance, popularity and
search engine confidence of each candidate result against the encountered
programming problems. Experiments with 75 programming errors and exceptions
using the proposed approach show that inclusion of different types of context
information associated with a given exception can enhance the recommendation
accuracy of a given exception. Experiments both with two existing approaches
and existing web search engines confirm that our approach can perform better
than them in terms of recall, mean precision and other performance measures
with little computational cost.
",Cybersecurity
"  Classification, which involves finding rules that partition a given data set
into disjoint groups, is one class of data mining problems. Approaches proposed
so far for mining classification rules for large databases are mainly decision
tree based symbolic learning methods. The connectionist approach based on
neural networks has been thought not well suited for data mining. One of the
major reasons cited is that knowledge generated by neural networks is not
explicitly represented in the form of rules suitable for verification or
interpretation by humans. This paper examines this issue. With our newly
developed algorithms, rules which are similar to, or more concise than those
generated by the symbolic methods can be extracted from the neural networks.
The data mining process using neural networks with the emphasis on rule
extraction is described. Experimental results and comparison with previously
published works are presented.
",Cybersecurity
"  Cyclic data structures, such as cyclic lists, in functional programming are
tricky to handle because of their cyclicity. This paper presents an
investigation of categorical, algebraic, and computational foundations of
cyclic datatypes. Our framework of cyclic datatypes is based on second-order
algebraic theories of Fiore et al., which give a uniform setting for syntax,
types, and computation rules for describing and reasoning about cyclic
datatypes. We extract the ""fold"" computation rules from the categorical
semantics based on iteration categories of Bloom and Esik. Thereby, the rules
are correct by construction. We prove strong normalisation using the General
Schema criterion for second-order computation rules. Rather than the fixed
point law, we particularly choose Bekic law for computation, which is a key to
obtaining strong normalisation. We also prove the property of ""Church-Rosser
modulo bisimulation"" for the computation rules. Combining these results, we
have a remarkable decidability result of the equational theory of cyclic data
and fold.
",Cybersecurity
"  In recent publications, we presented a novel formal symbolic process virtual
machine (FSPVM) framework that combined higher-order theorem proving and
symbolic execution for verifying the reliability and security of smart
contracts developed in the Ethereum blockchain system without suffering the
standard issues surrounding reusability, consistency, and automation. A
specific FSPVM, denoted as FSPVM-E, was developed in Coq based on a general,
extensible, and reusable formal memory (GERM) framework, an extensible and
universal formal intermediate programming language, denoted as Lolisa, which is
a large subset of the Solidity programming language that uses generalized
algebraic datatypes, and a corresponding formally verified interpreter for
Lolisa, denoted as FEther, which serves as a crucial component of FSPVM-E.
However, our past work has demonstrated that the execution efficiency of the
standard development of FEther is extremely low. As a result, FSPVM-E fails to
achieve its expected verification effect. The present work addresses this issue
by first identifying three root causes of the low execution efficiency of
formal interpreters. We then build abstract models of these causes, and present
respective optimization schemes for rectifying the identified conditions.
Finally, we apply these optimization schemes to FEther, and demonstrate that
its execution efficiency has been improved significantly.
",Cybersecurity
"  Domain shift refers to the well known problem that a model trained in one
source domain performs poorly when applied to a target domain with different
statistics. {Domain Generalization} (DG) techniques attempt to alleviate this
issue by producing models which by design generalize well to novel testing
domains. We propose a novel {meta-learning} method for domain generalization.
Rather than designing a specific model that is robust to domain shift as in
most previous DG work, we propose a model agnostic training procedure for DG.
Our algorithm simulates train/test domain shift during training by synthesizing
virtual testing domains within each mini-batch. The meta-optimization objective
requires that steps to improve training domain performance should also improve
testing domain performance. This meta-learning procedure trains models with
good generalization ability to novel domains. We evaluate our method and
achieve state of the art results on a recent cross-domain image classification
benchmark, as well demonstrating its potential on two classic reinforcement
learning tasks.
",Cybersecurity
"  Gaussian belief propagation (BP) has been widely used for distributed
estimation in large-scale networks such as the smart grid, communication
networks, and social networks, where local measurements/observations are
scattered over a wide geographical area. However, the convergence of Gaus- sian
BP is still an open issue. In this paper, we consider the convergence of
Gaussian BP, focusing in particular on the convergence of the information
matrix. We show analytically that the exchanged message information matrix
converges for arbitrary positive semidefinite initial value, and its dis- tance
to the unique positive definite limit matrix decreases exponentially fast.
",Cybersecurity
"  Distributed storage systems suffer from significant repair traffic generated
due to frequent storage node failures. This paper shows that properly designed
low-density parity-check (LDPC) codes can substantially reduce the amount of
required block downloads for repair thanks to the sparse nature of their factor
graph representation. In particular, with a careful construction of the factor
graph, both low repair-bandwidth and high reliability can be achieved for a
given code rate. First, a formula for the average repair bandwidth of LDPC
codes is developed. This formula is then used to establish that the minimum
repair bandwidth can be achieved by forcing a regular check node degree in the
factor graph. Moreover, it is shown that given a fixed code rate, the variable
node degree should also be regular to yield minimum repair bandwidth, under
some reasonable minimum variable node degree constraint. It is also shown that
for a given repair-bandwidth requirement, LDPC codes can yield substantially
higher reliability than currently utilized Reed-Solomon (RS) codes. Our
reliability analysis is based on a formulation of the general equation for the
mean-time-to-data-loss (MTTDL) associated with LDPC codes. The formulation
reveals that the stopping number is closely related to the MTTDL. It is further
shown that LDPC codes can be designed such that a small loss of
repair-bandwidth optimality may be traded for a large improvement in
erasure-correction capability and thus the MTTDL.
",Cybersecurity
"  A strong certification process is required to insure the safety of airplanes,
and more specifically the robustness of avionics applications. To implement
this process, the development of avionics software must follow long and costly
procedures. Most of these procedures have to be reexecuted each time the
software is modified. In this paper, we propose a framework to reduce the cost
and time impact of a software modification. With this new approach, the piece
of software likely to change is isolated from the rest of the application, so
it can be certified independently. This helps the system integrator to adapt an
avionics application to the specificities of the target airplane, without the
need for a new certification of the application.
",Cybersecurity
"  The study of Dense-$3$-Subhypergraph problem was initiated in Chlamt{á}c
et al. [Approx'16]. The input is a universe $U$ and collection ${\cal S}$ of
subsets of $U$, each of size $3$, and a number $k$. The goal is to choose a set
$W$ of $k$ elements from the universe, and maximize the number of sets, $S\in
{\cal S}$ so that $S\subseteq W$. The members in $U$ are called {\em vertices}
and the sets of ${\cal S}$ are called the {\em hyperedges}. This is the
simplest extension into hyperedges of the case of sets of size $2$ which is the
well known Dense $k$-subgraph problem.
The best known ratio for the Dense-$3$-Subhypergraph is $O(n^{0.69783..})$ by
Chlamt{á}c et al. We improve this ratio to $n^{0.61802..}$. More
importantly, we give a new algorithm that approximates Dense-$3$-Subhypergraph
within a ratio of $\tilde O(n/k)$, which improves the ratio of $O(n^2/k^2)$ of
Chlamt{á}c et al.
We prove that under the {\em log density conjecture} (see Bhaskara et al.
[STOC'10]) the ratio cannot be better than $\Omega(\sqrt{n})$ and demonstrate
some cases in which this optimum can be attained.
",Cybersecurity
"  Traffic for internet video streaming has been rapidly increasing and is
further expected to increase with the higher definition videos and IoT
applications, such as 360 degree videos and augmented virtual reality
applications. While efficient management of heterogeneous cloud resources to
optimize the quality of experience is important, existing work in this problem
space often left out important factors. In this paper, we present a model for
describing a today's representative system architecture for video streaming
applications, typically composed of a centralized origin server and several CDN
sites. Our model comprehensively considers the following factors: limited
caching spaces at the CDN sites, allocation of CDN for a video request, choice
of different ports from the CDN, and the central storage and bandwidth
allocation. With the model, we focus on minimizing a performance metric, stall
duration tail probability (SDTP), and present a novel, yet efficient, algorithm
to solve the formulated optimization problem. The theoretical bounds with
respect to the SDTP metric are also analyzed and presented. Our extensive
simulation results demonstrate that the proposed algorithms can significantly
improve the SDTP metric, compared to the baseline strategies. Small-scale video
streaming system implementation in a real cloud environment further validates
our results.
",Cybersecurity
"  This paper addresses the problem of selecting from a choice of possible
grasps, so that impact forces will be minimised if a collision occurs while the
robot is moving the grasped object along a post-grasp trajectory. Such
considerations are important for safety in human-robot interaction, where even
a certified ""human-safe"" (e.g. compliant) arm may become hazardous once it
grasps and begins moving an object, which may have significant mass, sharp
edges or other dangers. Additionally, minimising collision forces is critical
to preserving the longevity of robots which operate in uncertain and hazardous
environments, e.g. robots deployed for nuclear decommissioning, where removing
a damaged robot from a contaminated zone for repairs may be extremely difficult
and costly. Also, unwanted collisions between a robot and critical
infrastructure (e.g. pipework) in such high-consequence environments can be
disastrous. In this paper, we investigate how the safety of the post-grasp
motion can be considered during the pre-grasp approach phase, so that the
selected grasp is optimal in terms applying minimum impact forces if a
collision occurs during a desired post-grasp manipulation. We build on the
methods of augmented robot-object dynamics models and ""effective mass"" and
propose a method for combining these concepts with modern grasp and trajectory
planners, to enable the robot to achieve a grasp which maximises the safety of
the post-grasp trajectory, by minimising potential collision forces. We
demonstrate the effectiveness of our approach through several experiments with
both simulated and real robots.
",Cybersecurity
"  Future electricity distribution grids will host a considerable share of
variable renewable energy sources and local storage resources. Moreover, they
will face new load structures due for example to the growth of the electric
vehicle market. These trends raise the need for new paradigms for distribution
grids operation, in which Distribution System Operators will increasingly rely
on demand side flexibility and households will progressively become prosumers
playing an active role on smart grid energy management. However, in present
energy management architectures, the lack of coordination among actors limits
the capability of the grid to enable the mentioned trends. In this paper we
tackle this problem by proposing an architecture that enables households to
autonomously exchange energy blocks and flexibility services with neighbors,
operators and market actors. The solution is based on a blockchain transactive
platform. We focus on a market application, where households can trade energy
with their neighbors, aimed to locally balancing renewable energy production.
We propose a market mechanism and dynamic transport prices that provide an
incentive for households to locally manage energy resources in a way that
responds to both pro-sumer and operator needs. We evaluate the impact of such
markets through comprehensive simulations using power flow analysis and
realistic load profiles, providing valuable insight for the design of
appropriate mechanisms and incentives.
",Cybersecurity
"  High-precision modeling of subatomic particle interactions is critical for
many fields within the physical sciences, such as nuclear physics and high
energy particle physics. Most simulation pipelines in the sciences are
computationally intensive -- in a variety of scientific fields, Generative
Adversarial Networks have been suggested as a solution to speed up the forward
component of simulation, with promising results. An important component of any
simulation system for the sciences is the ability to condition on any number of
physically meaningful latent characteristics that can effect the forward
generation procedure. We introduce an auxiliary task to the training of a
Generative Adversarial Network on particle showers in a multi-layer
electromagnetic calorimeter, which allows our model to learn an attribute-aware
conditioning mechanism.
",Cybersecurity
"  This paper proposes a distributed consensus algorithm for linear event-based
heterogeneous multi-agent systems (MAS). The proposed scheme is event-triggered
in the sense that an agent selectively transmits its information within its
local neighbourhood based on a directed network topology under the fulfillment
of certain conditions. Using the Lyapunov stability theorem, the system
constraints and event-triggering condition are expressed in terms of several
linear matrix inequalities (LMIs) to derive the consensus parameters. The
objective is to design the transmission threshold and minimum-norm
heterogeneous control gains which collectively ensure an exponential consensus
convergence rate for the closed-loop systems. The LMI computed control gains
are robust to uncertainty with some deviation from their nominal values
allowed. The practicability of the proposed event-based framework is further
studied by proving the Zeno behaviour exclusion. Numerical simulations quantify
the advantages of our event-triggered consensus approach in second-order,
linear and heterogeneous multi-agent systems.
",Cybersecurity
"  We describe a new cardinality estimation algorithm that is extremely
space-efficient. It applies one of three novel estimators to the compressed
state of the Flajolet-Martin-85 coupon collection process. In an
apples-to-apples empirical comparison against compressed HyperLogLog sketches,
the new algorithm simultaneously wins on all three dimensions of the
time/space/accuracy tradeoff. Our prototype uses the zstd compression library,
and produces sketches that are smaller than the entropy of HLL, so no possible
implementation of compressed HLL can match its space efficiency. The paper's
technical contributions include analyses and simulations of the three new
estimators, accurate values for the entropies of FM85 and HLL, and a
non-trivial method for estimating a double asymptotic limit via simulation.
",Cybersecurity
"  Convolutional neural networks have recently demonstrated high-quality
reconstruction for single-image super-resolution. In this paper, we propose the
Laplacian Pyramid Super-Resolution Network (LapSRN) to progressively
reconstruct the sub-band residuals of high-resolution images. At each pyramid
level, our model takes coarse-resolution feature maps as input, predicts the
high-frequency residuals, and uses transposed convolutions for upsampling to
the finer level. Our method does not require the bicubic interpolation as the
pre-processing step and thus dramatically reduces the computational complexity.
We train the proposed LapSRN with deep supervision using a robust Charbonnier
loss function and achieve high-quality reconstruction. Furthermore, our network
generates multi-scale predictions in one feed-forward pass through the
progressive reconstruction, thereby facilitates resource-aware applications.
Extensive quantitative and qualitative evaluations on benchmark datasets show
that the proposed algorithm performs favorably against the state-of-the-art
methods in terms of speed and accuracy.
",Cybersecurity
"  Targeted advertising is meant to improve the efficiency of matching
advertisers to their customers. However, targeted advertising can also be
abused by malicious advertisers to efficiently reach people susceptible to
false stories, stoke grievances, and incite social conflict. Since targeted ads
are not seen by non-targeted and non-vulnerable people, malicious ads are
likely to go unreported and their effects undetected. This work examines a
specific case of malicious advertising, exploring the extent to which political
ads from the Russian Intelligence Research Agency (IRA) run prior to 2016 U.S.
elections exploited Facebook's targeted advertising infrastructure to
efficiently target ads on divisive or polarizing topics (e.g., immigration,
race-based policing) at vulnerable sub-populations. In particular, we do the
following: (a) We conduct U.S. census-representative surveys to characterize
how users with different political ideologies report, approve, and perceive
truth in the content of the IRA ads. Our surveys show that many ads are
""divisive"": they elicit very different reactions from people belonging to
different socially salient groups. (b) We characterize how these divisive ads
are targeted to sub-populations that feel particularly aggrieved by the status
quo. Our findings support existing calls for greater transparency of content
and targeting of political ads. (c) We particularly focus on how the Facebook
ad API facilitates such targeting. We show how the enormous amount of personal
data Facebook aggregates about users and makes available to advertisers enables
such malicious targeting.
",Cybersecurity
"  In this paper, we investigate the complexity of one-dimensional dynamic
programming, or more specifically, of the Least-Weight Subsequence (LWS)
problem: Given a sequence of $n$ data items together with weights for every
pair of the items, the task is to determine a subsequence $S$ minimizing the
total weight of the pairs adjacent in $S$. A large number of natural problems
can be formulated as LWS problems, yielding obvious $O(n^2)$-time solutions.
In many interesting instances, the $O(n^2)$-many weights can be succinctly
represented. Yet except for near-linear time algorithms for some specific
special cases, little is known about when an LWS instantiation admits a
subquadratic-time algorithm and when it does not. In particular, no lower
bounds for LWS instantiations have been known before. In an attempt to remedy
this situation, we provide a general approach to study the fine-grained
complexity of succinct instantiations of the LWS problem. In particular, given
an LWS instantiation we identify a highly parallel core problem that is
subquadratically equivalent. This provides either an explanation for the
apparent hardness of the problem or an avenue to find improved algorithms as
the case may be.
More specifically, we prove subquadratic equivalences between the following
pairs (an LWS instantiation and the corresponding core problem) of problems: a
low-rank version of LWS and minimum inner product, finding the longest chain of
nested boxes and vector domination, and a coin change problem which is closely
related to the knapsack problem and (min,+)-convolution. Using these
equivalences and known SETH-hardness results for some of the core problems, we
deduce tight conditional lower bounds for the corresponding LWS instantiations.
We also establish the (min,+)-convolution-hardness of the knapsack problem.
",Cybersecurity
"  Simultaneous Localization And Mapping (SLAM) is the problem of constructing
or updating a map of an unknown environment while simultaneously keeping track
of an agent's location within it. How to enable SLAM robustly and durably on
mobile, or even IoT grade devices, is the main challenge faced by the industry
today. The main problems we need to address are: 1.) how to accelerate the SLAM
pipeline to meet real-time requirements; and 2.) how to reduce SLAM energy
consumption to extend battery life. After delving into the problem, we found
out that feature extraction is indeed the bottleneck of performance and energy
consumption. Hence, in this paper, we design, implement, and evaluate a
hardware ORB feature extractor and prove that our design is a great balance
between performance and energy consumption compared with ARM Krait and Intel
Core i5.
",Cybersecurity
"  Deep network pruning is an effective method to reduce the storage and
computation cost of deep neural networks when applying them to resource-limited
devices. Among many pruning granularities, neuron level pruning will remove
redundant neurons and filters in the model and result in thinner networks. In
this paper, we propose a gradually global pruning scheme for neuron level
pruning. In each pruning step, a small percent of neurons were selected and
dropped across all layers in the model. We also propose a simple method to
eliminate the biases in evaluating the importance of neurons to make the scheme
feasible. Compared with layer-wise pruning scheme, our scheme avoid the
difficulty in determining the redundancy in each layer and is more effective
for deep networks. Our scheme would automatically find a thinner sub-network in
original network under a given performance.
",Cybersecurity
"  We present a new method for the automated synthesis of digital controllers
with formal safety guarantees for systems with nonlinear dynamics, noisy output
measurements, and stochastic disturbances. Our method derives digital
controllers such that the corresponding closed-loop system, modeled as a
sampled-data stochastic control system, satisfies a safety specification with
probability above a given threshold. The proposed synthesis method alternates
between two steps: generation of a candidate controller pc, and verification of
the candidate. pc is found by maximizing a Monte Carlo estimate of the safety
probability, and by using a non-validated ODE solver for simulating the system.
Such a candidate is therefore sub-optimal but can be generated very rapidly. To
rule out unstable candidate controllers, we prove and utilize Lyapunov's
indirect method for instability of sampled-data nonlinear systems. In the
subsequent verification step, we use a validated solver based on SMT
(Satisfiability Modulo Theories) to compute a numerically and statistically
valid confidence interval for the safety probability of pc. If the probability
so obtained is not above the threshold, we expand the search space for
candidates by increasing the controller degree. We evaluate our technique on
three case studies: an artificial pancreas model, a powertrain control model,
and a quadruple-tank process.
",Cybersecurity
"  In this work, we study the tradeoffs between the error probabilities of
classical-quantum channels and the blocklength $n$ when the transmission rates
approach the channel capacity at a rate slower than $1/\sqrt{n}$, a research
topic known as moderate deviation analysis. We show that the optimal error
probability vanishes under this rate convergence. Our main technical
contributions are a tight quantum sphere-packing bound, obtained via Chaganty
and Sethuraman's concentration inequality in strong large deviation theory, and
asymptotic expansions of error-exponent functions. Moderate deviation analysis
for quantum hypothesis testing is also established. The converse directly
follows from our channel coding result, while the achievability relies on a
martingale inequality.
",Cybersecurity
"  We present a formal model for a fragmentation and a reassembly protocol
running on top of the standardised CAN bus, which is widely used in automotive
and aerospace applications. Although the CAN bus comes with an in-built
mechanism for prioritisation, we argue that this is not sufficient and provide
another protocol to overcome this shortcoming.
",Cybersecurity
"  The performance of Neural Network (NN)-based language models is steadily
improving due to the emergence of new architectures, which are able to learn
different natural language characteristics. This paper presents a novel
framework, which shows that a significant improvement can be achieved by
combining different existing heterogeneous models in a single architecture.
This is done through 1) a feature layer, which separately learns different
NN-based models and 2) a mixture layer, which merges the resulting model
features. In doing so, this architecture benefits from the learning
capabilities of each model with no noticeable increase in the number of model
parameters or the training time. Extensive experiments conducted on the Penn
Treebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a
significant reduction of the perplexity when compared to state-of-the-art
feedforward as well as recurrent neural network architectures.
",Cybersecurity
"  A major investment made by a telecom operator goes into the infrastructure
and its maintenance, while business revenues are proportional to how big and
good the customer base is. We present a data-driven analytic strategy based on
combinatorial optimization and analysis of historical data. The data cover
historical mobility of the users in one region of Sweden during a week.
Applying the proposed method to the case study, we have identified the optimal
proportion of geo-demographic segments in the customer base, developed a
functionality to assess the potential of a planned marketing campaign, and
explored the problem of an optimal number and types of the geo-demographic
segments to target through marketing campaigns. With the help of fuzzy logic,
the conclusions of data analysis are automatically translated into
comprehensible recommendations in a natural language.
",Cybersecurity
"  Apprenticeship learning (AL) is a kind of Learning from Demonstration
techniques where the reward function of a Markov Decision Process (MDP) is
unknown to the learning agent and the agent has to derive a good policy by
observing an expert's demonstrations. In this paper, we study the problem of
how to make AL algorithms inherently safe while still meeting its learning
objective. We consider a setting where the unknown reward function is assumed
to be a linear combination of a set of state features, and the safety property
is specified in Probabilistic Computation Tree Logic (PCTL). By embedding
probabilistic model checking inside AL, we propose a novel
counterexample-guided approach that can ensure safety while retaining
performance of the learnt policy. We demonstrate the effectiveness of our
approach on several challenging AL scenarios where safety is essential.
",Cybersecurity
"  With the trend of increasing wind turbine rotor diameters, the mitigation of
blade fatigue loadings is of special interest to extend the turbine lifetime.
Fatigue load reductions can be partly accomplished using Individual Pitch
Control (IPC) facilitated by the so-called Multi-Blade Coordinate (MBC)
transformation. This operation transforms and decouples the blade load signals
in a yaw- and tilt-axis. However, in practical scenarios, the resulting
transformed system still shows coupling between the axes, posing a need for
more advanced Multiple-Input Multiple-Output (MIMO) control architectures. This
paper presents a novel analysis and design framework for decoupling of the
non-rotating axes by the inclusion of an azimuth offset in the reverse MBC
transformation, enabling the application of simple Single-Input Single-Output
(SISO) controllers. A thorough analysis is given by including the azimuth
offset in a frequency-domain representation. The result is evaluated on
simplified blade models, as well as linearizations obtained from the
NREL~5\nobreakdash-MW reference wind turbine. A sensitivity and decoupling
assessment justify the application of decentralized SISO control loops for IPC.
Furthermore, closed-loop high-fidelity simulations show beneficial effects on
pitch actuation and blade fatigue load reductions.
",Cybersecurity
"  Vehicle climate control systems aim to keep passengers thermally comfortable.
However, current systems control temperature rather than thermal comfort and
tend to be energy hungry, which is of particular concern when considering
electric vehicles. This paper poses energy-efficient vehicle comfort control as
a Markov Decision Process, which is then solved numerically using
Sarsa({\lambda}) and an empirically validated, single-zone, 1D thermal model of
the cabin. The resulting controller was tested in simulation using 200 randomly
selected scenarios and found to exceed the performance of bang-bang,
proportional, simple fuzzy logic, and commercial controllers with 23%, 43%,
40%, 56% increase, respectively. Compared to the next best performing
controller, energy consumption is reduced by 13% while the proportion of time
spent thermally comfortable is increased by 23%. These results indicate that
this is a viable approach that promises to translate into substantial comfort
and energy improvements in the car.
",Cybersecurity
"  Event detection is a critical feature in data-driven systems as it assists
with the identification of nominal and anomalous behavior. Event detection is
increasingly relevant in robotics as robots operate with greater autonomy in
increasingly unstructured environments. In this work, we present an accurate,
robust, fast, and versatile measure for skill and anomaly identification. A
theoretical proof establishes the link between the derivative of the
log-likelihood of the HMM filtered belief state and the latest emission
probabilities. The key insight is the inverse relationship in which gradient
analysis is used for skill and anomaly identification. Our measure showed
better performance across all metrics than related state-of-the art works. The
result is broadly applicable to domains that use HMMs for event detection.
",Cybersecurity
"  Spectral based heuristics belong to well-known commonly used methods which
determines provably minimal graph bisection or outputs ""fail"" when the
optimality cannot be certified. In this paper we focus on Boppana's algorithm
which belongs to one of the most prominent methods of this type. It is well
known that the algorithm works well in the random \emph{planted bisection
model} -- the standard class of graphs for analysis minimum bisection and
relevant problems. In 2001 Feige and Kilian posed the question if Boppana's
algorithm works well in the semirandom model by Blum and Spencer. In our paper
we answer this question affirmatively. We show also that the algorithm achieves
similar performance on graph classes which extend the semirandom model.
Since the behavior of Boppana's algorithm on the semirandom graphs remained
unknown, Feige and Kilian proposed a new semidefinite programming (SDP) based
approach and proved that it works on this model. The relationship between the
performance of the SDP based algorithm and Boppana's approach was left as an
open problem. In this paper we solve the problem in a complete way by proving
that the bisection algorithm of Feige and Kilian provides exactly the same
results as Boppana's algorithm. As a consequence we get that Boppana's
algorithm achieves the optimal threshold for exact cluster recovery in the
\emph{stochastic block model}. On the other hand we prove some limitations of
Boppana's approach: we show that if the density difference on the parameters of
the planted bisection model is too small then the algorithm fails with high
probability in the model.
",Cybersecurity
"  Similarity search is essential to many important applications and often
involves searching at scale on high-dimensional data based on their similarity
to a query. In biometric applications, recent vulnerability studies have shown
that adversarial machine learning can compromise biometric recognition systems
by exploiting the biometric similarity information. Existing methods for
biometric privacy protection are in general based on pairwise matching of
secured biometric templates and have inherent limitations in search efficiency
and scalability. In this paper, we propose an inference-based framework for
privacy-preserving similarity search in Hamming space. Our approach builds on
an obfuscated distance measure that can conceal Hamming distance in a dynamic
interval. Such a mechanism enables us to systematically design statistically
reliable methods for retrieving most likely candidates without knowing the
exact distance values. We further propose to apply Montgomery multiplication
for generating search indexes that can withstand adversarial similarity
analysis, and show that information leakage in randomized Montgomery domains
can be made negligibly small. Our experiments on public biometric datasets
demonstrate that the inference-based approach can achieve a search accuracy
close to the best performance possible with secure computation methods, but the
associated cost is reduced by orders of magnitude compared to cryptographic
primitives.
",Cybersecurity
"  We present a distributed control strategy for a team of quadrotors to
autonomously achieve a desired 3D formation. Our approach is based on local
relative position measurements and does not require global position information
or inter-vehicle communication. We assume that quadrotors have a common sense
of direction, which is chosen as the direction of gravitational force measured
by their onboard IMU sensors. However, this assumption is not crucial, and our
approach is robust to inaccuracies and effects of acceleration on gravitational
measurements. In particular, converge to the desired formation is unaffected if
each quadrotor has a velocity vector that projects positively onto the desired
velocity vector provided by the formation control strategy. We demonstrate the
validity of proposed approach in an experimental setup and show that a team of
quadrotors achieve a desired 3D formation.
",Cybersecurity
"  Today, in digital forensics, images normally provide important information
within an investigation. However, not all images may still be available within
a forensic digital investigation as they were all deleted for example. Data
carving can be used in this case to retrieve deleted images but the carving
time is normally significant and these images can be moreover overwritten by
other data. One of the solutions is to look at thumbnails of images that are no
longer available. These thumbnails can often be found within databases created
by either operating systems or image viewers. In literature, most research and
practical focus on the extraction of thumbnails from databases created by the
operating system. There is a little research working on the thumbnails created
by the image reviewers as these thumbnails are application-driven in terms of
pre-defined sizes, adjustments and storage location. Eventually, thumbnail
databases from image viewers are significant forensic artefacts for
investigators as these programs deal with large amounts of images. However,
investigating these databases so far is still manual or semi-automatic task
that leads to the huge amount of forensic time. Therefore, in this paper we
propose a new approach of automating extraction of thumbnails produced by image
viewers. We also test our approach with popular image viewers in different
storage structures and locations to show its robustness.
",Cybersecurity
"  Computer vision has made remarkable progress in recent years. Deep neural
network (DNN) models optimized to identify objects in images exhibit
unprecedented task-trained accuracy and, remarkably, some generalization
ability: new visual problems can now be solved more easily based on previous
learning. Biological vision (learned in life and through evolution) is also
accurate and general-purpose. Is it possible that these different learning
regimes converge to similar problem-dependent optimal computations? We
therefore asked whether the human system-level computation of visual perception
has DNN correlates and considered several anecdotal test cases. We found that
perceptual sensitivity to image changes has DNN mid-computation correlates,
while sensitivity to segmentation, crowding and shape has DNN end-computation
correlates. Our results quantify the applicability of using DNN computation to
estimate perceptual loss, and are consistent with the fascinating theoretical
view that properties of human perception are a consequence of
architecture-independent visual learning.
",Cybersecurity
"  In multi-object tracking applications, model parameter tuning is a
prerequisite for reliable performance. In particular, it is difficult to know
statistics of false measurements due to various sensing conditions and changes
in the field of views. In this paper we are interested in designing a
multi-object tracking algorithm that handles unknown false measurement rate.
Recently proposed robust multi-Bernoulli filter is employed for clutter
estimation while generalized labeled multi-Bernoulli filter is considered for
target tracking. Performance evaluation with real videos demonstrates the
effectiveness of the tracking algorithm for real-world scenarios.
",Cybersecurity
"  Haptic feedback is essential to acquire immersive experience when interacting
in virtual or augmented reality. Although the existing promising magnetic
levitation (maglev) haptic system has advantages of none mechanical friction,
its performance is limited by its navigation method, which mainly results from
the challenge that it is difficult to obtain high precision, high frame rate
and good stability with lightweight design at the same. In this study, we
propose to perform the visual-inertial fusion navigation based on
sequence-to-sequence learning for the maglev haptic interaction. Cascade LSTM
based-increment learning method is first presented to progressively learn the
increments of the target variables. Then, two cascade LSTM networks are
separately trained for accomplishing the visual-inertial fusion navigation in a
loosely-coupled mode. Additionally, we set up a maglev haptic platform as the
system testbed. Experimental results show that the proposed cascade LSTM
based-increment learning method can achieve high-precision prediction, and our
cascade LSTM based visual-inertial fusion navigation method can reach 200Hz
while maintaining high-precision (the mean absolute error of the position and
orientation is respectively less than 1mm and 0.02°)navigation for the
maglev haptic interaction application.
",Cybersecurity
"  We propose a source/channel duality in the exponential regime, where
success/failure in source coding parallels error/correctness in channel coding,
and a distortion constraint becomes a log-likelihood ratio (LLR) threshold. We
establish this duality by first deriving exact exponents for lossy coding of a
memoryless source P, at distortion D, for a general i.i.d. codebook
distribution Q, for both encoding success (R < R(P,Q,D)) and failure (R >
R(P,Q,D)). We then turn to maximum likelihood (ML) decoding over a memoryless
channel P with an i.i.d. input Q, and show that if we substitute P=QP, Q=Q, and
D=0 under the LLR distortion measure, then the exact exponents for
decoding-error (R < I(Q, P)) and strict correct-decoding (R > I(Q, P)) follow
as special cases of the exponents for source encoding success/failure,
respectively. Moreover, by letting the threshold D take general values, the
exact random-coding exponents for erasure (D > 0) and list decoding (D < 0)
under the simplified Forney decoder are obtained. Finally, we derive the exact
random-coding exponent for Forney's optimum tradeoff erasure/list decoder, and
show that at the erasure regime it coincides with Forney's lower bound and with
the simplified decoder exponent.
",Cybersecurity
"  The ability to accurately predict and simulate human driving behavior is
critical for the development of intelligent transportation systems. Traditional
modeling methods have employed simple parametric models and behavioral cloning.
This paper adopts a method for overcoming the problem of cascading errors
inherent in prior approaches, resulting in realistic behavior that is robust to
trajectory perturbations. We extend Generative Adversarial Imitation Learning
to the training of recurrent policies, and we demonstrate that our model
outperforms rule-based controllers and maximum likelihood models in realistic
highway simulations. Our model both reproduces emergent behavior of human
drivers, such as lane change rate, while maintaining realistic control over
long time horizons.
",Cybersecurity
"  We begin by summarizing the relevance and importance of inductive analytics
based on the geometry and topology of data and information. Contemporary issues
are then discussed. These include how sampling data for representativity is
increasingly to be questioned. While we can always avail of analytics from a
""bag of tools and techniques"", in the application of machine learning and
predictive analytics, nonetheless we present the case for Bourdieu and
Benzécri-based science of data, as follows. This is to construct bridges
between data sources and position-taking, and decision-making. There is summary
presentation of a few case studies, illustrating and exemplifying application
domains.
",Cybersecurity
"  Drone delivery has been a hot topic in the industry in the past few years.
However, existing approaches either focus on rural areas or rely on centralized
drop-off locations from where the last mile delivery is performed. In this
paper we tackle the problem of autonomous last mile delivery in urban
environments using an off-the-shelf drone. We build a prototype system that is
able to fly to the approximate delivery location using GPS and then find the
exact drop-off location using visual navigation. The drop-off location could,
e.g., be on a balcony or porch, and simply needs to be indicated by a visual
marker on the wall or window. We test our system components in simulated
environments, including the visual navigation and collision avoidance. Finally,
we deploy our drone in a real-world environment and show how it can find the
drop-off point on a balcony. To stimulate future research in this topic we open
source our code.
",Cybersecurity
"  We introduce an algorithm for word-level text spotting that is able to
accurately and reliably determine the bounding regions of individual words of
text ""in the wild"". Our system is formed by the cascade of two convolutional
neural networks. The first network is fully convolutional and is in charge of
detecting areas containing text. This results in a very reliable but possibly
inaccurate segmentation of the input image. The second network (inspired by the
popular YOLO architecture) analyzes each segment produced in the first stage,
and predicts oriented rectangular regions containing individual words. No
post-processing (e.g. text line grouping) is necessary. With execution time of
450 ms for a 1000-by-560 image on a Titan X GPU, our system achieves the
highest score to date among published algorithms on the ICDAR 2015 Incidental
Scene Text dataset benchmark.
",Cybersecurity
